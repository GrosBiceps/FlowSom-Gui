{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563bddce",
   "metadata": {},
   "source": [
    "# FlowSOM Analysis Pipeline - Notebook Headless\n",
    "\n",
    "## Pipeline compl√®te d'analyse FlowSOM pour donn√©es de cytom√©trie en flux\n",
    "\n",
    "Ce notebook \"miroir\" de l'application FlowSOM Analyzer permet:\n",
    "- **Debug & Introspection**: Visualiser les donn√©es √† chaque √©tape\n",
    "- **Tuning rapide**: Tester diff√©rents param√®tres sans relancer l'app\n",
    "- **S√©paration des responsabilit√©s**: Logique m√©tier pure, sans UI\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Florian Magne\n",
    "**Version**: 1.0\n",
    "**Date**: Janvier 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4bea0",
   "metadata": {},
   "source": [
    "## 1. Import des Librairies\n",
    "\n",
    "Import de toutes les librairies n√©cessaires avec v√©rification de disponibilit√© des d√©pendances optionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# IMPORTS d√©but du fichier\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports scientifiques de base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# CONFIGURATION PANDAS: Affichage en format lin√©aire (jamais exponentiel)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')  # 4 d√©cimales max\n",
    "pd.set_option('display.max_columns', None)  # Afficher toutes les colonnes\n",
    "pd.set_option('display.width', None)  # Largeur auto\n",
    "pd.set_option('display.max_rows', 100)  # Max 100 lignes affich√©es\n",
    "np.set_printoptions(suppress=True, precision=4)  # Numpy aussi en lin√©aire\n",
    "print(\"[OK] Pandas configur√©: affichage lin√©aire (pas de notation scientifique)\")\n",
    "\n",
    "# Imports visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['axes.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['text.color'] = \"#000000\"\n",
    "plt.rcParams['axes.labelcolor'] = \"#000000\"\n",
    "plt.rcParams['xtick.color'] = \"#000000\"\n",
    "plt.rcParams['ytick.color'] = \"#000000\"\n",
    "plt.rcParams['axes.edgecolor'] = \"#000000\"\n",
    "plt.rcParams['grid.color'] = \"#cccccc\"\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Plotly pour visualisations interactives\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    # Configuration pour affichage dans les notebooks\n",
    "    pio.renderers.default = 'notebook'\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"[OK] Plotly disponible\")\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non install√© (optionnel): pip install plotly\")\n",
    "\n",
    "# IMPORTS flowsom et anndata, l'un est le package d'analyse du FlowSOM, l'autre est pour g√©rer les donn√©es dans des objets AnnData\n",
    "try:\n",
    "    import flowsom as fs\n",
    "    import anndata as ad\n",
    "    FLOWSOM_AVAILABLE = True\n",
    "    print(\"[OK] FlowSOM disponible\")\n",
    "except ImportError:\n",
    "    FLOWSOM_AVAILABLE = False\n",
    "    print(\"[X] FlowSOM non install√©: pip install flowsom\")\n",
    "\n",
    "# Import de Scanpy pour UMAP/t-SNE\n",
    "try:\n",
    "    import scanpy as sc\n",
    "    SCANPY_AVAILABLE = True\n",
    "    print(\"[OK] Scanpy disponible\")\n",
    "except ImportError:\n",
    "    SCANPY_AVAILABLE = False\n",
    "    print(\"[!] Scanpy non install√© (optionnel): pip install scanpy\")\n",
    "\n",
    "# Import de UMAP\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"[OK] UMAP disponible\")\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"[!] UMAP non install√© (optionnel): pip install umap-learn\")\n",
    "\n",
    "\n",
    "# Import de t-SNE via sklearn car t-SNE trop lent √† √™tre impl√©ment√© dans Scanpy (et FlowSOM)\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"[OK] Scikit-learn disponible\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"[!] Scikit-learn non install√©: pip install scikit-learn\")\n",
    "\n",
    "# FlowKit pour transformations Logicle\n",
    "try:\n",
    "    import flowkit as fk\n",
    "    FLOWKIT_AVAILABLE = True\n",
    "    # Configuration FlowKit: format lin√©aire pour les exports/affichages\n",
    "    # FlowKit utilise pandas en interne, donc pd.set_option s'applique\n",
    "    # Mais on configure aussi les options de logging/affichage si disponibles\n",
    "    try:\n",
    "        import logging\n",
    "        logging.getLogger('flowkit').setLevel(logging.WARNING)  # Moins de logs verbose\n",
    "    except:\n",
    "        pass\n",
    "    print(\"[OK] FlowKit disponible (transformations Logicle pr√©cise en 1 fonction)\")\n",
    "except ImportError:\n",
    "    FLOWKIT_AVAILABLE = False\n",
    "    print(\"[!] FlowKit non install√© (optionnel): pip install flowkit)\")\n",
    "\n",
    "# FCSWrite pour export FCS\n",
    "try:\n",
    "    import fcswrite\n",
    "    FCSWRITE_AVAILABLE = True\n",
    "    print(\"[OK] FCSWrite disponible (export FCS)\")\n",
    "except ImportError:\n",
    "    FCSWRITE_AVAILABLE = False\n",
    "    print(\"[!] FCSWrite non install√© (optionnel): pip install fcswrite\")\n",
    "\n",
    "# Scipy pour statistiques \n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import en haut de fichier des classes utilitaires permettant les transformations des fichiers ainsi que le pre-gating \n",
    "\n",
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    Transformations de donn√©es de cytom√©trie (Logicle, Arcsinh, etc.).\n",
    "    Classe statique r√©utilisable sans d√©pendance √† l'UI.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_transform(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Arcsinh (inverse hyperbolic sine).\n",
    "        \n",
    "        Args en entr√©e:\n",
    "            data: Matrice de donn√©es (n_cells, n_markers)\n",
    "            cofactor: Facteur de division (5 pour flow cytometry)\n",
    "        \n",
    "        Returns:\n",
    "            Donn√©es transform√©es\n",
    "        \"\"\"\n",
    "        return np.arcsinh(data / cofactor)\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_inverse(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"Inverse de la transformation Arcsinh.\"\"\"\n",
    "        return np.sinh(data) * cofactor\n",
    "    \n",
    "    @staticmethod\n",
    "    def logicle_transform(data: np.ndarray, T: float = 262144.0, M: float = 4.5,\n",
    "                          W: float = 0.5, A: float = 0.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Logicle (biexponentielle).\n",
    "        \n",
    "        Args en entr√©e:\n",
    "            data: Matrice de donn√©es\n",
    "            T: Maximum de l'√©chelle lin√©aire (262144 = 2^18)\n",
    "            M: D√©cades de largeur\n",
    "            W: Lin√©arisation pr√®s de z√©ro\n",
    "            A: D√©cades additionnelles (n√©gatifs)\n",
    "        \n",
    "        Returns:\n",
    "            Donn√©es transform√©es\n",
    "        \"\"\"\n",
    "        if FLOWKIT_AVAILABLE:\n",
    "            # Utiliser FlowKit si disponible (plus pr√©cis) avec une fonction pr√©d√©finie\n",
    "            try:\n",
    "                xform = fk.transforms.LogicleTransform(T=T, M=M, W=W, A=A)\n",
    "                return xform.apply(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Approximation si FlowKit absent: Arcsinh modifi√©\n",
    "        w_val = W * np.log10(np.e)\n",
    "        return np.arcsinh(data / (T / (10 ** M))) * (M / np.log(10))\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_transform(data: np.ndarray, base: float = 10.0,\n",
    "                      min_val: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"Transformation logarithmique standard.\"\"\"\n",
    "        data_clipped = np.maximum(data, min_val)\n",
    "        return np.log(data_clipped) / np.log(base)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zscore_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Z-score (moyenne=0, std=1).\"\"\"\n",
    "        mean = np.nanmean(data, axis=0)\n",
    "        std = np.nanstd(data, axis=0)\n",
    "        std[std == 0] = 1  # √âviter division par z√©ro\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def min_max_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Min-Max [0, 1].\"\"\"\n",
    "        min_val = np.nanmin(data, axis=0)\n",
    "        max_val = np.nanmax(data, axis=0)\n",
    "        range_val = max_val - min_val\n",
    "        range_val[range_val == 0] = 1\n",
    "        return (data - min_val) / range_val\n",
    "\n",
    "\n",
    "class PreGating:\n",
    "    \"\"\"\n",
    "    Pre-gating automatique pour la s√©lection des populations d'int√©r√™t.\n",
    "    Bas√© sur FSC/SSC pour exclure les d√©bris et les doublets.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_marker_index(var_names: List[str], patterns: List[str]) -> Optional[int]:\n",
    "        \"\"\"Trouve l'index d'un marqueur parmi les patterns donn√©s.\"\"\"\n",
    "        var_upper = [v.upper() for v in var_names]\n",
    "        for pattern in patterns:\n",
    "            for i, name in enumerate(var_upper):\n",
    "                if pattern.upper() in name:\n",
    "                    return i\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_viable_cells(X: np.ndarray, var_names: List[str],\n",
    "                          min_percentile: float = 2.0, \n",
    "                          max_percentile: float = 98.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules viables bas√© sur FSC/SSC.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donn√©es (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            min_percentile: Percentile minimum (exclusion d√©bris)\n",
    "            max_percentile: Percentile maximum (exclusion doublets)\n",
    "        \n",
    "        Returns:\n",
    "            Masque bool√©en des cellules viables\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        mask = np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Trouver FSC (priorit√© √† FSC-A)\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A', 'FSC-H', 'FSC'])\n",
    "        if fsc_idx is not None:\n",
    "            fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "            fsc_vals = np.where(np.isfinite(fsc_vals), fsc_vals, np.nan)\n",
    "            low = np.nanpercentile(fsc_vals, min_percentile)\n",
    "            high = np.nanpercentile(fsc_vals, max_percentile)\n",
    "            mask &= np.isfinite(fsc_vals) & (fsc_vals >= low) & (fsc_vals <= high)\n",
    "        \n",
    "        # Trouver SSC (priorit√© √† SSC-A)\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "        if ssc_idx is not None:\n",
    "            ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "            ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "            low = np.nanpercentile(ssc_vals, min_percentile)\n",
    "            high = np.nanpercentile(ssc_vals, max_percentile)\n",
    "            mask &= np.isfinite(ssc_vals) & (ssc_vals >= low) & (ssc_vals <= high)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_singlets(X: np.ndarray, var_names: List[str],\n",
    "                      ratio_min: float = 0.6, ratio_max: float = 1.5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les singlets bas√© sur le ratio FSC-A/FSC-H.\n",
    "        Les doublets ont typiquement un ratio > 1.3-1.5.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donn√©es\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            ratio_min: Ratio minimum acceptable\n",
    "            ratio_max: Ratio maximum acceptable\n",
    "        \n",
    "        Returns:\n",
    "            Masque bool√©en des singlets\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouv√©, pas de gating singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # Valeurs minimum pour √©viter division par z√©ro\n",
    "        min_val = 100\n",
    "        valid_h = fsc_h > min_val\n",
    "        \n",
    "        ratio = np.full(n_cells, np.nan)\n",
    "        ratio[valid_h] = fsc_a[valid_h] / fsc_h[valid_h]\n",
    "        \n",
    "        mask = np.isfinite(ratio) & (ratio >= ratio_min) & (ratio <= ratio_max)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd45_positive(X: np.ndarray, var_names: List[str],\n",
    "                           threshold_percentile: float = 10) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules CD45+ (leucocytes).\n",
    "        \n",
    "        Returns:\n",
    "            Masque bool√©en des cellules CD45+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouv√©, pas de gating CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45_vals = X[:, cd45_idx].astype(np.float64)\n",
    "        cd45_vals = np.where(np.isfinite(cd45_vals), cd45_vals, np.nan)\n",
    "        \n",
    "        threshold = np.nanpercentile(cd45_vals, threshold_percentile)\n",
    "        \n",
    "        return np.where(np.isnan(cd45_vals), False, cd45_vals > threshold)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd34_blasts(X: np.ndarray, var_names: List[str],\n",
    "                         threshold_percentile: float = 85,\n",
    "                         use_ssc_filter: bool = True,\n",
    "                         ssc_max_percentile: float = 70) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les blastes CD34+ (cellules souches/prog√©nitrices).\n",
    "        \n",
    "        Les blastes sont typiquement:\n",
    "        - CD34 bright (haute expression)\n",
    "        - SSC low (faible granularit√©)\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donn√©es (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            threshold_percentile: Percentile pour d√©finir le seuil CD34+ (ex: 85 = top 15%)\n",
    "            use_ssc_filter: Appliquer aussi un filtre SSC pour enrichir en blastes\n",
    "            ssc_max_percentile: Percentile max de SSC pour blastes (faible granularit√©)\n",
    "        \n",
    "        Returns:\n",
    "            Masque bool√©en des blastes CD34+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        # Chercher CD34 avec diff√©rents nommages possibles\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouv√©, pas de gating blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34_vals = X[:, cd34_idx].astype(np.float64)\n",
    "        cd34_vals = np.where(np.isfinite(cd34_vals), cd34_vals, np.nan)\n",
    "        \n",
    "        # Seuil CD34+ (prendre les cellules avec haute expression)\n",
    "        threshold_cd34 = np.nanpercentile(cd34_vals, threshold_percentile)\n",
    "        mask_cd34 = np.where(np.isnan(cd34_vals), False, cd34_vals >= threshold_cd34)\n",
    "        \n",
    "        # Optionnel: filtrer aussi par SSC low (blastes = faible granularit√©)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "                ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "                threshold_ssc = np.nanpercentile(ssc_vals, ssc_max_percentile)\n",
    "                mask_ssc = np.where(np.isnan(ssc_vals), False, ssc_vals <= threshold_ssc)\n",
    "                return mask_cd34 & mask_ssc\n",
    "        \n",
    "        return mask_cd34\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_debris_polygon(X: np.ndarray, var_names: List[str],\n",
    "                            fsc_min: float = None, fsc_max: float = None,\n",
    "                            ssc_min: float = None, ssc_max: float = None,\n",
    "                            auto_percentiles: bool = True,\n",
    "                            min_pct: float = 1.0, max_pct: float = 99.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate rectangulaire/polygonal pour exclure les d√©bris sur FSC-A vs SSC-A.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donn√©es\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            fsc_min/fsc_max: Seuils FSC manuels (si auto_percentiles=False)\n",
    "            ssc_min/ssc_max: Seuils SSC manuels (si auto_percentiles=False)\n",
    "            auto_percentiles: Calculer automatiquement les seuils via percentiles\n",
    "            min_pct/max_pct: Percentiles pour auto-calcul\n",
    "        \n",
    "        Returns:\n",
    "            Masque bool√©en des cellules (non-d√©bris)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouv√© pour gate d√©bris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Calculer les seuils automatiquement si demand√©\n",
    "        if auto_percentiles:\n",
    "            fsc_min = np.nanpercentile(fsc_vals, min_pct)\n",
    "            fsc_max = np.nanpercentile(fsc_vals, max_pct)\n",
    "            ssc_min = np.nanpercentile(ssc_vals, min_pct)\n",
    "            ssc_max = np.nanpercentile(ssc_vals, max_pct)\n",
    "        \n",
    "        # Appliquer le gate rectangulaire\n",
    "        mask = (\n",
    "            np.isfinite(fsc_vals) & np.isfinite(ssc_vals) &\n",
    "            (fsc_vals >= fsc_min) & (fsc_vals <= fsc_max) &\n",
    "            (ssc_vals >= ssc_min) & (ssc_vals <= ssc_max)\n",
    "        )\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "print(\"[OK] Classes DataTransformer et PreGating charg√©es!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f742d5",
   "metadata": {},
   "source": [
    "## 2. Chargement des Fichiers FCS\n",
    "\n",
    "Chargement des fichiers FCS depuis les dossiers sp√©cifi√©s. \n",
    "- **Sain (NBM)**: Moelle osseuse normale (r√©f√©rence)\n",
    "- **Pathologique**: √âchantillons patients √† analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DES CHEMINS\n",
    "# Bien modifier ces chemins selon votre environnement actuel pour le bon chargement des donn√©es\n",
    "\n",
    "# Dossier des fichiers sains (r√©f√©rence NBM)\n",
    "HEALTHY_FOLDER = Path(r\"Data/Sain\")\n",
    "\n",
    "# Dossier des fichiers pathologiques (patients)\n",
    "PATHOLOGICAL_FOLDER = Path(r\"Data/Patho\")\n",
    "\n",
    "# Mode d'analyse: \n",
    "# - True: Comparer Sain vs Pathologique\n",
    "# - False: Analyser uniquement les fichiers pathologiques\n",
    "COMPARE_MODE = True\n",
    "\n",
    "print(f\"Dossier Sain: {HEALTHY_FOLDER}\")\n",
    "print(f\"Dossier Pathologique: {PATHOLOGICAL_FOLDER}\")\n",
    "print(f\"Mode comparaison: {'Activ√©' if COMPARE_MODE else 'Patient seul'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTIONS DE CHARGEMENT FCS\n",
    "\n",
    "def get_fcs_files(folder: Path) -> List[str]:\n",
    "    \"\"\"R√©cup√®re la liste des fichiers FCS dans un dossier. Et renvoie une chaine de caract√®re\"\"\"\n",
    "    if not folder.exists():\n",
    "        print(f\"[!] Dossier non trouv√©: {folder}\")\n",
    "        return []\n",
    "    \n",
    "    files = set()\n",
    "    for f in folder.glob(\"*.fcs\"):\n",
    "        files.add(str(f))\n",
    "    for f in folder.glob(\"*.FCS\"):\n",
    "        files.add(str(f))\n",
    "    \n",
    "    return sorted(list(files))\n",
    "\n",
    "\n",
    "def load_fcs_files(files: List[str], condition: str = \"Unknown\") -> List[ad.AnnData]:\n",
    "    \"\"\"\n",
    "    Charge plusieurs fichiers FCS et retourne une liste d'AnnData.\n",
    "    \n",
    "    Args:\n",
    "        files: Liste des chemins de fichiers FCS\n",
    "        condition: Label de condition (\"Sain\" ou \"Pathologique\")\n",
    "    \n",
    "    Returns:\n",
    "        Liste d'objets AnnData\n",
    "    \"\"\"\n",
    "    # La ligne suivante cr√©e la liste vide pour stocker les AnnData puis boucle sur chaque fichier (√©viter le plantage complet)\n",
    "    adatas = []\n",
    "    \n",
    "    for fpath in files:\n",
    "        try:\n",
    "            print(f\"    Chargement: {Path(fpath).name}...\", end=\" \")\n",
    "            \n",
    "            # Lecture avec la fonction de base de flowsom\n",
    "            adata = fs.io.read_FCS(fpath)\n",
    "            \n",
    "            # Ajouter les m√©tadonn√©es avec un nombre de cellules qui sera √©gale a la forme de l'objet adata \n",
    "            n_cells = adata.shape[0]\n",
    "            adata.obs['condition'] = condition # Rajoute la condition du fichier : \"Sain\" ou \"Pathologique\"\n",
    "            adata.obs['file_origin'] = Path(fpath).name # Rajoute une observation avec Nom du fichier source (obs = One-dimensional annotation of observations)\n",
    "            \n",
    "            adatas.append(adata) # Ajoute √† la liste des AnnData\n",
    "            print(f\"{n_cells:,} cellules\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur: {e}\")\n",
    "    \n",
    "    return adatas\n",
    "\n",
    "# Logs sur le cahrgement des fichiers\n",
    "print(\"=\"*60)\n",
    "print(\"CHARGEMENT DES FICHIERS FCS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fichiers sains en fonction du mode d√©fini\n",
    "healthy_files = get_fcs_files(HEALTHY_FOLDER) if COMPARE_MODE else []\n",
    "print(f\"\\nFichiers Sains (NBM): {len(healthy_files)}\")\n",
    "\n",
    "healthy_adatas = []\n",
    "if healthy_files:\n",
    "    healthy_adatas = load_fcs_files(healthy_files, condition=\"Sain\")\n",
    "\n",
    "# Fichiers sains en fonction du mode d√©fini\n",
    "patho_files = get_fcs_files(PATHOLOGICAL_FOLDER)\n",
    "print(f\"\\nFichiers Pathologiques: {len(patho_files)}\")\n",
    "\n",
    "patho_adatas = []\n",
    "if patho_files:\n",
    "    patho_adatas = load_fcs_files(patho_files, condition=\"Pathologique\")\n",
    "\n",
    "# R√©sum√©\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"R√âSUM√â DU CHARGEMENT\")\n",
    "print(f\"   Fichiers Sains charg√©s: {len(healthy_adatas)}\")\n",
    "print(f\"   Fichiers Pathologiques charg√©s: {len(patho_adatas)}\")\n",
    "# R√©sum√© a.shape = pour chaque AnnData, prend le nombre de cellules (lignes) et concat√®ne si n√©cessaire\n",
    "total_cells = sum([a.shape[0] for a in healthy_adatas + patho_adatas])\n",
    "print(f\"   Total cellules: {total_cells:,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495d578",
   "metadata": {},
   "source": [
    "## 3. Exploration de la Structure des Donn√©es Brutes\n",
    "\n",
    "Avant toute transformation, examinons la structure des donn√©es:\n",
    "- Dimensions (cellules x marqueurs)\n",
    "- Noms des colonnes (marqueurs)\n",
    "- Types de donn√©es et plages de valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de539adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCAT√âNATION DES DONN√âES\n",
    "\n",
    "# Combiner tous les AnnData d√©fini dans la cellule pr√©c√©dente\n",
    "all_adatas = healthy_adatas + patho_adatas\n",
    "\n",
    "# V√©rification\n",
    "if len(all_adatas) == 0:\n",
    "    raise ValueError(\"[X] Aucun fichier FCS charg√©! V√©rifiez les chemins.\")\n",
    "\n",
    "# Concat√©ner avec intersection des colonnes (communes √† tous les fichiers) ligne par ligne\n",
    "if len(all_adatas) > 1:\n",
    "    combined_data = ad.concat(all_adatas, join='inner') # join='inner' pour ne garder que les marqueurs communs √† changer par outer si on veut garder tous les marqueurs\n",
    "else:\n",
    "    combined_data = all_adatas[0].copy() # Si un seul fichier, juste copier pour √©viter de mofifier l'original\n",
    "\n",
    "print(f\"Donn√©es combin√©es: {combined_data.shape}\")\n",
    "print(f\"   ‚Üí {combined_data.shape[0]:,} cellules\")\n",
    "print(f\"   ‚Üí {combined_data.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATION DE LA STRUCTURE\n",
    "print(\"=\"*70)\n",
    "print(\"STRUCTURE DES DONN√âES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Liste des marqueurs enregistr√© dans la varaible var_names = canaux (ici c'est bien un nom de variable)\n",
    "var_names = list(combined_data.var_names)\n",
    "print(f\"\\nMarqueurs ({len(var_names)}):\")\n",
    "for i, name in enumerate(var_names):\n",
    "    print(f\"   [{i:2d}] {name}\")\n",
    "\n",
    "# Identification des types de marqueurs car les recos indiquent d'enelever le scatter pour les analyses de clustering\n",
    "print(\"\\nClassification des marqueurs:\")\n",
    "\n",
    "#Ici le code n for n in var pose la question : \"Est-ce qu'au moins UN des motifs de la liste scatter_patterns se trouve dans le nom actuel n ?\"\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "scatter_markers = [n for n in var_names if any(p in n.upper() for p in scatter_patterns)]\n",
    "fluor_markers = [n for n in var_names if n not in scatter_markers]\n",
    "\n",
    "print(f\"   Scatter/Time: {scatter_markers}\")\n",
    "print(f\"   Fluorescence: {fluor_markers}\")\n",
    "\n",
    "# Statistiques de base\n",
    "print(\"\\nObservations (m√©tadonn√©es):\")\n",
    "print(combined_data.obs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION EN DATAFRAME POUR EXPLORATION\n",
    "HEADER = True\n",
    "# Extraire la matrice de donn√©es\n",
    "X = combined_data.X # Matrice des donn√©es (n_cells, n_markers)\n",
    "if hasattr(X, 'toarray'): # Si sparse matrix, convertir en dense pour pandas\n",
    "    X = X.toarray()\n",
    "\n",
    "# Cr√©er un DataFrame pandas pour faciliter l'exploration avec df comme commande pandas classique\n",
    "df_raw = pd.DataFrame(X, columns=var_names) # Cr√©e le DataFrame avec les noms de colonnes \n",
    "df_raw['condition'] = combined_data.obs['condition'].values # Ajoute une colonne condition\n",
    "df_raw['file_origin'] = combined_data.obs['file_origin'].values # Ajoute une colonne file_origin\n",
    "\n",
    "print(\"DataFrame cr√©√© pour exploration\")\n",
    "print(f\"   Shape: {df_raw.shape}\")\n",
    "print(\"\\nAper√ßu des donn√©es brutes:\")\n",
    "df_raw.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats descriptives marqueurs de fluorescence et scatter\n",
    "print(\"Statistiques descriptives fluorescence\")\n",
    "display(df_raw[fluor_markers].describe())\n",
    "\n",
    "print(\"\\nStatistiques descriptives scatter\")\n",
    "display(df_raw[scatter_markers].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125cfaf",
   "metadata": {},
   "source": [
    "## 4. Contr√¥le Qualit√© des donn√©es- Analyse des Distributions\n",
    "\n",
    "Visualisation des distributions brutes pour identifier:\n",
    "- Outliers et valeurs aberrantes\n",
    "- Valeurs n√©gatives (probl√®me de compensation)\n",
    "- NaN/Inf dans les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rif des varaibles probl√©matiques suite de l'exploration du dataset\n",
    "\n",
    "print(\"ANALYSE DES DONN√âES BRUTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========== MARQUEURS DE FLUORESCENCE ==========\n",
    "print(\"\\nMARQUEURS DE FLUORESCENCE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# V√©rifier NaN\n",
    "nan_count = df_raw[fluor_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN d√©tect√©!\")\n",
    "\n",
    "# V√©rifier Inf (valeur infinie) ex sur un post log \n",
    "inf_count = np.isinf(df_raw[fluor_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf d√©tect√©!\")\n",
    "else:\n",
    "    for marker, count in inf_count.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# V√©rifier valeurs n√©gatives\n",
    "neg_count = (df_raw[fluor_markers] < 0).sum()\n",
    "print(f\"\\n‚ûñ Valeurs n√©gatives par marqueur:\")\n",
    "has_negatives = False\n",
    "for marker, count in neg_count.items():\n",
    "    if count > 0:\n",
    "        has_negatives = True\n",
    "        # Compter le nombre total de cellules valides (non-NaN) pour ce marqueur\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives:\n",
    "    print(\"   [OK] Aucune valeur n√©gative!\")\n",
    "else:\n",
    "    print(\"\\n   [!] Les valeurs n√©gatives peuvent indiquer un probl√®me de compensation\")\n",
    "    print(\"   ‚Üí La transformation Arcsinh ou Logicle peut les g√©rer\")\n",
    "\n",
    "# ========== MARQUEURS SCATTER/TIME ==========\n",
    "print(\"\\n\\nMARQUEURS SCATTER/TIME\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# V√©rifier NaN\n",
    "nan_count_scatter = df_raw[scatter_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count_scatter.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN d√©tect√©!\")\n",
    "\n",
    "# V√©rifier Inf\n",
    "inf_count_scatter = np.isinf(df_raw[scatter_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf d√©tect√©!\")\n",
    "else:\n",
    "    for marker, count in inf_count_scatter.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# V√©rifier valeurs n√©gatives\n",
    "neg_count_scatter = (df_raw[scatter_markers] < 0).sum()\n",
    "print(f\"\\n‚ûñ Valeurs n√©gatives par marqueur:\")\n",
    "has_negatives_scatter = False\n",
    "for marker, count in neg_count_scatter.items():\n",
    "    if count > 0:\n",
    "        has_negatives_scatter = True\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives_scatter:\n",
    "    print(\"   [OK] Aucune valeur n√©gative!\")\n",
    "else:\n",
    "    print(\"\\n   ‚ÑπÔ∏è Les valeurs n√©gatives dans scatter sont rares mais possibles\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des distributions brutes pour explorer visuellement les donn√©es\n",
    "\n",
    "# S√©lectionner les marqueurs √† visualiser (max 12 pour lisibilit√©)\n",
    "markers_to_plot = fluor_markers[:12] if len(fluor_markers) > 12 else fluor_markers  # Op√©rateur ternaire: prendre 12 premiers si > 12, sinon tous\n",
    "\n",
    "n_markers = len(markers_to_plot)  # Nombre de marqueurs √† afficher\n",
    "n_cols = 4  # 4 colonnes par ligne\n",
    "n_rows = (n_markers + n_cols - 1) // n_cols  # Calcul nb lignes (division enti√®re arrondie vers le haut)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))  # Cr√©er grille n_rows √ó n_cols (largeur 20, hauteur 5 par ligne)\n",
    "axes = axes.flatten() if n_markers > 1 else [axes]  # Aplatir tableau 2D en liste 1D pour it√©ration facile\n",
    "\n",
    "for i, marker in enumerate(markers_to_plot):  # Boucle sur chaque marqueur avec index i\n",
    "    ax = axes[i]  # R√©cup√©rer le sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Extraire donn√©es du marqueur et supprimer NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#89b4fa', alpha=0.7, edgecolor='none')  # Histogramme 100 barres, bleu, 70% opacit√©\n",
    "    ax.set_title(marker, fontsize=11, fontweight='bold')  # Titre = nom du marqueur\n",
    "    ax.set_xlabel('Valeur brute')  # Label axe X\n",
    "    ax.set_ylabel('Count')  # Label axe Y = nombre de cellules\n",
    "    ax.axvline(0, color='#f38ba8', linestyle='--', alpha=0.5, label='Z√©ro')  # Ligne verticale rouge √† x=0\n",
    "    \n",
    "    # Statistiques min/max dans une bo√Æte en haut √† droite\n",
    "    ax.text(0.98, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}',  # Texte avec stats\n",
    "            transform=ax.transAxes, ha='right', va='top', fontsize=8,  # Coordonn√©es relatives (0-1), alignement\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))  # Bo√Æte grise arrondie semi-transparente\n",
    "\n",
    "# Cacher les axes vides (si 10 marqueurs sur grille 3√ó4, cacher les 2 derni√®res cases)\n",
    "for i in range(n_markers, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Brutes des Marqueurs (avant transformation)',  # Titre g√©n√©ral\n",
    "             fontsize=14, fontweight='bold', y=1.02)  # D√©cal√© vers le haut\n",
    "plt.tight_layout()  # Ajuster espacement auto\n",
    "plt.show()  # Afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des marqueurs SCATTER/TIME pour exploration visuelle\n",
    "\n",
    "# S√©lectionner tous les marqueurs scatter (g√©n√©ralement peu nombreux)\n",
    "scatter_to_plot = scatter_markers  # FSC, SSC, TIME\n",
    "\n",
    "n_scatter = len(scatter_to_plot)  # Nombre de marqueurs scatter\n",
    "n_cols_scatter = min(3, n_scatter)  # Max 3 colonnes pour les scatter\n",
    "n_rows_scatter = (n_scatter + n_cols_scatter - 1) // n_cols_scatter  # Calcul nb lignes\n",
    "\n",
    "fig, axes = plt.subplots(n_rows_scatter, n_cols_scatter, figsize=(18, 6*n_rows_scatter))  # Grille pour scatter (largeur 18, hauteur 6 par ligne)\n",
    "axes = axes.flatten() if n_scatter > 1 else [axes]  # Aplatir en liste 1D\n",
    "\n",
    "for i, marker in enumerate(scatter_to_plot):  # Boucle sur chaque marqueur scatter\n",
    "    ax = axes[i]  # Sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Donn√©es sans NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#a6e3a1', alpha=0.7, edgecolor='none')  # Vert pour diff√©rencier\n",
    "    ax.set_title(marker, fontsize=12, fontweight='bold')  # Titre\n",
    "    ax.set_xlabel('Valeur brute')  # Axe X\n",
    "    ax.set_ylabel('Count')  # Axe Y\n",
    "    \n",
    "    # Statistiques compl√®tes\n",
    "    ax.text(0.02, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}\\nmean: {data.mean():.0f}\\nmedian: {data.median():.0f}',\n",
    "            transform=ax.transAxes, ha='left', va='top', fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))\n",
    "\n",
    "# Cacher axes vides\n",
    "for i in range(n_scatter, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Scatter/Time (FSC, SSC, TIME)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910ba5b",
   "metadata": {},
   "source": [
    "### Visualisation Interactive avec FlowKit + Bokeh\n",
    "\n",
    "Utilisation native de FlowKit pour visualisations interactives :\n",
    "- **Histogrammes** avec bins/ranges personnalisables\n",
    "- **Scatter plots** interactifs avec zoom/pan\n",
    "- **Contour plots** avec densit√©\n",
    "- Rendu Bokeh pour l'interactivit√© (zoom, pan, hover)\n",
    "\n",
    "üìö Documentation : https://flowkit.readthedocs.io/en/latest/index.html\n",
    "https://www.frontiersin.org/journals/immunology/articles/10.3389/fimmu.2021.768541/full\n",
    "\n",
    "---\n",
    "\n",
    "### [!] IMPORTANT : Nomenclature FCS\n",
    "\n",
    "**FlowKit utilise les PnN labels** (noms techniques), pas les PnS (descriptions).\n",
    "\n",
    "- **PnN** = Nom technique (ex: `'Horizon V500-A'`) ‚Üê √Ä utiliser\n",
    "- **PnS** = Description bio (ex: `'CD45 KO'`) ‚Üê Non utilisable\n",
    "\n",
    "**Exemple :** Pour CD45, utiliser `'Horizon V500-A'` (pas `'CD45 KO'`).\n",
    "\n",
    "Ex√©cutez la cellule suivante pour voir la correspondance PnN ‚Üî PnS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbddc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation FlowKit et Bokeh + Cr√©ation du Sample\n",
    "\n",
    "if not FLOWKIT_AVAILABLE:\n",
    "    fk_sample = None\n",
    "else:\n",
    "    try:\n",
    "        from bokeh.plotting import show, output_notebook\n",
    "        from bokeh.io import export_png\n",
    "        output_notebook()\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Utiliser les fichiers FCS d√©j√† identifi√©s dans le notebook\n",
    "    all_fcs_files = healthy_files + patho_files\n",
    "    \n",
    "    if all_fcs_files:\n",
    "        example_fcs = str(all_fcs_files[0])\n",
    "        fk_sample = fk.Sample(example_fcs)\n",
    "    else:\n",
    "        fk_sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHER LES NOMS DE CANAUX EXACTS DU FICHIER FCS\n",
    "\n",
    "if fk_sample is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"CANAUX DU FICHIER FCS: {Path(example_fcs).name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nPnN Labels ({len(fk_sample.pnn_labels)} canaux) - NOMS √Ä UTILISER DANS FLOWKIT:\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pnn_labels, 1):\n",
    "        print(f\"   [{i:2d}] '{label}'\")\n",
    "    \n",
    "    # Afficher aussi les PnS labels (descriptions) si disponibles\n",
    "    print(f\"\\n\\nPnS Labels (descriptions):\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pns_labels, 1):\n",
    "        print(f\"   [{i:2d}] {label}\")\n",
    "    \n",
    "else:\n",
    "    print(\"[!] FlowKit Sample non charg√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les colonnes FSC et SSC pour les visualisations ult√©rieures\n",
    "fsc_col = next((c for c in var_names if 'FSC-A' in c.upper() or 'FSC' in c.upper()), None)\n",
    "ssc_col = next((c for c in var_names if 'SSC-A' in c.upper() or 'SSC' in c.upper()), None)\n",
    "\n",
    "if fsc_col:\n",
    "    print(f\"[OK] FSC d√©tect√©: {fsc_col}\")\n",
    "if ssc_col:\n",
    "    print(f\"[OK] SSC d√©tect√©: {ssc_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae982a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme basique FlowKit (√©chelle lin√©aire)\n",
    "# source='raw' = donn√©es LIN√âAIRES (non transform√©es)\n",
    "# source='xform' = donn√©es transform√©es (Logicle)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    CHANNEL = 'Horizon V500-A'  # Changer ici le channel √† afficher\n",
    "    \n",
    "    # Histogramme en √©chelle LIN√âAIRE (source='raw')\n",
    "    p = fk_sample.plot_histogram(CHANNEL, source='raw', bins=256)\n",
    "    \n",
    "    # Forcer l'√©chelle lin√©aire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # D√©sactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Histogramme {CHANNEL} - √âchelle LIN√âAIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af808182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot 2D interactif (√©chelle lin√©aire)\n",
    "# source='raw' = donn√©es LIN√âAIRES (non transform√©es)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    x_channel = 'Horizon V500-A'\n",
    "    y_channel = 'PE-A'\n",
    "    \n",
    "    # Scatter en √©chelle LIN√âAIRE (source='raw')\n",
    "    p = fk_sample.plot_scatter(x_channel, y_channel, source='raw', color_density=True)\n",
    "    \n",
    "    # Forcer l'√©chelle lin√©aire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # D√©sactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Scatter {x_channel} vs {y_channel} - √âchelle LIN√âAIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme 1D interactif avec Plotly (zoom, pan, hover)\n",
    "# S√©lectionner un marqueur √† visualiser (modifiable)\n",
    "MARKER_TO_PLOT = 'CD45 KO'  # Changer ici le nom exact du marqueur √† visualiser\n",
    "\n",
    "print(f\"Visualisation: {MARKER_TO_PLOT}\")\n",
    "\n",
    "# Extraire les donn√©es\n",
    "marker_data = df_raw[MARKER_TO_PLOT].dropna().values\n",
    "\n",
    "# Importer plotly pour l'interactivit√©\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    \n",
    "    # Configurer le renderer pour Jupyter (√©vite l'erreur nbformat)\n",
    "    try:\n",
    "        pio.renderers.default = 'notebook'\n",
    "    except:\n",
    "        try:\n",
    "            pio.renderers.default = 'jupyterlab'\n",
    "        except:\n",
    "            pio.renderers.default = 'browser'\n",
    "    \n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non install√© - pip install plotly\")\n",
    "\n",
    "if PLOTLY_AVAILABLE:\n",
    "    # Cr√©er une figure avec 4 subplots (2x2)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            f'{MARKER_TO_PLOT} - Brut (Lin√©aire)',\n",
    "            f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)',\n",
    "            f'{MARKER_TO_PLOT} - Logicle/Arcsinh',\n",
    "            f'{MARKER_TO_PLOT} - Log10'\n",
    "        ),\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # 1. Donn√©es brutes\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_data, nbinsx=200, name='Brut',\n",
    "                     marker_color='#89b4fa', opacity=0.7,\n",
    "                     hovertemplate='Intensit√©: %{x:.1f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Arcsinh cofactor=5\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_arcsinh, nbinsx=200, name='Arcsinh (5)',\n",
    "                     marker_color='#a6e3a1', opacity=0.7,\n",
    "                     hovertemplate='Intensit√©: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Logicle ou Arcsinh cofactor=150\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        transform_name = 'Logicle'\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        transform_name = 'Arcsinh (150)'\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_logicle, nbinsx=200, name=transform_name,\n",
    "                     marker_color='#f9e2af', opacity=0.7,\n",
    "                     hovertemplate='Intensit√©: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Log10\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_log, nbinsx=200, name='Log10',\n",
    "                     marker_color='#cba6f7', opacity=0.7,\n",
    "                     hovertemplate='Intensit√©: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Mise en page\n",
    "    fig.update_xaxes(title_text=\"Intensit√© brute\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Intensit√© transform√©e\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Intensit√© transform√©e\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Intensit√© log10\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Fr√©quence\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Fr√©quence\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Fr√©quence\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Fr√©quence\", row=2, col=2)\n",
    "    \n",
    "    # Th√®me sombre et configuration\n",
    "    fig.update_layout(\n",
    "        title_text=f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)',\n",
    "        title_font_size=16,\n",
    "        height=900,\n",
    "        showlegend=False,\n",
    "        template='plotly_dark',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Afficher avec gestion d'erreur\n",
    "    try:\n",
    "        fig.show()\n",
    "        print(f\"\\n[OK] Visualisation interactive g√©n√©r√©e\")\n",
    "        print(f\"    Utilisez les outils Plotly: Zoom (box select), Pan, Reset, Download\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!] Erreur affichage Plotly: {e}\")\n",
    "        print(\"   ‚Üí Affichage en HTML dans le notebook...\")\n",
    "        \n",
    "        # Alternative: Afficher le HTML directement dans le notebook\n",
    "        try:\n",
    "            from IPython.display import HTML, display\n",
    "            html_str = fig.to_html(include_plotlyjs='cdn', include_mathjax='cdn')\n",
    "            display(HTML(html_str))\n",
    "            print(f\"   [OK] Graphique affich√© en HTML (pleinement interactif)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   [X] Erreur HTML: {e2}\")\n",
    "            # Dernier recours: sauvegarder en fichier\n",
    "            html_file = 'plotly_visualization.html'\n",
    "            fig.write_html(html_file)\n",
    "            print(f\"   ‚Üí Fichier sauvegard√©: {html_file}\")\n",
    "            print(f\"   ‚Üí Ouvrez ce fichier dans votre navigateur pour l'interactivit√© compl√®te\")\n",
    "    \n",
    "    print(f\"   Cellules: {len(marker_data):,}\")\n",
    "    print(f\"   Min brut: {marker_data.min():.2f} | Max brut: {marker_data.max():.2f}\")\n",
    "else:\n",
    "    # Fallback matplotlib si Plotly non disponible\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.hist(marker_data, bins=200, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Brut (Lin√©aire)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensit√© brute')\n",
    "    ax.set_ylabel('Fr√©quence')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    ax.hist(marker_arcsinh, bins=200, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensit√© transform√©e')\n",
    "    ax.set_ylabel('Fr√©quence')\n",
    "    \n",
    "    ax = axes[2]\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Logicle', fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=150)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensit√© transform√©e')\n",
    "    ax.set_ylabel('Fr√©quence')\n",
    "    \n",
    "    ax = axes[3]\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    ax.hist(marker_log, bins=200, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Log10', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensit√© transform√©e (log10)')\n",
    "    ax.set_ylabel('Fr√©quence')\n",
    "    \n",
    "    plt.suptitle(f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95bf80",
   "metadata": {},
   "source": [
    "## 5. Pre-Gating: √âlimination des D√©bris, Doublets et S√©lection des Blastes\n",
    "\n",
    "Application du pre-gating s√©quentiel en 3 √©tapes:\n",
    "\n",
    "1. **Gate 1 - D√©bris (SSC-A vs FSC-A)**: Exclusion des d√©bris et √©v√©nements hors-limites via gate rectangulaire bas√© sur percentiles\n",
    "2. **Gate 2 - Doublets (FSC-H vs FSC-A)**: Exclusion des agr√©gats cellulaires via ratio FSC-A/FSC-H (singlets line)\n",
    "3. **Gate 3 - Blastes CD34+ (optionnel)**: S√©lection des cellules souches/prog√©nitrices CD34 bright + SSC low\n",
    "\n",
    "### Strat√©gie de gating classique en cytom√©trie:\n",
    "```\n",
    "√âv√©nements totaux\n",
    "    ‚îî‚îÄ‚îÄ Gate D√©bris (SSC-A vs FSC-A) ‚Üí Cellules viables\n",
    "            ‚îî‚îÄ‚îÄ Gate Singlets (FSC-H vs FSC-A) ‚Üí Cellules individuelles\n",
    "                    ‚îî‚îÄ‚îÄ Gate CD34+ (CD34 vs SSC-A) ‚Üí Blastes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ba663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLICATION DU PRE-GATING S√âQUENTIEL (3 √âTAPES)\n",
    "# =============================================================================\n",
    "# Strat√©gie classique de cytom√©trie:\n",
    "# 1. SSC-A vs FSC-A ‚Üí Exclure d√©bris\n",
    "# 2. FSC-H vs FSC-A ‚Üí Exclure doublets (singlets line)\n",
    "# 3. CD34 vs SSC-A ‚Üí S√©lectionner blastes (optionnel)\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== OPTIONS DE PRE-GATING =====================\n",
    "APPLY_PREGATING = True  # Activer/d√©sactiver le pre-gating complet\n",
    "\n",
    "# =================================================================\n",
    "# MODE SP√âCIAL: BLASTES CD34+ (PATHO) vs MOELLE NORMALE (SAIN)\n",
    "# =================================================================\n",
    "# Si activ√©:\n",
    "#   - Fichier PATHOLOGIQUE: Gate complet (d√©bris + doublets + CD34+ blastes)\n",
    "#   - Fichier SAIN: Gate partiel (d√©bris + doublets UNIQUEMENT, pas de CD34+)\n",
    "# R√©sultat: Blastes purs du patient + Cellules normales de la moelle saine\n",
    "# Id√©al pour entra√Æner FlowSOM √† distinguer blastes vs cellules normales\n",
    "# =================================================================\n",
    "MODE_BLASTES_VS_NORMAL = True  # [!] ACTIVER POUR CE MODE SP√âCIAL\n",
    "\n",
    "# Gate 1: D√©bris (SSC-A vs FSC-A) - True/False\n",
    "GATE_DEBRIS = True\n",
    "DEBRIS_MIN_PERCENTILE = 1.0   # Exclure les 1% les plus bas (d√©bris/bruit)\n",
    "DEBRIS_MAX_PERCENTILE = 99.0  # Exclure les 1% les plus hauts (satur√©s)\n",
    "\n",
    "# Gate 2: Doublets (FSC-H vs FSC-A) - True/False\n",
    "GATE_DOUBLETS = True\n",
    "RATIO_MIN = 0.6   # Ratio FSC-A/FSC-H minimum (cellules trop petites)\n",
    "RATIO_MAX = 1.4   # Ratio FSC-A/FSC-H maximum (doublets/agr√©gats)\n",
    "\n",
    "# Gate 3: Blastes CD34+ (CD34 vs SSC-A) - True/False\n",
    "# NOTE: Si MODE_BLASTES_VS_NORMAL=True, ce gate s'applique UNIQUEMENT au fichier patho\n",
    "GATE_CD34_BLASTS = True  # Mettre True pour s√©lectionner uniquement les blastes\n",
    "CD34_THRESHOLD_PERCENTILE = 85  # Seuil CD34+ (top 15% = percentile 85)\n",
    "USE_SSC_FILTER_FOR_BLASTS = True  # Combiner avec SSC low pour blastes purs\n",
    "SSC_MAX_PERCENTILE_BLASTS = 60  # SSC maximum pour blastes (faible granularit√©)\n",
    "\n",
    "# =================================================================\n",
    "\n",
    "# V√©rification de coh√©rence pour MODE_BLASTES_VS_NORMAL\n",
    "if MODE_BLASTES_VS_NORMAL and not COMPARE_MODE:\n",
    "    print(\"[!] ATTENTION: MODE_BLASTES_VS_NORMAL n√©cessite COMPARE_MODE=True\")\n",
    "    print(\"    ‚Üí Le mode a besoin de fichiers Sain + Patho pour fonctionner\")\n",
    "    print(\"    ‚Üí D√©sactivation automatique du mode diff√©rentiel\")\n",
    "    MODE_BLASTES_VS_NORMAL = False\n",
    "\n",
    "# Donn√©es avant gating\n",
    "X_raw = combined_data.X\n",
    "if hasattr(X_raw, 'toarray'):\n",
    "    X_raw = X_raw.toarray()\n",
    "n_before = X_raw.shape[0]\n",
    "\n",
    "# R√©cup√©rer le vecteur de conditions pour le mode diff√©rentiel\n",
    "conditions = combined_data.obs['condition'].values\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" PRE-GATING S√âQUENTIEL - STRAT√âGIE EN 3 √âTAPES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n √âv√©nements initiaux: {n_before:,}\")\n",
    "\n",
    "# Affichage mode sp√©cial\n",
    "if MODE_BLASTES_VS_NORMAL:\n",
    "    print(\"\\n [!] MODE BLASTES vs MOELLE NORMALE ACTIV√â\")\n",
    "    print(\"     - Patho: Gate complet (d√©bris + doublets + CD34+) ‚Üí Blastes seuls\")\n",
    "    print(\"     - Sain:  Gate partiel (d√©bris + doublets) ‚Üí Cellules normales\")\n",
    "    n_patho = (conditions == \"Pathologique\").sum()\n",
    "    n_sain = (conditions == \"Sain\").sum()\n",
    "    print(f\"     - Cellules Patho: {n_patho:,}\")\n",
    "    print(f\"     - Cellules Sain: {n_sain:,}\")\n",
    "\n",
    "print(f\"\\n Configuration:\")\n",
    "print(f\"   [Gate 1] D√©bris (SSC-A/FSC-A):     {'[OK] ACTIV√â' if GATE_DEBRIS else '[X] D√âSACTIV√â'}\")\n",
    "print(f\"   [Gate 2] Doublets (FSC-H/FSC-A):   {'[OK] ACTIV√â' if GATE_DOUBLETS else '[X] D√âSACTIV√â'}\")\n",
    "if MODE_BLASTES_VS_NORMAL:\n",
    "    print(f\"   [Gate 3] Blastes CD34+:            [OK] PATHO UNIQUEMENT (mode diff√©rentiel)\")\n",
    "else:\n",
    "    print(f\"   [Gate 3] Blastes CD34+:            {'[OK] ACTIV√â' if GATE_CD34_BLASTS else '[X] D√âSACTIV√â'}\")\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    # Initialisation des masques\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    \n",
    "    # ========== GATE 1: D√âBRIS (SSC-A vs FSC-A) ==========\n",
    "    if GATE_DEBRIS:\n",
    "        print(\"\\n GATE 1: Exclusion des d√©bris (SSC-A vs FSC-A)\")\n",
    "        mask_debris = PreGating.gate_debris_polygon(\n",
    "            X_raw, var_names,\n",
    "            auto_percentiles=True,\n",
    "            min_pct=DEBRIS_MIN_PERCENTILE,\n",
    "            max_pct=DEBRIS_MAX_PERCENTILE\n",
    "        )\n",
    "        n_after_debris = mask_debris.sum()\n",
    "        n_excluded_debris = n_before - n_after_debris\n",
    "        print(f\"   Percentiles: [{DEBRIS_MIN_PERCENTILE}%, {DEBRIS_MAX_PERCENTILE}%]\")\n",
    "        print(f\"   ‚Üí Conserv√©s: {n_after_debris:,} ({n_after_debris/n_before*100:.1f}%)\")\n",
    "        print(f\"   ‚Üí Exclus (d√©bris): {n_excluded_debris:,} ({n_excluded_debris/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n GATE 1: D√©bris - SKIP\")\n",
    "    \n",
    "    # ========== GATE 2: DOUBLETS (FSC-H vs FSC-A) ==========\n",
    "    if GATE_DOUBLETS:\n",
    "        print(\"\\n GATE 2: Exclusion des doublets (FSC-H vs FSC-A)\")\n",
    "        mask_singlets = PreGating.gate_singlets(\n",
    "            X_raw, var_names,\n",
    "            ratio_min=RATIO_MIN,\n",
    "            ratio_max=RATIO_MAX\n",
    "        )\n",
    "        # Appliquer sur les cellules d√©j√† filtr√©es par gate 1\n",
    "        mask_after_g1_g2 = mask_debris & mask_singlets\n",
    "        n_after_singlets = mask_after_g1_g2.sum()\n",
    "        n_doublets = mask_debris.sum() - n_after_singlets\n",
    "        print(f\"   Ratio FSC-A/FSC-H: [{RATIO_MIN}, {RATIO_MAX}]\")\n",
    "        print(f\"   ‚Üí Conserv√©s (singlets): {n_after_singlets:,}\")\n",
    "        print(f\"   ‚Üí Exclus (doublets): {n_doublets:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 2: Doublets - SKIP\")\n",
    "    \n",
    "    # ========== GATE 3: BLASTES CD34+ (CD34 vs SSC-A) ==========\n",
    "    # Mode diff√©rentiel: appliquer CD34+ gate UNIQUEMENT sur les cellules pathologiques\n",
    "    if MODE_BLASTES_VS_NORMAL and GATE_CD34_BLASTS:\n",
    "        print(\"\\n GATE 3: S√©lection DIFF√âRENTIELLE des blastes CD34+\")\n",
    "        print(\"   ‚Üí Patho: Gate CD34+ appliqu√© (blastes uniquement)\")\n",
    "        print(\"   ‚Üí Sain: Gate CD34+ IGNOR√â (toutes les cellules conserv√©es)\")\n",
    "        \n",
    "        # Calculer le masque CD34+ sur TOUTES les donn√©es (pour avoir le seuil global)\n",
    "        mask_cd34_full = PreGating.gate_cd34_blasts(\n",
    "            X_raw, var_names,\n",
    "            threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "            use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "            ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "        )\n",
    "        \n",
    "        # Appliquer le gate CD34+ UNIQUEMENT aux cellules pathologiques\n",
    "        # Les cellules saines gardent mask_cd34 = True (pas de filtrage CD34+)\n",
    "        mask_patho = (conditions == \"Pathologique\")\n",
    "        mask_sain = (conditions == \"Sain\")\n",
    "        \n",
    "        # Masque CD34: True pour sain (on garde tout), mask_cd34_full pour patho\n",
    "        mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "        mask_cd34[mask_patho] = mask_cd34_full[mask_patho]  # Gate CD34 sur patho\n",
    "        # mask_cd34 reste True pour les cellules saines\n",
    "        \n",
    "        # Stats\n",
    "        n_patho_before = mask_patho.sum()\n",
    "        n_patho_cd34 = (mask_patho & mask_cd34_full).sum()\n",
    "        n_sain_kept = mask_sain.sum()\n",
    "        \n",
    "        print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "        if USE_SSC_FILTER_FOR_BLASTS:\n",
    "            print(f\"   Filtre SSC low: ‚â§ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "        print(f\"   ‚Üí Patho: {n_patho_cd34:,} blastes / {n_patho_before:,} ({n_patho_cd34/n_patho_before*100:.1f}%)\")\n",
    "        print(f\"   ‚Üí Sain: {n_sain_kept:,} cellules conserv√©es (100%)\")\n",
    "        \n",
    "    elif GATE_CD34_BLASTS:\n",
    "        print(\"\\n GATE 3: S√©lection des blastes CD34+ (CD34 vs SSC-A)\")\n",
    "        mask_cd34 = PreGating.gate_cd34_blasts(\n",
    "            X_raw, var_names,\n",
    "            threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "            use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "            ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "        )\n",
    "        print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "        if USE_SSC_FILTER_FOR_BLASTS:\n",
    "            print(f\"   Filtre SSC low: ‚â§ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 3: Blastes CD34+ - SKIP\")\n",
    "    \n",
    "    # ========== MASQUE FINAL COMBIN√â ==========\n",
    "    mask_final = mask_debris & mask_singlets & mask_cd34\n",
    "    n_final = mask_final.sum()\n",
    "    n_excluded = n_before - n_final\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" R√âSUM√â DU PRE-GATING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   √âv√©nements initiaux:  {n_before:,}\")\n",
    "    print(f\"   Apr√®s Gate 1 (d√©bris): {mask_debris.sum():,}\")\n",
    "    print(f\"   Apr√®s Gate 2 (doublets): {(mask_debris & mask_singlets).sum():,}\")\n",
    "    \n",
    "    if MODE_BLASTES_VS_NORMAL and GATE_CD34_BLASTS:\n",
    "        # R√©sum√© d√©taill√© pour le mode diff√©rentiel\n",
    "        mask_patho = (conditions == \"Pathologique\")\n",
    "        mask_sain = (conditions == \"Sain\")\n",
    "        n_blastes_final = (mask_final & mask_patho).sum()\n",
    "        n_sain_final = (mask_final & mask_sain).sum()\n",
    "        \n",
    "        print(f\"\\n   [MODE BLASTES vs NORMAL]\")\n",
    "        print(f\"   Blastes CD34+ (patho):     {n_blastes_final:,}\")\n",
    "        print(f\"   Cellules normales (sain):  {n_sain_final:,}\")\n",
    "        print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        print(f\"   [OK] TOTAL CONSERV√â:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "        print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "        print(f\"\\n   ‚Üí Pr√™t pour FlowSOM: Blastes purs + Cellules normales\")\n",
    "    else:\n",
    "        if GATE_CD34_BLASTS:\n",
    "            print(f\"   Apr√®s Gate 3 (CD34+): {n_final:,}\")\n",
    "        print(f\"\\n   [OK] √âV√âNEMENTS CONSERV√âS: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "        print(f\"   [X] √âV√âNEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n PRE-GATING COMPL√àTEMENT D√âSACTIV√â\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   ‚Üí Toutes les {n_before:,} cellules seront conserv√©es\")\n",
    "    mask_final = np.ones(n_before, dtype=bool)\n",
    "    n_final = n_before\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7672363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION PROFESSIONNELLE DES √âTAPES DE GATING\n",
    "# =============================================================================\n",
    "# Graphiques S√âPAR√âS et BIEN D√âFINIS pour chaque √©tape\n",
    "# Style professionnel type FlowJo/Kaluza\n",
    "# =============================================================================\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "# =============================================================================\n",
    "# FONCTIONS DE VISUALISATION\n",
    "# =============================================================================\n",
    "\n",
    "def format_axis(value, pos):\n",
    "    \"\"\"Format intelligent des axes (K pour milliers, M pour millions)\"\"\"\n",
    "    if abs(value) >= 1e6:\n",
    "        return f'{value/1e6:.1f}M'\n",
    "    elif abs(value) >= 1e3:\n",
    "        return f'{value/1e3:.0f}K'\n",
    "    return f'{value:.0f}'\n",
    "\n",
    "\n",
    "def plot_density(ax, x, y, title, xlabel, ylabel, n_bins=120):\n",
    "    \"\"\"Scatter plot avec densit√© 2D (style FlowJo)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[valid], y[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'Donn√©es insuffisantes', ha='center', va='center', \n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    \n",
    "    # Colormap densit√©\n",
    "    cmap = LinearSegmentedColormap.from_list('density', \n",
    "        ['#0d0d0d', '#1a1a2e', '#0077b6', '#00b4d8', '#90e0ef', '#f9e2af', '#ffffff'])\n",
    "    \n",
    "    # Histogramme 2D\n",
    "    h = ax.hist2d(x, y, bins=n_bins, \n",
    "                  range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                  cmap=cmap, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(h[3], ax=ax, shrink=0.85)\n",
    "    cbar.ax.tick_params(colors='white', labelsize=9)\n",
    "    cbar.set_label('Densit√©', color='white', fontsize=11)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "def plot_gating(ax, x, y, mask, title, xlabel, ylabel, \n",
    "                label_in='Conserv√©s', label_out='Exclus', max_pts=100000):\n",
    "    \"\"\"Scatter plot avec overlay gating (vert=conserv√©s, rouge=exclus)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y, mask = x[valid], y[valid], mask[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'Donn√©es insuffisantes', ha='center', va='center',\n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Sous-√©chantillonner\n",
    "    if len(x) > max_pts:\n",
    "        idx = np.random.choice(len(x), max_pts, replace=False)\n",
    "        x, y, mask = x[idx], y[idx], mask[idx]\n",
    "    \n",
    "    # Couleurs\n",
    "    c_out = '#f38ba8'  # Rouge pastel\n",
    "    c_in = '#a6e3a1'   # Vert pastel\n",
    "    \n",
    "    # Tracer exclus (fond)\n",
    "    ax.scatter(x[~mask], y[~mask], s=4, c=c_out, alpha=0.3, \n",
    "               label=label_out, edgecolors='none', rasterized=True)\n",
    "    # Tracer conserv√©s (avant-plan)\n",
    "    ax.scatter(x[mask], y[mask], s=5, c=c_in, alpha=0.5, \n",
    "               label=label_in, edgecolors='none', rasterized=True)\n",
    "    \n",
    "    # Stats\n",
    "    n_tot = len(x)\n",
    "    n_in = mask.sum()\n",
    "    pct = n_in / n_tot * 100 if n_tot > 0 else 0\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(f'{title}\\n{n_in:,} / {n_tot:,} ({pct:.1f}%)', \n",
    "                fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=10, markerscale=3,\n",
    "              facecolor='#313244', labelcolor='white', edgecolor='#45475a')\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    ax.set_xlim(x_lo - (x_hi-x_lo)*0.05, x_hi + (x_hi-x_lo)*0.05)\n",
    "    ax.set_ylim(y_lo - (y_hi-y_lo)*0.05, y_hi + (y_hi-y_lo)*0.05)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# G√âN√âRATION DES GRAPHIQUES (UN PAR UN)\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\" VISUALISATION DU PRE-GATING - GRAPHIQUES S√âPAR√âS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Indices des canaux\n",
    "    fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "    \n",
    "    # Sous-√©chantillonner\n",
    "    n_sample = min(60000, n_before)\n",
    "    np.random.seed(42)\n",
    "    idx_s = np.random.choice(n_before, n_sample, replace=False)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 1 : VUE D'ENSEMBLE (FSC-A vs SSC-A)\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"‚îÄ\"*50)\n",
    "    print(\" GRAPHIQUE 1 : VUE D'ENSEMBLE\")\n",
    "    print(\"‚îÄ\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "        \n",
    "        plot_density(ax1, \n",
    "                     X_raw[idx_s, fsc_a_idx], \n",
    "                     X_raw[idx_s, ssc_a_idx],\n",
    "                     f'VUE D\\'ENSEMBLE\\n{n_before:,} √©v√©nements totaux',\n",
    "                     'FSC-A (Forward Scatter - Taille)',\n",
    "                     'SSC-A (Side Scatter - Granularit√©)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_01_overview.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] Sauvegard√©: gating_01_overview.png\")\n",
    "    else:\n",
    "        print(\"   [!] FSC-A ou SSC-A non trouv√© dans les donn√©es\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 2 : GATE D√âBRIS (FSC-A vs SSC-A avec overlay)\n",
    "    # =========================================================================\n",
    "    if GATE_DEBRIS:\n",
    "        print(\"\\n\" + \"‚îÄ\"*50)\n",
    "        print(\" GRAPHIQUE 2 : GATE D√âBRIS\")\n",
    "        print(\"‚îÄ\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "            fig2, ax2 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            plot_gating(ax2,\n",
    "                        X_raw[idx_s, fsc_a_idx],\n",
    "                        X_raw[idx_s, ssc_a_idx],\n",
    "                        mask_debris[idx_s],\n",
    "                        'GATE 1 : Exclusion des D√©bris',\n",
    "                        'FSC-A (Taille)',\n",
    "                        'SSC-A (Granularit√©)',\n",
    "                        'Cellules viables', 'D√©bris/Bruit')\n",
    "            \n",
    "            # Rectangle de gate\n",
    "            fsc_lo = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            fsc_hi = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            ssc_lo = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            ssc_hi = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            \n",
    "            rect = Rectangle((fsc_lo, ssc_lo), fsc_hi-fsc_lo, ssc_hi-ssc_lo,\n",
    "                             fill=False, edgecolor='#f9e2af', linewidth=3, linestyle='--')\n",
    "            ax2.add_patch(rect)\n",
    "            ax2.text(fsc_lo + (fsc_hi-fsc_lo)/2, ssc_hi, ' Zone de s√©lection',\n",
    "                    ha='center', va='bottom', fontsize=11, color='#f9e2af', fontweight='bold')\n",
    "            \n",
    "            # Stats\n",
    "            n_kept = mask_debris.sum()\n",
    "            print(f\"   ‚Üí √âv√©nements conserv√©s: {n_kept:,} ({n_kept/n_before*100:.1f}%)\")\n",
    "            print(f\"   ‚Üí D√©bris exclus: {n_before - n_kept:,}\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('gating_02_debris.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"   [OK] Sauvegard√©: gating_02_debris.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 3 : GATE SINGLETS (FSC-H vs FSC-A)\n",
    "    # =========================================================================\n",
    "    if GATE_DOUBLETS:\n",
    "        print(\"\\n\" + \"‚îÄ\"*50)\n",
    "        print(\" GRAPHIQUE 3 : GATE SINGLETS (Doublets)\")\n",
    "        print(\"‚îÄ\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and fsc_h_idx is not None:\n",
    "            fig3, ax3 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Apr√®s gate 1\n",
    "            m_g1 = mask_debris[idx_s]\n",
    "            x3 = X_raw[idx_s, fsc_a_idx][m_g1]\n",
    "            y3 = X_raw[idx_s, fsc_h_idx][m_g1]\n",
    "            m3 = mask_singlets[idx_s][m_g1]\n",
    "            \n",
    "            if len(x3) > 100:\n",
    "                plot_gating(ax3, x3, y3, m3,\n",
    "                            'GATE 2 : Exclusion des Doublets',\n",
    "                            'FSC-A (Area)',\n",
    "                            'FSC-H (Height)',\n",
    "                            'Singlets', 'Doublets/Agr√©gats')\n",
    "                \n",
    "                # Lignes de ratio\n",
    "                x_range = np.linspace(np.nanpercentile(x3, 1), np.nanpercentile(x3, 99), 100)\n",
    "                ax3.plot(x_range, x_range, 'w-', lw=2, alpha=0.7, label='Ratio 1:1')\n",
    "                ax3.plot(x_range, x_range * RATIO_MIN, '--', color='#f9e2af', lw=2)\n",
    "                ax3.plot(x_range, x_range * RATIO_MAX, '--', color='#f9e2af', lw=2)\n",
    "                ax3.fill_between(x_range, x_range * RATIO_MIN, x_range * RATIO_MAX,\n",
    "                                alpha=0.1, color='#f9e2af')\n",
    "                \n",
    "                # Stats\n",
    "                n_after_g2 = (mask_debris & mask_singlets).sum()\n",
    "                n_doublets = mask_debris.sum() - n_after_g2\n",
    "                print(f\"   ‚Üí Singlets conserv√©s: {n_after_g2:,}\")\n",
    "                print(f\"   ‚Üí Doublets exclus: {n_doublets:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_03_singlets.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegard√©: gating_03_singlets.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 4 : GATE CD34+ (CD34 vs SSC-A)\n",
    "    # =========================================================================\n",
    "    if GATE_CD34_BLASTS:\n",
    "        print(\"\\n\" + \"‚îÄ\"*50)\n",
    "        print(\" GRAPHIQUE 4 : GATE CD34+ (Blastes)\")\n",
    "        print(\"‚îÄ\"*50)\n",
    "        \n",
    "        if cd34_idx is not None and ssc_a_idx is not None:\n",
    "            fig4, ax4 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Apr√®s gates 1+2\n",
    "            m_g12 = (mask_debris & mask_singlets)[idx_s]\n",
    "            x4 = X_raw[idx_s, cd34_idx][m_g12]\n",
    "            y4 = X_raw[idx_s, ssc_a_idx][m_g12]\n",
    "            m4 = mask_cd34[idx_s][m_g12]\n",
    "            \n",
    "            if len(x4) > 100:\n",
    "                plot_gating(ax4, x4, y4, m4,\n",
    "                            'GATE 3 : S√©lection des Blastes CD34+',\n",
    "                            'CD34 (Intensit√©)',\n",
    "                            'SSC-A (Granularit√©)',\n",
    "                            'Blastes CD34+', 'Autres cellules')\n",
    "                \n",
    "                # Seuils\n",
    "                cd34_th = np.nanpercentile(X_raw[:, cd34_idx], CD34_THRESHOLD_PERCENTILE)\n",
    "                ax4.axvline(x=cd34_th, color='#f9e2af', lw=3, ls='--')\n",
    "                ax4.text(cd34_th, ax4.get_ylim()[1], f' Seuil CD34\\n (P{CD34_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#f9e2af', fontweight='bold')\n",
    "                \n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    ssc_th = np.nanpercentile(X_raw[:, ssc_a_idx], SSC_MAX_PERCENTILE_BLASTS)\n",
    "                    ax4.axhline(y=ssc_th, color='#fab387', lw=3, ls='--')\n",
    "                    ax4.text(ax4.get_xlim()[1], ssc_th, f' SSC max (P{SSC_MAX_PERCENTILE_BLASTS}) ',\n",
    "                            va='bottom', ha='right', fontsize=10, color='#fab387', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                print(f\"   ‚Üí Blastes CD34+ s√©lectionn√©s: {n_final:,}\")\n",
    "                print(f\"   ‚Üí Autres cellules exclues: {(mask_debris & mask_singlets).sum() - n_final:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_04_cd34.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegard√©: gating_04_cd34.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD34 non trouv√© - Gate CD34+ ignor√©\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 5 : COMPARAISON AVANT / APR√àS\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"‚îÄ\"*50)\n",
    "    print(\" GRAPHIQUE 5 : COMPARAISON AVANT / APR√àS\")\n",
    "    print(\"‚îÄ\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig5, (ax5a, ax5b) = plt.subplots(1, 2, figsize=(16, 7), facecolor='#1e1e2e')\n",
    "        \n",
    "        # AVANT\n",
    "        cmap_red = LinearSegmentedColormap.from_list('reds', \n",
    "            ['#1a1a2e', '#7f1d1d', '#dc2626', '#fca5a5', '#ffffff'])\n",
    "        \n",
    "        valid = np.isfinite(X_raw[idx_s, fsc_a_idx]) & np.isfinite(X_raw[idx_s, ssc_a_idx])\n",
    "        x_bef = X_raw[idx_s, fsc_a_idx][valid]\n",
    "        y_bef = X_raw[idx_s, ssc_a_idx][valid]\n",
    "        \n",
    "        x_lo, x_hi = np.percentile(x_bef, [0.5, 99.5])\n",
    "        y_lo, y_hi = np.percentile(y_bef, [0.5, 99.5])\n",
    "        \n",
    "        h1 = ax5a.hist2d(x_bef, y_bef, bins=100, \n",
    "                         range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                         cmap=cmap_red, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        ax5a.set_title(f'AVANT Gating\\n{n_before:,} √©v√©nements', fontsize=14, fontweight='bold', color='white')\n",
    "        ax5a.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_facecolor('#1e1e2e')\n",
    "        ax5a.tick_params(colors='white')\n",
    "        ax5a.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5a.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5a.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        # APR√àS\n",
    "        cmap_green = LinearSegmentedColormap.from_list('greens', \n",
    "            ['#1a1a2e', '#14532d', '#22c55e', '#86efac', '#ffffff'])\n",
    "        \n",
    "        m_final = mask_final[idx_s]\n",
    "        x_aft = X_raw[idx_s, fsc_a_idx][m_final]\n",
    "        y_aft = X_raw[idx_s, ssc_a_idx][m_final]\n",
    "        \n",
    "        if len(x_aft) > 100:\n",
    "            h2 = ax5b.hist2d(x_aft, y_aft, bins=100,\n",
    "                             range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                             cmap=cmap_green, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        \n",
    "        pct_final = n_final / n_before * 100\n",
    "        ax5b.set_title(f'APR√àS Gating\\n{n_final:,} √©v√©nements ({pct_final:.1f}%)', \n",
    "                      fontsize=14, fontweight='bold', color='white')\n",
    "        ax5b.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_facecolor('#1e1e2e')\n",
    "        ax5b.tick_params(colors='white')\n",
    "        ax5b.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5b.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5b.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_05_comparison.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] Sauvegard√©: gating_05_comparison.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # R√âSUM√â FINAL\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" R√âSUM√â DU PRE-GATING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ret_g1 = mask_debris.sum() / n_before * 100\n",
    "    ret_g2 = (mask_debris & mask_singlets).sum() / n_before * 100\n",
    "    ret_final = n_final / n_before * 100\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ                    STATISTIQUES DE R√âTENTION                ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ  √âtape                        Cellules        R√©tention     ‚îÇ\n",
    "    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ   Initial                   {n_before:>10,}        100.0%     ‚îÇ\n",
    "    ‚îÇ  - Gate 1 (D√©bris)           {mask_debris.sum():>10,}        {ret_g1:>5.1f}%     ‚îÇ\n",
    "    ‚îÇ  - Gate 2 (Doublets)         {(mask_debris & mask_singlets).sum():>10,}        {ret_g2:>5.1f}%     ‚îÇ\"\"\")\n",
    "    if GATE_CD34_BLASTS:\n",
    "        print(f\"    ‚îÇ  - Gate 3 (CD34+)            {n_final:>10,}        {ret_final:>5.1f}%     ‚îÇ\")\n",
    "    print(f\"\"\"    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ  [OK] CELLULES CONSERV√âES       {n_final:>10,}        {ret_final:>5.1f}%     ‚îÇ\n",
    "    ‚îÇ  [X] CELLULES EXCLUES          {n_before - n_final:>10,}        {100-ret_final:>5.1f}%     ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\" Fichiers g√©n√©r√©s:\")\n",
    "    print(\"   ‚Ä¢ gating_01_overview.png    - Vue d'ensemble\")\n",
    "    print(\"   ‚Ä¢ gating_02_debris.png      - Gate d√©bris\")\n",
    "    print(\"   ‚Ä¢ gating_03_singlets.png    - Gate singlets\")\n",
    "    print(\"   ‚Ä¢ gating_04_cd34.png        - Gate CD34+\")\n",
    "    print(\"   ‚Ä¢ gating_05_comparison.png  - Avant/Apr√®s\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n Pre-gating d√©sactiv√© - Aucun graphique g√©n√©r√©\")\n",
    "    print(\"   ‚Üí Activez APPLY_PREGATING = True pour visualiser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CR√âATION DU SECOND ANNDATA (avec ou sans gating)\n",
    "# =============================================================================\n",
    "\n",
    "# Cr√©er l'AnnData filtr√© (ou copie compl√®te si pas de gating)\n",
    "combined_gated = combined_data[mask_final].copy()\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    print(f\"[OK] AnnData apr√®s gating: {combined_gated.shape}\")\n",
    "    print(f\"   ‚Üí {combined_gated.shape[0]:,} cellules conserv√©es\")\n",
    "    print(f\"   ‚Üí {combined_gated.shape[1]} marqueurs\")\n",
    "else:\n",
    "    print(f\"[OK] AnnData cr√©√© (sans pre-gating): {combined_gated.shape}\")\n",
    "    print(f\"   ‚Üí {combined_gated.shape[0]:,} cellules (toutes conserv√©es)\")\n",
    "    print(f\"   ‚Üí {combined_gated.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0e40a",
   "metadata": {},
   "source": [
    "## 6. Transformation des Donn√©es (Arcsinh / Logicle)\n",
    "\n",
    "Les donn√©es brutes de cytom√©trie n√©cessitent une transformation pour:\n",
    "- G√©rer les valeurs n√©gatives (compensation)\n",
    "- Compresser la plage dynamique\n",
    "- Am√©liorer la visualisation des populations faiblement exprim√©es\n",
    "\n",
    "### Transformations disponibles:\n",
    "- **Arcsinh (cofactor=5)**: Recommand√© pour flow cytometry\n",
    "- **Logicle**: Transformation biexponentielle (standard ISAC)\n",
    "- **Log10**: Transformation logarithmique simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DE LA TRANSFORMATION\n",
    "\n",
    "# Choix de la transformation\n",
    "TRANSFORM_TYPE = \"none\"  # Options: \"arcsinh\", \"logicle\", \"log10\", \"none\"\n",
    "COFACTOR = 5  # Pour arcsinh: 5 (flow)\n",
    "\n",
    "# Appliquer uniquement aux marqueurs de fluorescence (pas FSC/SSC/Time)\n",
    "APPLY_TO_SCATTER = False\n",
    "\n",
    "print(\"TRANSFORMATION DES DONN√âES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Type: {TRANSFORM_TYPE.upper()}\")\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"   Cofacteur: {COFACTOR}\")\n",
    "print(f\"   Appliquer au scatter: {'Oui' if APPLY_TO_SCATTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION DE LA TRANSFORMATION\n",
    "\n",
    "# Extraire les donn√©es\n",
    "X_gated = combined_gated.X\n",
    "if hasattr(X_gated, 'toarray'):\n",
    "    X_gated = X_gated.toarray()\n",
    "\n",
    "# Copie pour transformation\n",
    "X_transformed = X_gated.copy()\n",
    "\n",
    "# D√©terminer les indices des colonnes √† transformer\n",
    "if APPLY_TO_SCATTER:\n",
    "    cols_to_transform = list(range(len(var_names)))\n",
    "else:\n",
    "    # Exclure FSC, SSC, Time\n",
    "    scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "    cols_to_transform = [i for i, name in enumerate(var_names) \n",
    "                         if not any(p in name.upper() for p in scatter_patterns)]\n",
    "\n",
    "print(f\"\\nColonnes √† transformer: {len(cols_to_transform)}/{len(var_names)}\")\n",
    "\n",
    "# Appliquer la transformation\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"\\n Application Arcsinh (cofactor={COFACTOR})...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.arcsinh_transform(\n",
    "        X_gated[:, cols_to_transform], cofactor=COFACTOR\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"logicle\":\n",
    "    print(\"\\n Application Logicle...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.logicle_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"log10\":\n",
    "    print(\"\\n Application Log10...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.log_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"\\n[!] Pas de transformation appliqu√©e\")\n",
    "\n",
    "# V√©rifier les r√©sultats\n",
    "print(f\"\\n[OK] Transformation termin√©e!\")\n",
    "print(f\"   Plage avant: [{X_gated[:, cols_to_transform].min():.2f}, {X_gated[:, cols_to_transform].max():.2f}]\")\n",
    "print(f\"   Plage apr√®s: [{X_transformed[:, cols_to_transform].min():.2f}, {X_transformed[:, cols_to_transform].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec484f1",
   "metadata": {},
   "source": [
    "## 7. Comparaison Avant/Apr√®s Transformation\n",
    "\n",
    "Visualisation c√¥te √† c√¥te des distributions pour valider l'effet de la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAISON DISTRIBUTIONS AVANT/APR√àS\n",
    "\n",
    "# S√©lectionner quelques marqueurs repr√©sentatifs\n",
    "markers_compare = [var_names[i] for i in cols_to_transform[:6]]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(markers_compare), figsize=(4*len(markers_compare), 8))\n",
    "\n",
    "for i, marker in enumerate(markers_compare):\n",
    "    col_idx = var_names.index(marker)\n",
    "    \n",
    "    # Avant transformation\n",
    "    ax = axes[0, i]\n",
    "    data_before = X_gated[:, col_idx]\n",
    "    ax.hist(data_before, bins=80, color='#f38ba8', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{marker}\\n(Brut)', fontsize=10, fontweight='bold')\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('AVANT\\nCount', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Apr√®s transformation\n",
    "    ax = axes[1, i]\n",
    "    data_after = X_transformed[:, col_idx]\n",
    "    ax.hist(data_after, bins=80, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{TRANSFORM_TYPE.upper()}', fontsize=10)\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('APR√àS\\nCount', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Comparaison des Distributions: Brut vs {TRANSFORM_TYPE.upper()} (cofactor={COFACTOR})', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DE DIFF√âRENTS COFACTEURS (pour tuning)\n",
    "\n",
    "print(\"COMPARAISON DES COFACTEURS ARCSINH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# S√©lectionner un marqueur repr√©sentatif\n",
    "test_marker = markers_compare[0]\n",
    "test_idx = var_names.index(test_marker)\n",
    "test_data = X_gated[:, test_idx]\n",
    "\n",
    "# Tester diff√©rents cofacteurs\n",
    "cofactors = [1, 5, 50, 150, 500]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cofactors)+1, figsize=(4*(len(cofactors)+1), 4))\n",
    "\n",
    "# Donn√©es brutes\n",
    "ax = axes[0]\n",
    "ax.hist(test_data, bins=80, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "ax.set_title('Brut\\n(pas de transfo)', fontsize=10, fontweight='bold')\n",
    "ax.set_xlabel(test_marker)\n",
    "\n",
    "# Transformations avec diff√©rents cofacteurs\n",
    "for i, cof in enumerate(cofactors):\n",
    "    ax = axes[i+1]\n",
    "    transformed = DataTransformer.arcsinh_transform(test_data, cofactor=cof)\n",
    "    ax.hist(transformed, bins=80, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'Arcsinh\\ncofactor={cof}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(test_marker)\n",
    "\n",
    "plt.suptitle(f'Impact du Cofacteur sur la Distribution ({test_marker})', \n",
    "             fontsize=13, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087eb83",
   "metadata": {},
   "source": [
    "## 8. Pr√©paration des Donn√©es pour FlowSOM\n",
    "\n",
    "S√©lection des colonnes pour le clustering:\n",
    "- Exclusion des param√®tres scatter (FSC, SSC) et Time\n",
    "- Conservation uniquement des marqueurs de fluorescence\n",
    "- Nettoyage final (NaN/Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√âLECTION DES COLONNES POUR FLOWSOM\n",
    "\n",
    "# Option: exclure FSC/SSC/Time\n",
    "EXCLUDE_SCATTER = True\n",
    "\n",
    "# Identifier les colonnes √† utiliser\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "\n",
    "if EXCLUDE_SCATTER:\n",
    "    cols_to_use = [i for i, name in enumerate(var_names) \n",
    "                   if not any(p in name.upper() for p in scatter_patterns)]\n",
    "else:\n",
    "    cols_to_use = list(range(len(var_names)))\n",
    "\n",
    "used_markers = [var_names[i] for i in cols_to_use]\n",
    "\n",
    "print(\"COLONNES POUR FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Exclure scatter: {'Oui' if EXCLUDE_SCATTER else 'Non'}\")\n",
    "print(f\"   Colonnes s√©lectionn√©es: {len(cols_to_use)}/{len(var_names)}\")\n",
    "print(f\"\\nMarqueurs utilis√©s:\")\n",
    "for i, marker in enumerate(used_markers):\n",
    "    print(f\"   [{i:2d}] {marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTRAGE PAR TYPE D'√âCHANTILLON (-A ou -H) - OPTIONNEL\n",
    "# =============================================================================\n",
    "# Ce filtre permet de s√©lectionner uniquement les cellules provenant de fichiers\n",
    "# dont le nom contient \"-A\" (ex: √©chantillons de type A) ou \"-H\" (ex: √©chantillons de type H)\n",
    "# \n",
    "# [!] IMPORTANT: Si tes fichiers n'ont pas ces suffixes, d√©sactive le filtrage!\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== ACTIVATION DU FILTRAGE =====================\n",
    "APPLY_FILE_FILTERING = False  # [!] Mettre True pour activer, False pour D√âSACTIVER\n",
    "\n",
    "# OPTIONS DE FILTRAGE (utilis√©es seulement si APPLY_FILE_FILTERING = True)\n",
    "INCLUDE_A = True   # Inclure les √©chantillons avec \"-A\" dans le nom\n",
    "INCLUDE_H = False  # Inclure les √©chantillons avec \"-H\" dans le nom\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FILTRAGE PAR TYPE D'√âCHANTILLON (-A / -H)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Filtrage activ√©: {'[OK] OUI' if APPLY_FILE_FILTERING else '[X] NON (toutes les donn√©es conserv√©es)'}\")\n",
    "\n",
    "if APPLY_FILE_FILTERING:\n",
    "    print(f\"   Inclure -A: {'[OK] Oui' if INCLUDE_A else '[X] Non'}\")\n",
    "    print(f\"   Inclure -H: {'[OK] Oui' if INCLUDE_H else '[X] Non'}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES/MARQUEURS AVEC -A ET -H\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ANALYSE DES COLONNES (MARQUEURS) PAR TYPE -A / -H\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# R√©cup√©rer les noms de colonnes\n",
    "all_columns = list(combined_gated.var_names)\n",
    "\n",
    "# S√©parer les colonnes avec -A, -H, ou autres\n",
    "cols_with_A = [col for col in all_columns if \"-A\" in col.upper()]\n",
    "cols_with_H = [col for col in all_columns if \"-H\" in col.upper()]\n",
    "cols_other = [col for col in all_columns if \"-A\" not in col.upper() and \"-H\" not in col.upper()]\n",
    "\n",
    "print(f\"\\nüîµ COLONNES avec '-A' ({len(cols_with_A)}):\")\n",
    "for col in cols_with_A:\n",
    "    print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "print(f\"\\n[+] COLONNES avec '-H' ({len(cols_with_H)}):\")\n",
    "for col in cols_with_H:\n",
    "    print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "print(f\"\\n‚ö™ COLONNES sans -A/-H ({len(cols_other)}):\")\n",
    "for col in cols_other:\n",
    "    print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTRAGE DES FICHIERS (si activ√©)\n",
    "# =============================================================================\n",
    "if APPLY_FILE_FILTERING:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES FICHIERS PAR TYPE -A / -H\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Afficher les fichiers disponibles avant filtrage\n",
    "    print(f\"\\n Fichiers disponibles AVANT filtrage:\")\n",
    "    file_counts_before = combined_gated.obs['file_origin'].value_counts()\n",
    "\n",
    "    files_A = []\n",
    "    files_H = []\n",
    "    files_other = []\n",
    "\n",
    "    for fname, count in file_counts_before.items():\n",
    "        has_A = \"-A\" in fname.upper()\n",
    "        has_H = \"-H\" in fname.upper()\n",
    "        type_label = []\n",
    "        if has_A:\n",
    "            type_label.append(\"-A\")\n",
    "            files_A.append((fname, count))\n",
    "        if has_H:\n",
    "            type_label.append(\"-H\")\n",
    "            files_H.append((fname, count))\n",
    "        if not has_A and not has_H:\n",
    "            files_other.append((fname, count))\n",
    "        type_str = \", \".join(type_label) if type_label else \"(autre)\"\n",
    "        print(f\"   {fname}: {count:,} cellules [{type_str}]\")\n",
    "\n",
    "    print(f\"\\n R√©sum√© des fichiers:\")\n",
    "    print(f\"   Fichiers -A: {len(files_A)} ({sum(c for _, c in files_A):,} cellules)\")\n",
    "    print(f\"   Fichiers -H: {len(files_H)} ({sum(c for _, c in files_H):,} cellules)\")\n",
    "    print(f\"   Fichiers autres: {len(files_other)} ({sum(c for _, c in files_other):,} cellules)\")\n",
    "\n",
    "    # Cr√©er le masque de filtrage\n",
    "    file_names = combined_gated.obs['file_origin'].values.astype(str)\n",
    "\n",
    "    # Initialiser le masque √† False (aucun √©chantillon inclus par d√©faut)\n",
    "    mask_A = np.zeros(len(file_names), dtype=bool)\n",
    "    mask_H = np.zeros(len(file_names), dtype=bool)\n",
    "\n",
    "    # Appliquer les filtres\n",
    "    for i, fname in enumerate(file_names):\n",
    "        fname_upper = fname.upper()\n",
    "        if \"-A\" in fname_upper:\n",
    "            mask_A[i] = True\n",
    "        if \"-H\" in fname_upper:\n",
    "            mask_H[i] = True\n",
    "\n",
    "    # Combiner selon les options\n",
    "    if INCLUDE_A and INCLUDE_H:\n",
    "        filter_mask = mask_A | mask_H\n",
    "        filter_description = \"√©chantillons -A ET -H\"\n",
    "    elif INCLUDE_A and not INCLUDE_H:\n",
    "        filter_mask = mask_A\n",
    "        filter_description = \"√©chantillons -A uniquement\"\n",
    "    elif not INCLUDE_A and INCLUDE_H:\n",
    "        filter_mask = mask_H\n",
    "        filter_description = \"√©chantillons -H uniquement\"\n",
    "    else:\n",
    "        print(\"\\n[!] ATTENTION: INCLUDE_A et INCLUDE_H sont tous les deux False!\")\n",
    "        print(\"   ‚Üí Garde tous les √©chantillons par d√©faut\")\n",
    "        filter_mask = np.ones(len(file_names), dtype=bool)\n",
    "        filter_description = \"tous les √©chantillons (aucun filtre)\"\n",
    "\n",
    "    # [!] V√âRIFICATION: Si aucune cellule ne correspond, d√©sactiver le filtrage\n",
    "    n_matching = filter_mask.sum()\n",
    "    if n_matching == 0:\n",
    "        print(\"\\n\" + \"!\"*70)\n",
    "        print(\"[!] ATTENTION: AUCUN FICHIER NE CORRESPOND AU FILTRE!\")\n",
    "        print(\"!\"*70)\n",
    "        print(f\"   ‚Üí Tes fichiers n'ont pas de suffixe -A ou -H\")\n",
    "        print(f\"   ‚Üí FILTRAGE D√âSACTIV√â AUTOMATIQUEMENT\")\n",
    "        print(f\"   ‚Üí Toutes les cellules sont conserv√©es\")\n",
    "        filter_mask = np.ones(len(file_names), dtype=bool)\n",
    "        filter_description = \"AUCUN (auto-d√©sactiv√© - pas de fichiers correspondants)\"\n",
    "\n",
    "    # Appliquer le filtre\n",
    "    n_before = combined_gated.shape[0]\n",
    "    combined_gated_filtered = combined_gated[filter_mask].copy()\n",
    "    n_after = combined_gated_filtered.shape[0]\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(f\" R√âSULTAT DU FILTRAGE ({filter_description})\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Cellules avant filtrage: {n_before:,}\")\n",
    "    print(f\"   Cellules apr√®s filtrage: {n_after:,}\")\n",
    "    if n_before > 0:\n",
    "        print(f\"   Cellules exclues: {n_before - n_after:,} ({100*(n_before-n_after)/n_before:.1f}%)\")\n",
    "\n",
    "    # Afficher les fichiers restants apr√®s filtrage\n",
    "    if n_after > 0:\n",
    "        print(f\"\\n Fichiers CONSERV√âS apr√®s filtrage:\")\n",
    "        file_counts_after = combined_gated_filtered.obs['file_origin'].value_counts()\n",
    "        for fname, count in file_counts_after.items():\n",
    "            print(f\"   [OK] {fname}: {count:,} cellules\")\n",
    "\n",
    "    # Mettre √† jour X_transformed\n",
    "    X_transformed = X_transformed[filter_mask]\n",
    "    combined_gated = combined_gated_filtered\n",
    "\n",
    "else:\n",
    "    # FILTRAGE D√âSACTIV√â - garder toutes les donn√©es\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES FICHIERS D√âSACTIV√â\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   ‚Üí Toutes les {combined_gated.shape[0]:,} cellules sont conserv√©es\")\n",
    "    \n",
    "    # Afficher quand m√™me les fichiers disponibles\n",
    "    print(f\"\\n Fichiers disponibles:\")\n",
    "    file_counts = combined_gated.obs['file_origin'].value_counts()\n",
    "    for fname, count in file_counts.items():\n",
    "        has_A = \"-A\" in fname.upper()\n",
    "        has_H = \"-H\" in fname.upper()\n",
    "        type_label = []\n",
    "        if has_A:\n",
    "            type_label.append(\"-A\")\n",
    "        if has_H:\n",
    "            type_label.append(\"-H\")\n",
    "        type_str = \", \".join(type_label) if type_label else \"(pas de suffixe -A/-H)\"\n",
    "        print(f\"   {fname}: {count:,} cellules [{type_str}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES UTILIS√âES POUR FLOWSOM\n",
    "# =============================================================================\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\" COLONNES DISPONIBLES POUR FLOWSOM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nToutes les colonnes ({len(list(combined_gated.var_names))}):\")\n",
    "for i, col in enumerate(combined_gated.var_names):\n",
    "    marker_type = \"\"\n",
    "    if \"-A\" in col.upper():\n",
    "        marker_type = \" [Type -A]\"\n",
    "    elif \"-H\" in col.upper():\n",
    "        marker_type = \" [Type -H]\"\n",
    "    print(f\"   [{i:2d}] {col}{marker_type}\")\n",
    "\n",
    "print(f\"\\n[OK] Donn√©es pr√™tes pour la suite du pipeline\")\n",
    "print(f\"   Shape combined_gated: {combined_gated.shape}\")\n",
    "print(f\"   Shape X_transformed: {X_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CR√âATION DE L'ANNDATA TRANSFORM√â ET EXPLORATION POST-ARCSINH\n",
    "\n",
    "# Cr√©er un nouvel AnnData avec les donn√©es transform√©es (X_transformed)\n",
    "import anndata as ad\n",
    "\n",
    "# Cr√©er adata_flowsom - le nouvel AnnData pour FlowSOM avec donn√©es transform√©es\n",
    "adata_flowsom = ad.AnnData(\n",
    "    X=X_transformed,  # Donn√©es POST-transformation arcsinh\n",
    "    obs=combined_gated.obs.copy(),  # Copie des m√©tadonn√©es\n",
    "    var=combined_gated.var.copy() if combined_gated.var is not None else None\n",
    ")\n",
    "\n",
    "# Ajouter les noms de variables\n",
    "adata_flowsom.var_names = var_names\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CR√âATION ANNDATA POUR FLOWSOM (DONN√âES POST-ARCSINH)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n[OK] Nouvel AnnData 'adata_flowsom' cr√©√© avec donn√©es transform√©es\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Observations (cellules): {adata_flowsom.n_obs:,}\")\n",
    "print(f\"   Variables (marqueurs): {adata_flowsom.n_vars}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPLORATION DU DATAFRAME POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "\n",
    "# Extraire la matrice transform√©e depuis le NOUVEL AnnData\n",
    "X_trans = adata_flowsom.X\n",
    "if hasattr(X_trans, 'toarray'):\n",
    "    X_trans = X_trans.toarray()\n",
    "\n",
    "# Cr√©er un DataFrame pour exploration\n",
    "df_transformed = pd.DataFrame(X_trans, columns=var_names)\n",
    "df_transformed['condition'] = adata_flowsom.obs['condition'].values\n",
    "df_transformed['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"APER√áU DES DONN√âES TRANSFORM√âES (premi√®res 10 lignes)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape du DataFrame: {df_transformed.shape}\")\n",
    "display(df_transformed.head(10))\n",
    "\n",
    "# V√âRIFICATION DES NaN ET Inf POST-ARCSINH\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"V√âRIFICATION DES VALEURS NaN ET Inf POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Colonnes num√©riques uniquement\n",
    "numeric_cols = df_transformed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Comptage des NaN\n",
    "nan_counts = df_transformed[numeric_cols].isna().sum()\n",
    "total_nan = nan_counts.sum()\n",
    "\n",
    "# Comptage des Inf (positifs et n√©gatifs)\n",
    "inf_pos_counts = (df_transformed[numeric_cols] == np.inf).sum()\n",
    "inf_neg_counts = (df_transformed[numeric_cols] == -np.inf).sum()\n",
    "total_inf_pos = inf_pos_counts.sum()\n",
    "total_inf_neg = inf_neg_counts.sum()\n",
    "total_inf = total_inf_pos + total_inf_neg\n",
    "\n",
    "total_cells = df_transformed.shape[0] * len(numeric_cols)\n",
    "\n",
    "print(f\"\\nR√âSUM√â GLOBAL:\")\n",
    "print(f\"   Total valeurs analys√©es: {total_cells:,}\")\n",
    "print(f\"   Total NaN:    {total_nan:,} ({100*total_nan/total_cells:.4f}%)\")\n",
    "print(f\"   Total +Inf:   {total_inf_pos:,} ({100*total_inf_pos/total_cells:.4f}%)\")\n",
    "print(f\"   Total -Inf:   {total_inf_neg:,} ({100*total_inf_neg/total_cells:.4f}%)\")\n",
    "\n",
    "# D√©tail par colonne si probl√®mes d√©tect√©s\n",
    "if total_nan > 0 or total_inf > 0:\n",
    "    print(f\"\\nD√âTAIL PAR COLONNE AVEC PROBL√àMES:\")\n",
    "    print(\"-\"*60)\n",
    "    for col in numeric_cols:\n",
    "        n_nan = df_transformed[col].isna().sum()\n",
    "        n_inf_pos = (df_transformed[col] == np.inf).sum()\n",
    "        n_inf_neg = (df_transformed[col] == -np.inf).sum()\n",
    "        if n_nan > 0 or n_inf_pos > 0 or n_inf_neg > 0:\n",
    "            print(f\"   {col:30s}: NaN={n_nan:,}, +Inf={n_inf_pos:,}, -Inf={n_inf_neg:,}\")\n",
    "else:\n",
    "    print(f\"\\nAucune valeur NaN ou Inf d√©tect√©e - Donn√©es propres!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTIQUES DESCRIPTIVES POST-ARCSINH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTIQUES DESCRIPTIVES POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "display(df_transformed[numeric_cols].describe())\n",
    "\n",
    "# ============================================================================\n",
    "# V√âRIFICATION DES RANGES POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"V√âRIFICATION DES RANGES POST-TRANSFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"(arcsinh avec cofactor=150 donne typiquement des valeurs entre -5 et 10)\\n\")\n",
    "\n",
    "for col in used_markers[:10]:  # Premiers 10 marqueurs utilis√©s\n",
    "    col_min = df_transformed[col].min()\n",
    "    col_max = df_transformed[col].max()\n",
    "    col_mean = df_transformed[col].mean()\n",
    "    print(f\"   {col:30s}: min={col_min:8.3f}, max={col_max:8.3f}, mean={col_mean:8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETTOYAGE FINAL ET VALIDATION DE L'ANNDATA POUR FLOWSOM\n",
    "\n",
    "# Nettoyage final: remplacer NaN/Inf par 0 dans adata_flowsom\n",
    "X_final = adata_flowsom.X\n",
    "if hasattr(X_final, 'toarray'):\n",
    "    X_final = X_final.toarray()\n",
    "\n",
    "# V√©rifier et nettoyer\n",
    "nan_mask = ~np.isfinite(X_final)\n",
    "n_nan = nan_mask.sum()\n",
    "if n_nan > 0:\n",
    "    print(f\"[!] {n_nan} valeurs NaN/Inf d√©tect√©es et remplac√©es par 0\")\n",
    "    X_final = np.nan_to_num(X_final, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    adata_flowsom.X = X_final\n",
    "else:\n",
    "    print(\"[OK] Aucune valeur probl√©matique - pas de nettoyage n√©cessaire\")\n",
    "\n",
    "print(f\"\\n[OK] AnnData 'adata_flowsom' pr√™t pour FlowSOM:\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Colonnes pour clustering: {len(cols_to_use)}\")\n",
    "\n",
    "# R√©sum√© par condition\n",
    "print(f\"\\n Distribution par condition:\")\n",
    "for condition in adata_flowsom.obs['condition'].unique():\n",
    "    n = (adata_flowsom.obs['condition'] == condition).sum()\n",
    "    print(f\"   {condition}: {n:,} cellules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08a195",
   "metadata": {},
   "source": [
    "## 9. Ex√©cution du Clustering FlowSOM\n",
    "\n",
    "Configuration et lancement de l'analyse FlowSOM avec:\n",
    "- Grille SOM (xdim √ó ydim)\n",
    "- Nombre de m√©taclusters\n",
    "- Seed pour reproductibilit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAM√àTRES FLOWSOM\n",
    "\n",
    "# Dimensions de la grille SOM\n",
    "XDIM = 10\n",
    "YDIM = 10\n",
    "\n",
    "# Nombre de m√©taclusters\n",
    "N_CLUSTERS = 2\n",
    "\n",
    "# Seed pour reproductibilit√©\n",
    "SEED = 42\n",
    "\n",
    "# Auto-clustering avec silhouette score?\n",
    "AUTO_CLUSTER = False\n",
    "MAX_CLUSTERS_AUTO = 20\n",
    "\n",
    "print(\"PARAM√àTRES FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Grille SOM: {XDIM} √ó {YDIM} = {XDIM*YDIM} nodes\")\n",
    "print(f\"   M√©taclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "print(f\"   Auto-clustering: {'Oui' if AUTO_CLUSTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR TROUVER LE NOMBRE OPTIMAL DE CLUSTERS (optionnel)\n",
    "# [!] Le silhouette score n√©cessite une matrice N√óN ‚Üí impossible avec 1M cellules\n",
    "# Solution: Sous-√©chantillonner pour l'√©valuation silhouette uniquement\n",
    "\n",
    "SAMPLE_SIZE_SILHOUETTE = 10000  # Taille de l'√©chantillon pour silhouette\n",
    "\n",
    "def find_optimal_clusters(data, cols_to_use, seed, max_clusters=20, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Trouve le nombre optimal de m√©taclusters via silhouette score.\n",
    "    Utilise un √©chantillon repr√©sentatif pour √©viter l'explosion m√©moire.\n",
    "    \"\"\"\n",
    "    print(\"Recherche du nombre optimal de clusters...\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = data.X\n",
    "    if hasattr(X, 'toarray'):\n",
    "        X = X.toarray()\n",
    "    \n",
    "    X_full = X[:, cols_to_use]\n",
    "    X_full = np.nan_to_num(X_full, nan=0.0)\n",
    "    \n",
    "    n_total = X_full.shape[0]\n",
    "    \n",
    "    # Sous-√©chantillonner pour silhouette (sinon O(N¬≤) m√©moire)\n",
    "    if n_total > sample_size:\n",
    "        print(f\"   [!] {n_total:,} cellules ‚Üí √©chantillon de {sample_size:,} pour silhouette\")\n",
    "        idx = np.random.choice(n_total, sample_size, replace=False)\n",
    "        X_sample = X_full[idx]\n",
    "    else:\n",
    "        print(f\"   Utilisation de {n_total:,} cellules\")\n",
    "        X_sample = X_full\n",
    "    \n",
    "    scores = []\n",
    "    cluster_range = range(2, min(max_clusters + 1, len(X_sample) // 10))\n",
    "    \n",
    "    for k in cluster_range:\n",
    "        try:\n",
    "            clustering = AgglomerativeClustering(n_clusters=k)\n",
    "            labels = clustering.fit_predict(X_sample)\n",
    "            score = silhouette_score(X_sample, labels)\n",
    "            scores.append((k, score))\n",
    "            print(f\"   k={k}: silhouette={score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   k={k}: erreur - {e}\")\n",
    "    \n",
    "    if scores:\n",
    "        best_k, best_score = max(scores, key=lambda x: x[1])\n",
    "        print(f\"\\n[OK] Nombre optimal: {best_k} (silhouette={best_score:.4f})\")\n",
    "        return best_k\n",
    "    \n",
    "    return 10  # Valeur par d√©faut\n",
    "\n",
    "# Ex√©cuter si AUTO_CLUSTER est activ√©\n",
    "if AUTO_CLUSTER:\n",
    "    N_CLUSTERS = find_optimal_clusters(\n",
    "        combined_gated, cols_to_use, SEED, \n",
    "        MAX_CLUSTERS_AUTO, SAMPLE_SIZE_SILHOUETTE\n",
    "    )\n",
    "    print(f\"\\n Utilisation de {N_CLUSTERS} m√©taclusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EX√âCUTION FLOWSOM\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Ex√©cuter FlowSOM avec adata_flowsom (donn√©es transform√©es arcsinh)\n",
    "fsom = fs.FlowSOM(\n",
    "    adata_flowsom,  # ‚Üê IMPORTANT: utilise les donn√©es POST-transformation\n",
    "    cols_to_use=cols_to_use,\n",
    "    xdim=XDIM,\n",
    "    ydim=YDIM,\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTemps d'ex√©cution: {elapsed:.2f} secondes\")\n",
    "\n",
    "# R√©cup√©rer les donn√©es de clustering\n",
    "cell_data = fsom.get_cell_data()\n",
    "cluster_data = fsom.get_cluster_data()\n",
    "\n",
    "# Ajouter les m√©tadonn√©es originales\n",
    "cell_data.obs['condition'] = adata_flowsom.obs['condition'].values\n",
    "cell_data.obs['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(f\"\\n[OK] FlowSOM termin√©!\")\n",
    "print(f\"   Cellules analys√©es: {cell_data.shape[0]:,}\")\n",
    "print(f\"   Nodes SOM: {cluster_data.shape[0]}\")\n",
    "print(f\"   M√©taclusters: {N_CLUSTERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0e07e",
   "metadata": {},
   "source": [
    "## 10. Visualisation des R√©sultats FlowSOM\n",
    "\n",
    "G√©n√©ration des visualisations standards:\n",
    "- Heatmap d'expression par m√©tacluster\n",
    "- Arbre MST (Minimum Spanning Tree)\n",
    "- Star Charts\n",
    "- Distribution par condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP D'EXPRESSION PAR M√âTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" G√©n√©ration de la Heatmap d'expression...\")\n",
    "\n",
    "# R√©cup√©rer les donn√©es\n",
    "X = cell_data.X\n",
    "if hasattr(X, 'toarray'):\n",
    "    X = X.toarray()\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "\n",
    "# Calculer la MFI (Mean Fluorescence Intensity) par m√©tacluster\n",
    "mfi_matrix = np.zeros((N_CLUSTERS, len(cols_to_use)))\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    if mask.sum() > 0:\n",
    "        mfi_matrix[i, :] = np.nanmean(X[mask][:, cols_to_use], axis=0)\n",
    "\n",
    "# Normalisation Z-score pour la heatmap\n",
    "mfi_normalized = (mfi_matrix - np.nanmean(mfi_matrix, axis=0)) / (np.nanstd(mfi_matrix, axis=0) + 1e-10)\n",
    "\n",
    "# Cr√©er la heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "im = ax.imshow(mfi_normalized.T, aspect='auto', cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "\n",
    "# Labels\n",
    "ax.set_yticks(range(len(used_markers)))\n",
    "ax.set_yticklabels(used_markers, fontsize=9)\n",
    "ax.set_xticks(range(N_CLUSTERS))\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "\n",
    "ax.set_title('Heatmap - Expression par M√©tacluster (Z-score)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('M√©tacluster', fontsize=12)\n",
    "ax.set_ylabel('Marqueur', fontsize=12)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8, label='Z-score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAR CHART FLOWSOM (MST View)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"G√©n√©ration du Star Chart MST...\")\n",
    "\n",
    "try:\n",
    "    # Utiliser l'API FlowSOM pour le Star Chart\n",
    "    fig_stars = fs.pl.plot_stars(\n",
    "        fsom,\n",
    "        background_values=fsom.get_cluster_data().obs.metaclustering,\n",
    "        view=\"MST\"\n",
    "    )\n",
    "    plt.suptitle('FlowSOM Star Chart (MST View)', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur Star Chart: {e}\")\n",
    "    print(\"   Utilisation de la visualisation alternative...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION GRILLE SOM (xGrid, yGrid) - Style FlowSOM R exact\n",
    "# =============================================================================\n",
    "\n",
    "print(\" VISUALISATION GRILLE SOM (style FlowSOM R avec cercles)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R)\n",
    "# =====================================================================\n",
    "def circular_jitter_viz(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    G√©n√®re un jitter circulaire style FlowSOM R.\n",
    "    Le rayon des cercles d√©pend du nombre de cellules dans le node.\n",
    "    \"\"\"\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    max_size_val = node_sizes.max()\n",
    "    \n",
    "    radii = np.zeros(n_points, dtype=np.float32)\n",
    "    for i in range(n_points):\n",
    "        node_id = int(cluster_ids[i])\n",
    "        node_size = node_sizes[node_id]\n",
    "        size_ratio = np.sqrt(node_size / max_size_val)\n",
    "        node_radius = min_radius + (max_radius - min_radius) * size_ratio\n",
    "        radii[i] = node_radius\n",
    "    \n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "try:\n",
    "    # R√©cup√©rer les coordonn√©es de grille\n",
    "    grid_coords = cluster_data.obsm.get('grid', None)\n",
    "    \n",
    "    if grid_coords is not None:\n",
    "        # R√©cup√©rer les infos de clustering\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        conditions = cell_data.obs['condition'].values\n",
    "        \n",
    "        # Calculer les coordonn√©es de grille pour chaque cellule\n",
    "        xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "        yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "        \n",
    "        # D√©caler pour commencer √† 1\n",
    "        xGrid_shifted = xGrid_base - xGrid_base.min() + 1\n",
    "        yGrid_shifted = yGrid_base - yGrid_base.min() + 1\n",
    "        \n",
    "        # M√©tacluster pour chaque cellule\n",
    "        metaclustering_cells = np.array([metaclustering_nodes[int(c)] for c in clustering])\n",
    "        \n",
    "        # Calculer la taille de chaque node\n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes, dtype=np.float32)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        # JITTER CIRCULAIRE style FlowSOM R\n",
    "        MAX_NODE_SIZE = 0.45\n",
    "        MIN_NODE_SIZE = 0.1\n",
    "        np.random.seed(SEED)\n",
    "        jitter_x, jitter_y = circular_jitter_viz(len(clustering), clustering, node_sizes, \n",
    "                                                  max_radius=MAX_NODE_SIZE, \n",
    "                                                  min_radius=MIN_NODE_SIZE)\n",
    "        \n",
    "        print(f\" Jitter circulaire appliqu√© (rayon proportionnel √† la taille du node)\")\n",
    "        print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "        \n",
    "        # Cr√©er la figure avec 2 sous-plots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 1: Grille SOM color√©e par M√©tacluster\n",
    "        # =====================================================================\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        \n",
    "        scatter1 = ax1.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=metaclustering_cells,\n",
    "            cmap=cmap,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        # Ajouter les labels des m√©taclusters au centre de chaque node\n",
    "        for node_id in range(n_nodes):\n",
    "            if node_sizes[node_id] > 0:\n",
    "                x_pos = grid_coords[node_id, 0] - xGrid_base.min() + 1\n",
    "                y_pos = grid_coords[node_id, 1] - yGrid_base.min() + 1\n",
    "                meta_id = metaclustering_nodes[node_id]\n",
    "                ax1.annotate(\n",
    "                    str(int(meta_id + 1)),\n",
    "                    (x_pos, y_pos),\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=8, fontweight='bold',\n",
    "                    color='white',\n",
    "                    bbox=dict(boxstyle='circle,pad=0.2', facecolor=cmap(meta_id / max(n_meta - 1, 1)), edgecolor='white', alpha=0.9)\n",
    "                )\n",
    "        \n",
    "        ax1.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColor√© par M√©tacluster (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax1.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax1.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax1.set_aspect('equal')\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        cbar1 = plt.colorbar(scatter1, ax=ax1, label='M√©tacluster')\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 2: Grille SOM color√©e par Condition\n",
    "        # =====================================================================\n",
    "        ax2 = axes[1]\n",
    "        \n",
    "        condition_num = np.array([0 if c == 'Sain' else 1 for c in conditions])\n",
    "        \n",
    "        from matplotlib.colors import ListedColormap\n",
    "        cmap_cond = ListedColormap(['#a6e3a1', '#f38ba8'])\n",
    "        \n",
    "        scatter2 = ax2.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=condition_num,\n",
    "            cmap=cmap_cond,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        ax2.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColor√© par Condition (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax2.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax2.set_aspect('equal')\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='#a6e3a1', edgecolor='white', label='Sain (NBM)'),\n",
    "            Patch(facecolor='#f38ba8', edgecolor='white', label='Pathologique')\n",
    "        ]\n",
    "        ax2.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Afficher les statistiques\n",
    "        print(f\"\\n STATISTIQUES DE LA GRILLE SOM:\")\n",
    "        print(f\"   Dimensions: {XDIM} x {YDIM} = {XDIM * YDIM} nodes\")\n",
    "        print(f\"   Nodes utilis√©s: {(node_sizes > 0).sum()} / {n_nodes}\")\n",
    "        print(f\"   xGrid range: [{xGrid_shifted.min():.1f}, {xGrid_shifted.max():.1f}]\")\n",
    "        print(f\"   yGrid range: [{yGrid_shifted.min():.1f}, {yGrid_shifted.max():.1f}]\")\n",
    "        \n",
    "        # Afficher la taille des nodes\n",
    "        print(f\"\\n Distribution des tailles de nodes:\")\n",
    "        print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "        print(f\"   Max: {node_sizes.max():.0f} cellules\")\n",
    "        print(f\"   Moyenne: {node_sizes.mean():.0f} cellules\")\n",
    "        \n",
    "    else:\n",
    "        print(\"[!] Coordonn√©es de grille non disponibles dans cluster_data.obsm['grid']\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur visualisation grille: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714730ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ARBRE MST EN MATPLOTLIB (alternative)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"G√©n√©ration de l'arbre MST...\")\n",
    "\n",
    "try:\n",
    "    # R√©cup√©rer les coordonn√©es du layout MST\n",
    "    layout = cluster_data.obsm.get('layout', None)\n",
    "    \n",
    "    if layout is not None:\n",
    "        # Clustering et metaclustering\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        \n",
    "        # Calculer la taille de chaque node\n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        # Normaliser les tailles\n",
    "        max_size = node_sizes.max() if node_sizes.max() > 0 else 1\n",
    "        sizes = 100 + (node_sizes / max_size) * 800\n",
    "        \n",
    "        # Couleurs par m√©tacluster\n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        colors = [cmap(int(m) / max(n_meta - 1, 1)) for m in metaclustering_nodes]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        # Scatter des nodes\n",
    "        scatter = ax.scatter(layout[:, 0], layout[:, 1], \n",
    "                           s=sizes, c=colors, edgecolors='white', \n",
    "                           linewidths=1.5, alpha=0.9, zorder=2)\n",
    "        \n",
    "        # Annoter avec les num√©ros\n",
    "        for i in range(n_nodes):\n",
    "            ax.annotate(str(int(metaclustering_nodes[i])), \n",
    "                       (layout[i, 0], layout[i, 1]),\n",
    "                       ha='center', va='center', fontsize=8, \n",
    "                       color='white', fontweight='bold')\n",
    "        \n",
    "        ax.set_xlabel('xNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('yNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Arbre MST - {n_nodes} nodes, {n_meta} m√©taclusters', \n",
    "                    fontsize=14, fontweight='bold', pad=15)\n",
    "        ax.grid(True, alpha=0.15, linestyle='--')\n",
    "        \n",
    "        # L√©gende\n",
    "        from matplotlib.patches import Patch\n",
    "        if n_meta <= 15:\n",
    "            legend_elements = [Patch(facecolor=cmap(i/max(n_meta-1, 1)), \n",
    "                                    label=f'MC {i}') for i in range(n_meta)]\n",
    "            ax.legend(handles=legend_elements, loc='center left', \n",
    "                     bbox_to_anchor=(1.02, 0.5), fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"[!] Layout MST non disponible\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"[!] Erreur MST: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION PAR CONDITION (Sain vs Pathologique)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Distribution des m√©taclusters par condition...\")\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "conditions = cell_data.obs['condition'].values\n",
    "\n",
    "healthy_pcts = []\n",
    "patho_pcts = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask_cluster = metaclustering == i\n",
    "    \n",
    "    # Pourcentage dans Sain\n",
    "    mask_healthy = (conditions == 'Sain') & mask_cluster\n",
    "    total_healthy = (conditions == 'Sain').sum()\n",
    "    healthy_pcts.append((mask_healthy.sum() / total_healthy * 100) if total_healthy > 0 else 0)\n",
    "    \n",
    "    # Pourcentage dans Pathologique\n",
    "    mask_patho = (conditions == 'Pathologique') & mask_cluster\n",
    "    total_patho = (conditions == 'Pathologique').sum()\n",
    "    patho_pcts.append((mask_patho.sum() / total_patho * 100) if total_patho > 0 else 0)\n",
    "\n",
    "# Cr√©er le graphique\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x = np.arange(N_CLUSTERS)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, healthy_pcts, width, label='Sain (NBM)', \n",
    "               color='#a6e3a1', edgecolor='white', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, patho_pcts, width, label='Pathologique', \n",
    "               color='#f38ba8', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('M√©tacluster', fontsize=12)\n",
    "ax.set_ylabel('Pourcentage (%)', fontsize=12)\n",
    "ax.set_title('Distribution des M√©taclusters par Condition', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    if height > 1:  # N'afficher que si > 1%\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3), textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau r√©capitulatif\n",
    "print(\"\\nTableau r√©capitulatif:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'MC':>4} | {'Sain (%)':>10} | {'Patho (%)':>10} | {'Diff':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(N_CLUSTERS):\n",
    "    diff = patho_pcts[i] - healthy_pcts[i]\n",
    "    print(f\"{i:>4} | {healthy_pcts[i]:>10.2f} | {patho_pcts[i]:>10.2f} | {diff:>+8.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acff00",
   "metadata": {},
   "source": [
    "## 11. Analyse D√©taill√©e des M√©taclusters\n",
    "\n",
    "Statistiques approfondies par m√©tacluster:\n",
    "- Nombre de cellules\n",
    "- MFI par marqueur\n",
    "- Ph√©notype caract√©ristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATISTIQUES PAR M√âTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" STATISTIQUES PAR M√âTACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er un DataFrame de statistiques\n",
    "stats_data = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    n_cells = mask.sum()\n",
    "    pct_total = n_cells / len(metaclustering) * 100\n",
    "    \n",
    "    # Calculer MFI pour chaque marqueur\n",
    "    mfi = np.nanmean(X[mask][:, cols_to_use], axis=0) if n_cells > 0 else np.zeros(len(cols_to_use))\n",
    "    \n",
    "    # Top 3 marqueurs les plus exprim√©s\n",
    "    top_indices = np.argsort(mfi)[::-1][:3]\n",
    "    top_markers = [used_markers[idx] for idx in top_indices]\n",
    "    \n",
    "    stats_data.append({\n",
    "        'Metacluster': i,\n",
    "        'N_Cells': n_cells,\n",
    "        'Pct_Total': pct_total,\n",
    "        'Top_Markers': ', '.join(top_markers)\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats_data)\n",
    "print(df_stats.to_string(index=False))\n",
    "\n",
    "# Graphique camembert\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Pie chart des tailles\n",
    "ax = axes[0]\n",
    "sizes = [s['N_Cells'] for s in stats_data]\n",
    "labels = [f\"MC{s['Metacluster']}\" for s in stats_data]\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, N_CLUSTERS))\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, \n",
    "                                   autopct='%1.1f%%', pctdistance=0.8)\n",
    "ax.set_title('Distribution des Cellules par M√©tacluster', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Bar chart des tailles\n",
    "ax = axes[1]\n",
    "ax.barh(range(N_CLUSTERS), sizes, color=colors, edgecolor='white')\n",
    "ax.set_yticks(range(N_CLUSTERS))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Nombre de cellules')\n",
    "ax.set_title('Taille des M√©taclusters', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c773749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROFIL D'EXPRESSION D√âTAILL√â PAR M√âTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n PROFIL D'EXPRESSION MOYEN PAR M√âTACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er un DataFrame avec MFI par marqueur et m√©tacluster\n",
    "mfi_matrix = np.zeros((N_CLUSTERS, len(used_markers)))\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    if mask.sum() > 0:\n",
    "        mfi_matrix[i] = np.nanmean(X[mask][:, cols_to_use], axis=0)\n",
    "\n",
    "df_mfi = pd.DataFrame(mfi_matrix, \n",
    "                       columns=used_markers,\n",
    "                       index=[f'MC{i}' for i in range(N_CLUSTERS)])\n",
    "\n",
    "# Afficher le tableau format√©\n",
    "print(df_mfi.round(2).to_string())\n",
    "\n",
    "# Visualisation Radar/Spider plot pour les clusters principaux\n",
    "from math import pi\n",
    "\n",
    "# S√©lectionner les 5 plus gros clusters\n",
    "top_clusters = df_stats.nlargest(5, 'N_Cells')['Metacluster'].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "\n",
    "angles = [n / float(len(used_markers)) * 2 * pi for n in range(len(used_markers))]\n",
    "angles += angles[:1]  # Fermer le polygone\n",
    "\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(top_clusters)))\n",
    "\n",
    "for idx, cluster_id in enumerate(top_clusters):\n",
    "    values = mfi_matrix[cluster_id].tolist()\n",
    "    # Normaliser entre 0 et 1 pour la visualisation\n",
    "    values_norm = (values - np.min(values)) / (np.max(values) - np.min(values) + 1e-10)\n",
    "    values_norm = values_norm.tolist()\n",
    "    values_norm += values_norm[:1]\n",
    "    \n",
    "    ax.plot(angles, values_norm, 'o-', linewidth=2, label=f'MC{cluster_id}', color=colors[idx])\n",
    "    ax.fill(angles, values_norm, alpha=0.1, color=colors[idx])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(used_markers, size=9)\n",
    "ax.set_title('Profil d\\'Expression Normalis√© des 5 Plus Gros M√©taclusters', \n",
    "             fontsize=12, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc989dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANALYSE DES CLUSTERS EXCLUSIFS (mono-condition)\n",
    "# =============================================================================\n",
    "# Identification des clusters contenant UNIQUEMENT des cellules d'une condition\n",
    "# Utile pour d√©tecter les populations pathologiques sp√©cifiques\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" ANALYSE DES CLUSTERS EXCLUSIFS PAR CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# R√©cup√©rer les conditions des cellules\n",
    "cell_conditions = adata_flowsom.obs['condition'].values\n",
    "unique_conditions = np.unique(cell_conditions)\n",
    "\n",
    "print(f\"\\nConditions pr√©sentes: {list(unique_conditions)}\")\n",
    "print(f\"Nombre de metaclusters: {n_meta}\")\n",
    "\n",
    "# Analyse par metacluster\n",
    "clusters_patho_only = []\n",
    "clusters_sain_only = []\n",
    "clusters_mixed = []\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\" METACLUSTERS EXCLUSIFS (100% d'une seule condition)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cluster_id in range(1, n_meta + 1):\n",
    "    mask_cluster = (metaclustering_cells == cluster_id)\n",
    "    n_cluster = mask_cluster.sum()\n",
    "    \n",
    "    if n_cluster == 0:\n",
    "        continue\n",
    "    \n",
    "    # Compter les cellules par condition dans ce cluster\n",
    "    conditions_in_cluster = cell_conditions[mask_cluster]\n",
    "    \n",
    "    # Calculer les proportions\n",
    "    condition_counts = {}\n",
    "    for cond in unique_conditions:\n",
    "        count = (conditions_in_cluster == cond).sum()\n",
    "        condition_counts[cond] = count\n",
    "    \n",
    "    # V√©rifier si le cluster est exclusif √† une condition\n",
    "    total = sum(condition_counts.values())\n",
    "    \n",
    "    # Cluster 100% pathologique\n",
    "    if \"Pathologique\" in condition_counts and condition_counts.get(\"Pathologique\", 0) == total:\n",
    "        clusters_patho_only.append((cluster_id, total))\n",
    "        print(f\"   [PATHO] Metacluster {cluster_id:2d}: {total:6,} cellules (100% Pathologique)\")\n",
    "    \n",
    "    # Cluster 100% sain\n",
    "    elif \"Sain\" in condition_counts and condition_counts.get(\"Sain\", 0) == total:\n",
    "        clusters_sain_only.append((cluster_id, total))\n",
    "        print(f\"   [SAIN]  Metacluster {cluster_id:2d}: {total:6,} cellules (100% Sain)\")\n",
    "    \n",
    "    else:\n",
    "        clusters_mixed.append(cluster_id)\n",
    "\n",
    "# R√©sum√©\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" R√âSUM√â\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if clusters_patho_only:\n",
    "    total_patho_exclusive = sum([c[1] for c in clusters_patho_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% PATHOLOGIQUES: {len(clusters_patho_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_patho_only]}\")\n",
    "    print(f\"    Total cellules: {total_patho_exclusive:,}\")\n",
    "    print(f\"    ‚Üí Ces clusters repr√©sentent des populations UNIQUEMENT pr√©sentes chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement pathologique d√©tect√©\")\n",
    "\n",
    "if clusters_sain_only:\n",
    "    total_sain_exclusive = sum([c[1] for c in clusters_sain_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% SAINS: {len(clusters_sain_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_sain_only]}\")\n",
    "    print(f\"    Total cellules: {total_sain_exclusive:,}\")\n",
    "    print(f\"    ‚Üí Ces clusters repr√©sentent des populations ABSENTES chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement sain d√©tect√©\")\n",
    "\n",
    "print(f\"\\n    Clusters mixtes (partag√©s): {len(clusters_mixed)}\")\n",
    "\n",
    "# Visualisation si clusters exclusifs pathologiques\n",
    "if clusters_patho_only and len(clusters_patho_only) > 0:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" D√âTAIL DES CLUSTERS PATHOLOGIQUES EXCLUSIFS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Calculer le MFI des marqueurs pour ces clusters\n",
    "    for cluster_id, n_cells in clusters_patho_only:\n",
    "        mask_c = (metaclustering_cells == cluster_id)\n",
    "        print(f\"\\n   Metacluster {cluster_id} ({n_cells:,} cellules):\")\n",
    "        \n",
    "        # Top 3 marqueurs les plus exprim√©s\n",
    "        mfi_cluster = adata_flowsom.X[mask_c].mean(axis=0)\n",
    "        top_3_idx = np.argsort(mfi_cluster)[-3:][::-1]\n",
    "        print(f\"      Top marqueurs: \", end=\"\")\n",
    "        for idx in top_3_idx:\n",
    "            marker_name = adata_flowsom.var_names[idx]\n",
    "            print(f\"{marker_name}({mfi_cluster[idx]:.2f}) \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0c0fd",
   "metadata": {},
   "source": [
    "## 12. Export des R√©sultats\n",
    "\n",
    "Sauvegarde des r√©sultats d'analyse:\n",
    "- **CSV**: Tableau avec m√©taclusters assign√©s √† chaque cellule\n",
    "- **FCS**: Fichier FCS avec colonne m√©tacluster ajout√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT CSV/FCS AVEC COORDONN√âES SOM (style FlowSOM R EXACT)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Cr√©er le dossier de sortie\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\" PR√âPARATION DES DONN√âES POUR EXPORT (style FlowSOM R EXACT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# PARAM√àTRES DE JITTER - STYLE FLOWSOM R EXACT\n",
    "# Dans FlowSOM R, le jitter est CIRCULAIRE (pas carr√©!)\n",
    "# La taille du cercle d√©pend du nombre de cellules dans le cluster\n",
    "# Formule R: rnorm() * scale_factor * sqrt(node_size/max_size)\n",
    "# =====================================================================\n",
    "np.random.seed(SEED)  # Pour reproductibilit√©\n",
    "\n",
    "# Param√®tres FlowSOM R\n",
    "MAX_NODE_SIZE = 0.45  # Rayon maximum du cercle (quand le node est le plus grand)\n",
    "MIN_NODE_SIZE = 0.1   # Rayon minimum du cercle (pour √©viter que les petits nodes disparaissent)\n",
    "\n",
    "# R√©cup√©rer les coordonn√©es de grille et MST depuis cluster_data\n",
    "grid_coords = cluster_data.obsm.get('grid', None)\n",
    "layout_coords = cluster_data.obsm.get('layout', None)\n",
    "\n",
    "# R√©cup√©rer le clustering pour mapper les coordonn√©es sur chaque cellule\n",
    "clustering = cell_data.obs['clustering'].values\n",
    "n_cells = len(clustering)\n",
    "n_nodes = len(cluster_data)\n",
    "\n",
    "# Calculer la taille de chaque node (nombre de cellules)\n",
    "node_sizes = np.zeros(n_nodes, dtype=np.float32)\n",
    "for i in range(n_nodes):\n",
    "    node_sizes[i] = (clustering == i).sum()\n",
    "\n",
    "max_size = node_sizes.max()\n",
    "print(f\"\\n Taille des nodes:\")\n",
    "print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "print(f\"   Max: {max_size:.0f} cellules\")\n",
    "print(f\"   Total: {n_cells} cellules\")\n",
    "\n",
    "# Cr√©er un DataFrame avec toutes les donn√©es\n",
    "df_export = pd.DataFrame(X, columns=var_names)\n",
    "\n",
    "# MetaCluster avec +1 pour Kaluza (√©viter le 0, commencer √† 1)\n",
    "df_export['FlowSOM_metacluster'] = metaclustering + 1\n",
    "\n",
    "# FlowSOM cluster (nodes) avec +1\n",
    "df_export['FlowSOM_cluster'] = clustering + 1\n",
    "\n",
    "# Ajouter les m√©tadonn√©es si disponibles\n",
    "if 'condition' in cell_data.obs.columns:\n",
    "    df_export['Condition'] = cell_data.obs['condition'].values\n",
    "    df_export['Condition_Num'] = np.where(df_export['Condition'] == 'Sain', 1, 2)\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    df_export['File_Origin'] = cell_data.obs['file_origin'].values\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R exact)\n",
    "# G√©n√®re des points distribu√©s uniform√©ment dans un disque\n",
    "# Le rayon d√©pend de la taille du cluster\n",
    "# =====================================================================\n",
    "def circular_jitter(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    G√©n√®re un jitter circulaire style FlowSOM R.\n",
    "    \n",
    "    Dans FlowSOM R, les cellules sont distribu√©es dans des cercles\n",
    "    dont le rayon d√©pend du nombre de cellules dans le node.\n",
    "    Plus un node a de cellules, plus le cercle est grand.\n",
    "    \n",
    "    M√©thode: \n",
    "    - Angle theta uniforme [0, 2*pi]\n",
    "    - Rayon r = sqrt(u) * max_r (pour distribution uniforme dans le disque)\n",
    "    - Le max_r d√©pend de la taille du node\n",
    "    \"\"\"\n",
    "    # Angle uniforme autour du cercle\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    \n",
    "    # Rayon - distribution uniforme dans le disque (sqrt pour uniformit√©)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    # Calculer le rayon pour chaque cellule selon la taille de son cluster\n",
    "    # Dans FlowSOM R, le rayon est proportionnel √† sqrt(node_size/max_size)\n",
    "    max_size_val = node_sizes.max()\n",
    "    \n",
    "    # Rayon pour chaque cellule\n",
    "    radii = np.zeros(n_points, dtype=np.float32)\n",
    "    for i in range(n_points):\n",
    "        node_id = int(cluster_ids[i])\n",
    "        node_size = node_sizes[node_id]\n",
    "        # Rayon proportionnel √† sqrt(taille relative)\n",
    "        size_ratio = np.sqrt(node_size / max_size_val)\n",
    "        # Interpolation entre min et max radius\n",
    "        node_radius = min_radius + (max_radius - min_radius) * size_ratio\n",
    "        radii[i] = node_radius\n",
    "    \n",
    "    # Rayon final pour distribution uniforme dans le disque\n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    # Convertir en coordonn√©es cart√©siennes\n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONN√âES GRILLE SOM (xGrid, yGrid) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "print(f\"\\n Application du jitter CIRCULAIRE style FlowSOM R\")\n",
    "print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "\n",
    "if grid_coords is not None:\n",
    "    # G√©n√©rer jitter CIRCULAIRE d√©pendant de la taille du node\n",
    "    jitter_x, jitter_y = circular_jitter(n_cells, clustering, node_sizes, \n",
    "                                          max_radius=MAX_NODE_SIZE, \n",
    "                                          min_radius=MIN_NODE_SIZE)\n",
    "    \n",
    "    # Mapper les coordonn√©es de grille sur chaque cellule\n",
    "    xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "    yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "    \n",
    "    # Appliquer le jitter circulaire\n",
    "    xGrid_jittered = xGrid_base + jitter_x\n",
    "    yGrid_jittered = yGrid_base + jitter_y\n",
    "    \n",
    "    # D√©caler pour que les axes commencent √† 1 (X ET Y)\n",
    "    xGrid = xGrid_jittered - xGrid_jittered.min() + 1.0\n",
    "    yGrid = yGrid_jittered - yGrid_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xGrid'] = xGrid.astype(np.float32)\n",
    "    df_export['yGrid'] = yGrid.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xGrid: [{xGrid.min():.3f} - {xGrid.max():.3f}]\")\n",
    "    print(f\"[OK] yGrid: [{yGrid.min():.3f} - {yGrid.max():.3f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONN√âES MST (xNodes, yNodes) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "if layout_coords is not None:\n",
    "    # Mapper les coordonn√©es MST sur chaque cellule\n",
    "    xNodes_base = np.array([layout_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "    yNodes_base = np.array([layout_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "    \n",
    "    # Calculer l'√©chelle pour le jitter MST (proportionnel √† l'espacement moyen)\n",
    "    x_range = xNodes_base.max() - xNodes_base.min()\n",
    "    y_range = yNodes_base.max() - yNodes_base.min()\n",
    "    mst_scale = min(x_range, y_range) / (XDIM * 2)  # Proportionnel √† la grille\n",
    "    \n",
    "    # Jitter circulaire pour MST aussi\n",
    "    mst_jitter_x, mst_jitter_y = circular_jitter(\n",
    "        n_cells, clustering, node_sizes,\n",
    "        max_radius=mst_scale * 0.8,  # Un peu moins que Grid car MST est plus espac√©\n",
    "        min_radius=mst_scale * 0.2\n",
    "    )\n",
    "    \n",
    "    # Appliquer le jitter\n",
    "    xNodes_jittered = xNodes_base + mst_jitter_x\n",
    "    yNodes_jittered = yNodes_base + mst_jitter_y\n",
    "    \n",
    "    # D√©caler pour que les axes commencent √† 1 (X ET Y)\n",
    "    xNodes = xNodes_jittered - xNodes_jittered.min() + 1.0\n",
    "    yNodes = yNodes_jittered - yNodes_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xNodes'] = xNodes.astype(np.float32)\n",
    "    df_export['yNodes'] = yNodes.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xNodes: [{xNodes.min():.3f} - {xNodes.max():.3f}]\")\n",
    "    print(f\"[OK] yNodes: [{yNodes.min():.3f} - {yNodes.max():.3f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# TAILLE DES NODES (pour chaque cellule)\n",
    "# =====================================================================\n",
    "size_col = np.array([node_sizes[int(c)] for c in clustering], dtype=np.float32)\n",
    "df_export['size'] = size_col\n",
    "print(f\"[OK] size: [{size_col.min():.0f} - {size_col.max():.0f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT CSV\n",
    "# =====================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_path = os.path.join(OUTPUT_DIR, f\"flowsom_results_{timestamp}.csv\")\n",
    "df_export.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n[OK] CSV export√©: {csv_path}\")\n",
    "print(f\"   Shape: {df_export.shape}\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT FCS COMPATIBLE KALUZA\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÑ EXPORT FCS COMPATIBLE KALUZA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def export_to_fcs_kaluza(df, output_path):\n",
    "    \"\"\"Export FCS compatible Kaluza avec toutes les coordonn√©es positives.\"\"\"\n",
    "    try:\n",
    "        import fcswrite\n",
    "        \n",
    "        numeric_df = df.select_dtypes(include=[np.number])\n",
    "        data = numeric_df.values.astype(np.float32)\n",
    "        channels = list(numeric_df.columns)\n",
    "        \n",
    "        # Nettoyer NaN/Inf\n",
    "        data = np.nan_to_num(data, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "        \n",
    "        print(f\"   {data.shape[0]:,} events, {data.shape[1]} canaux\")\n",
    "        \n",
    "        fcswrite.write_fcs(output_path, channels, data, compat_chn_names=True)\n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"   [!] fcswrite non disponible (pip install fcswrite)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "# Pr√©parer le DataFrame FCS\n",
    "df_fcs = df_export.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# V√©rifier les ranges\n",
    "print(f\"\\n Colonnes export√©es vers FCS:\")\n",
    "for col in ['FlowSOM_metacluster', 'FlowSOM_cluster', 'xGrid', 'yGrid', 'xNodes', 'yNodes', 'size', 'Condition_Num']:\n",
    "    if col in df_fcs.columns:\n",
    "        print(f\"   [OK] {col:25s}: [{df_fcs[col].min():10.2f}, {df_fcs[col].max():10.2f}]\")\n",
    "\n",
    "# Export\n",
    "fcs_path = os.path.join(OUTPUT_DIR, f\"flowsom_results_{timestamp}.fcs\")\n",
    "if export_to_fcs_kaluza(df_fcs, fcs_path):\n",
    "    print(f\"\\n[OK] FCS export√©: {fcs_path}\")\n",
    "    print(f\"\\n Dans Kaluza/FlowJo:\")\n",
    "    print(f\"   - xGrid vs yGrid ‚Üí visualisation grille SOM (cercles style FlowSOM R)\")\n",
    "    print(f\"   - xNodes vs yNodes ‚Üí visualisation arbre MST\")\n",
    "    print(f\"   - La taille des cercles = proportionnelle au nombre de cellules\")\n",
    "    print(f\"   - Colorez par FlowSOM_metacluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT DU RAPPORT DE STATISTIQUES\n",
    "# =============================================================================\n",
    "\n",
    "# Sauvegarder le rapport de statistiques\n",
    "stats_path = os.path.join(OUTPUT_DIR, f\"flowsom_statistics_{timestamp}.csv\")\n",
    "df_stats.to_csv(stats_path, index=False)\n",
    "print(f\"[OK] Statistiques export√©es: {stats_path}\")\n",
    "\n",
    "# Sauvegarder la matrice MFI\n",
    "mfi_path = os.path.join(OUTPUT_DIR, f\"flowsom_mfi_matrix_{timestamp}.csv\")\n",
    "df_mfi.to_csv(mfi_path)\n",
    "print(f\"[OK] Matrice MFI export√©e: {mfi_path}\")\n",
    "\n",
    "# R√©sum√© final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" R√âSUM√â DE L'ANALYSE FLOWSOM\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Fichiers analys√©s: {len(all_adatas)}\")\n",
    "print(f\"   Cellules totales: {len(cell_data)}\")\n",
    "print(f\"   Marqueurs utilis√©s: {len(used_markers)}\")\n",
    "print(f\"   Nombre de m√©taclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Transformation: {TRANSFORM_TYPE}\")\n",
    "print(f\"   Cofacteur: {COFACTOR}\")\n",
    "print(\"=\"*80)\n",
    "print(\"[OK] Analyse FlowSOM termin√©e avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECTION DES VARIABLES DU NOTEBOOK\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" LISTE DES OBJETS AnnData\")\n",
    "print(\"=\"*70)\n",
    "%who AnnData\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" LISTE DES DataFrames\")\n",
    "print(\"=\"*70)\n",
    "%who DataFrame\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" D√âTAILS DE adata_flowsom\")\n",
    "print(\"=\"*70)\n",
    "print(adata_flowsom)\n",
    "\n",
    "print(\"\\n- Shape:\", adata_flowsom.shape)\n",
    "print(\"- Variables (colonnes):\", list(adata_flowsom.var_names))\n",
    "print(\"- Observations (fichiers):\", adata_flowsom.obs.columns.tolist() if len(adata_flowsom.obs.columns) > 0 else \"Aucune annotation\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Statistiques de la matrice X:\")\n",
    "print(\"-\"*70)\n",
    "import pandas as pd\n",
    "stats = pd.DataFrame({\n",
    "    'Colonne': adata_flowsom.var_names,\n",
    "    'Min': adata_flowsom.X.min(axis=0),\n",
    "    'Max': adata_flowsom.X.max(axis=0),\n",
    "    'Moyenne': adata_flowsom.X.mean(axis=0),\n",
    "    'Std': adata_flowsom.X.std(axis=0)\n",
    "})\n",
    "display(stats)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Aper√ßu des observations (.obs):\")\n",
    "print(\"-\"*70)\n",
    "if adata_flowsom.obs.shape[1] > 0:\n",
    "    display(adata_flowsom.obs.head(10))\n",
    "else:\n",
    "    print(\"Aucune annotation dans .obs\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Toutes les variables disponibles:\")\n",
    "print(\"-\"*70)\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e481f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FLOWSOM SUMMARY - RAPPORT PDF COMPLET\n",
    "# =============================================================================\n",
    "# G√©n√©ration automatique d'un PDF r√©capitulatif avec toutes les visualisations\n",
    "# Documentation: https://flowsom.readthedocs.io/en/stable/generated/flowsom.pl.FlowSOMmary.html\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Chemin du fichier PDF de sortie\n",
    "summary_pdf_path = os.path.join(OUTPUT_DIR, f\"FlowSOMmary_{timestamp}.pdf\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" G√âN√âRATION DU RAPPORT FlowSOMmary (PDF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # G√©n√©ration du rapport FlowSOMmary\n",
    "    # Inclut: marker_diff, cluster_profiles, grid, mst\n",
    "    # Exclut: UMAP (non demand√©)\n",
    "    fs.pl.FlowSOMmary(\n",
    "        fsom,\n",
    "        plot_file=summary_pdf_path\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[OK] Rapport PDF g√©n√©r√© avec succ√®s!\")\n",
    "    print(f\"    Fichier: {summary_pdf_path}\")\n",
    "    print(f\"\\n    Contenu du rapport:\")\n",
    "    print(f\"    - Star plots (profils MFI par cluster)\")\n",
    "    print(f\"    - Grid SOM avec metaclusters\")\n",
    "    print(f\"    - Arbre MST avec metaclusters\")\n",
    "    print(f\"    - Heatmap des marqueurs par cluster\")\n",
    "    print(f\"    - Distribution des tailles de clusters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n[!] Erreur lors de la g√©n√©ration du FlowSOMmary:\")\n",
    "    print(f\"    {str(e)}\")\n",
    "    print(f\"\\n    Tentative de g√©n√©ration manuelle des graphiques...\")\n",
    "    \n",
    "    # Alternative: g√©n√©rer les graphiques individuellement\n",
    "    try:\n",
    "        from matplotlib.backends.backend_pdf import PdfPages\n",
    "        \n",
    "        with PdfPages(summary_pdf_path) as pdf:\n",
    "            # 1. Star plots par metacluster\n",
    "            print(\"    - G√©n√©ration des star plots...\")\n",
    "            fig_stars = fs.pl.plot_stars(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_stars, bbox_inches='tight')\n",
    "            plt.close(fig_stars)\n",
    "            \n",
    "            # 2. Grid SOM\n",
    "            print(\"    - G√©n√©ration de la grille SOM...\")\n",
    "            fig_grid = fs.pl.plot_grid(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_grid, bbox_inches='tight')\n",
    "            plt.close(fig_grid)\n",
    "            \n",
    "            # 3. Arbre MST\n",
    "            print(\"    - G√©n√©ration de l'arbre MST...\")\n",
    "            fig_mst = fs.pl.plot_mst(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_mst, bbox_inches='tight')\n",
    "            plt.close(fig_mst)\n",
    "            \n",
    "            # 4. Marker heatmap\n",
    "            print(\"    - G√©n√©ration de la heatmap des marqueurs...\")\n",
    "            fig_heatmap = fs.pl.plot_marker_heatmap(fsom)\n",
    "            pdf.savefig(fig_heatmap, bbox_inches='tight')\n",
    "            plt.close(fig_heatmap)\n",
    "            \n",
    "        print(f\"\\n[OK] Rapport PDF alternatif g√©n√©r√©!\")\n",
    "        print(f\"    Fichier: {summary_pdf_path}\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"\\n[X] Impossible de g√©n√©rer le rapport: {str(e2)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FIN DE L'ANALYSE FlowSOM\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
