{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563bddce",
   "metadata": {},
   "source": [
    "# FlowSOM Analysis Pipeline - Notebook Headless\n",
    "\n",
    "## Pipeline complÃ¨te d'analyse FlowSOM pour donnÃ©es de cytomÃ©trie en flux\n",
    "\n",
    "Ce notebook \"miroir\" de l'application FlowSOM Analyzer permet:\n",
    "- **Debug & Introspection**: Visualiser les donnÃ©es Ã  chaque Ã©tape\n",
    "- **Tuning rapide**: Tester diffÃ©rents paramÃ¨tres sans relancer l'app\n",
    "- **SÃ©paration des responsabilitÃ©s**: Logique mÃ©tier pure, sans UI\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Florian Magne\n",
    "**Version**: 1.0\n",
    "**Date**: Janvier 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fa351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PANNEAU DE CONFIGURATION INTERACTIF â€” Tous les paramÃ¨tres du pipeline\n",
    "# =============================================================================\n",
    "# ExÃ©cuter cette cellule en PREMIER pour configurer l'analyse via widgets.\n",
    "# Les valeurs sont stockÃ©es dans un dictionnaire global CONFIG puis injectÃ©es\n",
    "# dans les variables du notebook lorsque vous cliquez sur \"Appliquer\".\n",
    "# =============================================================================\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€ Ã‰tat global de la configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CONFIG = {}\n",
    "\n",
    "def build_config_panel():\n",
    "    \"\"\"Construit et affiche le panneau de configuration interactif.\"\"\"\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  STYLE GLOBAL\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    style = {'description_width': '200px'}\n",
    "    layout_wide = widgets.Layout(width='520px')\n",
    "    layout_slider = widgets.Layout(width='520px')\n",
    "    layout_path = widgets.Layout(width='620px')\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  SECTION 1 â€” CHEMINS & MODE D'ANALYSE\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    w_healthy_folder = widgets.Text(\n",
    "        value=r\"C:\\Users\\Florian Travail\\Documents\\FlowSom\\Data\\Moelle normale\",\n",
    "        description='Dossier Sain (NBM):',\n",
    "        style=style, layout=layout_path,\n",
    "        placeholder='Chemin vers les FCS sains'\n",
    "    )\n",
    "    w_patho_folder = widgets.Text(\n",
    "        value=r\"Data/Patho\",\n",
    "        description='Dossier Pathologique:',\n",
    "        style=style, layout=layout_path,\n",
    "        placeholder='Chemin vers les FCS pathologiques'\n",
    "    )\n",
    "    w_compare_mode = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Mode comparaison (Sain vs Pathologique)',\n",
    "        style=style, layout=layout_wide,\n",
    "        indent=False\n",
    "    )\n",
    "\n",
    "    sec1 = widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"margin:0;color:#1565C0;\">Chemins & Mode d\\'analyse</h3>'),\n",
    "        w_healthy_folder, w_patho_folder, w_compare_mode\n",
    "    ], layout=widgets.Layout(padding='8px', border='1px solid #BBDEFB',\n",
    "                             border_radius='8px', margin='4px 0'))\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  SECTION 2 â€” PRE-GATING\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    w_apply_pregating = widgets.Checkbox(\n",
    "        value=True, description='Activer le prÃ©-gating',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_gating_mode = widgets.Dropdown(\n",
    "        options=[('Automatique (GMM adaptatif)', 'auto'),\n",
    "                 ('Manuel (percentiles)', 'manual')],\n",
    "        value='auto', description='Mode de gating:',\n",
    "        style=style, layout=layout_wide\n",
    "    )\n",
    "    w_mode_blastes = widgets.Checkbox(\n",
    "        value=True, description='Mode Blastes vs Normal',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    # Gate 1: DÃ©bris\n",
    "    w_gate_debris = widgets.Checkbox(\n",
    "        value=True, description='Gate DÃ©bris (FSC/SSC)',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_debris_min = widgets.FloatSlider(\n",
    "        value=1.0, min=0.0, max=10.0, step=0.5,\n",
    "        description='DÃ©bris min %ile:',\n",
    "        style=style, layout=layout_slider, readout_format='.1f'\n",
    "    )\n",
    "    w_debris_max = widgets.FloatSlider(\n",
    "        value=99.0, min=90.0, max=100.0, step=0.5,\n",
    "        description='DÃ©bris max %ile:',\n",
    "        style=style, layout=layout_slider, readout_format='.1f'\n",
    "    )\n",
    "    # Gate 2: Doublets\n",
    "    w_gate_doublets = widgets.Checkbox(\n",
    "        value=True, description='Gate Doublets (FSC-A/FSC-H)',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_ratio_min = widgets.FloatSlider(\n",
    "        value=0.6, min=0.1, max=1.0, step=0.05,\n",
    "        description='Ratio FSC min:',\n",
    "        style=style, layout=layout_slider, readout_format='.2f'\n",
    "    )\n",
    "    w_ratio_max = widgets.FloatSlider(\n",
    "        value=1.4, min=1.0, max=2.5, step=0.05,\n",
    "        description='Ratio FSC max:',\n",
    "        style=style, layout=layout_slider, readout_format='.2f'\n",
    "    )\n",
    "    # Gate 3: CD45\n",
    "    w_gate_cd45 = widgets.Checkbox(\n",
    "        value=True, description='Gate CD45+ (leucocytes)',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_cd45_pct = widgets.IntSlider(\n",
    "        value=5, min=0, max=30, step=1,\n",
    "        description='CD45 seuil %ile:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    # Gate 4: CD34\n",
    "    w_filter_blasts = widgets.Checkbox(\n",
    "        value=False, description='Filtrer Blastes CD34+',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_cd34_pct = widgets.IntSlider(\n",
    "        value=85, min=50, max=99, step=1,\n",
    "        description='CD34 seuil %ile:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_ssc_filter = widgets.Checkbox(\n",
    "        value=True, description='  + Filtre SSC low pour blastes',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_ssc_max_pct = widgets.IntSlider(\n",
    "        value=70, min=30, max=95, step=5,\n",
    "        description='SSC max %ile blastes:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "\n",
    "    sec2 = widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"margin:0;color:#2E7D32;\">PrÃ©-gating</h3>'),\n",
    "        w_apply_pregating, w_gating_mode, w_mode_blastes,\n",
    "        widgets.HTML('<hr style=\"margin:4px 0;border-color:#C8E6C9;\">'),\n",
    "        w_gate_debris, w_debris_min, w_debris_max,\n",
    "        widgets.HTML('<hr style=\"margin:4px 0;border-color:#C8E6C9;\">'),\n",
    "        w_gate_doublets, w_ratio_min, w_ratio_max,\n",
    "        widgets.HTML('<hr style=\"margin:4px 0;border-color:#C8E6C9;\">'),\n",
    "        w_gate_cd45, w_cd45_pct,\n",
    "        widgets.HTML('<hr style=\"margin:4px 0;border-color:#C8E6C9;\">'),\n",
    "        w_filter_blasts, w_cd34_pct, w_ssc_filter, w_ssc_max_pct\n",
    "    ], layout=widgets.Layout(padding='8px', border='1px solid #C8E6C9',\n",
    "                             border_radius='8px', margin='4px 0'))\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  SECTION 3 â€” TRANSFORMATION\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    w_transform = widgets.Dropdown(\n",
    "        options=[('Logicle (biexponentielle)', 'logicle'),\n",
    "                 ('Arcsinh (inverse hyperbolique)', 'arcsinh'),\n",
    "                 ('Log10', 'log10'),\n",
    "                 ('Aucune', 'none')],\n",
    "        value='logicle', description='Transformation:',\n",
    "        style=style, layout=layout_wide\n",
    "    )\n",
    "    w_cofactor = widgets.IntSlider(\n",
    "        value=5, min=1, max=500, step=1,\n",
    "        description='Cofacteur (arcsinh):',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_apply_scatter = widgets.Checkbox(\n",
    "        value=False, description='Appliquer au scatter',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "\n",
    "    sec3 = widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"margin:0;color:#E65100;\">Transformation</h3>'),\n",
    "        w_transform, w_cofactor, w_apply_scatter\n",
    "    ], layout=widgets.Layout(padding='8px', border='1px solid #FFE0B2',\n",
    "                             border_radius='8px', margin='4px 0'))\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  SECTION 4 â€” SÃ‰LECTION DES MARQUEURS\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    w_exclude_scatter = widgets.Checkbox(\n",
    "        value=True, description='Exclure FSC/SSC/Time',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_exclude_markers = widgets.Text(\n",
    "        value='CD45',\n",
    "        description='Marqueurs exclus (,):',\n",
    "        style=style, layout=layout_path,\n",
    "        placeholder='SÃ©parer par des virgules, ex: CD45, CD34'\n",
    "    )\n",
    "\n",
    "    sec4 = widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"margin:0;color:#6A1B9A;\">SÃ©lection des marqueurs</h3>'),\n",
    "        w_exclude_scatter, w_exclude_markers\n",
    "    ], layout=widgets.Layout(padding='8px', border='1px solid #E1BEE7',\n",
    "                             border_radius='8px', margin='4px 0'))\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  SECTION 5 â€” FLOWSOM\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    w_xdim = widgets.IntSlider(\n",
    "        value=10, min=3, max=20, step=1,\n",
    "        description='X dim (grille SOM):',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_ydim = widgets.IntSlider(\n",
    "        value=10, min=3, max=20, step=1,\n",
    "        description='Y dim (grille SOM):',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_rlen = widgets.Dropdown(\n",
    "        options=[('Auto (âˆšN Ã— 0.1)', 'auto'), ('10', 10), ('20', 20),\n",
    "                 ('50', 50), ('100', 100)],\n",
    "        value='auto', description='rlen (itÃ©rations SOM):',\n",
    "        style=style, layout=layout_wide\n",
    "    )\n",
    "    w_n_clusters = widgets.IntSlider(\n",
    "        value=7, min=2, max=50, step=1,\n",
    "        description='MÃ©taclusters (manuel):',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_seed = widgets.IntText(\n",
    "        value=42, description='Seed:',\n",
    "        style=style, layout=layout_wide\n",
    "    )\n",
    "\n",
    "    # Auto-clustering\n",
    "    w_auto_cluster = widgets.Checkbox(\n",
    "        value=False, description='Auto-clustering (StabilitÃ© + Silhouette)',\n",
    "        style=style, layout=layout_wide, indent=False\n",
    "    )\n",
    "    w_min_k = widgets.IntSlider(\n",
    "        value=5, min=2, max=20, step=1,\n",
    "        description='k min:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_max_k = widgets.IntSlider(\n",
    "        value=35, min=10, max=60, step=1,\n",
    "        description='k max:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_n_bootstrap = widgets.IntSlider(\n",
    "        value=10, min=3, max=30, step=1,\n",
    "        description='Bootstraps:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_sample_boot = widgets.IntSlider(\n",
    "        value=20000, min=5000, max=100000, step=5000,\n",
    "        description='Sample bootstrap:',\n",
    "        style=style, layout=layout_slider\n",
    "    )\n",
    "    w_min_stability = widgets.FloatSlider(\n",
    "        value=0.75, min=0.5, max=0.95, step=0.05,\n",
    "        description='Seuil stabilitÃ© (ARI):',\n",
    "        style=style, layout=layout_slider, readout_format='.2f'\n",
    "    )\n",
    "    w_w_stability = widgets.FloatSlider(\n",
    "        value=0.65, min=0.0, max=1.0, step=0.05,\n",
    "        description='Poids stabilitÃ©:',\n",
    "        style=style, layout=layout_slider, readout_format='.2f'\n",
    "    )\n",
    "    w_w_silhouette = widgets.FloatSlider(\n",
    "        value=0.35, min=0.0, max=1.0, step=0.05,\n",
    "        description='Poids silhouette:',\n",
    "        style=style, layout=layout_slider, readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    # Lier poids stabilitÃ© + silhouette pour qu'ils somment Ã  1\n",
    "    def on_w_stability_change(change):\n",
    "        w_w_silhouette.value = round(1.0 - change['new'], 2)\n",
    "    def on_w_silhouette_change(change):\n",
    "        w_w_stability.value = round(1.0 - change['new'], 2)\n",
    "    w_w_stability.observe(on_w_stability_change, names='value')\n",
    "    w_w_silhouette.observe(on_w_silhouette_change, names='value')\n",
    "\n",
    "    sec5 = widgets.VBox([\n",
    "        widgets.HTML('<h3 style=\"margin:0;color:#C62828;\">FlowSOM â€” ParamÃ¨tres</h3>'),\n",
    "        w_xdim, w_ydim, w_rlen, w_n_clusters, w_seed,\n",
    "        widgets.HTML('<hr style=\"margin:6px 0;border-color:#FFCDD2;\">'),\n",
    "        widgets.HTML('<b style=\"color:#C62828;\">Optimisation auto-clusters (MÃ©thode StabilitÃ© 2024)</b>'),\n",
    "        w_auto_cluster, w_min_k, w_max_k,\n",
    "        w_n_bootstrap, w_sample_boot,\n",
    "        w_min_stability, w_w_stability, w_w_silhouette\n",
    "    ], layout=widgets.Layout(padding='8px', border='1px solid #FFCDD2',\n",
    "                             border_radius='8px', margin='4px 0'))\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  BOUTONS D'ACTION\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    btn_apply = widgets.Button(\n",
    "        description='âœ… Appliquer la configuration',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(width='300px', height='40px'),\n",
    "        icon='check'\n",
    "    )\n",
    "    btn_reset = widgets.Button(\n",
    "        description='RÃ©initialiser',\n",
    "        button_style='warning',\n",
    "        layout=widgets.Layout(width='200px', height='40px'),\n",
    "        icon='refresh'\n",
    "    )\n",
    "\n",
    "    def apply_config(_):\n",
    "        \"\"\"Injecte toutes les valeurs des widgets dans CONFIG et les variables globales.\"\"\"\n",
    "        global CONFIG\n",
    "        CONFIG = {\n",
    "            # Chemins\n",
    "            'HEALTHY_FOLDER': w_healthy_folder.value,\n",
    "            'PATHOLOGICAL_FOLDER': w_patho_folder.value,\n",
    "            'COMPARE_MODE': w_compare_mode.value,\n",
    "            # Gating\n",
    "            'APPLY_PREGATING': w_apply_pregating.value,\n",
    "            'GATING_MODE': w_gating_mode.value,\n",
    "            'MODE_BLASTES_VS_NORMAL': w_mode_blastes.value,\n",
    "            'GATE_DEBRIS': w_gate_debris.value,\n",
    "            'DEBRIS_MIN_PERCENTILE': w_debris_min.value,\n",
    "            'DEBRIS_MAX_PERCENTILE': w_debris_max.value,\n",
    "            'GATE_DOUBLETS': w_gate_doublets.value,\n",
    "            'RATIO_MIN': w_ratio_min.value,\n",
    "            'RATIO_MAX': w_ratio_max.value,\n",
    "            'GATE_CD45': w_gate_cd45.value,\n",
    "            'CD45_THRESHOLD_PERCENTILE': int(w_cd45_pct.value),\n",
    "            'FILTER_BLASTS': w_filter_blasts.value,\n",
    "            'CD34_THRESHOLD_PERCENTILE': int(w_cd34_pct.value),\n",
    "            'USE_SSC_FILTER_FOR_BLASTS': w_ssc_filter.value,\n",
    "            'SSC_MAX_PERCENTILE_BLASTS': int(w_ssc_max_pct.value),\n",
    "            # Transformation\n",
    "            'TRANSFORM_TYPE': w_transform.value,\n",
    "            'COFACTOR': w_cofactor.value,\n",
    "            'APPLY_TO_SCATTER': w_apply_scatter.value,\n",
    "            # Marqueurs\n",
    "            'EXCLUDE_SCATTER': w_exclude_scatter.value,\n",
    "            'EXCLUDE_ADDITIONAL_MARKERS': [m.strip() for m in w_exclude_markers.value.split(',') if m.strip()],\n",
    "            # FlowSOM\n",
    "            'XDIM': w_xdim.value,\n",
    "            'YDIM': w_ydim.value,\n",
    "            'RLEN': w_rlen.value,\n",
    "            'N_CLUSTERS': w_n_clusters.value,\n",
    "            'SEED': w_seed.value,\n",
    "            'AUTO_CLUSTER': w_auto_cluster.value,\n",
    "            'MIN_CLUSTERS_AUTO': w_min_k.value,\n",
    "            'MAX_CLUSTERS_AUTO': w_max_k.value,\n",
    "            'N_BOOTSTRAP': w_n_bootstrap.value,\n",
    "            'SAMPLE_SIZE_BOOTSTRAP': w_sample_boot.value,\n",
    "            'MIN_STABILITY_THRESHOLD': w_min_stability.value,\n",
    "            'W_STABILITY': w_w_stability.value,\n",
    "            'W_SILHOUETTE': w_w_silhouette.value,\n",
    "        }\n",
    "\n",
    "        # Injection dans les variables globales du notebook\n",
    "        g = globals()\n",
    "        for key, val in CONFIG.items():\n",
    "            if key in ('HEALTHY_FOLDER', 'PATHOLOGICAL_FOLDER'):\n",
    "                g[key] = Path(val)\n",
    "            else:\n",
    "                g[key] = val\n",
    "\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            n_nodes = CONFIG['XDIM'] * CONFIG['YDIM']\n",
    "            print(\"=\" * 60)\n",
    "            print(\"  CONFIGURATION APPLIQUÃ‰E\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"   Sain   : {CONFIG['HEALTHY_FOLDER']}\")\n",
    "            print(f\"   Patho  : {CONFIG['PATHOLOGICAL_FOLDER']}\")\n",
    "            print(f\"   Comparaison : {'Oui' if CONFIG['COMPARE_MODE'] else 'Non'}\")\n",
    "            print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "            print(f\"  ğŸ”¬ Gating     : {CONFIG['GATING_MODE'].upper()}\")\n",
    "            gt = []\n",
    "            if CONFIG['GATE_DEBRIS']: gt.append('DÃ©bris')\n",
    "            if CONFIG['GATE_DOUBLETS']: gt.append('Doublets')\n",
    "            if CONFIG['GATE_CD45']: gt.append('CD45+')\n",
    "            if CONFIG['FILTER_BLASTS']: gt.append('CD34+')\n",
    "            print(f\"   Gates actifs: {' â†’ '.join(gt) if gt else 'Aucun'}\")\n",
    "            print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "            print(f\"    Transform  : {CONFIG['TRANSFORM_TYPE'].upper()}\")\n",
    "            if CONFIG['TRANSFORM_TYPE'] == 'arcsinh':\n",
    "                print(f\"    Cofacteur  : {CONFIG['COFACTOR']}\")\n",
    "            print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "            print(f\"   Excl. scatter: {'Oui' if CONFIG['EXCLUDE_SCATTER'] else 'Non'}\")\n",
    "            print(f\"   Excl. marqueurs: {CONFIG['EXCLUDE_ADDITIONAL_MARKERS']}\")\n",
    "            print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "            print(f\"   Grille SOM : {CONFIG['XDIM']}Ã—{CONFIG['YDIM']} = {n_nodes} nodes\")\n",
    "            print(f\"   rlen       : {CONFIG['RLEN']}\")\n",
    "            print(f\"   nClus      : {CONFIG['N_CLUSTERS']} (manuel)\")\n",
    "            print(f\"   Seed       : {CONFIG['SEED']}\")\n",
    "            if CONFIG['AUTO_CLUSTER']:\n",
    "                print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "                print(f\"   AUTO k     : {CONFIG['MIN_CLUSTERS_AUTO']}â€“{CONFIG['MAX_CLUSTERS_AUTO']}\")\n",
    "                print(f\"   Bootstraps : {CONFIG['N_BOOTSTRAP']}\")\n",
    "                print(f\"   Sample     : {CONFIG['SAMPLE_SIZE_BOOTSTRAP']:,}\")\n",
    "                print(f\"   Seuil ARI  : {CONFIG['MIN_STABILITY_THRESHOLD']}\")\n",
    "                print(f\"   Poids      : stab={CONFIG['W_STABILITY']}, sil={CONFIG['W_SILHOUETTE']}\")\n",
    "            else:\n",
    "                print(f\"   Auto-cluster: DÃ©sactivÃ© â†’ k fixe = {CONFIG['N_CLUSTERS']}\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"  âœ… Variables globales mises Ã  jour. ExÃ©cutez les cellules suivantes.\")\n",
    "\n",
    "    def reset_config(_):\n",
    "        \"\"\"RÃ©initialise tous les widgets aux valeurs par dÃ©faut.\"\"\"\n",
    "        w_healthy_folder.value = r\"C:\\Users\\Florian Travail\\Documents\\FlowSom\\Data\\Moelle normale\"\n",
    "        w_patho_folder.value = r\"Data/Patho\"\n",
    "        w_compare_mode.value = True\n",
    "        w_apply_pregating.value = True\n",
    "        w_gating_mode.value = 'auto'\n",
    "        w_mode_blastes.value = True\n",
    "        w_gate_debris.value = True\n",
    "        w_debris_min.value = 1.0\n",
    "        w_debris_max.value = 99.0\n",
    "        w_gate_doublets.value = True\n",
    "        w_ratio_min.value = 0.6\n",
    "        w_ratio_max.value = 1.4\n",
    "        w_gate_cd45.value = True\n",
    "        w_cd45_pct.value = 5\n",
    "        w_filter_blasts.value = False\n",
    "        w_cd34_pct.value = 85\n",
    "        w_ssc_filter.value = True\n",
    "        w_ssc_max_pct.value = 70\n",
    "        w_transform.value = 'logicle'\n",
    "        w_cofactor.value = 5\n",
    "        w_apply_scatter.value = False\n",
    "        w_exclude_scatter.value = True\n",
    "        w_exclude_markers.value = 'CD45'\n",
    "        w_xdim.value = 10\n",
    "        w_ydim.value = 10\n",
    "        w_rlen.value = 'auto'\n",
    "        w_n_clusters.value = 7\n",
    "        w_seed.value = 42\n",
    "        w_auto_cluster.value = False\n",
    "        w_min_k.value = 5\n",
    "        w_max_k.value = 35\n",
    "        w_n_bootstrap.value = 10\n",
    "        w_sample_boot.value = 20000\n",
    "        w_min_stability.value = 0.75\n",
    "        w_w_stability.value = 0.65\n",
    "        w_w_silhouette.value = 0.35\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(\"Configuration rÃ©initialisÃ©e aux valeurs par dÃ©faut.\")\n",
    "\n",
    "    btn_apply.on_click(apply_config)\n",
    "    btn_reset.on_click(reset_config)\n",
    "\n",
    "    buttons = widgets.HBox([btn_apply, btn_reset],\n",
    "                           layout=widgets.Layout(margin='8px 0'))\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  ACCORDÃ‰ON (sections repliables)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    accordion = widgets.Accordion(children=[sec1, sec2, sec3, sec4, sec5])\n",
    "    accordion.set_title(0, 'Chemins & Mode d\\'analyse')\n",
    "    accordion.set_title(1, 'PrÃ©-gating (Gates 1â€“4)')\n",
    "    accordion.set_title(2, 'Transformation')\n",
    "    accordion.set_title(3, 'SÃ©lection des marqueurs')\n",
    "    accordion.set_title(4, 'FlowSOM & Auto-clustering')\n",
    "    accordion.selected_index = None  # Toutes repliÃ©es par dÃ©faut\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    #  ASSEMBLAGE FINAL\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    title_html = widgets.HTML(\"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #1a237e 0%, #283593 50%, #1565c0 100%);\n",
    "                padding: 16px 24px; border-radius: 12px; margin-bottom: 8px;\n",
    "                box-shadow: 0 4px 12px rgba(0,0,0,0.15);\">\n",
    "        <h2 style=\"margin:0; color:white; font-family: 'Segoe UI', sans-serif;\">\n",
    "            FlowSOM Analysis Pipeline â€” Configuration\n",
    "        </h2>\n",
    "        <p style=\"margin:4px 0 0; color:#B3E5FC; font-size:13px;\">\n",
    "            Configurez tous les paramÃ¨tres du pipeline puis cliquez sur\n",
    "            <b style=\"color:#69F0AE;\">Appliquer</b>.\n",
    "            Les valeurs seront injectÃ©es dans les cellules suivantes.\n",
    "        </p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "\n",
    "    panel = widgets.VBox([\n",
    "        title_html,\n",
    "        accordion,\n",
    "        buttons,\n",
    "        output_area\n",
    "    ], layout=widgets.Layout(\n",
    "        border='2px solid #1565C0',\n",
    "        border_radius='12px',\n",
    "        padding='12px',\n",
    "        max_width='720px'\n",
    "    ))\n",
    "\n",
    "    display(panel)\n",
    "\n",
    "    # Auto-apply pour que les variables globales soient dÃ©finies dÃ¨s l'exÃ©cution\n",
    "    apply_config(None)\n",
    "\n",
    "# â”€â”€â”€ Lancer le panneau â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "build_config_panel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4bea0",
   "metadata": {},
   "source": [
    "## 1. Import des Librairies\n",
    "\n",
    "Import de toutes les librairies nÃ©cessaires avec vÃ©rification de disponibilitÃ© des dÃ©pendances optionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# IMPORTS dÃ©but du fichier\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports scientifiques de base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# CONFIGURATION PANDAS: Affichage en format linÃ©aire (jamais exponentiel)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')  # 4 dÃ©cimales max\n",
    "pd.set_option('display.max_columns', None)  # Afficher toutes les colonnes\n",
    "pd.set_option('display.width', None)  # Largeur auto\n",
    "pd.set_option('display.max_rows', 100)  # Max 100 lignes affichÃ©es\n",
    "np.set_printoptions(suppress=True, precision=4)  # Numpy aussi en linÃ©aire\n",
    "print(\"[OK] Pandas configurÃ©: affichage linÃ©aire (pas de notation scientifique)\")\n",
    "\n",
    "# Imports visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['axes.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['text.color'] = \"#000000\"\n",
    "plt.rcParams['axes.labelcolor'] = \"#000000\"\n",
    "plt.rcParams['xtick.color'] = \"#000000\"\n",
    "plt.rcParams['ytick.color'] = \"#000000\"\n",
    "plt.rcParams['axes.edgecolor'] = \"#000000\"\n",
    "plt.rcParams['grid.color'] = \"#cccccc\"\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Plotly pour visualisations interactives\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    # Configuration pour affichage dans les notebooks\n",
    "    try:\n",
    "        # Essayer d'abord notebook_connected (meilleur pour Jupyter Lab/Notebook moderne)\n",
    "        pio.renderers.default = 'notebook_connected'\n",
    "    except:\n",
    "        # Sinon fallback sur notebook\n",
    "        pio.renderers.default = 'notebook'\n",
    "    # Alternative: forcer l'affichage inline\n",
    "    from plotly.offline import init_notebook_mode\n",
    "    init_notebook_mode(connected=True)\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"[OK] Plotly disponible\")\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non installÃ© (optionnel): pip install plotly\")\n",
    "\n",
    "# IMPORTS flowsom et anndata, l'un est le package d'analyse du FlowSOM, l'autre est pour gÃ©rer les donnÃ©es dans des objets AnnData\n",
    "try:\n",
    "    import flowsom as fs\n",
    "    import anndata as ad\n",
    "    FLOWSOM_AVAILABLE = True\n",
    "    print(\"[OK] FlowSOM disponible\")\n",
    "except ImportError:\n",
    "    FLOWSOM_AVAILABLE = False\n",
    "    print(\"[X] FlowSOM non installÃ©: pip install flowsom\")\n",
    "\n",
    "# Import de Scanpy pour UMAP/t-SNE\n",
    "try:\n",
    "    import scanpy as sc\n",
    "    SCANPY_AVAILABLE = True\n",
    "    print(\"[OK] Scanpy disponible\")\n",
    "except ImportError:\n",
    "    SCANPY_AVAILABLE = False\n",
    "    print(\"[!] Scanpy non installÃ© (optionnel): pip install scanpy\")\n",
    "\n",
    "# Import de UMAP\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"[OK] UMAP disponible\")\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"[!] UMAP non installÃ© (optionnel): pip install umap-learn\")\n",
    "\n",
    "\n",
    "# Import de t-SNE via sklearn car t-SNE trop lent Ã  Ãªtre implÃ©mentÃ© dans Scanpy (et FlowSOM)\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.metrics import silhouette_score, r2_score\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"[OK] Scikit-learn disponible\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"[!] Scikit-learn non installÃ©: pip install scikit-learn\")\n",
    "\n",
    "# FlowKit pour transformations Logicle\n",
    "try:\n",
    "    import flowkit as fk\n",
    "    FLOWKIT_AVAILABLE = True\n",
    "    # Configuration FlowKit: format linÃ©aire pour les exports/affichages\n",
    "    # FlowKit utilise pandas en interne, donc pd.set_option s'applique\n",
    "    # Mais on configure aussi les options de logging/affichage si disponibles\n",
    "    try:\n",
    "        import logging\n",
    "        logging.getLogger('flowkit').setLevel(logging.WARNING)  # Moins de logs verbose\n",
    "    except:\n",
    "        pass\n",
    "    print(\"[OK] FlowKit disponible (transformations Logicle prÃ©cise en 1 fonction)\")\n",
    "except ImportError:\n",
    "    FLOWKIT_AVAILABLE = False\n",
    "    print(\"[!] FlowKit non installÃ© (optionnel): pip install flowkit)\")\n",
    "\n",
    "# FCSWrite pour export FCS\n",
    "try:\n",
    "    import fcswrite\n",
    "    FCSWRITE_AVAILABLE = True\n",
    "    print(\"[OK] FCSWrite disponible (export FCS)\")\n",
    "except ImportError:\n",
    "    FCSWRITE_AVAILABLE = False\n",
    "    print(\"[!] FCSWrite non installÃ© (optionnel): pip install fcswrite\")\n",
    "\n",
    "# Scipy pour statistiques \n",
    "from scipy import stats\n",
    "\n",
    "# =============================================================================\n",
    "# GATERESULT â€” Structure de retour pour chaque fonction de gating\n",
    "# =============================================================================\n",
    "@dataclass\n",
    "class GateResult:\n",
    "    \"\"\"\n",
    "    RÃ©sultat structurÃ© d'une opÃ©ration de gating.\n",
    "    StockÃ© dans combined_data.uns[\"gating_reports\"] pour audit et rapport HTML.\n",
    "    \"\"\"\n",
    "    mask: np.ndarray\n",
    "    n_kept: int\n",
    "    n_total: int\n",
    "    method: str\n",
    "    gate_name: str = \"\"\n",
    "    details: Dict[str, Any] = field(default_factory=dict)\n",
    "    warnings: List[str] = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def pct_kept(self) -> float:\n",
    "        return (self.n_kept / max(self.n_total, 1)) * 100\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"SÃ©rialisation JSON-safe (sans le mask numpy).\"\"\"\n",
    "        return {\n",
    "            \"gate_name\": self.gate_name,\n",
    "            \"method\": self.method,\n",
    "            \"n_kept\": self.n_kept,\n",
    "            \"n_total\": self.n_total,\n",
    "            \"pct_kept\": round(self.pct_kept, 2),\n",
    "            \"details\": self.details,\n",
    "            \"warnings\": self.warnings,\n",
    "        }\n",
    "\n",
    "# Liste globale pour collecter les rapports de gating\n",
    "gating_reports: List[GateResult] = []\n",
    "\n",
    "# =============================================================================\n",
    "# LOGGING STRUCTURÃ‰ â€” gating_log.json\n",
    "# =============================================================================\n",
    "gating_log_entries: List[Dict[str, Any]] = []\n",
    "\n",
    "def log_gating_event(gate_name: str, method: str, status: str, \n",
    "                     details: Dict[str, Any] = None, warning_msg: str = None):\n",
    "    \"\"\"Log structurÃ© d'un Ã©vÃ©nement de gating (JSON exportable).\"\"\"\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"gate_name\": gate_name,\n",
    "        \"method\": method,\n",
    "        \"status\": status,  # \"success\", \"fallback\", \"warning\", \"error\"\n",
    "        \"details\": details or {},\n",
    "    }\n",
    "    if warning_msg:\n",
    "        entry[\"warning\"] = warning_msg\n",
    "        print(f\"   [WARNING] {gate_name}: {warning_msg}\")\n",
    "    gating_log_entries.append(entry)\n",
    "\n",
    "print(\"\\n[OK] GateResult dataclass + logging structurÃ© chargÃ©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import en haut de fichier des classes utilitaires permettant les transformations des fichiers ainsi que le pre-gating \n",
    "\n",
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    Transformations de donnÃ©es de cytomÃ©trie (Logicle, Arcsinh, etc.).\n",
    "    Classe statique rÃ©utilisable sans dÃ©pendance Ã  l'UI.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_transform(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Arcsinh (inverse hyperbolic sine).\n",
    "        \n",
    "        Args en entrÃ©e:\n",
    "            data: Matrice de donnÃ©es (n_cells, n_markers)\n",
    "            cofactor: Facteur de division (5 pour flow cytometry)\n",
    "        \n",
    "        Returns:\n",
    "            DonnÃ©es transformÃ©es\n",
    "        \"\"\"\n",
    "        return np.arcsinh(data / cofactor)\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_inverse(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"Inverse de la transformation Arcsinh.\"\"\"\n",
    "        return np.sinh(data) * cofactor\n",
    "    \n",
    "    @staticmethod\n",
    "    def logicle_transform(data: np.ndarray, T: float = 262144.0, M: float = 4.5,\n",
    "                          W: float = 0.5, A: float = 0.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Logicle (biexponentielle).\n",
    "        \n",
    "        Args en entrÃ©e:\n",
    "            data: Matrice de donnÃ©es\n",
    "            T: Maximum de l'Ã©chelle linÃ©aire (262144 = 2^18)\n",
    "            M: DÃ©cades de largeur\n",
    "            W: LinÃ©arisation prÃ¨s de zÃ©ro\n",
    "            A: DÃ©cades additionnelles (nÃ©gatifs)\n",
    "        \n",
    "        Returns:\n",
    "            DonnÃ©es transformÃ©es\n",
    "        \"\"\"\n",
    "        if FLOWKIT_AVAILABLE:\n",
    "            # Utiliser FlowKit si disponible (plus prÃ©cis) avec une fonction prÃ©dÃ©finie\n",
    "            try:\n",
    "                xform = fk.transforms.LogicleTransform(T=T, M=M, W=W, A=A)\n",
    "                return xform.apply(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Approximation si FlowKit absent: Arcsinh modifiÃ©\n",
    "        w_val = W * np.log10(np.e)\n",
    "        return np.arcsinh(data / (T / (10 ** M))) * (M / np.log(10))\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_transform(data: np.ndarray, base: float = 10.0,\n",
    "                      min_val: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"Transformation logarithmique standard.\"\"\"\n",
    "        data_clipped = np.maximum(data, min_val)\n",
    "        return np.log(data_clipped) / np.log(base)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zscore_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Z-score (moyenne=0, std=1).\"\"\"\n",
    "        mean = np.nanmean(data, axis=0)\n",
    "        std = np.nanstd(data, axis=0)\n",
    "        std[std == 0] = 1  # Ã‰viter division par zÃ©ro\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def min_max_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Min-Max [0, 1].\"\"\"\n",
    "        min_val = np.nanmin(data, axis=0)\n",
    "        max_val = np.nanmax(data, axis=0)\n",
    "        range_val = max_val - min_val\n",
    "        range_val[range_val == 0] = 1\n",
    "        return (data - min_val) / range_val\n",
    "\n",
    "\n",
    "class PreGating:\n",
    "    \"\"\"\n",
    "    Pre-gating automatique pour la sÃ©lection des populations d'intÃ©rÃªt.\n",
    "    BasÃ© sur FSC/SSC pour exclure les dÃ©bris et les doublets.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_marker_index(var_names: List[str], patterns: List[str]) -> Optional[int]:\n",
    "        \"\"\"Trouve l'index d'un marqueur parmi les patterns donnÃ©s.\"\"\"\n",
    "        var_upper = [v.upper() for v in var_names]\n",
    "        for pattern in patterns:\n",
    "            for i, name in enumerate(var_upper):\n",
    "                if pattern.upper() in name:\n",
    "                    return i\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_viable_cells(X: np.ndarray, var_names: List[str],\n",
    "                          min_percentile: float = 2.0, \n",
    "                          max_percentile: float = 98.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules viables basÃ© sur FSC/SSC.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            min_percentile: Percentile minimum (exclusion dÃ©bris)\n",
    "            max_percentile: Percentile maximum (exclusion doublets)\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en des cellules viables\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        mask = np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Trouver FSC (prioritÃ© Ã  FSC-A)\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A', 'FSC-H', 'FSC'])\n",
    "        if fsc_idx is not None:\n",
    "            fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "            fsc_vals = np.where(np.isfinite(fsc_vals), fsc_vals, np.nan)\n",
    "            low = np.nanpercentile(fsc_vals, min_percentile)\n",
    "            high = np.nanpercentile(fsc_vals, max_percentile)\n",
    "            mask &= np.isfinite(fsc_vals) & (fsc_vals >= low) & (fsc_vals <= high)\n",
    "        \n",
    "        # Trouver SSC (prioritÃ© Ã  SSC-A)\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "        if ssc_idx is not None:\n",
    "            ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "            ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "            low = np.nanpercentile(ssc_vals, min_percentile)\n",
    "            high = np.nanpercentile(ssc_vals, max_percentile)\n",
    "            mask &= np.isfinite(ssc_vals) & (ssc_vals >= low) & (ssc_vals <= high)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_singlets(X: np.ndarray, var_names: List[str],\n",
    "                      ratio_min: float = 0.6, ratio_max: float = 1.5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les singlets basÃ© sur le ratio FSC-A/FSC-H.\n",
    "        Les doublets ont typiquement un ratio > 1.3-1.5.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            ratio_min: Ratio minimum acceptable\n",
    "            ratio_max: Ratio maximum acceptable\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en des singlets\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouvÃ©, pas de gating singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # Valeurs minimum pour Ã©viter division par zÃ©ro\n",
    "        min_val = 100\n",
    "        valid_h = fsc_h > min_val\n",
    "        \n",
    "        ratio = np.full(n_cells, np.nan)\n",
    "        ratio[valid_h] = fsc_a[valid_h] / fsc_h[valid_h]\n",
    "        \n",
    "        mask = np.isfinite(ratio) & (ratio >= ratio_min) & (ratio <= ratio_max)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd45_positive(X: np.ndarray, var_names: List[str],\n",
    "                           threshold_percentile: float = 10) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules CD45+ (leucocytes).\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en des cellules CD45+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouvÃ©, pas de gating CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45_vals = X[:, cd45_idx].astype(np.float64)\n",
    "        cd45_vals = np.where(np.isfinite(cd45_vals), cd45_vals, np.nan)\n",
    "        \n",
    "        threshold = np.nanpercentile(cd45_vals, threshold_percentile)\n",
    "        \n",
    "        return np.where(np.isnan(cd45_vals), False, cd45_vals > threshold)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd34_blasts(X: np.ndarray, var_names: List[str],\n",
    "                         threshold_percentile: float = 85,\n",
    "                         use_ssc_filter: bool = True,\n",
    "                         ssc_max_percentile: float = 70) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les blastes CD34+ (cellules souches/progÃ©nitrices).\n",
    "        \n",
    "        Les blastes sont typiquement:\n",
    "        - CD34 bright (haute expression)\n",
    "        - SSC low (faible granularitÃ©)\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            threshold_percentile: Percentile pour dÃ©finir le seuil CD34+ (ex: 85 = top 15%)\n",
    "            use_ssc_filter: Appliquer aussi un filtre SSC pour enrichir en blastes\n",
    "            ssc_max_percentile: Percentile max de SSC pour blastes (faible granularitÃ©)\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en des blastes CD34+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        # Chercher CD34 avec diffÃ©rents nommages possibles\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouvÃ©, pas de gating blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34_vals = X[:, cd34_idx].astype(np.float64)\n",
    "        cd34_vals = np.where(np.isfinite(cd34_vals), cd34_vals, np.nan)\n",
    "        \n",
    "        # Seuil CD34+ (prendre les cellules avec haute expression)\n",
    "        threshold_cd34 = np.nanpercentile(cd34_vals, threshold_percentile)\n",
    "        mask_cd34 = np.where(np.isnan(cd34_vals), False, cd34_vals >= threshold_cd34)\n",
    "        \n",
    "        # Optionnel: filtrer aussi par SSC low (blastes = faible granularitÃ©)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "                ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "                threshold_ssc = np.nanpercentile(ssc_vals, ssc_max_percentile)\n",
    "                mask_ssc = np.where(np.isnan(ssc_vals), False, ssc_vals <= threshold_ssc)\n",
    "                return mask_cd34 & mask_ssc\n",
    "        \n",
    "        return mask_cd34\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_debris_polygon(X: np.ndarray, var_names: List[str],\n",
    "                            fsc_min: float = None, fsc_max: float = None,\n",
    "                            ssc_min: float = None, ssc_max: float = None,\n",
    "                            auto_percentiles: bool = True,\n",
    "                            min_pct: float = 1.0, max_pct: float = 99.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate rectangulaire/polygonal pour exclure les dÃ©bris sur FSC-A vs SSC-A.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            fsc_min/fsc_max: Seuils FSC manuels (si auto_percentiles=False)\n",
    "            ssc_min/ssc_max: Seuils SSC manuels (si auto_percentiles=False)\n",
    "            auto_percentiles: Calculer automatiquement les seuils via percentiles\n",
    "            min_pct/max_pct: Percentiles pour auto-calcul\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en des cellules (non-dÃ©bris)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouvÃ© pour gate dÃ©bris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Calculer les seuils automatiquement si demandÃ©\n",
    "        if auto_percentiles:\n",
    "            fsc_min = np.nanpercentile(fsc_vals, min_pct)\n",
    "            fsc_max = np.nanpercentile(fsc_vals, max_pct)\n",
    "            ssc_min = np.nanpercentile(ssc_vals, min_pct)\n",
    "            ssc_max = np.nanpercentile(ssc_vals, max_pct)\n",
    "        \n",
    "        # Appliquer le gate rectangulaire\n",
    "        mask = (\n",
    "            np.isfinite(fsc_vals) & np.isfinite(ssc_vals) &\n",
    "            (fsc_vals >= fsc_min) & (fsc_vals <= fsc_max) &\n",
    "            (ssc_vals >= ssc_min) & (ssc_vals <= ssc_max)\n",
    "        )\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "print(\"[OK] Classes DataTransformer et PreGating chargÃ©es!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715de552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLASSE AutoGating â€” Gating adaptatif par GMM/KDE\n",
    "# =============================================================================\n",
    "# InspirÃ© de CytoPy AutonomousGate (sans dÃ©pendance MongoDB)\n",
    "# Utilise scikit-learn GaussianMixture pour trouver les \"creux\" rÃ©els\n",
    "# entre les populations au lieu de couper Ã  des percentiles fixes.\n",
    "#\n",
    "# Avantages vs PreGating (percentiles):\n",
    "#   - Si un Ã©chantillon a 10% de dÃ©bris â†’ la porte s'adapte automatiquement\n",
    "#   - Si un Ã©chantillon est propre â†’ moins de perte de donnÃ©es\n",
    "#   - Pour les doublets: modÃ©lise la diagonale FSC-A/FSC-H statistiquement\n",
    "#   - Pour CD45+: trouve le creux bimodal entre CD45- et CD45+\n",
    "#\n",
    "# [V2 AMÃ‰LIORATIONS]:\n",
    "#   - safe_fit_gmm: sous-Ã©chantillonnage Ã  200k points max avant fit\n",
    "#   - auto_gate_singlets: contrÃ´le RÂ² RANSAC + fallback ratio si RÂ² < 0.85\n",
    "#   - Toutes les fonctions retournent un GateResult structurÃ©\n",
    "#   - Scatter FSC-A vs FSC-H par fichier + tableau % singlets stockÃ©s\n",
    "#   - Log structurÃ© JSON pour audit automatique des runs\n",
    "# =============================================================================\n",
    "\n",
    "# Stockage global des scatter data RANSAC par fichier (pour le rapport HTML)\n",
    "ransac_scatter_data = {}  # {file_name: {fsc_h, fsc_a, pred, inlier_mask, r2, slope, intercept, pct_singlets}}\n",
    "singlets_summary_per_file = []  # Liste de dicts pour tableau \"% singlets par fichier\"\n",
    "\n",
    "class AutoGating:\n",
    "    \"\"\"\n",
    "    Gating automatique adaptatif basÃ© sur des modÃ¨les de mÃ©lange gaussien (GMM)\n",
    "    et estimation de densitÃ©. InspirÃ© de CytoPy AutonomousGate.\n",
    "    \n",
    "    Chaque mÃ©thode utilise un GMM pour identifier les populations naturelles\n",
    "    dans les donnÃ©es, au lieu de seuils fixes basÃ©s sur des percentiles.\n",
    "    \n",
    "    DÃ©pendances: scikit-learn (GaussianMixture, StandardScaler)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Seuil RÂ² minimal pour la rÃ©gression RANSAC (en dessous â†’ fallback ratio)\n",
    "    RANSAC_R2_THRESHOLD = 0.85\n",
    "    # Sous-Ã©chantillonnage max avant GMM (convergence + performance)\n",
    "    GMM_MAX_SAMPLES = 200_000\n",
    "    \n",
    "    @staticmethod\n",
    "    def _subsample_for_gmm(data: np.ndarray, max_samples: int = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Sous-Ã©chantillonne les donnÃ©es si elles dÃ©passent max_samples.\n",
    "        AmÃ©liore la convergence et Ã©vite les timeouts implicites sur gros jeux.\n",
    "        \n",
    "        Args:\n",
    "            data: DonnÃ©es (n_samples, n_features)\n",
    "            max_samples: Nombre max de points (dÃ©faut: GMM_MAX_SAMPLES)\n",
    "        \n",
    "        Returns:\n",
    "            data_subsampled: DonnÃ©es sous-Ã©chantillonnÃ©es (ou originales si < max)\n",
    "        \"\"\"\n",
    "        if max_samples is None:\n",
    "            max_samples = AutoGating.GMM_MAX_SAMPLES\n",
    "        if data.shape[0] > max_samples:\n",
    "            idx = np.random.choice(data.shape[0], size=max_samples, replace=False)\n",
    "            print(f\"      [GMM] Sous-Ã©chantillonnage: {data.shape[0]:,} â†’ {max_samples:,} points\")\n",
    "            return data[idx]\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def safe_fit_gmm(data: np.ndarray, n_components: int = 2,\n",
    "                     n_init: int = 3, max_retries: int = 5,\n",
    "                     random_state: int = 42,\n",
    "                     covariance_type: str = 'full',\n",
    "                     max_iter: int = 200,\n",
    "                     subsample: bool = True) -> Any:\n",
    "        \"\"\"\n",
    "        Wrapper robuste pour le fitting GMM avec gestion d'erreurs.\n",
    "        \n",
    "        Tente le fit plusieurs fois avec diffÃ©rentes initialisations.\n",
    "        En cas d'Ã©chec total sur n_components > 1, fallback sur 1 composante.\n",
    "        VÃ©rifie la convergence et Ã©met des warnings si nÃ©cessaire.\n",
    "        \n",
    "        [V2] Sous-Ã©chantillonnage automatique Ã  200k points max avant fit.\n",
    "        \n",
    "        Args:\n",
    "            data: DonnÃ©es Ã  fitter (n_samples, n_features) ou (n_samples, 1)\n",
    "            n_components: Nombre de composantes GMM\n",
    "            n_init: Nombre d'initialisations par tentative\n",
    "            max_retries: Nombre max de tentatives avant fallback\n",
    "            random_state: Seed pour reproductibilitÃ©\n",
    "            covariance_type: Type de covariance ('full', 'diag', 'spherical', 'tied')\n",
    "            max_iter: Nombre max d'itÃ©rations EM\n",
    "            subsample: Si True, sous-Ã©chantillonne avant fit (dÃ©faut True)\n",
    "        \n",
    "        Returns:\n",
    "            GaussianMixture fittÃ©\n",
    "        \n",
    "        Raises:\n",
    "            RuntimeError: Si le fit Ã©choue aprÃ¨s toutes les tentatives (y compris fallback)\n",
    "        \"\"\"\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        \n",
    "        # Sous-Ã©chantillonnage pour convergence rapide sur gros jeux de donnÃ©es\n",
    "        if subsample:\n",
    "            data_fit = AutoGating._subsample_for_gmm(data)\n",
    "        else:\n",
    "            data_fit = data\n",
    "        \n",
    "        last_error = None\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=n_components,\n",
    "                    random_state=random_state + attempt,\n",
    "                    n_init=n_init,\n",
    "                    covariance_type=covariance_type,\n",
    "                    max_iter=max_iter\n",
    "                )\n",
    "                gmm.fit(data_fit)\n",
    "                if not gmm.converged_:\n",
    "                    warnings.warn(f\"GMM non-convergÃ© (n={n_components}, tentative {attempt+1}/{max_retries})\")\n",
    "                    log_gating_event(\"GMM\", f\"n_components={n_components}\", \"warning\",\n",
    "                                     {\"attempt\": attempt+1},\n",
    "                                     f\"Non-convergÃ© tentative {attempt+1}/{max_retries}\")\n",
    "                    continue\n",
    "                return gmm\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                log_gating_event(\"GMM\", f\"n_components={n_components}\", \"error\",\n",
    "                                 {\"attempt\": attempt+1, \"error\": str(e)})\n",
    "                continue\n",
    "        \n",
    "        # Fallback: tenter avec 1 composante si n_components > 1\n",
    "        if n_components > 1:\n",
    "            warn_msg = f\"GMM fallback unimodal aprÃ¨s {max_retries} Ã©checs (derniÃ¨re erreur: {last_error})\"\n",
    "            warnings.warn(warn_msg)\n",
    "            log_gating_event(\"GMM\", \"fallback_unimodal\", \"fallback\",\n",
    "                             {\"original_n_components\": n_components, \"error\": str(last_error)},\n",
    "                             warn_msg)\n",
    "            try:\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=1,\n",
    "                    random_state=random_state,\n",
    "                    n_init=1,\n",
    "                    covariance_type=covariance_type,\n",
    "                    max_iter=max_iter\n",
    "                )\n",
    "                gmm.fit(data_fit)\n",
    "                return gmm\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\n",
    "                    f\"GMM fit Ã©chouÃ© aprÃ¨s {max_retries} tentatives + fallback unimodal: {e}\"\n",
    "                )\n",
    "        \n",
    "        raise RuntimeError(\n",
    "            f\"GMM fit Ã©chouÃ© aprÃ¨s {max_retries} tentatives: {last_error}\"\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_debris(X: np.ndarray, var_names: List[str],\n",
    "                          n_components: int = 3,\n",
    "                          min_cluster_fraction: float = 0.02) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate dÃ©bris adaptatif par GMM 2D sur FSC-A / SSC-A.\n",
    "        \n",
    "        L'algorithme identifie les clusters naturels dans l'espace FSC/SSC:\n",
    "        - DÃ©bris: Ã©vÃ©nements bas en FSC-A (petites particules)\n",
    "        - Cellules: population principale (cluster dominant)  \n",
    "        - SaturÃ©s: Ã©vÃ©nements trÃ¨s hauts (optionnel, dÃ©tectÃ© par BIC)\n",
    "        \n",
    "        SÃ©lection automatique du nombre de composantes par BIC (2 ou 3).\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es (n_cells, n_markers)\n",
    "            var_names: Noms des marqueurs\n",
    "            n_components: Nombre max de composantes GMM Ã  tester\n",
    "            min_cluster_fraction: Fraction min d'Ã©vÃ©nements pour inclure un cluster\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en (True = cellule viable, False = dÃ©bris/saturÃ©)\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouvÃ© pour auto-gate dÃ©bris\")\n",
    "            log_gating_event(\"debris\", \"auto_gmm\", \"error\", warning_msg=\"FSC-A ou SSC-A non trouvÃ©\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Filtrer les NaN/Inf\n",
    "        valid = np.isfinite(fsc) & np.isfinite(ssc)\n",
    "        data_2d = np.column_stack([fsc[valid], ssc[valid]])\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de donnÃ©es valides pour auto-gate dÃ©bris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Standardiser avant GMM pour meilleure convergence\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(data_2d)\n",
    "        \n",
    "        # SÃ©lection automatique du nombre de composantes par BIC\n",
    "        best_bic = np.inf\n",
    "        best_gmm = None\n",
    "        for n_comp in [2, 3]:\n",
    "            try:\n",
    "                gmm_test = AutoGating.safe_fit_gmm(\n",
    "                    data_scaled, n_components=n_comp,\n",
    "                    covariance_type='full', n_init=3, max_iter=200\n",
    "                )\n",
    "                bic = gmm_test.bic(data_scaled if data_scaled.shape[0] <= AutoGating.GMM_MAX_SAMPLES \n",
    "                                   else AutoGating._subsample_for_gmm(data_scaled))\n",
    "                if bic < best_bic:\n",
    "                    best_bic = bic\n",
    "                    best_gmm = gmm_test\n",
    "            except RuntimeError as e:\n",
    "                print(f\"   [!] GMM {n_comp} composantes Ã©chouÃ©: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if best_gmm is None:\n",
    "            print(\"   [!] Aucun GMM n'a convergÃ©, conservation de tous les Ã©vÃ©nements\")\n",
    "            log_gating_event(\"debris\", \"auto_gmm\", \"fallback\",\n",
    "                             warning_msg=\"Aucun GMM convergÃ©, toutes cellules conservÃ©es\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        labels = best_gmm.predict(data_scaled)\n",
    "        n_comp = best_gmm.n_components\n",
    "        \n",
    "        # Statistiques par cluster (en espace original)\n",
    "        cluster_sizes = np.bincount(labels, minlength=n_comp)\n",
    "        cluster_fsc_means = np.array([data_2d[labels == i, 0].mean() for i in range(n_comp)])\n",
    "        \n",
    "        # Population principale = plus grand cluster\n",
    "        main_cluster = np.argmax(cluster_sizes)\n",
    "        \n",
    "        # Inclure les clusters avec assez d'Ã©vÃ©nements et un FSC raisonnable\n",
    "        # (exclure les dÃ©bris = FSC trÃ¨s bas)\n",
    "        mask_valid = np.zeros(valid.sum(), dtype=bool)\n",
    "        fsc_threshold = cluster_fsc_means[main_cluster] * 0.25\n",
    "        \n",
    "        for i in range(n_comp):\n",
    "            fraction = cluster_sizes[i] / len(labels)\n",
    "            if fraction >= min_cluster_fraction and cluster_fsc_means[i] >= fsc_threshold:\n",
    "                mask_valid |= (labels == i)\n",
    "        \n",
    "        # SÃ©curitÃ©: si aucun cluster sÃ©lectionnÃ©, garder le principal\n",
    "        if not mask_valid.any():\n",
    "            mask_valid = (labels == main_cluster)\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = mask_valid\n",
    "        \n",
    "        n_kept = mask.sum()\n",
    "        print(f\"   [Auto-GMM] {best_gmm.n_components} composantes dÃ©tectÃ©es (BIC={best_bic:.0f})\")\n",
    "        for i in range(n_comp):\n",
    "            status = \"âœ“\" if mask_valid[labels == i].any() else \"âœ—\"\n",
    "            print(f\"     {status} Cluster {i}: {cluster_sizes[i]:,} evt, FSC-A moy={cluster_fsc_means[i]:.0f}\")\n",
    "        print(f\"   [Auto-GMM] â†’ ConservÃ©s: {n_kept:,} Ã©vÃ©nements\")\n",
    "        \n",
    "        # Log structurÃ©\n",
    "        log_gating_event(\"debris\", \"auto_gmm\", \"success\", {\n",
    "            \"n_components\": int(n_comp), \"bic\": float(best_bic),\n",
    "            \"n_kept\": int(n_kept), \"n_total\": int(n_cells),\n",
    "            \"cluster_sizes\": cluster_sizes.tolist(),\n",
    "        })\n",
    "        \n",
    "        # Construire GateResult\n",
    "        gate_result = GateResult(\n",
    "            mask=mask, n_kept=int(n_kept), n_total=int(n_cells),\n",
    "            method=\"auto_gmm_debris\", gate_name=\"G1_debris\",\n",
    "            details={\"n_components\": int(n_comp), \"bic\": float(best_bic),\n",
    "                     \"cluster_fsc_means\": cluster_fsc_means.tolist()},\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_singlets(X: np.ndarray, var_names: List[str], \n",
    "                          file_origin: Optional[np.ndarray] = None,\n",
    "                          per_file: bool = True,\n",
    "                          r2_threshold: float = 0.85) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate singlets adaptatif par rÃ©gression linÃ©aire robuste (RANSAC).\n",
    "        \n",
    "        Les singlets forment une diagonale sur le plot FSC-A vs FSC-H.\n",
    "        Les doublets se situent au-dessus de cette diagonale (FSC-A augmente mais pas FSC-H).\n",
    "        \n",
    "        MÃ©thode amÃ©liorÃ©e (V2):\n",
    "        1. PrÃ©-filtre viable (FSC/SSC 1-99%) pour exclure les outliers extrÃªmes\n",
    "        2. RÃ©gression linÃ©aire robuste RANSAC sur FSC-A vs FSC-H\n",
    "        3. ContrÃ´le qualitÃ© RÂ² sur les inliers RANSAC\n",
    "        4. Si RÂ² < seuil (0.85): fallback vers gating ratio FSC-A/FSC-H simple\n",
    "        5. Stockage des scatter data par fichier pour le rapport HTML\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es (n_cells, n_markers)\n",
    "            var_names: Noms des marqueurs\n",
    "            file_origin: Array contenant l'origine de chaque cellule (pour gating par fichier)\n",
    "            per_file: Si True, applique le gating sÃ©parÃ©ment par fichier\n",
    "            r2_threshold: Seuil RÂ² minimum (dÃ©faut 0.85). En dessous â†’ fallback ratio\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en (True = singlet, False = doublet)\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import RANSACRegressor\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouvÃ© pour auto-gate singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # PrÃ©-filtre viable (FSC/SSC 1-99%) pour rÃ©duire l'impact des outliers\n",
    "        # extrÃªmes (blastes matures, granulocytes agrÃ©gÃ©s) sur la rÃ©gression RANSAC\n",
    "        viable = PreGating.gate_viable_cells(X, var_names, min_percentile=1.0, max_percentile=99.0)\n",
    "        \n",
    "        # Filtrer: valeurs valides avec FSC > seuil minimal + viabilitÃ©\n",
    "        valid = viable & np.isfinite(fsc_a) & np.isfinite(fsc_h) & (fsc_h > 100) & (fsc_a > 100)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de donnÃ©es valides pour auto-gate singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        \n",
    "        # â”€â”€â”€ Helper interne: fallback ratio FSC-A/FSC-H â”€â”€â”€\n",
    "        def _fallback_ratio_gating(fsc_a_local, fsc_h_local, ratio_min=0.6, ratio_max=1.5):\n",
    "            \"\"\"Gating simple par ratio FSC-A/FSC-H (ancienne mÃ©thode).\"\"\"\n",
    "            ratio = fsc_a_local.ravel() / np.maximum(fsc_h_local.ravel(), 1.0)\n",
    "            return (ratio >= ratio_min) & (ratio <= ratio_max)\n",
    "        \n",
    "        # Gating par fichier si demandÃ© et si file_origin fourni\n",
    "        if per_file and file_origin is not None:\n",
    "            unique_files = np.unique(file_origin)\n",
    "            print(f\"   [Auto-RANSAC] Gating par fichier ({len(unique_files)} fichiers)\")\n",
    "            \n",
    "            total_singlets = 0\n",
    "            total_doublets = 0\n",
    "            \n",
    "            for file_name in unique_files:\n",
    "                # SÃ©lectionner les cellules de ce fichier\n",
    "                file_mask = (file_origin == file_name) & valid\n",
    "                \n",
    "                if file_mask.sum() < 50:\n",
    "                    # Trop peu de cellules, garder toutes\n",
    "                    mask[file_mask] = True\n",
    "                    singlets_summary_per_file.append({\n",
    "                        \"file\": str(file_name), \"n_total\": int(file_mask.sum()),\n",
    "                        \"n_singlets\": int(file_mask.sum()), \"pct_singlets\": 100.0,\n",
    "                        \"method\": \"skip_too_few\", \"r2\": None,\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                fsc_a_file = fsc_a[file_mask].reshape(-1, 1)\n",
    "                fsc_h_file = fsc_h[file_mask].reshape(-1, 1)\n",
    "                \n",
    "                # RÃ©gression RANSAC pour trouver la diagonale des singlets\n",
    "                try:\n",
    "                    ransac = RANSACRegressor(\n",
    "                        estimator=LinearRegression(),\n",
    "                        min_samples=50,\n",
    "                        residual_threshold=None,  # Auto (MAD)\n",
    "                        random_state=42,\n",
    "                        max_trials=100\n",
    "                    )\n",
    "                    ransac.fit(fsc_h_file, fsc_a_file.ravel())\n",
    "                    \n",
    "                    # â”€â”€â”€ CONTRÃ”LE QUALITÃ‰ RÂ² SUR INLIERS RANSAC â”€â”€â”€\n",
    "                    inlier_mask = ransac.inlier_mask_\n",
    "                    r2_val = None\n",
    "                    used_method = \"ransac\"\n",
    "                    \n",
    "                    if inlier_mask is not None and inlier_mask.sum() > 50:\n",
    "                        r2_val = r2_score(\n",
    "                            fsc_a_file[inlier_mask].ravel(),\n",
    "                            ransac.predict(fsc_h_file[inlier_mask])\n",
    "                        )\n",
    "                        \n",
    "                        if r2_val < r2_threshold:\n",
    "                            # â”€â”€â”€ FALLBACK: gating ratio simple â”€â”€â”€\n",
    "                            warn_msg = f\"RÂ² faible pour {file_name} (RÂ²={r2_val:.2f} < {r2_threshold}), fallback gating ratio\"\n",
    "                            print(f\"      [!] {warn_msg}\")\n",
    "                            log_gating_event(\"singlets\", \"ransac_fallback_ratio\", \"fallback\",\n",
    "                                             {\"file\": str(file_name), \"r2\": float(r2_val)}, warn_msg)\n",
    "                            \n",
    "                            singlets_file = _fallback_ratio_gating(fsc_a_file, fsc_h_file)\n",
    "                            used_method = \"ratio_fallback\"\n",
    "                            \n",
    "                            # Appliquer\n",
    "                            file_indices = np.where(file_mask)[0]\n",
    "                            mask[file_indices] = singlets_file\n",
    "                            \n",
    "                            n_sing = int(singlets_file.sum())\n",
    "                            n_doub = len(singlets_file) - n_sing\n",
    "                            total_singlets += n_sing\n",
    "                            total_doublets += n_doub\n",
    "                            \n",
    "                            file_short = file_name if len(file_name) <= 25 else file_name[:22] + \"...\"\n",
    "                            print(f\"      â€¢ {file_short}: {n_sing:,} singlets / {n_sing+n_doub:,} ({n_sing/(n_sing+n_doub)*100:.1f}%) - RATIO FALLBACK (RÂ²={r2_val:.2f})\")\n",
    "                            \n",
    "                            # Stocker les scatter data (mÃªme si fallback, pour diagnostic)\n",
    "                            n_sample_pts = min(2000, len(fsc_a_file))\n",
    "                            sample_idx = np.random.choice(len(fsc_a_file), n_sample_pts, replace=False)\n",
    "                            ransac_scatter_data[str(file_name)] = {\n",
    "                                \"fsc_h\": fsc_h_file[sample_idx].ravel().tolist(),\n",
    "                                \"fsc_a\": fsc_a_file[sample_idx].ravel().tolist(),\n",
    "                                \"pred\": ransac.predict(fsc_h_file[sample_idx]).tolist(),\n",
    "                                \"r2\": float(r2_val),\n",
    "                                \"method\": \"ratio_fallback\",\n",
    "                                \"slope\": float(ransac.estimator_.coef_[0]),\n",
    "                                \"intercept\": float(ransac.estimator_.intercept_),\n",
    "                            }\n",
    "                            singlets_summary_per_file.append({\n",
    "                                \"file\": str(file_name), \"n_total\": int(len(singlets_file)),\n",
    "                                \"n_singlets\": n_sing, \"pct_singlets\": round(n_sing/(n_sing+n_doub)*100, 1),\n",
    "                                \"method\": \"ratio_fallback\", \"r2\": round(float(r2_val), 3),\n",
    "                            })\n",
    "                            continue\n",
    "                    \n",
    "                    # â”€â”€â”€ RÂ² OK (ou pas de inlier_mask): utiliser RANSAC normal â”€â”€â”€\n",
    "                    # PrÃ©diction sur la droite\n",
    "                    fsc_a_pred = ransac.predict(fsc_h_file)\n",
    "                    \n",
    "                    # Distance verticale (rÃ©sidus) - doublets au-dessus de la ligne\n",
    "                    residuals = fsc_a_file.ravel() - fsc_a_pred\n",
    "                    \n",
    "                    # Seuil adaptatif basÃ© sur MAD (Median Absolute Deviation)\n",
    "                    median_residual = np.median(residuals)\n",
    "                    mad = np.median(np.abs(residuals - median_residual))\n",
    "                    \n",
    "                    # Seuil: mÃ©diane + 3 * MAD\n",
    "                    threshold_upper = median_residual + 3.0 * mad\n",
    "                    \n",
    "                    # Singlets: points prÃ¨s de la diagonale (pas trop au-dessus)\n",
    "                    singlets_file = residuals <= threshold_upper\n",
    "                    \n",
    "                    # Appliquer le masque local\n",
    "                    file_indices = np.where(file_mask)[0]\n",
    "                    mask[file_indices] = singlets_file\n",
    "                    \n",
    "                    n_sing = int(singlets_file.sum())\n",
    "                    n_doub = len(singlets_file) - n_sing\n",
    "                    total_singlets += n_sing\n",
    "                    total_doublets += n_doub\n",
    "                    \n",
    "                    # Affichage compact par fichier\n",
    "                    slope = ransac.estimator_.coef_[0]\n",
    "                    intercept = ransac.estimator_.intercept_\n",
    "                    file_short = file_name if len(file_name) <= 25 else file_name[:22] + \"...\"\n",
    "                    r2_str = f\", RÂ²={r2_val:.3f}\" if r2_val is not None else \"\"\n",
    "                    print(f\"      â€¢ {file_short}: {n_sing:,} singlets / {n_sing+n_doub:,} ({n_sing/(n_sing+n_doub)*100:.1f}%) - y={slope:.3f}x+{intercept:.0f}{r2_str}\")\n",
    "                    \n",
    "                    # Stocker scatter data pour le rapport HTML (Ã©chantillonnÃ©)\n",
    "                    n_sample_pts = min(2000, len(fsc_a_file))\n",
    "                    sample_idx = np.random.choice(len(fsc_a_file), n_sample_pts, replace=False)\n",
    "                    ransac_scatter_data[str(file_name)] = {\n",
    "                        \"fsc_h\": fsc_h_file[sample_idx].ravel().tolist(),\n",
    "                        \"fsc_a\": fsc_a_file[sample_idx].ravel().tolist(),\n",
    "                        \"pred\": ransac.predict(fsc_h_file[sample_idx]).tolist(),\n",
    "                        \"r2\": float(r2_val) if r2_val is not None else None,\n",
    "                        \"method\": \"ransac\",\n",
    "                        \"slope\": float(slope),\n",
    "                        \"intercept\": float(intercept),\n",
    "                    }\n",
    "                    singlets_summary_per_file.append({\n",
    "                        \"file\": str(file_name), \"n_total\": int(len(singlets_file)),\n",
    "                        \"n_singlets\": n_sing, \"pct_singlets\": round(n_sing/(n_sing+n_doub)*100, 1),\n",
    "                        \"method\": \"ransac\", \"r2\": round(float(r2_val), 3) if r2_val is not None else None,\n",
    "                    })\n",
    "                    \n",
    "                    # Log structurÃ©\n",
    "                    log_gating_event(\"singlets\", \"ransac\", \"success\", {\n",
    "                        \"file\": str(file_name), \"r2\": float(r2_val) if r2_val else None,\n",
    "                        \"slope\": float(slope), \"intercept\": float(intercept),\n",
    "                        \"n_singlets\": n_sing, \"n_doublets\": n_doub,\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      [!] Ã‰chec RANSAC pour {file_name}: {e}\")\n",
    "                    log_gating_event(\"singlets\", \"ransac\", \"error\",\n",
    "                                     {\"file\": str(file_name), \"error\": str(e)},\n",
    "                                     f\"Ã‰chec RANSAC pour {file_name}: {e}\")\n",
    "                    # En cas d'Ã©chec, garder toutes les cellules du fichier\n",
    "                    mask[file_mask] = True\n",
    "                    total_singlets += file_mask.sum()\n",
    "                    singlets_summary_per_file.append({\n",
    "                        \"file\": str(file_name), \"n_total\": int(file_mask.sum()),\n",
    "                        \"n_singlets\": int(file_mask.sum()), \"pct_singlets\": 100.0,\n",
    "                        \"method\": \"error_keep_all\", \"r2\": None,\n",
    "                    })\n",
    "            \n",
    "            print(f\"   [Auto-RANSAC] Total: {total_singlets:,} singlets, {total_doublets:,} doublets exclus\")\n",
    "            \n",
    "            # RÃ©sumÃ© tableau % singlets par fichier\n",
    "            if singlets_summary_per_file:\n",
    "                print(f\"\\n   {'Fichier':<30} {'MÃ©thode':<18} {'RÂ²':>6} {'% Singlets':>12}\")\n",
    "                print(f\"   {'â”€'*30} {'â”€'*18} {'â”€'*6} {'â”€'*12}\")\n",
    "                for row in singlets_summary_per_file:\n",
    "                    r2_disp = f\"{row['r2']:.3f}\" if row['r2'] is not None else \"N/A\"\n",
    "                    fname_short = row['file'] if len(row['file']) <= 30 else row['file'][:27] + \"...\"\n",
    "                    print(f\"   {fname_short:<30} {row['method']:<18} {r2_disp:>6} {row['pct_singlets']:>10.1f}%\")\n",
    "            \n",
    "        else:\n",
    "            # Gating global (ancien comportement)\n",
    "            print(f\"   [Auto-RANSAC] Gating global sur toutes les donnÃ©es\")\n",
    "            \n",
    "            fsc_a_valid = fsc_a[valid].reshape(-1, 1)\n",
    "            fsc_h_valid = fsc_h[valid].reshape(-1, 1)\n",
    "            \n",
    "            # RÃ©gression RANSAC\n",
    "            ransac = RANSACRegressor(\n",
    "                estimator=LinearRegression(),\n",
    "                min_samples=100,\n",
    "                residual_threshold=None,\n",
    "                random_state=42,\n",
    "                max_trials=100\n",
    "            )\n",
    "            ransac.fit(fsc_h_valid, fsc_a_valid.ravel())\n",
    "            \n",
    "            # â”€â”€â”€ CONTRÃ”LE QUALITÃ‰ RÂ² GLOBAL â”€â”€â”€\n",
    "            inlier_mask = ransac.inlier_mask_\n",
    "            r2_val = None\n",
    "            if inlier_mask is not None and inlier_mask.sum() > 50:\n",
    "                r2_val = r2_score(\n",
    "                    fsc_a_valid[inlier_mask].ravel(),\n",
    "                    ransac.predict(fsc_h_valid[inlier_mask])\n",
    "                )\n",
    "                if r2_val < r2_threshold:\n",
    "                    warn_msg = f\"RÂ² faible global (RÂ²={r2_val:.2f} < {r2_threshold}), fallback gating ratio\"\n",
    "                    print(f\"   [!] {warn_msg}\")\n",
    "                    log_gating_event(\"singlets\", \"ransac_fallback_ratio\", \"fallback\",\n",
    "                                     {\"r2\": float(r2_val)}, warn_msg)\n",
    "                    \n",
    "                    singlets_mask = _fallback_ratio_gating(fsc_a_valid, fsc_h_valid)\n",
    "                    mask[valid] = singlets_mask\n",
    "                    \n",
    "                    n_singlets = mask.sum()\n",
    "                    n_doublets = valid.sum() - n_singlets\n",
    "                    print(f\"   [RATIO FALLBACK] Singlets: {n_singlets:,} ({n_singlets/valid.sum()*100:.1f}%)\")\n",
    "                    \n",
    "                    gate_result = GateResult(\n",
    "                        mask=mask, n_kept=int(n_singlets), n_total=int(n_cells),\n",
    "                        method=\"ratio_fallback_global\", gate_name=\"G2_singlets\",\n",
    "                        details={\"r2\": float(r2_val)},\n",
    "                        warnings=[warn_msg],\n",
    "                    )\n",
    "                    gating_reports.append(gate_result)\n",
    "                    return mask\n",
    "            \n",
    "            # PrÃ©diction et rÃ©sidus\n",
    "            fsc_a_pred = ransac.predict(fsc_h_valid)\n",
    "            residuals = fsc_a_valid.ravel() - fsc_a_pred\n",
    "            \n",
    "            # Seuil adaptatif MAD\n",
    "            median_residual = np.median(residuals)\n",
    "            mad = np.median(np.abs(residuals - median_residual))\n",
    "            threshold_upper = median_residual + 3.0 * mad\n",
    "            \n",
    "            # Masque singlets\n",
    "            singlets_mask = residuals <= threshold_upper\n",
    "            mask[valid] = singlets_mask\n",
    "            \n",
    "            n_singlets = mask.sum()\n",
    "            n_doublets = valid.sum() - n_singlets\n",
    "            slope = ransac.estimator_.coef_[0]\n",
    "            intercept = ransac.estimator_.intercept_\n",
    "            \n",
    "            r2_str = f\", RÂ²={r2_val:.3f}\" if r2_val is not None else \"\"\n",
    "            print(f\"   [Auto-RANSAC] Droite: y = {slope:.3f}x + {intercept:.0f}{r2_str}\")\n",
    "            print(f\"   [Auto-RANSAC] Seuil MAD: mÃ©diane + {3.0:.1f}Ã—MAD = {threshold_upper:.0f}\")\n",
    "            print(f\"   [Auto-RANSAC] Singlets: {n_singlets:,} ({n_singlets/valid.sum()*100:.1f}%)\")\n",
    "            print(f\"   [Auto-RANSAC] Doublets rejetÃ©s: {n_doublets:,} ({n_doublets/valid.sum()*100:.1f}%)\")\n",
    "        \n",
    "        # GateResult structurÃ©\n",
    "        gate_result = GateResult(\n",
    "            mask=mask, n_kept=int(mask.sum()), n_total=int(n_cells),\n",
    "            method=\"ransac_singlets\", gate_name=\"G2_singlets\",\n",
    "            details={\n",
    "                \"per_file\": per_file,\n",
    "                \"n_files\": len(singlets_summary_per_file) if per_file else 1,\n",
    "                \"files_summary\": singlets_summary_per_file if per_file else [],\n",
    "            },\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_cd45(X: np.ndarray, var_names: List[str],\n",
    "                        n_components: int = 2,\n",
    "                        uniform_gating: bool = False,\n",
    "                        threshold_percentile: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate CD45+ adaptatif par GMM 1D.\n",
    "        \n",
    "        Trouve automatiquement le creux bimodal entre CD45- et CD45+\n",
    "        au lieu d'un percentile fixe. Le GMM modÃ©lise la distribution\n",
    "        bimodale et assigne chaque Ã©vÃ©nement Ã  la population la plus probable.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es\n",
    "            var_names: Noms des marqueurs\n",
    "            n_components: Nombre de composantes GMM (2 = CD45- / CD45+)\n",
    "            uniform_gating: Si True, applique un seuil soft (percentile)\n",
    "            threshold_percentile: Percentile pour le seuil soft CD45\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en (True = CD45+, False = CD45-)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        \n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouvÃ© pour auto-gate CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45 = X[:, cd45_idx].astype(np.float64)\n",
    "        valid = np.isfinite(cd45)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de donnÃ©es valides pour auto-gate CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Mode uniform_gating: seuil soft par percentile (pas de GMM)\n",
    "        if uniform_gating:\n",
    "            threshold = np.nanpercentile(cd45[valid], threshold_percentile)\n",
    "            mask = np.zeros(n_cells, dtype=bool)\n",
    "            mask[valid] = cd45[valid] > threshold\n",
    "            n_pos = mask.sum()\n",
    "            print(f\"   [Uniform-CD45] Seuil soft: {threshold:.0f} (percentile {threshold_percentile}%)\")\n",
    "            print(f\"   [Uniform-CD45] CD45+ identifiÃ©s: {n_pos:,} ({n_pos/valid.sum()*100:.1f}%)\")\n",
    "            \n",
    "            gate_result = GateResult(\n",
    "                mask=mask, n_kept=int(n_pos), n_total=int(valid.sum()),\n",
    "                method=\"gmm_cd45_uniform\", gate_name=\"G3_cd45\",\n",
    "                details={\"threshold\": float(threshold), \"percentile\": threshold_percentile, \"fallback\": False},\n",
    "            )\n",
    "            gating_reports.append(gate_result)\n",
    "            log_gating_event(\"cd45\", \"uniform_percentile\", \"success\",\n",
    "                             {\"threshold\": float(threshold), \"n_pos\": int(n_pos)})\n",
    "            return mask\n",
    "        \n",
    "        # GMM pour sÃ©parer CD45- et CD45+\n",
    "        try:\n",
    "            gmm = AutoGating.safe_fit_gmm(\n",
    "                cd45[valid].reshape(-1, 1),\n",
    "                n_components=n_components, n_init=3\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            warn_msg = f\"GMM CD45 Ã©chouÃ©: {e} â€” fallback percentile\"\n",
    "            print(f\"   [!] {warn_msg}\")\n",
    "            log_gating_event(\"cd45\", \"gmm_fallback_percentile\", \"fallback\",\n",
    "                             {\"error\": str(e)}, warn_msg)\n",
    "            threshold = np.nanpercentile(cd45[valid], threshold_percentile)\n",
    "            mask = np.zeros(n_cells, dtype=bool)\n",
    "            mask[valid] = cd45[valid] > threshold\n",
    "            \n",
    "            gate_result = GateResult(\n",
    "                mask=mask, n_kept=int(mask.sum()), n_total=int(valid.sum()),\n",
    "                method=\"gmm_cd45_fallback_percentile\", gate_name=\"G3_cd45\",\n",
    "                details={\"threshold\": float(threshold), \"fallback\": True},\n",
    "                warnings=[warn_msg],\n",
    "            )\n",
    "            gating_reports.append(gate_result)\n",
    "            return mask\n",
    "        \n",
    "        labels = gmm.predict(cd45[valid].reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        \n",
    "        # CD45+ = composant avec la moyenne la plus Ã©levÃ©e\n",
    "        pos_component = np.argmax(means)\n",
    "        \n",
    "        # Calculer le seuil approximatif (intersection des 2 gaussiennes)\n",
    "        sorted_means = np.sort(means)\n",
    "        stds = np.sqrt(gmm.covariances_.flatten())\n",
    "        sorted_stds = stds[np.argsort(means)]\n",
    "        threshold_approx = (sorted_means[0] * sorted_stds[1] + sorted_means[1] * sorted_stds[0]) / (sorted_stds[0] + sorted_stds[1])\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = (labels == pos_component)\n",
    "        \n",
    "        n_pos = mask.sum()\n",
    "        print(f\"   [Auto-GMM] CD45: {n_components} composantes, Î¼={means.round(0)}\")\n",
    "        print(f\"   [Auto-GMM] Seuil adaptatif â‰ˆ {threshold_approx:.0f} (creux entre populations)\")\n",
    "        print(f\"   [Auto-GMM] CD45+ identifiÃ©s: {n_pos:,} ({n_pos/valid.sum()*100:.1f}%)\")\n",
    "        \n",
    "        gate_result = GateResult(\n",
    "            mask=mask, n_kept=int(n_pos), n_total=int(valid.sum()),\n",
    "            method=\"gmm_cd45\", gate_name=\"G3_cd45\",\n",
    "            details={\n",
    "                \"means\": means.tolist(), \"threshold\": float(threshold_approx),\n",
    "                \"n_components\": int(n_components), \"fallback\": False,\n",
    "            },\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        log_gating_event(\"cd45\", \"gmm\", \"success\", {\n",
    "            \"means\": means.tolist(), \"threshold\": float(threshold_approx), \"n_pos\": int(n_pos),\n",
    "        })\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_cd34(X: np.ndarray, var_names: List[str],\n",
    "                        use_ssc_filter: bool = True,\n",
    "                        n_components: int = 2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate CD34+ blastes adaptatif par GMM.\n",
    "        \n",
    "        Identifie la population CD34 bright (blastes) par GMM au lieu d'un \n",
    "        percentile fixe. Optionnel: combine avec SSC low (blastes = faible granularitÃ©).\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des donnÃ©es\n",
    "            var_names: Noms des marqueurs\n",
    "            use_ssc_filter: Combiner avec filtre GMM SSC low\n",
    "            n_components: Nombre de composantes GMM\n",
    "        \n",
    "        Returns:\n",
    "            Masque boolÃ©en (True = blaste CD34+, False = autre)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        \n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouvÃ© pour auto-gate blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34 = X[:, cd34_idx].astype(np.float64)\n",
    "        valid = np.isfinite(cd34)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de donnÃ©es valides pour auto-gate CD34\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # GMM pour sÃ©parer CD34- et CD34+\n",
    "        try:\n",
    "            gmm = AutoGating.safe_fit_gmm(\n",
    "                cd34[valid].reshape(-1, 1),\n",
    "                n_components=n_components, n_init=3\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            warn_msg = f\"GMM CD34 Ã©chouÃ©: {e} â€” conservation de toutes les cellules\"\n",
    "            print(f\"   [!] {warn_msg}\")\n",
    "            log_gating_event(\"cd34\", \"gmm\", \"error\", {\"error\": str(e)}, warn_msg)\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        labels = gmm.predict(cd34[valid].reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        pos_component = np.argmax(means)\n",
    "        \n",
    "        mask_cd34 = np.zeros(n_cells, dtype=bool)\n",
    "        mask_cd34[valid] = (labels == pos_component)\n",
    "        \n",
    "        n_cd34_pos = mask_cd34.sum()\n",
    "        print(f\"   [Auto-GMM] CD34: Î¼={means.round(0)}, CD34+ cluster = Î¼={means[pos_component]:.0f}\")\n",
    "        \n",
    "        # Filtre SSC low optionnel (blastes = faible granularitÃ©)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc = X[:, ssc_idx].astype(np.float64)\n",
    "                valid_ssc = np.isfinite(ssc)\n",
    "                \n",
    "                if valid_ssc.sum() >= 200:\n",
    "                    try:\n",
    "                        gmm_ssc = AutoGating.safe_fit_gmm(\n",
    "                            ssc[valid_ssc].reshape(-1, 1),\n",
    "                            n_components=2, n_init=3\n",
    "                        )\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"   [!] GMM SSC Ã©chouÃ©: {e} â€” filtre SSC ignorÃ©\")\n",
    "                        print(f\"   [Auto-GMM] CD34+ blastes: {n_cd34_pos:,}\")\n",
    "                        gate_result = GateResult(\n",
    "                            mask=mask_cd34, n_kept=int(n_cd34_pos), n_total=int(valid.sum()),\n",
    "                            method=\"gmm_cd34_no_ssc\", gate_name=\"G4_cd34\",\n",
    "                            details={\"means\": means.tolist(), \"ssc_filter\": False},\n",
    "                            warnings=[f\"GMM SSC Ã©chouÃ©: {e}\"],\n",
    "                        )\n",
    "                        gating_reports.append(gate_result)\n",
    "                        return mask_cd34\n",
    "                    \n",
    "                    labels_ssc = gmm_ssc.predict(ssc[valid_ssc].reshape(-1, 1))\n",
    "                    ssc_means = gmm_ssc.means_.flatten()\n",
    "                    low_ssc_component = np.argmin(ssc_means)\n",
    "                    \n",
    "                    mask_ssc = np.zeros(n_cells, dtype=bool)\n",
    "                    mask_ssc[valid_ssc] = (labels_ssc == low_ssc_component)\n",
    "                    \n",
    "                    combined = mask_cd34 & mask_ssc\n",
    "                    print(f\"   [Auto-GMM] + Filtre SSC low (Î¼={ssc_means[low_ssc_component]:.0f}): {combined.sum():,} blastes purs\")\n",
    "                    \n",
    "                    gate_result = GateResult(\n",
    "                        mask=combined, n_kept=int(combined.sum()), n_total=int(valid.sum()),\n",
    "                        method=\"gmm_cd34_ssc\", gate_name=\"G4_cd34\",\n",
    "                        details={\"cd34_means\": means.tolist(), \"ssc_means\": ssc_means.tolist(),\n",
    "                                 \"ssc_filter\": True},\n",
    "                    )\n",
    "                    gating_reports.append(gate_result)\n",
    "                    log_gating_event(\"cd34\", \"gmm+ssc\", \"success\", {\n",
    "                        \"cd34_means\": means.tolist(), \"ssc_means\": ssc_means.tolist(),\n",
    "                        \"n_blastes\": int(combined.sum()),\n",
    "                    })\n",
    "                    return combined\n",
    "        \n",
    "        print(f\"   [Auto-GMM] CD34+ blastes: {n_cd34_pos:,}\")\n",
    "        gate_result = GateResult(\n",
    "            mask=mask_cd34, n_kept=int(n_cd34_pos), n_total=int(valid.sum()),\n",
    "            method=\"gmm_cd34\", gate_name=\"G4_cd34\",\n",
    "            details={\"means\": means.tolist()},\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        return mask_cd34\n",
    "\n",
    "\n",
    "print(\"[OK] Classe AutoGating chargÃ©e (gating adaptatif)\")\n",
    "print(\"     MÃ©thodes disponibles:\")\n",
    "print(\"       â€¢ safe_fit_gmm:       Wrapper robuste GMM (retry + fallback unimodal + sous-Ã©chantillonnage)\")\n",
    "print(\"       â€¢ auto_gate_debris:   GMM 2D sur FSC-A/SSC-A (dÃ©tection adaptative dÃ©bris)\")\n",
    "print(\"       â€¢ auto_gate_singlets: RANSAC robuste FSC-A vs FSC-H + contrÃ´le RÂ² + fallback ratio\")\n",
    "print(\"       â€¢ auto_gate_cd45:     GMM 1D bimodal CD45- / CD45+ (+ uniform_gating)\")\n",
    "print(\"       â€¢ auto_gate_cd34:     GMM 1D + optionnel SSC low pour blastes\")\n",
    "print(\"     \")\n",
    "print(\"     [AMÃ‰LIORATIONS V2]\")\n",
    "print(\"       â†’ safe_fit_gmm: sous-Ã©chantillonnage 200k pts + retry + fallback unimodal\")\n",
    "print(\"       â†’ RANSAC singlets: contrÃ´le RÂ² inliers + fallback ratio si RÂ² < 0.85\")\n",
    "print(\"       â†’ Scatter FSC-A vs FSC-H par fichier + tableau % singlets stockÃ©s\")\n",
    "print(\"       â†’ GateResult structurÃ© retournÃ© par chaque fonction\")\n",
    "print(\"       â†’ Log structurÃ© JSON (gating_log_entries) pour audit automatique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f742d5",
   "metadata": {},
   "source": [
    "## 2. Chargement des Fichiers FCS\n",
    "\n",
    "Chargement des fichiers FCS depuis les dossiers spÃ©cifiÃ©s. \n",
    "- **Sain (NBM)**: Moelle osseuse normale (rÃ©fÃ©rence)\n",
    "- **Pathologique**: Ã‰chantillons patients Ã  analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DES CHEMINS\n",
    "# â†’ Valeurs contrÃ´lÃ©es par le panneau interactif (cellule 2) si exÃ©cutÃ©.\n",
    "#   Sinon, les valeurs par dÃ©faut ci-dessous sont utilisÃ©es.\n",
    "\n",
    "_cfg = globals().get('CONFIG', {})\n",
    "\n",
    "# Dossier des fichiers sains (rÃ©fÃ©rence NBM)\n",
    "HEALTHY_FOLDER = Path(_cfg.get('HEALTHY_FOLDER', r\"C:\\Users\\Florian Travail\\Documents\\FlowSom\\Data\\Moelle normale\"))\n",
    "\n",
    "# Dossier des fichiers pathologiques (patients)\n",
    "PATHOLOGICAL_FOLDER = Path(_cfg.get('PATHOLOGICAL_FOLDER', r\"Data/Patho\"))\n",
    "\n",
    "# Mode d'analyse: True = Comparer Sain vs Pathologique, False = Patient seul\n",
    "COMPARE_MODE = _cfg.get('COMPARE_MODE', True)\n",
    "\n",
    "print(f\"Dossier Sain: {HEALTHY_FOLDER}\")\n",
    "print(f\"Dossier Pathologique: {PATHOLOGICAL_FOLDER}\")\n",
    "print(f\"Mode comparaison: {'ActivÃ©' if COMPARE_MODE else 'Patient seul'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTIONS DE CHARGEMENT FCS\n",
    "\n",
    "def get_fcs_files(folder: Path) -> List[str]:\n",
    "    \"\"\"RÃ©cupÃ¨re la liste des fichiers FCS dans un dossier. Et renvoie une chaine de caractÃ¨re\"\"\"\n",
    "    if not folder.exists():\n",
    "        print(f\"[!] Dossier non trouvÃ©: {folder}\")\n",
    "        return []\n",
    "    \n",
    "    files = set()\n",
    "    for f in folder.glob(\"*.fcs\"):\n",
    "        files.add(str(f))\n",
    "    for f in folder.glob(\"*.FCS\"):\n",
    "        files.add(str(f))\n",
    "    \n",
    "    return sorted(list(files))\n",
    "\n",
    "\n",
    "def load_fcs_files(files: List[str], condition: str = \"Unknown\") -> List[ad.AnnData]:\n",
    "    \"\"\"\n",
    "    Charge plusieurs fichiers FCS et retourne une liste d'AnnData.\n",
    "    \n",
    "    Args:\n",
    "        files: Liste des chemins de fichiers FCS\n",
    "        condition: Label de condition (\"Sain\" ou \"Pathologique\")\n",
    "    \n",
    "    Returns:\n",
    "        Liste d'objets AnnData\n",
    "    \"\"\"\n",
    "    # La ligne suivante crÃ©e la liste vide pour stocker les AnnData puis boucle sur chaque fichier (Ã©viter le plantage complet)\n",
    "    adatas = []\n",
    "    \n",
    "    for fpath in files:\n",
    "        try:\n",
    "            print(f\"    Chargement: {Path(fpath).name}...\", end=\" \")\n",
    "            \n",
    "            # Lecture avec la fonction de base de flowsom\n",
    "            adata = fs.io.read_FCS(fpath)\n",
    "            \n",
    "            # Ajouter les mÃ©tadonnÃ©es avec un nombre de cellules qui sera Ã©gale a la forme de l'objet adata \n",
    "            n_cells = adata.shape[0]\n",
    "            adata.obs['condition'] = condition # Rajoute la condition du fichier : \"Sain\" ou \"Pathologique\"\n",
    "            adata.obs['file_origin'] = Path(fpath).name # Rajoute une observation avec Nom du fichier source (obs = One-dimensional annotation of observations)\n",
    "            \n",
    "            adatas.append(adata) # Ajoute Ã  la liste des AnnData\n",
    "            print(f\"{n_cells:,} cellules\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur: {e}\")\n",
    "    \n",
    "    return adatas\n",
    "\n",
    "# Logs sur le cahrgement des fichiers\n",
    "print(\"=\"*60)\n",
    "print(\"CHARGEMENT DES FICHIERS FCS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fichiers sains en fonction du mode dÃ©fini\n",
    "healthy_files = get_fcs_files(HEALTHY_FOLDER) if COMPARE_MODE else []\n",
    "print(f\"\\nFichiers Sains (NBM): {len(healthy_files)}\")\n",
    "\n",
    "healthy_adatas = []\n",
    "if healthy_files:\n",
    "    healthy_adatas = load_fcs_files(healthy_files, condition=\"Sain\")\n",
    "\n",
    "# Fichiers sains en fonction du mode dÃ©fini\n",
    "patho_files = get_fcs_files(PATHOLOGICAL_FOLDER)\n",
    "print(f\"\\nFichiers Pathologiques: {len(patho_files)}\")\n",
    "\n",
    "patho_adatas = []\n",
    "if patho_files:\n",
    "    patho_adatas = load_fcs_files(patho_files, condition=\"Pathologique\")\n",
    "\n",
    "# RÃ©sumÃ©\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"RÃ‰SUMÃ‰ DU CHARGEMENT\")\n",
    "print(f\"   Fichiers Sains chargÃ©s: {len(healthy_adatas)}\")\n",
    "print(f\"   Fichiers Pathologiques chargÃ©s: {len(patho_adatas)}\")\n",
    "# RÃ©sumÃ© a.shape = pour chaque AnnData, prend le nombre de cellules (lignes) et concatÃ¨ne si nÃ©cessaire\n",
    "total_cells = sum([a.shape[0] for a in healthy_adatas + patho_adatas])\n",
    "print(f\"   Total cellules: {total_cells:,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495d578",
   "metadata": {},
   "source": [
    "## 3. Exploration de la Structure des DonnÃ©es Brutes\n",
    "\n",
    "Avant toute transformation, examinons la structure des donnÃ©es:\n",
    "- Dimensions (cellules x marqueurs)\n",
    "- Noms des colonnes (marqueurs)\n",
    "- Types de donnÃ©es et plages de valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de539adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATÃ‰NATION DES DONNÃ‰ES\n",
    "\n",
    "# Combiner tous les AnnData dÃ©fini dans la cellule prÃ©cÃ©dente\n",
    "all_adatas = healthy_adatas + patho_adatas\n",
    "\n",
    "# VÃ©rification\n",
    "if len(all_adatas) == 0:\n",
    "    raise ValueError(\"[X] Aucun fichier FCS chargÃ©! VÃ©rifiez les chemins.\")\n",
    "\n",
    "# ConcatÃ©ner avec intersection des colonnes (communes Ã  tous les fichiers) ligne par ligne\n",
    "if len(all_adatas) > 1:\n",
    "    combined_data = ad.concat(all_adatas, join='inner') # join='inner' pour ne garder que les marqueurs communs Ã  changer par outer si on veut garder tous les marqueurs\n",
    "else:\n",
    "    combined_data = all_adatas[0].copy() # Si un seul fichier, juste copier pour Ã©viter de mofifier l'original\n",
    "\n",
    "print(f\"DonnÃ©es combinÃ©es: {combined_data.shape}\")\n",
    "print(f\"   â†’ {combined_data.shape[0]:,} cellules\")\n",
    "print(f\"   â†’ {combined_data.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATION DE LA STRUCTURE\n",
    "print(\"=\"*70)\n",
    "print(\"STRUCTURE DES DONNÃ‰ES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Liste des marqueurs enregistrÃ© dans la varaible var_names = canaux (ici c'est bien un nom de variable)\n",
    "var_names = list(combined_data.var_names)\n",
    "print(f\"\\nMarqueurs ({len(var_names)}):\")\n",
    "for i, name in enumerate(var_names):\n",
    "    print(f\"   [{i:2d}] {name}\")\n",
    "\n",
    "# Identification des types de marqueurs car les recos indiquent d'enelever le scatter pour les analyses de clustering\n",
    "print(\"\\nClassification des marqueurs:\")\n",
    "\n",
    "#Ici le code n for n in var pose la question : \"Est-ce qu'au moins UN des motifs de la liste scatter_patterns se trouve dans le nom actuel n ?\"\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "scatter_markers = [n for n in var_names if any(p in n.upper() for p in scatter_patterns)]\n",
    "fluor_markers = [n for n in var_names if n not in scatter_markers]\n",
    "\n",
    "print(f\"   Scatter/Time: {scatter_markers}\")\n",
    "print(f\"   Fluorescence: {fluor_markers}\")\n",
    "\n",
    "# Statistiques de base\n",
    "print(\"\\nObservations (mÃ©tadonnÃ©es):\")\n",
    "print(combined_data.obs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION EN DATAFRAME POUR EXPLORATION\n",
    "HEADER = True\n",
    "# Extraire la matrice de donnÃ©es\n",
    "X = combined_data.X # Matrice des donnÃ©es (n_cells, n_markers)\n",
    "if hasattr(X, 'toarray'): # Si sparse matrix, convertir en dense pour pandas\n",
    "    X = X.toarray()\n",
    "\n",
    "# CrÃ©er un DataFrame pandas pour faciliter l'exploration avec df comme commande pandas classique\n",
    "df_raw = pd.DataFrame(X, columns=var_names) # CrÃ©e le DataFrame avec les noms de colonnes \n",
    "df_raw['condition'] = combined_data.obs['condition'].values # Ajoute une colonne condition\n",
    "df_raw['file_origin'] = combined_data.obs['file_origin'].values # Ajoute une colonne file_origin\n",
    "\n",
    "print(\"DataFrame crÃ©Ã© pour exploration\")\n",
    "print(f\"   Shape: {df_raw.shape}\")\n",
    "print(\"\\nAperÃ§u des donnÃ©es brutes:\")\n",
    "df_raw.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats descriptives marqueurs de fluorescence et scatter\n",
    "print(\"Statistiques descriptives fluorescence\")\n",
    "display(df_raw[fluor_markers].describe())\n",
    "\n",
    "print(\"\\nStatistiques descriptives scatter\")\n",
    "display(df_raw[scatter_markers].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125cfaf",
   "metadata": {},
   "source": [
    "## 4. ContrÃ´le QualitÃ© des donnÃ©es- Analyse des Distributions\n",
    "\n",
    "Visualisation des distributions brutes pour identifier:\n",
    "- Outliers et valeurs aberrantes\n",
    "- Valeurs nÃ©gatives (problÃ¨me de compensation)\n",
    "- NaN/Inf dans les donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VÃ©rif des varaibles problÃ©matiques suite de l'exploration du dataset\n",
    "\n",
    "print(\"ANALYSE DES DONNÃ‰ES BRUTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========== MARQUEURS DE FLUORESCENCE ==========\n",
    "print(\"\\nMARQUEURS DE FLUORESCENCE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# VÃ©rifier NaN\n",
    "nan_count = df_raw[fluor_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN dÃ©tectÃ©!\")\n",
    "\n",
    "# VÃ©rifier Inf (valeur infinie) ex sur un post log \n",
    "inf_count = np.isinf(df_raw[fluor_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf dÃ©tectÃ©!\")\n",
    "else:\n",
    "    for marker, count in inf_count.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# VÃ©rifier valeurs nÃ©gatives\n",
    "neg_count = (df_raw[fluor_markers] < 0).sum()\n",
    "print(f\"\\nâ– Valeurs nÃ©gatives par marqueur:\")\n",
    "has_negatives = False\n",
    "for marker, count in neg_count.items():\n",
    "    if count > 0:\n",
    "        has_negatives = True\n",
    "        # Compter le nombre total de cellules valides (non-NaN) pour ce marqueur\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives:\n",
    "    print(\"   [OK] Aucune valeur nÃ©gative!\")\n",
    "else:\n",
    "    print(\"\\n   [!] Les valeurs nÃ©gatives peuvent indiquer un problÃ¨me de compensation\")\n",
    "    print(\"   â†’ La transformation Arcsinh ou Logicle peut les gÃ©rer\")\n",
    "\n",
    "# ========== MARQUEURS SCATTER/TIME ==========\n",
    "print(\"\\n\\nMARQUEURS SCATTER/TIME\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# VÃ©rifier NaN\n",
    "nan_count_scatter = df_raw[scatter_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count_scatter.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN dÃ©tectÃ©!\")\n",
    "\n",
    "# VÃ©rifier Inf\n",
    "inf_count_scatter = np.isinf(df_raw[scatter_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf dÃ©tectÃ©!\")\n",
    "else:\n",
    "    for marker, count in inf_count_scatter.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# VÃ©rifier valeurs nÃ©gatives\n",
    "neg_count_scatter = (df_raw[scatter_markers] < 0).sum()\n",
    "print(f\"\\nâ– Valeurs nÃ©gatives par marqueur:\")\n",
    "has_negatives_scatter = False\n",
    "for marker, count in neg_count_scatter.items():\n",
    "    if count > 0:\n",
    "        has_negatives_scatter = True\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives_scatter:\n",
    "    print(\"   [OK] Aucune valeur nÃ©gative!\")\n",
    "else:\n",
    "    print(\"\\n   â„¹ï¸ Les valeurs nÃ©gatives dans scatter sont rares mais possibles\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des distributions brutes pour explorer visuellement les donnÃ©es\n",
    "\n",
    "# SÃ©lectionner les marqueurs Ã  visualiser (max 12 pour lisibilitÃ©)\n",
    "markers_to_plot = fluor_markers[:12] if len(fluor_markers) > 12 else fluor_markers  # OpÃ©rateur ternaire: prendre 12 premiers si > 12, sinon tous\n",
    "\n",
    "n_markers = len(markers_to_plot)  # Nombre de marqueurs Ã  afficher\n",
    "n_cols = 4  # 4 colonnes par ligne\n",
    "n_rows = (n_markers + n_cols - 1) // n_cols  # Calcul nb lignes (division entiÃ¨re arrondie vers le haut)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))  # CrÃ©er grille n_rows Ã— n_cols (largeur 20, hauteur 5 par ligne)\n",
    "axes = axes.flatten() if n_markers > 1 else [axes]  # Aplatir tableau 2D en liste 1D pour itÃ©ration facile\n",
    "\n",
    "for i, marker in enumerate(markers_to_plot):  # Boucle sur chaque marqueur avec index i\n",
    "    ax = axes[i]  # RÃ©cupÃ©rer le sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Extraire donnÃ©es du marqueur et supprimer NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#89b4fa', alpha=0.7, edgecolor='none')  # Histogramme 100 barres, bleu, 70% opacitÃ©\n",
    "    ax.set_title(marker, fontsize=11, fontweight='bold')  # Titre = nom du marqueur\n",
    "    ax.set_xlabel('Valeur brute')  # Label axe X\n",
    "    ax.set_ylabel('Count')  # Label axe Y = nombre de cellules\n",
    "    ax.axvline(0, color='#f38ba8', linestyle='--', alpha=0.5, label='ZÃ©ro')  # Ligne verticale rouge Ã  x=0\n",
    "    \n",
    "    # Statistiques min/max dans une boÃ®te en haut Ã  droite\n",
    "    ax.text(0.98, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}',  # Texte avec stats\n",
    "            transform=ax.transAxes, ha='right', va='top', fontsize=8,  # CoordonnÃ©es relatives (0-1), alignement\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))  # BoÃ®te grise arrondie semi-transparente\n",
    "\n",
    "# Cacher les axes vides (si 10 marqueurs sur grille 3Ã—4, cacher les 2 derniÃ¨res cases)\n",
    "for i in range(n_markers, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Brutes des Marqueurs (avant transformation)',  # Titre gÃ©nÃ©ral\n",
    "             fontsize=14, fontweight='bold', y=1.02)  # DÃ©calÃ© vers le haut\n",
    "plt.tight_layout()  # Ajuster espacement auto\n",
    "plt.show()  # Afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des marqueurs SCATTER/TIME pour exploration visuelle\n",
    "\n",
    "# SÃ©lectionner tous les marqueurs scatter (gÃ©nÃ©ralement peu nombreux)\n",
    "scatter_to_plot = scatter_markers  # FSC, SSC, TIME\n",
    "\n",
    "n_scatter = len(scatter_to_plot)  # Nombre de marqueurs scatter\n",
    "n_cols_scatter = min(3, n_scatter)  # Max 3 colonnes pour les scatter\n",
    "n_rows_scatter = (n_scatter + n_cols_scatter - 1) // n_cols_scatter  # Calcul nb lignes\n",
    "\n",
    "fig, axes = plt.subplots(n_rows_scatter, n_cols_scatter, figsize=(18, 6*n_rows_scatter))  # Grille pour scatter (largeur 18, hauteur 6 par ligne)\n",
    "axes = axes.flatten() if n_scatter > 1 else [axes]  # Aplatir en liste 1D\n",
    "\n",
    "for i, marker in enumerate(scatter_to_plot):  # Boucle sur chaque marqueur scatter\n",
    "    ax = axes[i]  # Sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # DonnÃ©es sans NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#a6e3a1', alpha=0.7, edgecolor='none')  # Vert pour diffÃ©rencier\n",
    "    ax.set_title(marker, fontsize=12, fontweight='bold')  # Titre\n",
    "    ax.set_xlabel('Valeur brute')  # Axe X\n",
    "    ax.set_ylabel('Count')  # Axe Y\n",
    "    \n",
    "    # Statistiques complÃ¨tes\n",
    "    ax.text(0.02, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}\\nmean: {data.mean():.0f}\\nmedian: {data.median():.0f}',\n",
    "            transform=ax.transAxes, ha='left', va='top', fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))\n",
    "\n",
    "# Cacher axes vides\n",
    "for i in range(n_scatter, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Scatter/Time (FSC, SSC, TIME)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910ba5b",
   "metadata": {},
   "source": [
    "### Visualisation Interactive avec FlowKit + Bokeh\n",
    "\n",
    "Utilisation native de FlowKit pour visualisations interactives :\n",
    "- **Histogrammes** avec bins/ranges personnalisables\n",
    "- **Scatter plots** interactifs avec zoom/pan\n",
    "- **Contour plots** avec densitÃ©\n",
    "- Rendu Bokeh pour l'interactivitÃ© (zoom, pan, hover)\n",
    "\n",
    "ğŸ“š Documentation : https://flowkit.readthedocs.io/en/latest/index.html\n",
    "https://www.frontiersin.org/journals/immunology/articles/10.3389/fimmu.2021.768541/full\n",
    "\n",
    "---\n",
    "\n",
    "### [!] IMPORTANT : Nomenclature FCS\n",
    "\n",
    "**FlowKit utilise les PnN labels** (noms techniques), pas les PnS (descriptions).\n",
    "\n",
    "- **PnN** = Nom technique (ex: `'Horizon V500-A'`) â† Ã€ utiliser\n",
    "- **PnS** = Description bio (ex: `'CD45 KO'`) â† Non utilisable\n",
    "\n",
    "**Exemple :** Pour CD45, utiliser `'Horizon V500-A'` (pas `'CD45 KO'`).\n",
    "\n",
    "ExÃ©cutez la cellule suivante pour voir la correspondance PnN â†” PnS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbddc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation FlowKit et Bokeh + CrÃ©ation du Sample\n",
    "\n",
    "if not FLOWKIT_AVAILABLE:\n",
    "    fk_sample = None\n",
    "else:\n",
    "    try:\n",
    "        from bokeh.plotting import show, output_notebook\n",
    "        from bokeh.io import export_png\n",
    "        output_notebook()\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Utiliser les fichiers FCS dÃ©jÃ  identifiÃ©s dans le notebook\n",
    "    all_fcs_files = healthy_files + patho_files\n",
    "    \n",
    "    if all_fcs_files:\n",
    "        example_fcs = str(all_fcs_files[0])\n",
    "        fk_sample = fk.Sample(example_fcs)\n",
    "    else:\n",
    "        fk_sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHER LES NOMS DE CANAUX EXACTS DU FICHIER FCS\n",
    "\n",
    "if fk_sample is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"CANAUX DU FICHIER FCS: {Path(example_fcs).name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nPnN Labels ({len(fk_sample.pnn_labels)} canaux) - NOMS Ã€ UTILISER DANS FLOWKIT:\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pnn_labels, 1):\n",
    "        print(f\"   [{i:2d}] '{label}'\")\n",
    "    \n",
    "    # Afficher aussi les PnS labels (descriptions) si disponibles\n",
    "    print(f\"\\n\\nPnS Labels (descriptions):\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pns_labels, 1):\n",
    "        print(f\"   [{i:2d}] {label}\")\n",
    "    \n",
    "else:\n",
    "    print(\"[!] FlowKit Sample non chargÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finir les colonnes FSC et SSC pour les visualisations ultÃ©rieures\n",
    "fsc_col = next((c for c in var_names if 'FSC-A' in c.upper() or 'FSC' in c.upper()), None)\n",
    "ssc_col = next((c for c in var_names if 'SSC-A' in c.upper() or 'SSC' in c.upper()), None)\n",
    "\n",
    "if fsc_col:\n",
    "    print(f\"[OK] FSC dÃ©tectÃ©: {fsc_col}\")\n",
    "if ssc_col:\n",
    "    print(f\"[OK] SSC dÃ©tectÃ©: {ssc_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae982a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme basique FlowKit (Ã©chelle linÃ©aire)\n",
    "# source='raw' = donnÃ©es LINÃ‰AIRES (non transformÃ©es)\n",
    "# source='xform' = donnÃ©es transformÃ©es (Logicle)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    CHANNEL = 'FSC-H'  # Changer ici le channel Ã  afficher\n",
    "    \n",
    "    # Histogramme en Ã©chelle LINÃ‰AIRE (source='raw')\n",
    "    p = fk_sample.plot_histogram(CHANNEL, source='raw', bins=256)\n",
    "    \n",
    "    # Forcer l'Ã©chelle linÃ©aire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # DÃ©sactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Histogramme {CHANNEL} - Ã‰chelle LINÃ‰AIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af808182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot 2D interactif (Ã©chelle linÃ©aire)\n",
    "# source='raw' = donnÃ©es LINÃ‰AIRES (non transformÃ©es)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    x_channel = 'FSC-H'\n",
    "    y_channel = 'SSC-H'\n",
    "    \n",
    "    # Scatter en Ã©chelle LINÃ‰AIRE (source='raw')\n",
    "    p = fk_sample.plot_scatter(x_channel, y_channel, source='raw', color_density=True)\n",
    "    \n",
    "    # Forcer l'Ã©chelle linÃ©aire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # DÃ©sactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Scatter {x_channel} vs {y_channel} - Ã‰chelle LINÃ‰AIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme 1D interactif avec Plotly (zoom, pan, hover)\n",
    "# SÃ©lectionner un marqueur Ã  visualiser (modifiable)\n",
    "MARKER_TO_PLOT = 'CD45 KO525-H'  # Changer ici le nom exact du marqueur Ã  visualiser\n",
    "\n",
    "print(f\"Visualisation: {MARKER_TO_PLOT}\")\n",
    "\n",
    "# Extraire les donnÃ©es\n",
    "marker_data = df_raw[MARKER_TO_PLOT].dropna().values\n",
    "\n",
    "# Importer plotly pour l'interactivitÃ©\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    \n",
    "    # Configurer le renderer pour Jupyter (Ã©vite l'erreur nbformat)\n",
    "    try:\n",
    "        pio.renderers.default = 'notebook'\n",
    "    except:\n",
    "        try:\n",
    "            pio.renderers.default = 'jupyterlab'\n",
    "        except:\n",
    "            pio.renderers.default = 'browser'\n",
    "    \n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non installÃ© - pip install plotly\")\n",
    "\n",
    "if PLOTLY_AVAILABLE:\n",
    "    # CrÃ©er une figure avec 4 subplots (2x2)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            f'{MARKER_TO_PLOT} - Brut (LinÃ©aire)',\n",
    "            f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)',\n",
    "            f'{MARKER_TO_PLOT} - Logicle',\n",
    "            f'{MARKER_TO_PLOT} - Log10'\n",
    "        ),\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # 1. DonnÃ©es brutes\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_data, nbinsx=200, name='Brut',\n",
    "                     marker_color='#89b4fa', opacity=0.7,\n",
    "                     hovertemplate='IntensitÃ©: %{x:.1f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Arcsinh cofactor=5\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_arcsinh, nbinsx=200, name='Arcsinh (5)',\n",
    "                     marker_color='#a6e3a1', opacity=0.7,\n",
    "                     hovertemplate='IntensitÃ©: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Logicle ou Arcsinh cofactor=150\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        transform_name = 'Logicle'\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        transform_name = 'Arcsinh (150)'\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_logicle, nbinsx=200, name=transform_name,\n",
    "                     marker_color='#f9e2af', opacity=0.7,\n",
    "                     hovertemplate='IntensitÃ©: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Log10\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_log, nbinsx=200, name='Log10',\n",
    "                     marker_color='#cba6f7', opacity=0.7,\n",
    "                     hovertemplate='IntensitÃ©: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Mise en page\n",
    "    fig.update_xaxes(title_text=\"IntensitÃ© brute\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"IntensitÃ© transformÃ©e\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"IntensitÃ© transformÃ©e\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"IntensitÃ© log10\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"FrÃ©quence\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"FrÃ©quence\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"FrÃ©quence\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"FrÃ©quence\", row=2, col=2)\n",
    "    \n",
    "    # ThÃ¨me sombre et configuration\n",
    "    fig.update_layout(\n",
    "        title_text=f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)',\n",
    "        title_font_size=16,\n",
    "        height=900,\n",
    "        showlegend=False,\n",
    "        template='plotly_dark',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Afficher avec gestion d'erreur\n",
    "    try:\n",
    "        fig.show()\n",
    "        print(f\"\\n[OK] Visualisation interactive gÃ©nÃ©rÃ©e\")\n",
    "        print(f\"    Utilisez les outils Plotly: Zoom (box select), Pan, Reset, Download\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!] Erreur affichage Plotly: {e}\")\n",
    "        print(\"   â†’ Affichage en HTML dans le notebook...\")\n",
    "        \n",
    "        # Alternative: Afficher le HTML directement dans le notebook\n",
    "        try:\n",
    "            from IPython.display import HTML, display\n",
    "            html_str = fig.to_html(include_plotlyjs='cdn', include_mathjax='cdn')\n",
    "            display(HTML(html_str))\n",
    "            print(f\"   [OK] Graphique affichÃ© en HTML (pleinement interactif)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   [X] Erreur HTML: {e2}\")\n",
    "            # Dernier recours: sauvegarder en fichier\n",
    "            html_file = 'plotly_visualization.html'\n",
    "            fig.write_html(html_file)\n",
    "            print(f\"   â†’ Fichier sauvegardÃ©: {html_file}\")\n",
    "            print(f\"   â†’ Ouvrez ce fichier dans votre navigateur pour l'interactivitÃ© complÃ¨te\")\n",
    "    \n",
    "    print(f\"   Cellules: {len(marker_data):,}\")\n",
    "    print(f\"   Min brut: {marker_data.min():.2f} | Max brut: {marker_data.max():.2f}\")\n",
    "else:\n",
    "    # Fallback matplotlib si Plotly non disponible\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.hist(marker_data, bins=200, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Brut (LinÃ©aire)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('IntensitÃ© brute')\n",
    "    ax.set_ylabel('FrÃ©quence')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    ax.hist(marker_arcsinh, bins=200, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('IntensitÃ© transformÃ©e')\n",
    "    ax.set_ylabel('FrÃ©quence')\n",
    "    \n",
    "    ax = axes[2]\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Logicle', fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=150)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('IntensitÃ© transformÃ©e')\n",
    "    ax.set_ylabel('FrÃ©quence')\n",
    "    \n",
    "    ax = axes[3]\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    ax.hist(marker_log, bins=200, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Log10', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('IntensitÃ© transformÃ©e (log10)')\n",
    "    ax.set_ylabel('FrÃ©quence')\n",
    "    \n",
    "    plt.suptitle(f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95bf80",
   "metadata": {},
   "source": [
    "## 5. Pre-Gating: Ã‰limination des DÃ©bris, Doublets et SÃ©lection des Populations\n",
    "\n",
    "Application du pre-gating sÃ©quentiel en 4 Ã©tapes:\n",
    "\n",
    "1. **Gate 1 - DÃ©bris (SSC-A vs FSC-A)**: Exclusion des dÃ©bris et Ã©vÃ©nements hors-limites\n",
    "2. **Gate 2 - Doublets (FSC-H vs FSC-A)**: Exclusion des agrÃ©gats cellulaires\n",
    "3. **Gate 3 - Leucocytes CD45+ (CD45 vs SSC-A)**: SÃ©lection des leucocytes â€” **Gate principal**\n",
    "4. **Gate 4 - Blastes CD34+ (optionnel)**: Sous-sÃ©lection CD34 bright + SSC low\n",
    "\n",
    "### Choix du mode de gating : `GATING_MODE`\n",
    "\n",
    "| Mode | MÃ©thode | Avantage | InconvÃ©nient |\n",
    "|------|---------|----------|-------------|\n",
    "| `\"manual\"` | Percentiles fixes (PreGating) | Reproductible, rapide | Seuils arbitraires, perte si Ã©chantillon propre |\n",
    "| `\"auto\"` | GMM adaptatif (AutoGating) | Trouve le creux rÃ©el entre populations, s'adapte | DÃ©pend de la forme des distributions |\n",
    "\n",
    "### StratÃ©gie de gating classique en cytomÃ©trie:\n",
    "```\n",
    "Ã‰vÃ©nements totaux\n",
    "    â””â”€â”€ Gate DÃ©bris (SSC-A vs FSC-A) â†’ Cellules viables\n",
    "            â””â”€â”€ Gate Singlets (FSC-H vs FSC-A) â†’ Cellules individuelles\n",
    "                    â””â”€â”€ Gate CD45+ (CD45 vs SSC-A) â†’ Leucocytes\n",
    "                            â””â”€â”€ [optionnel] Gate CD34+ (CD34 vs SSC-A) â†’ Blastes\n",
    "```\n",
    "\n",
    "### ParamÃ¨tres:\n",
    "- **`GATING_MODE`**: `\"manual\"` (percentiles) ou `\"auto\"` (GMM adaptatif)\n",
    "- **`FILTER_BLASTS`**: True = sous-filtrage CD34+ | False = tous les CD45+ conservÃ©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ba663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLICATION DU PRE-GATING SÃ‰QUENTIEL (4 Ã‰TAPES)\n",
    "# =============================================================================\n",
    "# StratÃ©gie de gating hiÃ©rarchique:\n",
    "# 1. SSC-A vs FSC-A â†’ Exclure dÃ©bris\n",
    "# 2. FSC-H vs FSC-A â†’ Exclure doublets (singlets line)\n",
    "# 3. CD45 vs SSC-A  â†’ SÃ©lectionner leucocytes (GATE PRINCIPAL)\n",
    "# 4. CD34 vs SSC-A  â†’ SÃ©lectionner blastes (optionnel, si FILTER_BLASTS=True)\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== OPTIONS DE PRE-GATING =====================\n",
    "# â†’ Valeurs contrÃ´lÃ©es par le panneau interactif (cellule 2) si exÃ©cutÃ©.\n",
    "_cfg = globals().get('CONFIG', {})\n",
    "\n",
    "APPLY_PREGATING = _cfg.get('APPLY_PREGATING', True)\n",
    "GATING_MODE = _cfg.get('GATING_MODE', 'auto')  # \"manual\" ou \"auto\"\n",
    "MODE_BLASTES_VS_NORMAL = _cfg.get('MODE_BLASTES_VS_NORMAL', True)\n",
    "\n",
    "# Gate 1: DÃ©bris (SSC-A vs FSC-A)\n",
    "GATE_DEBRIS = _cfg.get('GATE_DEBRIS', True)\n",
    "DEBRIS_MIN_PERCENTILE = _cfg.get('DEBRIS_MIN_PERCENTILE', 1.0)\n",
    "DEBRIS_MAX_PERCENTILE = _cfg.get('DEBRIS_MAX_PERCENTILE', 99.0)\n",
    "\n",
    "# Gate 2: Doublets (FSC-H vs FSC-A)\n",
    "GATE_DOUBLETS = _cfg.get('GATE_DOUBLETS', True)\n",
    "RATIO_MIN = _cfg.get('RATIO_MIN', 0.6)\n",
    "RATIO_MAX = _cfg.get('RATIO_MAX', 1.4)\n",
    "\n",
    "# Gate 3: Leucocytes CD45+\n",
    "GATE_CD45 = _cfg.get('GATE_CD45', True)\n",
    "CD45_THRESHOLD_PERCENTILE = _cfg.get('CD45_THRESHOLD_PERCENTILE', 5)\n",
    "\n",
    "# Gate 4: Blastes CD34+ (optionnel)\n",
    "FILTER_BLASTS = _cfg.get('FILTER_BLASTS', False)\n",
    "CD34_THRESHOLD_PERCENTILE = _cfg.get('CD34_THRESHOLD_PERCENTILE', 85)\n",
    "USE_SSC_FILTER_FOR_BLASTS = _cfg.get('USE_SSC_FILTER_FOR_BLASTS', True)\n",
    "SSC_MAX_PERCENTILE_BLASTS = _cfg.get('SSC_MAX_PERCENTILE_BLASTS', 60)\n",
    "\n",
    "# =================================================================\n",
    "# VALIDATION DES PARAMÃˆTRES\n",
    "# =================================================================\n",
    "assert GATING_MODE in (\"manual\", \"auto\"), f\"GATING_MODE doit Ãªtre 'manual' ou 'auto', reÃ§u: '{GATING_MODE}'\"\n",
    "\n",
    "if GATING_MODE == \"auto\" and not SKLEARN_AVAILABLE:\n",
    "    print(\"[!] ATTENTION: scikit-learn requis pour GATING_MODE='auto'\")\n",
    "    print(\"    â†’ Fallback automatique vers mode 'manual'\")\n",
    "    GATING_MODE = \"manual\"\n",
    "\n",
    "# VÃ©rification de cohÃ©rence pour MODE_BLASTES_VS_NORMAL\n",
    "if MODE_BLASTES_VS_NORMAL and not COMPARE_MODE:\n",
    "    print(\"[!] ATTENTION: MODE_BLASTES_VS_NORMAL nÃ©cessite COMPARE_MODE=True\")\n",
    "    print(\"    â†’ Le mode a besoin de fichiers Sain + Patho pour fonctionner\")\n",
    "    print(\"    â†’ DÃ©sactivation automatique du mode diffÃ©rentiel\")\n",
    "    MODE_BLASTES_VS_NORMAL = False\n",
    "\n",
    "# DonnÃ©es avant gating\n",
    "X_raw = combined_data.X\n",
    "if hasattr(X_raw, 'toarray'):\n",
    "    X_raw = X_raw.toarray()\n",
    "n_before = X_raw.shape[0]\n",
    "\n",
    "# RÃ©cupÃ©rer le vecteur de conditions pour le mode diffÃ©rentiel\n",
    "conditions = combined_data.obs['condition'].values\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" PRE-GATING SÃ‰QUENTIEL - STRATÃ‰GIE EN 4 Ã‰TAPES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n Ã‰vÃ©nements initiaux: {n_before:,}\")\n",
    "\n",
    "# Affichage du mode de gating\n",
    "mode_label = \"AUTOMATIQUE (GMM adaptatif)\" if GATING_MODE == \"auto\" else \"MANUEL (percentiles fixes)\"\n",
    "print(f\"\\n Mode de gating: {mode_label}\")\n",
    "if GATING_MODE == \"auto\":\n",
    "    print(\"    â†’ Les seuils sont calculÃ©s automatiquement par modÃ¨le de mÃ©lange gaussien\")\n",
    "    print(\"    â†’ Les paramÃ¨tres [Manual] ci-dessus sont IGNORÃ‰S\")\n",
    "else:\n",
    "    print(\"    â†’ Seuils basÃ©s sur les percentiles configurÃ©s ci-dessus\")\n",
    "\n",
    "# Affichage mode spÃ©cial\n",
    "if MODE_BLASTES_VS_NORMAL:\n",
    "    print(\"\\n [!] MODE BLASTES vs MOELLE NORMALE ACTIVÃ‰ (GATING ASYMÃ‰TRIQUE)\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"     - Patho: Gate complet (dÃ©bris + doublets + CD45+ + CD34+) â†’ Blastes seuls\")\n",
    "    else:\n",
    "        print(\"     - Patho: Gate (dÃ©bris + doublets + CD45+) â†’ Leucocytes CD45+ stricts\")\n",
    "    print(\"     - Sain:  Gate (dÃ©bris + doublets UNIQUEMENT) â†’ Toutes les cellules conservÃ©es (pas de gate CD45)\")\n",
    "    n_patho = (conditions == \"Pathologique\").sum()\n",
    "    n_sain = (conditions == \"Sain\").sum()\n",
    "    print(f\"     - Cellules Patho: {n_patho:,}\")\n",
    "    print(f\"     - Cellules Sain: {n_sain:,}\")\n",
    "\n",
    "print(f\"\\n Configuration:\")\n",
    "print(f\"   [Gate 1] DÃ©bris (SSC-A/FSC-A):     {'[OK] ACTIVÃ‰' if GATE_DEBRIS else '[X] DÃ‰SACTIVÃ‰'}\")\n",
    "print(f\"   [Gate 2] Doublets (FSC-H/FSC-A):   {'[OK] ACTIVÃ‰' if GATE_DOUBLETS else '[X] DÃ‰SACTIVÃ‰'}\")\n",
    "if MODE_BLASTES_VS_NORMAL and GATE_CD45:\n",
    "    print(f\"   [Gate 3] Leucocytes CD45+:         [OK] PATHO UNIQUEMENT (gating asymÃ©trique â€” Sain: pas de gate CD45)\")\n",
    "else:\n",
    "    print(f\"   [Gate 3] Leucocytes CD45+:         {'[OK] ACTIVÃ‰' if GATE_CD45 else '[X] DÃ‰SACTIVÃ‰'}\")\n",
    "if FILTER_BLASTS:\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        print(f\"   [Gate 4] Blastes CD34+:            [OK] PATHO UNIQUEMENT (mode diffÃ©rentiel)\")\n",
    "    else:\n",
    "        print(f\"   [Gate 4] Blastes CD34+:            [OK] ACTIVÃ‰ (FILTER_BLASTS=True)\")\n",
    "else:\n",
    "    print(f\"   [Gate 4] Blastes CD34+:            [X] DÃ‰SACTIVÃ‰ (FILTER_BLASTS=False â†’ tous les CD45+ conservÃ©s)\")\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    # Initialisation des masques\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    \n",
    "    # ========== GATE 1: DÃ‰BRIS (SSC-A vs FSC-A) ==========\n",
    "    if GATE_DEBRIS:\n",
    "        print(f\"\\n GATE 1: Exclusion des dÃ©bris (SSC-A vs FSC-A) [{GATING_MODE.upper()}]\")\n",
    "        if GATING_MODE == \"auto\":\n",
    "            mask_debris = AutoGating.auto_gate_debris(X_raw, var_names)\n",
    "        else:\n",
    "            mask_debris = PreGating.gate_debris_polygon(\n",
    "                X_raw, var_names,\n",
    "                auto_percentiles=True,\n",
    "                min_pct=DEBRIS_MIN_PERCENTILE,\n",
    "                max_pct=DEBRIS_MAX_PERCENTILE\n",
    "            )\n",
    "        n_after_debris = mask_debris.sum()\n",
    "        n_excluded_debris = n_before - n_after_debris\n",
    "        if GATING_MODE == \"manual\":\n",
    "            print(f\"   Percentiles: [{DEBRIS_MIN_PERCENTILE}%, {DEBRIS_MAX_PERCENTILE}%]\")\n",
    "        print(f\"   â†’ ConservÃ©s: {n_after_debris:,} ({n_after_debris/n_before*100:.1f}%)\")\n",
    "        print(f\"   â†’ Exclus (dÃ©bris): {n_excluded_debris:,} ({n_excluded_debris/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n GATE 1: DÃ©bris - SKIP\")\n",
    "    \n",
    "    # ========== GATE 2: DOUBLETS (FSC-H vs FSC-A) ==========\n",
    "    if GATE_DOUBLETS:\n",
    "        print(f\"\\n GATE 2: Exclusion des doublets (FSC-H vs FSC-A) [{GATING_MODE.upper()}]\")\n",
    "        if GATING_MODE == \"auto\":\n",
    "            # Passer l'information des fichiers pour gating adaptatif par fichier\n",
    "            file_origins = combined_data.obs['file_origin'].values\n",
    "            mask_singlets = AutoGating.auto_gate_singlets(\n",
    "                X_raw, var_names, \n",
    "                file_origin=file_origins,\n",
    "                per_file=True  # Activer le gating par fichier\n",
    "            )\n",
    "        else:\n",
    "            mask_singlets = PreGating.gate_singlets(\n",
    "                X_raw, var_names,\n",
    "                ratio_min=RATIO_MIN,\n",
    "                ratio_max=RATIO_MAX\n",
    "            )\n",
    "        # Appliquer sur les cellules dÃ©jÃ  filtrÃ©es par gate 1\n",
    "        mask_after_g1_g2 = mask_debris & mask_singlets\n",
    "        n_after_singlets = mask_after_g1_g2.sum()\n",
    "        n_doublets = mask_debris.sum() - n_after_singlets\n",
    "        if GATING_MODE == \"manual\":\n",
    "            print(f\"   Ratio FSC-A/FSC-H: [{RATIO_MIN}, {RATIO_MAX}]\")\n",
    "        print(f\"   â†’ ConservÃ©s (singlets): {n_after_singlets:,}\")\n",
    "        print(f\"   â†’ Exclus (doublets): {n_doublets:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 2: Doublets - SKIP\")\n",
    "    \n",
    "    # ========== GATE 3: LEUCOCYTES CD45+ (CD45 vs SSC-A) â€” GATE PRINCIPAL ==========\n",
    "    # LOGIQUE ASYMÃ‰TRIQUE: Pathologique â†’ CD45 strict | Sain â†’ Pas de gate CD45\n",
    "    if GATE_CD45:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n GATE 3: SÃ©lection ASYMÃ‰TRIQUE CD45+ [{GATING_MODE.upper()}]\")\n",
    "            print(\"   â†’ Patho: Gate CD45+ STRICT appliquÃ© (Ã©limination CD45-)\")\n",
    "            print(\"   â†’ Sain:  Gate CD45+ IGNORÃ‰ (toutes cellules conservÃ©es â€” progÃ©niteurs, CD45 low/neg inclus)\")\n",
    "            \n",
    "            # Calculer le masque CD45+ sur TOUTES les donnÃ©es\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd45_full = AutoGating.auto_gate_cd45(X_raw, var_names)\n",
    "            else:\n",
    "                mask_cd45_full = PreGating.gate_cd45_positive(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD45_THRESHOLD_PERCENTILE\n",
    "                )\n",
    "            \n",
    "            # Appliquer le gate CD45 UNIQUEMENT aux cellules pathologiques\n",
    "            mask_patho_cd45 = (conditions == \"Pathologique\")\n",
    "            mask_sain_cd45 = (conditions == \"Sain\")\n",
    "            \n",
    "            # Masque CD45: True pour Sain (on garde tout), mask_cd45_full pour Patho\n",
    "            mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "            mask_cd45[mask_patho_cd45] = mask_cd45_full[mask_patho_cd45]\n",
    "            # Sain: mask_cd45 reste True â†’ aucun filtrage CD45\n",
    "            \n",
    "            # Stats par condition\n",
    "            n_patho_g12 = (mask_patho_cd45 & mask_debris & mask_singlets).sum()\n",
    "            n_patho_cd45_kept = (mask_patho_cd45 & mask_debris & mask_singlets & mask_cd45).sum()\n",
    "            n_patho_cd45_excl = n_patho_g12 - n_patho_cd45_kept\n",
    "            n_sain_g12 = (mask_sain_cd45 & mask_debris & mask_singlets).sum()\n",
    "            \n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD45+: percentile {CD45_THRESHOLD_PERCENTILE} (appliquÃ© PATHO uniquement)\")\n",
    "            print(f\"   â†’ Patho CD45+ conservÃ©s: {n_patho_cd45_kept:,} / {n_patho_g12:,} ({n_patho_cd45_kept/max(n_patho_g12,1)*100:.1f}%)\")\n",
    "            print(f\"   â†’ Patho CD45- exclus:    {n_patho_cd45_excl:,}\")\n",
    "            print(f\"   â†’ Sain conservÃ©s (100%):  {n_sain_g12:,} / {n_sain_g12:,} (aucun gate CD45)\")\n",
    "            \n",
    "            mask_after_g1_g2_g3 = mask_debris & mask_singlets & mask_cd45\n",
    "            n_after_cd45 = mask_after_g1_g2_g3.sum()\n",
    "            n_cd45_excluded = (mask_debris & mask_singlets).sum() - n_after_cd45\n",
    "            print(f\"   â†’ Total aprÃ¨s Gate 3: {n_after_cd45:,} (exclus CD45: {n_cd45_excluded:,} â€” Patho uniquement)\")\n",
    "        else:\n",
    "            print(f\"\\n GATE 3: SÃ©lection des leucocytes CD45+ (GATE PRINCIPAL) [{GATING_MODE.upper()}]\")\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd45 = AutoGating.auto_gate_cd45(X_raw, var_names)\n",
    "            else:\n",
    "                mask_cd45 = PreGating.gate_cd45_positive(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD45_THRESHOLD_PERCENTILE\n",
    "                )\n",
    "            mask_after_g1_g2_g3 = mask_debris & mask_singlets & mask_cd45\n",
    "            n_after_cd45 = mask_after_g1_g2_g3.sum()\n",
    "            n_cd45_excluded = (mask_debris & mask_singlets).sum() - n_after_cd45\n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD45+: percentile {CD45_THRESHOLD_PERCENTILE} (exclure les {CD45_THRESHOLD_PERCENTILE}% les plus bas)\")\n",
    "            print(f\"   â†’ Leucocytes CD45+ conservÃ©s: {n_after_cd45:,}\")\n",
    "            print(f\"   â†’ Exclus (CD45-): {n_cd45_excluded:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 3: CD45+ - SKIP\")\n",
    "    \n",
    "    # ========== GATE 4: BLASTES CD34+ (optionnel, conditionnÃ© par FILTER_BLASTS) ==========\n",
    "    if FILTER_BLASTS:\n",
    "        # Mode diffÃ©rentiel: appliquer CD34+ gate UNIQUEMENT sur les cellules pathologiques\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n GATE 4: SÃ©lection DIFFÃ‰RENTIELLE des blastes CD34+ [{GATING_MODE.upper()}]\")\n",
    "            print(\"   â†’ Patho: Gate CD34+ appliquÃ© (blastes uniquement)\")\n",
    "            print(\"   â†’ Sain: Gate CD34+ IGNORÃ‰ (tous les leucocytes CD45+ conservÃ©s)\")\n",
    "            \n",
    "            # Calculer le masque CD34+ sur TOUTES les donnÃ©es\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd34_full = AutoGating.auto_gate_cd34(\n",
    "                    X_raw, var_names,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS\n",
    "                )\n",
    "            else:\n",
    "                mask_cd34_full = PreGating.gate_cd34_blasts(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "                    ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "                )\n",
    "            \n",
    "            # Appliquer le gate CD34+ UNIQUEMENT aux cellules pathologiques\n",
    "            mask_patho = (conditions == \"Pathologique\")\n",
    "            mask_sain = (conditions == \"Sain\")\n",
    "            \n",
    "            # Masque CD34: True pour sain (on garde tout), mask_cd34_full pour patho\n",
    "            mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "            mask_cd34[mask_patho] = mask_cd34_full[mask_patho]\n",
    "            \n",
    "            # Stats\n",
    "            n_patho_before = mask_patho.sum()\n",
    "            n_patho_cd34 = (mask_patho & mask_cd34_full).sum()\n",
    "            n_sain_kept = mask_sain.sum()\n",
    "            \n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    print(f\"   Filtre SSC low: â‰¤ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "            print(f\"   â†’ Patho: {n_patho_cd34:,} blastes / {n_patho_before:,} ({n_patho_cd34/n_patho_before*100:.1f}%)\")\n",
    "            print(f\"   â†’ Sain: {n_sain_kept:,} leucocytes conservÃ©s (100%)\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n GATE 4: SÃ©lection des blastes CD34+ (toutes conditions) [{GATING_MODE.upper()}]\")\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd34 = AutoGating.auto_gate_cd34(\n",
    "                    X_raw, var_names,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS\n",
    "                )\n",
    "            else:\n",
    "                mask_cd34 = PreGating.gate_cd34_blasts(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "                    ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "                )\n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    print(f\"   Filtre SSC low: â‰¤ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 4: Blastes CD34+ - SKIP (FILTER_BLASTS=False)\")\n",
    "        print(\"   â†’ Tous les leucocytes CD45+ seront conservÃ©s pour FlowSOM\")\n",
    "    \n",
    "    # ========== MASQUE FINAL COMBINÃ‰ ==========\n",
    "    mask_final = mask_debris & mask_singlets & mask_cd45 & mask_cd34\n",
    "    n_final = mask_final.sum()\n",
    "    n_excluded = n_before - n_final\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\" RÃ‰SUMÃ‰ DU PRE-GATING [{mode_label}]\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Ã‰vÃ©nements initiaux:       {n_before:,}\")\n",
    "    print(f\"   AprÃ¨s Gate 1 (dÃ©bris):     {mask_debris.sum():,}\")\n",
    "    print(f\"   AprÃ¨s Gate 2 (doublets):   {(mask_debris & mask_singlets).sum():,}\")\n",
    "    print(f\"   AprÃ¨s Gate 3 (CD45+):      {(mask_debris & mask_singlets & mask_cd45).sum():,}\")\n",
    "    \n",
    "    # --- DÃ©tails par condition si MODE_BLASTES_VS_NORMAL ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        mask_patho = (conditions == \"Pathologique\")\n",
    "        mask_sain = (conditions == \"Sain\")\n",
    "        n_patho_total = mask_patho.sum()\n",
    "        n_sain_total = mask_sain.sum()\n",
    "        n_patho_final = (mask_final & mask_patho).sum()\n",
    "        n_sain_final = (mask_final & mask_sain).sum()\n",
    "        \n",
    "        print(f\"\\n   {'â”€'*55}\")\n",
    "        print(f\"   DÃ‰TAIL PAR CONDITION (GATING ASYMÃ‰TRIQUE)\")\n",
    "        print(f\"   {'â”€'*55}\")\n",
    "        print(f\"   PATHOLOGIQUE (CD45 strict):\")\n",
    "        print(f\"     Initial:                 {n_patho_total:,}\")\n",
    "        print(f\"     AprÃ¨s dÃ©bris+doublets:   {(mask_patho & mask_debris & mask_singlets).sum():,}\")\n",
    "        print(f\"     AprÃ¨s CD45+ (strict):    {(mask_patho & mask_debris & mask_singlets & mask_cd45).sum():,}\")\n",
    "        print(f\"     Final conservÃ©:          {n_patho_final:,} ({n_patho_final/max(n_patho_total,1)*100:.1f}%)\")\n",
    "        print(f\"   SAIN / NBM (pas de gate CD45):\")\n",
    "        print(f\"     Initial:                 {n_sain_total:,}\")\n",
    "        print(f\"     AprÃ¨s dÃ©bris+doublets:   {(mask_sain & mask_debris & mask_singlets).sum():,}\")\n",
    "        print(f\"     CD45 gate:               NON APPLIQUÃ‰ (toutes cellules conservÃ©es)\")\n",
    "        print(f\"     Final conservÃ©:          {n_sain_final:,} ({n_sain_final/max(n_sain_total,1)*100:.1f}%)\")\n",
    "        print(f\"   {'â”€'*55}\")\n",
    "    \n",
    "    if FILTER_BLASTS:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"   AprÃ¨s Gate 4 (CD34+ patho): {n_final:,}\")\n",
    "            print(f\"\\n   [MODE BLASTES vs MOELLE NORMALE]\")\n",
    "            print(f\"   Blastes CD34+ (patho):     {n_patho_final:,}\")\n",
    "            print(f\"   Cellules normales (sain):  {n_sain_final:,}\")\n",
    "            print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "            print(f\"   [OK] TOTAL CONSERVÃ‰:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   â†’ PrÃªt pour FlowSOM: Blastes purs + Cellules normales (moelle saine complÃ¨te)\")\n",
    "        else:\n",
    "            print(f\"   AprÃ¨s Gate 4 (CD34+):      {n_final:,}\")\n",
    "            print(f\"\\n   [OK] Ã‰VÃ‰NEMENTS CONSERVÃ‰S: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] Ã‰VÃ‰NEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n   [MODE ASYMÃ‰TRIQUE â€” LEUCOCYTES vs MOELLE NORMALE]\")\n",
    "            print(f\"   Patho (CD45+ stricts):     {n_patho_final:,} ({n_patho_final/max(n_patho_total,1)*100:.1f}% du fichier patient)\")\n",
    "            print(f\"   Sain (toutes cellules):    {n_sain_final:,} ({n_sain_final/max(n_sain_total,1)*100:.1f}% du fichier NBM)\")\n",
    "            print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "            print(f\"   [OK] TOTAL CONSERVÃ‰:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   â†’ PrÃªt pour FlowSOM: Leucocytes CD45+ (patho) + Moelle normale complÃ¨te (sain)\")\n",
    "        else:\n",
    "            population_type = \"Leucocytes CD45+\" if GATE_CD45 else \"Cellules\"\n",
    "            print(f\"\\n   [OK] {population_type} CONSERVÃ‰S: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] Ã‰VÃ‰NEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   â†’ PrÃªt pour FlowSOM: Population CD45+ complÃ¨te (pas de sous-sÃ©lection CD34+)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n PRE-GATING COMPLÃˆTEMENT DÃ‰SACTIVÃ‰\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   â†’ Toutes les {n_before:,} cellules seront conservÃ©es\")\n",
    "    mask_final = np.ones(n_before, dtype=bool)\n",
    "    n_final = n_before\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7672363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION PROFESSIONNELLE DES Ã‰TAPES DE GATING\n",
    "# =============================================================================\n",
    "# Graphiques SÃ‰PARÃ‰S et BIEN DÃ‰FINIS pour chaque Ã©tape\n",
    "# Style professionnel type FlowJo/Kaluza\n",
    "# =============================================================================\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "# =============================================================================\n",
    "# FONCTIONS DE VISUALISATION\n",
    "# =============================================================================\n",
    "\n",
    "def format_axis(value, pos):\n",
    "    \"\"\"Format intelligent des axes (K pour milliers, M pour millions)\"\"\"\n",
    "    if abs(value) >= 1e6:\n",
    "        return f'{value/1e6:.1f}M'\n",
    "    elif abs(value) >= 1e3:\n",
    "        return f'{value/1e3:.0f}K'\n",
    "    return f'{value:.0f}'\n",
    "\n",
    "\n",
    "def plot_density(ax, x, y, title, xlabel, ylabel, n_bins=120):\n",
    "    \"\"\"Scatter plot avec densitÃ© 2D (style FlowJo)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[valid], y[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'DonnÃ©es insuffisantes', ha='center', va='center', \n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    \n",
    "    # Colormap densitÃ©\n",
    "    cmap = LinearSegmentedColormap.from_list('density', \n",
    "        ['#0d0d0d', '#1a1a2e', '#0077b6', '#00b4d8', '#90e0ef', '#f9e2af', '#ffffff'])\n",
    "    \n",
    "    # Histogramme 2D\n",
    "    h = ax.hist2d(x, y, bins=n_bins, \n",
    "                  range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                  cmap=cmap, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(h[3], ax=ax, shrink=0.85)\n",
    "    cbar.ax.tick_params(colors='white', labelsize=9)\n",
    "    cbar.set_label('DensitÃ©', color='white', fontsize=11)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "def plot_gating(ax, x, y, mask, title, xlabel, ylabel, \n",
    "                label_in='ConservÃ©s', label_out='Exclus', max_pts=100000):\n",
    "    \"\"\"Scatter plot avec overlay gating (vert=conservÃ©s, rouge=exclus)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y, mask = x[valid], y[valid], mask[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'DonnÃ©es insuffisantes', ha='center', va='center',\n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Sous-Ã©chantillonner\n",
    "    if len(x) > max_pts:\n",
    "        idx = np.random.choice(len(x), max_pts, replace=False)\n",
    "        x, y, mask = x[idx], y[idx], mask[idx]\n",
    "    \n",
    "    # Couleurs\n",
    "    c_out = '#f38ba8'  # Rouge pastel\n",
    "    c_in = '#a6e3a1'   # Vert pastel\n",
    "    \n",
    "    # Tracer exclus (fond)\n",
    "    ax.scatter(x[~mask], y[~mask], s=4, c=c_out, alpha=0.3, \n",
    "               label=label_out, edgecolors='none', rasterized=True)\n",
    "    # Tracer conservÃ©s (avant-plan)\n",
    "    ax.scatter(x[mask], y[mask], s=5, c=c_in, alpha=0.5, \n",
    "               label=label_in, edgecolors='none', rasterized=True)\n",
    "    \n",
    "    # Stats\n",
    "    n_tot = len(x)\n",
    "    n_in = mask.sum()\n",
    "    pct = n_in / n_tot * 100 if n_tot > 0 else 0\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(f'{title}\\n{n_in:,} / {n_tot:,} ({pct:.1f}%)', \n",
    "                fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=10, markerscale=3,\n",
    "              facecolor='#313244', labelcolor='white', edgecolor='#45475a')\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    ax.set_xlim(x_lo - (x_hi-x_lo)*0.05, x_hi + (x_hi-x_lo)*0.05)\n",
    "    ax.set_ylim(y_lo - (y_hi-y_lo)*0.05, y_hi + (y_hi-y_lo)*0.05)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GÃ‰NÃ‰RATION DES GRAPHIQUES (UN PAR UN)\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\" VISUALISATION DU PRE-GATING - GRAPHIQUES SÃ‰PARÃ‰S\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Indices des canaux\n",
    "    fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "    cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "    \n",
    "    # Sous-Ã©chantillonner\n",
    "    n_sample = min(60000, n_before)\n",
    "    np.random.seed(42)\n",
    "    idx_s = np.random.choice(n_before, n_sample, replace=False)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 1 : VUE D'ENSEMBLE (FSC-A vs SSC-A)\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"â”€\"*50)\n",
    "    print(\" GRAPHIQUE 1 : VUE D'ENSEMBLE\")\n",
    "    print(\"â”€\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "        \n",
    "        plot_density(ax1, \n",
    "                     X_raw[idx_s, fsc_a_idx], \n",
    "                     X_raw[idx_s, ssc_a_idx],\n",
    "                     f'VUE D\\'ENSEMBLE\\n{n_before:,} Ã©vÃ©nements totaux',\n",
    "                     'FSC-A (Forward Scatter - Taille)',\n",
    "                     'SSC-A (Side Scatter - GranularitÃ©)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_01_overview.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] SauvegardÃ©: gating_01_overview.png\")\n",
    "    else:\n",
    "        print(\"   [!] FSC-A ou SSC-A non trouvÃ© dans les donnÃ©es\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 2 : GATE DÃ‰BRIS (FSC-A vs SSC-A avec overlay)\n",
    "    # =========================================================================\n",
    "    if GATE_DEBRIS:\n",
    "        print(\"\\n\" + \"â”€\"*50)\n",
    "        print(\" GRAPHIQUE 2 : GATE DÃ‰BRIS\")\n",
    "        print(\"â”€\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "            fig2, ax2 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            plot_gating(ax2,\n",
    "                        X_raw[idx_s, fsc_a_idx],\n",
    "                        X_raw[idx_s, ssc_a_idx],\n",
    "                        mask_debris[idx_s],\n",
    "                        'GATE 1 : Exclusion des DÃ©bris',\n",
    "                        'FSC-A (Taille)',\n",
    "                        'SSC-A (GranularitÃ©)',\n",
    "                        'Cellules viables', 'DÃ©bris/Bruit')\n",
    "            \n",
    "            # Rectangle de gate\n",
    "            fsc_lo = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            fsc_hi = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            ssc_lo = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            ssc_hi = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            \n",
    "            rect = Rectangle((fsc_lo, ssc_lo), fsc_hi-fsc_lo, ssc_hi-ssc_lo,\n",
    "                             fill=False, edgecolor='#f9e2af', linewidth=3, linestyle='--')\n",
    "            ax2.add_patch(rect)\n",
    "            ax2.text(fsc_lo + (fsc_hi-fsc_lo)/2, ssc_hi, ' Zone de sÃ©lection',\n",
    "                    ha='center', va='bottom', fontsize=11, color='#f9e2af', fontweight='bold')\n",
    "            \n",
    "            # Stats\n",
    "            n_kept = mask_debris.sum()\n",
    "            print(f\"   â†’ Ã‰vÃ©nements conservÃ©s: {n_kept:,} ({n_kept/n_before*100:.1f}%)\")\n",
    "            print(f\"   â†’ DÃ©bris exclus: {n_before - n_kept:,}\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('gating_02_debris.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"   [OK] SauvegardÃ©: gating_02_debris.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 3 : GATE SINGLETS (FSC-H vs FSC-A)\n",
    "    # =========================================================================\n",
    "    if GATE_DOUBLETS:\n",
    "        print(\"\\n\" + \"â”€\"*50)\n",
    "        print(\" GRAPHIQUE 3 : GATE SINGLETS (Doublets)\")\n",
    "        print(\"â”€\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and fsc_h_idx is not None:\n",
    "            fig3, ax3 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # AprÃ¨s gate 1\n",
    "            m_g1 = mask_debris[idx_s]\n",
    "            x3 = X_raw[idx_s, fsc_a_idx][m_g1]\n",
    "            y3 = X_raw[idx_s, fsc_h_idx][m_g1]\n",
    "            m3 = mask_singlets[idx_s][m_g1]\n",
    "            \n",
    "            if len(x3) > 100:\n",
    "                plot_gating(ax3, x3, y3, m3,\n",
    "                            f'GATE 2 : Exclusion des Doublets - Mode {GATING_MODE.upper()}',\n",
    "                            'FSC-A (Area)',\n",
    "                            'FSC-H (Height)',\n",
    "                            'Singlets', 'Doublets/AgrÃ©gats')\n",
    "                \n",
    "                if GATING_MODE == \"auto\":\n",
    "                    # Tracer les droites RANSAC par fichier\n",
    "                    from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "                    \n",
    "                    # RÃ©cupÃ©rer les fichiers pour les cellules Ã©chantillonnÃ©es\n",
    "                    file_origins_sample = combined_data.obs['file_origin'].values[idx_s][m_g1]\n",
    "                    unique_files_sample = np.unique(file_origins_sample)\n",
    "                    \n",
    "                    # Palette de couleurs pour les droites\n",
    "                    colors_lines = ['#f9e2af', '#89b4fa', '#cba6f7', '#fab387', '#a6e3a1']\n",
    "                    \n",
    "                    print(f\"   â†’ Visualisation des {len(unique_files_sample)} droites RANSAC\")\n",
    "                    \n",
    "                    for i, file_name in enumerate(unique_files_sample):\n",
    "                        file_mask_sample = (file_origins_sample == file_name)\n",
    "                        if file_mask_sample.sum() < 50:\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            x_file = x3[file_mask_sample].reshape(-1, 1)\n",
    "                            y_file = y3[file_mask_sample].reshape(-1, 1)\n",
    "                            \n",
    "                            ransac = RANSACRegressor(\n",
    "                                estimator=LinearRegression(),\n",
    "                                min_samples=50,\n",
    "                                residual_threshold=None,\n",
    "                                random_state=42,\n",
    "                                max_trials=100\n",
    "                            )\n",
    "                            ransac.fit(y_file, x_file.ravel())\n",
    "                            \n",
    "                            # Tracer la droite\n",
    "                            y_range = np.linspace(y_file.min(), y_file.max(), 100)\n",
    "                            x_pred = ransac.predict(y_range.reshape(-1, 1))\n",
    "                            \n",
    "                            color = colors_lines[i % len(colors_lines)]\n",
    "                            file_short = file_name[:20] + \"...\" if len(file_name) > 20 else file_name\n",
    "                            ax3.plot(x_pred, y_range, '-', color=color, lw=2.5, alpha=0.8,\n",
    "                                    label=f'{file_short}')\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"      [!] Ã‰chec visualisation pour {file_name}: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # LÃ©gende compacte\n",
    "                    if len(unique_files_sample) <= 5:\n",
    "                        ax3.legend(loc='lower right', fontsize=9, markerscale=2,\n",
    "                                  facecolor='#313244', labelcolor='white', edgecolor='#45475a',\n",
    "                                  title='Droites RANSAC par fichier', title_fontsize=10)\n",
    "                    else:\n",
    "                        ax3.text(0.98, 0.02, f'{len(unique_files_sample)} droites calculÃ©es',\n",
    "                                transform=ax3.transAxes, ha='right', va='bottom',\n",
    "                                fontsize=10, color='#f9e2af', fontweight='bold',\n",
    "                                bbox=dict(boxstyle='round', facecolor='#313244', alpha=0.8))\n",
    "                    \n",
    "                else:\n",
    "                    # Mode manuel: lignes de ratio fixes\n",
    "                    x_range = np.linspace(np.nanpercentile(x3, 1), np.nanpercentile(x3, 99), 100)\n",
    "                    ax3.plot(x_range, x_range, 'w-', lw=2, alpha=0.7, label='Ratio 1:1')\n",
    "                    ax3.plot(x_range, x_range * RATIO_MIN, '--', color='#f9e2af', lw=2,\n",
    "                            label=f'Ratio min ({RATIO_MIN})')\n",
    "                    ax3.plot(x_range, x_range * RATIO_MAX, '--', color='#fab387', lw=2,\n",
    "                            label=f'Ratio max ({RATIO_MAX})')\n",
    "                    ax3.fill_between(x_range, x_range * RATIO_MIN, x_range * RATIO_MAX,\n",
    "                                    alpha=0.1, color='#f9e2af')\n",
    "                    ax3.legend(loc='lower right', fontsize=10, markerscale=2,\n",
    "                              facecolor='#313244', labelcolor='white', edgecolor='#45475a')\n",
    "                \n",
    "                # Stats\n",
    "                n_after_g2 = (mask_debris & mask_singlets).sum()\n",
    "                n_doublets = mask_debris.sum() - n_after_g2\n",
    "                print(f\"   â†’ Singlets conservÃ©s: {n_after_g2:,}\")\n",
    "                print(f\"   â†’ Doublets exclus: {n_doublets:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_03_singlets.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] SauvegardÃ©: gating_03_singlets.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 4 : GATE CD45+ (CD45 vs SSC-A) â€” GATE PRINCIPAL\n",
    "    # =========================================================================\n",
    "    if GATE_CD45:\n",
    "        print(\"\\n\" + \"â”€\"*50)\n",
    "        print(\" GRAPHIQUE 4 : GATE CD45+ (Leucocytes) â€” GATE PRINCIPAL\")\n",
    "        print(\"â”€\"*50)\n",
    "        \n",
    "        if cd45_idx is not None and ssc_a_idx is not None:\n",
    "            fig4, ax4 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # AprÃ¨s gates 1+2\n",
    "            m_g12 = (mask_debris & mask_singlets)[idx_s]\n",
    "            x4 = X_raw[idx_s, cd45_idx][m_g12]\n",
    "            y4 = X_raw[idx_s, ssc_a_idx][m_g12]\n",
    "            m4 = mask_cd45[idx_s][m_g12]\n",
    "            \n",
    "            if len(x4) > 100:\n",
    "                plot_gating(ax4, x4, y4, m4,\n",
    "                            'GATE 3 : SÃ©lection des Leucocytes CD45+',\n",
    "                            'CD45 (IntensitÃ©)',\n",
    "                            'SSC-A (GranularitÃ©)',\n",
    "                            'Leucocytes CD45+', 'Cellules CD45-')\n",
    "                \n",
    "                # Seuil CD45\n",
    "                cd45_th = np.nanpercentile(X_raw[:, cd45_idx], CD45_THRESHOLD_PERCENTILE)\n",
    "                ax4.axvline(x=cd45_th, color='#89b4fa', lw=3, ls='--')\n",
    "                ax4.text(cd45_th, ax4.get_ylim()[1], f' Seuil CD45+\\n (P{CD45_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#89b4fa', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                n_cd45_kept = (mask_debris & mask_singlets & mask_cd45).sum()\n",
    "                print(f\"   â†’ Leucocytes CD45+ conservÃ©s: {n_cd45_kept:,}\")\n",
    "                print(f\"   â†’ CD45- exclus: {(mask_debris & mask_singlets).sum() - n_cd45_kept:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_04_cd45.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] SauvegardÃ©: gating_04_cd45.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD45 non trouvÃ© - Gate CD45+ ignorÃ©\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 5 : GATE CD34+ (CD34 vs SSC-A) â€” OPTIONNEL\n",
    "    # =========================================================================\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"\\n\" + \"â”€\"*50)\n",
    "        print(\" GRAPHIQUE 5 : GATE CD34+ (Blastes) â€” Sous-population des CD45+\")\n",
    "        print(\"â”€\"*50)\n",
    "        \n",
    "        if cd34_idx is not None and ssc_a_idx is not None:\n",
    "            fig_cd34, ax_cd34 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # AprÃ¨s gates 1+2+3 (CD45+)\n",
    "            m_g123 = (mask_debris & mask_singlets & mask_cd45)[idx_s]\n",
    "            x5 = X_raw[idx_s, cd34_idx][m_g123]\n",
    "            y5 = X_raw[idx_s, ssc_a_idx][m_g123]\n",
    "            m5 = mask_cd34[idx_s][m_g123]\n",
    "            \n",
    "            if len(x5) > 100:\n",
    "                plot_gating(ax_cd34, x5, y5, m5,\n",
    "                            'GATE 4 : SÃ©lection des Blastes CD34+ (parmi CD45+)',\n",
    "                            'CD34 (IntensitÃ©)',\n",
    "                            'SSC-A (GranularitÃ©)',\n",
    "                            'Blastes CD34+', 'Autres leucocytes')\n",
    "                \n",
    "                # Seuils\n",
    "                cd34_th = np.nanpercentile(X_raw[:, cd34_idx], CD34_THRESHOLD_PERCENTILE)\n",
    "                ax_cd34.axvline(x=cd34_th, color='#f9e2af', lw=3, ls='--')\n",
    "                ax_cd34.text(cd34_th, ax_cd34.get_ylim()[1], f' Seuil CD34\\n (P{CD34_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#f9e2af', fontweight='bold')\n",
    "                \n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    ssc_th = np.nanpercentile(X_raw[:, ssc_a_idx], SSC_MAX_PERCENTILE_BLASTS)\n",
    "                    ax_cd34.axhline(y=ssc_th, color='#fab387', lw=3, ls='--')\n",
    "                    ax_cd34.text(ax_cd34.get_xlim()[1], ssc_th, f' SSC max (P{SSC_MAX_PERCENTILE_BLASTS}) ',\n",
    "                            va='bottom', ha='right', fontsize=10, color='#fab387', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                print(f\"   â†’ Blastes CD34+ sÃ©lectionnÃ©s: {n_final:,}\")\n",
    "                print(f\"   â†’ Autres leucocytes exclus: {(mask_debris & mask_singlets & mask_cd45).sum() - n_final:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_05_cd34.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] SauvegardÃ©: gating_05_cd34.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD34 non trouvÃ© - Gate CD34+ ignorÃ©\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 6 : COMPARAISON AVANT / APRÃˆS\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"â”€\"*50)\n",
    "    print(\" GRAPHIQUE 6 : COMPARAISON AVANT / APRÃˆS\")\n",
    "    print(\"â”€\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig5, (ax5a, ax5b) = plt.subplots(1, 2, figsize=(16, 7), facecolor='#1e1e2e')\n",
    "        \n",
    "        # AVANT\n",
    "        cmap_red = LinearSegmentedColormap.from_list('reds', \n",
    "            ['#1a1a2e', '#7f1d1d', '#dc2626', '#fca5a5', '#ffffff'])\n",
    "        \n",
    "        valid = np.isfinite(X_raw[idx_s, fsc_a_idx]) & np.isfinite(X_raw[idx_s, ssc_a_idx])\n",
    "        x_bef = X_raw[idx_s, fsc_a_idx][valid]\n",
    "        y_bef = X_raw[idx_s, ssc_a_idx][valid]\n",
    "        \n",
    "        x_lo, x_hi = np.percentile(x_bef, [0.5, 99.5])\n",
    "        y_lo, y_hi = np.percentile(y_bef, [0.5, 99.5])\n",
    "        \n",
    "        h1 = ax5a.hist2d(x_bef, y_bef, bins=100, \n",
    "                         range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                         cmap=cmap_red, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        ax5a.set_title(f'AVANT Gating\\n{n_before:,} Ã©vÃ©nements', fontsize=14, fontweight='bold', color='white')\n",
    "        ax5a.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_facecolor('#1e1e2e')\n",
    "        ax5a.tick_params(colors='white')\n",
    "        ax5a.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5a.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5a.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        # APRÃˆS\n",
    "        cmap_green = LinearSegmentedColormap.from_list('greens', \n",
    "            ['#1a1a2e', '#14532d', '#22c55e', '#86efac', '#ffffff'])\n",
    "        \n",
    "        m_final = mask_final[idx_s]\n",
    "        x_aft = X_raw[idx_s, fsc_a_idx][m_final]\n",
    "        y_aft = X_raw[idx_s, ssc_a_idx][m_final]\n",
    "        \n",
    "        if len(x_aft) > 100:\n",
    "            h2 = ax5b.hist2d(x_aft, y_aft, bins=100,\n",
    "                             range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                             cmap=cmap_green, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        \n",
    "        pct_final = n_final / n_before * 100\n",
    "        population_label = \"Blastes CD34+\" if FILTER_BLASTS else \"Leucocytes CD45+\"\n",
    "        ax5b.set_title(f'APRÃˆS Gating ({population_label})\\n{n_final:,} Ã©vÃ©nements ({pct_final:.1f}%)', \n",
    "                      fontsize=14, fontweight='bold', color='white')\n",
    "        ax5b.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_facecolor('#1e1e2e')\n",
    "        ax5b.tick_params(colors='white')\n",
    "        ax5b.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5b.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5b.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_06_comparison.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] SauvegardÃ©: gating_06_comparison.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RÃ‰SUMÃ‰ FINAL\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" RÃ‰SUMÃ‰ DU PRE-GATING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ret_g1 = mask_debris.sum() / n_before * 100\n",
    "    ret_g2 = (mask_debris & mask_singlets).sum() / n_before * 100\n",
    "    ret_g3 = (mask_debris & mask_singlets & mask_cd45).sum() / n_before * 100\n",
    "    ret_final = n_final / n_before * 100\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚                    STATISTIQUES DE RÃ‰TENTION                â”‚\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚  Ã‰tape                        Cellules        RÃ©tention     â”‚\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚   Initial                   {n_before:>10,}        100.0%     â”‚\n",
    "    â”‚  - Gate 1 (DÃ©bris)           {mask_debris.sum():>10,}        {ret_g1:>5.1f}%     â”‚\n",
    "    â”‚  - Gate 2 (Doublets)         {(mask_debris & mask_singlets).sum():>10,}        {ret_g2:>5.1f}%     â”‚\n",
    "    â”‚  - Gate 3 (CD45+)            {(mask_debris & mask_singlets & mask_cd45).sum():>10,}        {ret_g3:>5.1f}%     â”‚\"\"\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(f\"    â”‚  - Gate 4 (CD34+)            {n_final:>10,}        {ret_final:>5.1f}%     â”‚\")\n",
    "    print(f\"\"\"    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚  [OK] CELLULES CONSERVÃ‰ES       {n_final:>10,}        {ret_final:>5.1f}%     â”‚\n",
    "    â”‚  [X] CELLULES EXCLUES          {n_before - n_final:>10,}        {100-ret_final:>5.1f}%     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    \"\"\")\n",
    "    \n",
    "    # --- DÃ©tail par condition si gating asymÃ©trique ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        _mask_patho = (conditions == \"Pathologique\")\n",
    "        _mask_sain = (conditions == \"Sain\")\n",
    "        _n_patho_tot = _mask_patho.sum()\n",
    "        _n_sain_tot = _mask_sain.sum()\n",
    "        _n_patho_fin = (mask_final & _mask_patho).sum()\n",
    "        _n_sain_fin = (mask_final & _mask_sain).sum()\n",
    "        _ret_patho = _n_patho_fin / max(_n_patho_tot, 1) * 100\n",
    "        _ret_sain = _n_sain_fin / max(_n_sain_tot, 1) * 100\n",
    "        print(f\"\"\"\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚          DÃ‰TAIL GATING ASYMÃ‰TRIQUE PAR CONDITION            â”‚\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚  PATHOLOGIQUE (CD45 strict appliquÃ©):                       â”‚\n",
    "    â”‚    Initial:          {_n_patho_tot:>10,}                              â”‚\n",
    "    â”‚    ConservÃ©:         {_n_patho_fin:>10,}   ({_ret_patho:>5.1f}%)                   â”‚\n",
    "    â”‚    Gates: DÃ©bris + Doublets + CD45+ strict                  â”‚\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚  SAIN / NBM (PAS de gate CD45):                             â”‚\n",
    "    â”‚    Initial:          {_n_sain_tot:>10,}                              â”‚\n",
    "    â”‚    ConservÃ©:         {_n_sain_fin:>10,}   ({_ret_sain:>5.1f}%)                   â”‚\n",
    "    â”‚    Gates: DÃ©bris + Doublets UNIQUEMENT                      â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        \"\"\")\n",
    "    \n",
    "    population_desc = \"Blastes CD34+ (parmi CD45+)\" if FILTER_BLASTS else (\"Leucocytes CD45+ (patho) + Moelle normale complÃ¨te (sain)\" if MODE_BLASTES_VS_NORMAL else \"Leucocytes CD45+ (population complÃ¨te)\")\n",
    "    print(f\" Population finale: {population_desc}\")\n",
    "    \n",
    "    print(\"\\n Fichiers gÃ©nÃ©rÃ©s:\")\n",
    "    print(\"   - gating_01_overview.png    - Vue d'ensemble\")\n",
    "    print(\"   - gating_02_debris.png      - Gate dÃ©bris\")\n",
    "    print(\"   - gating_03_singlets.png    - Gate singlets\")\n",
    "    print(\"   - gating_04_cd45.png        - Gate CD45+ (leucocytes)\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"   - gating_05_cd34.png        - Gate CD34+ (blastes)\")\n",
    "    print(\"   - gating_06_comparison.png  - Avant/AprÃ¨s\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n Pre-gating dÃ©sactivÃ© - Aucun graphique gÃ©nÃ©rÃ©\")\n",
    "    print(\"   â†’ Activez APPLY_PREGATING = True pour visualiser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f56b5b",
   "metadata": {},
   "source": [
    "## Visualisation Interactive du Pre-Gating â€” Style CytoPy\n",
    "\n",
    "Dashboard interactif Plotly pour inspecter chaque Ã©tape du gating sÃ©quentiel :\n",
    "\n",
    "1. **Sankey Diagram** : Flux des Ã©vÃ©nements Ã  travers les 4 gates (rÃ©tention vs exclusion)\n",
    "2. **Density Plots Interactifs** : Scatter 2D avec contours de densitÃ© pour chaque gate\n",
    "3. **Histogrammes 1D** : Distribution des marqueurs clÃ©s avec seuils GMM annotÃ©s\n",
    "4. **Comparaison Patho / Sain** (si `MODE_BLASTES_VS_NORMAL`)\n",
    "\n",
    "> *InspirÃ© de CytoPy AutonomousGate â€” tous les graphiques sont interactifs (zoom, hover, export)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION INTERACTIVE STYLE CYTOPY â€” DASHBOARD DE GATING\n",
    "# =============================================================================\n",
    "# Utilise Plotly pour des graphiques interactifs (zoom, hover, export)\n",
    "# InspirÃ© de CytoPy AutonomousGate et FlowJo hierarchical gating\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING and PLOTLY_AVAILABLE:\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\" CYTOPY-STYLE GATING DASHBOARD â€” VISUALISATION INTERACTIVE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # =====================================================================\n",
    "    # 0. PRÃ‰PARATION DES DONNÃ‰ES\n",
    "    # =====================================================================\n",
    "    _fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    _fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    _ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    _cd45_idx  = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "    _cd34_idx  = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "\n",
    "    # Sous-Ã©chantillonner pour fluiditÃ© Plotly\n",
    "    _n_pts = min(40_000, n_before)\n",
    "    np.random.seed(42)\n",
    "    _idx = np.random.choice(n_before, _n_pts, replace=False)\n",
    "\n",
    "    # Masques cumulatifs appliquÃ©s sÃ©quentiellement\n",
    "    _m_g1     = mask_debris[_idx]\n",
    "    _m_g12    = (mask_debris & mask_singlets)[_idx]\n",
    "    _m_g123   = (mask_debris & mask_singlets & mask_cd45)[_idx]\n",
    "    _m_final  = mask_final[_idx]\n",
    "\n",
    "    # Vecteur de conditions pour le sous-Ã©chantillon\n",
    "    _cond_sub = conditions[_idx]\n",
    "    _is_sain_sub = (_cond_sub == \"Sain\")\n",
    "\n",
    "    # Labels de gate pour chaque Ã©vÃ©nement (gating asymÃ©trique)\n",
    "    # â”€â”€â”€ LÃ‰GENDE DÃ‰TAILLÃ‰E : sÃ©pare Patho conservÃ©s / Sain NBM conservÃ©s â”€â”€â”€\n",
    "    def _gate_label(i):\n",
    "        if not _m_g1[i]:\n",
    "            return \"DÃ©bris (exclu G1)\"\n",
    "        if not _m_g12[i]:\n",
    "            return \"Doublet (exclu G2)\"\n",
    "        if not _m_g123[i]:\n",
    "            # En mode asymÃ©trique, seuls les Patho peuvent Ãªtre exclus par CD45\n",
    "            return \"CD45- Patho (exclu G3)\"\n",
    "        if FILTER_BLASTS and not _m_final[i]:\n",
    "            return \"Non-blaste (exclu G4)\"\n",
    "        # Cellule conservÃ©e â†’ distinguer Patho CD45+ vs Sain NBM\n",
    "        if _cond_sub[i] == \"Pathologique\":\n",
    "            return \"CD45+ Patho conservÃ©s âœ“\"\n",
    "        elif _cond_sub[i] == \"Sain\":\n",
    "            return \"ConservÃ©s sains NBM âœ“\"\n",
    "        return \"ConservÃ© âœ“\"\n",
    "\n",
    "    _labels = np.array([_gate_label(i) for i in range(_n_pts)])\n",
    "\n",
    "    # Palette CytoPy-style (avec catÃ©gories dÃ©taillÃ©es pour conservÃ©s)\n",
    "    _color_map = {\n",
    "        \"DÃ©bris (exclu G1)\":        \"#636363\",\n",
    "        \"Doublet (exclu G2)\":       \"#e6550d\",\n",
    "        \"CD45- Patho (exclu G3)\":   \"#fd8d3c\",\n",
    "        \"Non-blaste (exclu G4)\":    \"#fdae6b\",\n",
    "        \"CD45+ Patho conservÃ©s âœ“\":  \"#d62728\",   # rouge â€“ patho conservÃ©s\n",
    "        \"ConservÃ©s sains NBM âœ“\":    \"#2ca02c\",   # vert  â€“ sains NBM conservÃ©s\n",
    "        \"ConservÃ© âœ“\":               \"#31a354\",   # fallback\n",
    "    }\n",
    "\n",
    "    # =====================================================================\n",
    "    # 1. SANKEY DIAGRAM â€” FLUX DES Ã‰VÃ‰NEMENTS (avec % relatifs)\n",
    "    # =====================================================================\n",
    "    print(\"\\n [1/6] Sankey Diagram â€” Flux du gating hiÃ©rarchique (avec % relatifs)\")\n",
    "\n",
    "    _n_total   = n_before\n",
    "    _n_g1_pass = int(mask_debris.sum())\n",
    "    _n_g1_fail = _n_total - _n_g1_pass\n",
    "    _n_g2_pass = int((mask_debris & mask_singlets).sum())\n",
    "    _n_g2_fail = _n_g1_pass - _n_g2_pass\n",
    "    _n_g3_pass = int((mask_debris & mask_singlets & mask_cd45).sum())\n",
    "    _n_g3_fail = _n_g2_pass - _n_g3_pass\n",
    "    _n_g4_pass = int(n_final)\n",
    "    _n_g4_fail = _n_g3_pass - _n_g4_pass\n",
    "\n",
    "    # Helper: % of previous gate\n",
    "    def _pct_of(value, parent):\n",
    "        return f\"{value/max(parent,1)*100:.1f}%\"\n",
    "\n",
    "    _sankey_labels = [\n",
    "        f\"Ã‰vÃ©nements<br>totaux<br>{_n_total:,}\",                                                    # 0\n",
    "        f\"Gate 1<br>Viables<br>{_n_g1_pass:,}<br>({_pct_of(_n_g1_pass, _n_total)} of total)\",       # 1\n",
    "        f\"DÃ©bris<br>exclus<br>{_n_g1_fail:,}<br>({_pct_of(_n_g1_fail, _n_total)})\",                  # 2\n",
    "        f\"Gate 2<br>Singlets<br>{_n_g2_pass:,}<br>({_pct_of(_n_g2_pass, _n_g1_pass)} of G1)\",       # 3\n",
    "        f\"Doublets<br>exclus<br>{_n_g2_fail:,}<br>({_pct_of(_n_g2_fail, _n_g1_pass)})\",              # 4\n",
    "        f\"Gate 3<br>CD45+<br>{_n_g3_pass:,}<br>({_pct_of(_n_g3_pass, _n_g2_pass)} of G2)\",          # 5\n",
    "        f\"CD45-<br>exclus<br>{_n_g3_fail:,}<br>({_pct_of(_n_g3_fail, _n_g2_pass)})\",                 # 6\n",
    "    ]\n",
    "\n",
    "    _src  = [0, 0, 1, 1, 3, 3]\n",
    "    _tgt  = [1, 2, 3, 4, 5, 6]\n",
    "    _vals = [_n_g1_pass, _n_g1_fail, _n_g2_pass, _n_g2_fail, _n_g3_pass, _n_g3_fail]\n",
    "    _link_colors = [\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(99,99,99,0.3)\",      # G1: vert conservÃ© / gris dÃ©bris\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(230,85,13,0.3)\",      # G2: vert singlets / orange doublets\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(253,141,60,0.3)\",      # G3: vert CD45+ / orange CD45-\n",
    "    ]\n",
    "\n",
    "    if FILTER_BLASTS:\n",
    "        _sankey_labels.append(f\"Gate 4<br>CD34+<br>{_n_g4_pass:,}<br>({_pct_of(_n_g4_pass, _n_g3_pass)} of G3)\")   # 7\n",
    "        _sankey_labels.append(f\"Non-blastes<br>exclus<br>{_n_g4_fail:,}<br>({_pct_of(_n_g4_fail, _n_g3_pass)})\")    # 8\n",
    "        _src  += [5, 5]\n",
    "        _tgt  += [7, 8]\n",
    "        _vals += [_n_g4_pass, _n_g4_fail]\n",
    "        _link_colors += [\"rgba(49,163,84,0.4)\", \"rgba(253,174,107,0.3)\"]\n",
    "        _final_label = f\"Population<br>finale<br>{_n_g4_pass:,}<br>({_pct_of(_n_g4_pass, _n_total)} of total)\"\n",
    "        _sankey_labels.append(_final_label)  # 9\n",
    "        _src.append(7)\n",
    "        _tgt.append(9)\n",
    "        _vals.append(_n_g4_pass)\n",
    "        _link_colors.append(\"rgba(49,163,84,0.6)\")\n",
    "    else:\n",
    "        _final_label = f\"Population<br>finale<br>{_n_g3_pass:,}<br>({_pct_of(_n_g3_pass, _n_total)} of total)\"\n",
    "        _sankey_labels.append(_final_label)  # 7\n",
    "        _src.append(5)\n",
    "        _tgt.append(7)\n",
    "        _vals.append(_n_g3_pass)\n",
    "        _link_colors.append(\"rgba(49,163,84,0.6)\")\n",
    "\n",
    "    # Couleurs harmonisÃ©es: vert = conservÃ©, orange/rouge = exclu\n",
    "    _node_colors = [\"#4a90d9\"] + [\"#31a354\", \"#636363\"] * 1 + \\\n",
    "                   [\"#31a354\", \"#e6550d\", \"#31a354\", \"#fd8d3c\"]\n",
    "    if FILTER_BLASTS:\n",
    "        _node_colors += [\"#31a354\", \"#fdae6b\", \"#2ca02c\"]\n",
    "    else:\n",
    "        _node_colors += [\"#2ca02c\"]\n",
    "\n",
    "    fig_sankey = go.Figure(go.Sankey(\n",
    "        arrangement=\"snap\",\n",
    "        node=dict(\n",
    "            pad=20,\n",
    "            thickness=25,\n",
    "            line=dict(color=\"#333\", width=1),\n",
    "            label=_sankey_labels,\n",
    "            color=_node_colors[:len(_sankey_labels)],\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=_src,\n",
    "            target=_tgt,\n",
    "            value=_vals,\n",
    "            color=_link_colors,\n",
    "        ),\n",
    "    ))\n",
    "    fig_sankey.update_layout(\n",
    "        title=dict(\n",
    "            text=\"<b>Gating Hierarchy â€” Flux des Ã‰vÃ©nements (global)</b>\",\n",
    "            font=dict(size=18),\n",
    "        ),\n",
    "        font=dict(size=13, color=\"#222\"),\n",
    "        paper_bgcolor=\"#fafafa\",\n",
    "        height=450,\n",
    "        margin=dict(l=20, r=20, t=60, b=20),\n",
    "    )\n",
    "    fig_sankey.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 1b. MINI SANKEY PAR FICHIER (onglet secondaire)\n",
    "    # =====================================================================\n",
    "    if 'file_origins' in dir() and file_origins is not None and len(singlets_summary_per_file) > 0:\n",
    "        print(\" [1b/6] Mini Sankey par fichier (rÃ©sumÃ©)\")\n",
    "        \n",
    "        _unique_files_sankey = np.unique(file_origins) if hasattr(file_origins, '__len__') else []\n",
    "        \n",
    "        # Limiter Ã  max 6 fichiers mini-Sankey pour ne pas saturer le rapport\n",
    "        _files_to_show = _unique_files_sankey[:6] if len(_unique_files_sankey) > 6 else _unique_files_sankey\n",
    "        \n",
    "        if len(_files_to_show) > 0:\n",
    "            from plotly.subplots import make_subplots\n",
    "            \n",
    "            for _f_name in _files_to_show:\n",
    "                _f_mask = (file_origins == _f_name)\n",
    "                _f_total = int(_f_mask.sum())\n",
    "                if _f_total < 10:\n",
    "                    continue\n",
    "                \n",
    "                _f_g1 = int((mask_debris & _f_mask).sum())\n",
    "                _f_g1_fail = _f_total - _f_g1\n",
    "                _f_g2 = int((mask_debris & mask_singlets & _f_mask).sum())\n",
    "                _f_g2_fail = _f_g1 - _f_g2\n",
    "                _f_g3 = int((mask_debris & mask_singlets & mask_cd45 & _f_mask).sum())\n",
    "                _f_g3_fail = _f_g2 - _f_g3\n",
    "                _f_final = int((mask_final & _f_mask).sum())\n",
    "                _f_g4_fail = _f_g3 - _f_final\n",
    "                \n",
    "                _f_short = str(_f_name) if len(str(_f_name)) <= 30 else str(_f_name)[:27] + \"...\"\n",
    "                \n",
    "                _f_labels = [\n",
    "                    f\"Total<br>{_f_total:,}\",\n",
    "                    f\"G1<br>{_f_g1:,}<br>({_pct_of(_f_g1, _f_total)})\",\n",
    "                    f\"DÃ©bris<br>{_f_g1_fail:,}\",\n",
    "                    f\"G2<br>{_f_g2:,}<br>({_pct_of(_f_g2, _f_g1)})\",\n",
    "                    f\"Doubl.<br>{_f_g2_fail:,}\",\n",
    "                    f\"G3<br>{_f_g3:,}<br>({_pct_of(_f_g3, _f_g2)})\",\n",
    "                    f\"CD45-<br>{_f_g3_fail:,}\",\n",
    "                ]\n",
    "                _f_src = [0, 0, 1, 1, 3, 3]\n",
    "                _f_tgt = [1, 2, 3, 4, 5, 6]\n",
    "                _f_vals_sk = [_f_g1, max(_f_g1_fail, 1), _f_g2, max(_f_g2_fail, 1), _f_g3, max(_f_g3_fail, 1)]\n",
    "                _f_link_col = [\n",
    "                    \"rgba(49,163,84,0.4)\", \"rgba(99,99,99,0.3)\",\n",
    "                    \"rgba(49,163,84,0.4)\", \"rgba(230,85,13,0.3)\",\n",
    "                    \"rgba(49,163,84,0.4)\", \"rgba(253,141,60,0.3)\",\n",
    "                ]\n",
    "                \n",
    "                if FILTER_BLASTS:\n",
    "                    _f_labels += [\n",
    "                        f\"G4<br>{_f_final:,}<br>({_pct_of(_f_final, _f_g3)})\",\n",
    "                        f\"Excl.<br>{_f_g4_fail:,}\",\n",
    "                        f\"Final<br>{_f_final:,}\",\n",
    "                    ]\n",
    "                    _f_src += [5, 5, 7]\n",
    "                    _f_tgt += [7, 8, 9]\n",
    "                    _f_vals_sk += [_f_final, max(_f_g4_fail, 1), _f_final]\n",
    "                    _f_link_col += [\"rgba(49,163,84,0.4)\", \"rgba(253,174,107,0.3)\", \"rgba(49,163,84,0.6)\"]\n",
    "                    _f_node_col = [\"#4a90d9\", \"#31a354\", \"#636363\", \"#31a354\", \"#e6550d\",\n",
    "                                   \"#31a354\", \"#fd8d3c\", \"#31a354\", \"#fdae6b\", \"#2ca02c\"]\n",
    "                else:\n",
    "                    _f_labels.append(f\"Final<br>{_f_g3:,}\")\n",
    "                    _f_src.append(5)\n",
    "                    _f_tgt.append(7)\n",
    "                    _f_vals_sk.append(_f_g3)\n",
    "                    _f_link_col.append(\"rgba(49,163,84,0.6)\")\n",
    "                    _f_node_col = [\"#4a90d9\", \"#31a354\", \"#636363\", \"#31a354\", \"#e6550d\",\n",
    "                                   \"#31a354\", \"#fd8d3c\", \"#2ca02c\"]\n",
    "                \n",
    "                _fig_f_sankey = go.Figure(go.Sankey(\n",
    "                    arrangement=\"snap\",\n",
    "                    node=dict(pad=15, thickness=20, line=dict(color=\"#333\", width=0.5),\n",
    "                              label=_f_labels, color=_f_node_col[:len(_f_labels)]),\n",
    "                    link=dict(source=_f_src, target=_f_tgt, value=_f_vals_sk, color=_f_link_col),\n",
    "                ))\n",
    "                _fig_f_sankey.update_layout(\n",
    "                    title=dict(text=f\"<b>Gating â€” {_f_short}</b>\", font=dict(size=14)),\n",
    "                    font=dict(size=11, color=\"#222\"), paper_bgcolor=\"#fafafa\",\n",
    "                    height=300, margin=dict(l=10, r=10, t=45, b=10),\n",
    "                )\n",
    "                _fig_f_sankey.show()\n",
    "        \n",
    "        # Nettoyer la variable temporaire pour Ã©viter le doublon dans le rapport HTML\n",
    "        try:\n",
    "            del _fig_f_sankey\n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        if len(_unique_files_sankey) > 6:\n",
    "            print(f\"      (Affichage limitÃ© Ã  6/{len(_unique_files_sankey)} fichiers pour lisibilitÃ©)\")\n",
    "    \n",
    "    # =====================================================================\n",
    "    # 1c. SCATTER FSC-A vs FSC-H PAR FICHIER (avec droite RANSAC)\n",
    "    # =====================================================================\n",
    "    if ransac_scatter_data:\n",
    "        print(\" [1c/6] Scatter FSC-A vs FSC-H par fichier (droite RANSAC + RÂ²)\")\n",
    "        \n",
    "        _n_scatter_files = len(ransac_scatter_data)\n",
    "        _n_cols_sc = min(3, _n_scatter_files)\n",
    "        _n_rows_sc = int(np.ceil(_n_scatter_files / _n_cols_sc))\n",
    "        \n",
    "        _fig_ransac_scatter = make_subplots(\n",
    "            rows=_n_rows_sc, cols=_n_cols_sc,\n",
    "            subplot_titles=[f[:30] for f in ransac_scatter_data.keys()],\n",
    "            horizontal_spacing=0.06, vertical_spacing=0.10,\n",
    "        )\n",
    "        \n",
    "        for _si, (_sf_name, _sf_data) in enumerate(ransac_scatter_data.items()):\n",
    "            _row = _si // _n_cols_sc + 1\n",
    "            _col = _si % _n_cols_sc + 1\n",
    "            \n",
    "            _r2_disp = f\"RÂ²={_sf_data['r2']:.3f}\" if _sf_data['r2'] is not None else \"RÂ²=N/A\"\n",
    "            _method_disp = \"RATIO\" if _sf_data['method'] == 'ratio_fallback' else \"RANSAC\"\n",
    "            _color_pts = \"#d62728\" if _sf_data['method'] == 'ratio_fallback' else \"#2ca02c\"\n",
    "            \n",
    "            # Points (Ã©chantillonnÃ©s)\n",
    "            _fig_ransac_scatter.add_trace(go.Scattergl(\n",
    "                x=_sf_data['fsc_h'], y=_sf_data['fsc_a'],\n",
    "                mode='markers', marker=dict(size=2, color=_color_pts, opacity=0.3),\n",
    "                name=f\"{_sf_name[:20]} ({_method_disp})\", showlegend=False,\n",
    "                hovertemplate=f\"FSC-H: %{{x:.0f}}<br>FSC-A: %{{y:.0f}}<br>{_r2_disp}<extra></extra>\",\n",
    "            ), row=_row, col=_col)\n",
    "            \n",
    "            # Droite RANSAC\n",
    "            _x_line = sorted(_sf_data['fsc_h'])\n",
    "            _y_line = [_sf_data['slope'] * x + _sf_data['intercept'] for x in _x_line]\n",
    "            _fig_ransac_scatter.add_trace(go.Scatter(\n",
    "                x=_x_line, y=_y_line,\n",
    "                mode='lines', line=dict(color='#ff7f0e', width=2, dash='dash'),\n",
    "                name=f\"RANSAC {_r2_disp}\", showlegend=False,\n",
    "            ), row=_row, col=_col)\n",
    "            \n",
    "            _fig_ransac_scatter.update_xaxes(title_text=\"FSC-H\", row=_row, col=_col)\n",
    "            _fig_ransac_scatter.update_yaxes(title_text=\"FSC-A\", row=_row, col=_col)\n",
    "        \n",
    "        _fig_ransac_scatter.update_layout(\n",
    "            title=\"<b>QC RANSAC â€” FSC-A vs FSC-H par fichier (droite + RÂ²)</b>\",\n",
    "            height=350 * _n_rows_sc, width=min(450 * _n_cols_sc, 1400),\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "        )\n",
    "        del _fig_ransac_scatter  # Ã‰viter doublon dans le collecteur de figures\n",
    "    \n",
    "    # =====================================================================\n",
    "    # 1d. TABLEAU % SINGLETS PAR FICHIER\n",
    "    # =====================================================================\n",
    "    if singlets_summary_per_file:\n",
    "        print(\" [1d/6] Tableau % singlets par fichier\")\n",
    "        \n",
    "        _df_singlets = pd.DataFrame(singlets_summary_per_file)\n",
    "        \n",
    "        # Coloriser les RÂ² faibles\n",
    "        _cell_colors = []\n",
    "        for col_name in _df_singlets.columns:\n",
    "            col_colors = []\n",
    "            for _, row in _df_singlets.iterrows():\n",
    "                if col_name == 'r2' and row['r2'] is not None and row['r2'] < 0.85:\n",
    "                    col_colors.append('#ffe0e0')  # Rouge lÃ©ger\n",
    "                elif col_name == 'method' and row['method'] == 'ratio_fallback':\n",
    "                    col_colors.append('#fff3cd')  # Jaune lÃ©ger\n",
    "                else:\n",
    "                    col_colors.append('#f9f9f9' if _ % 2 == 0 else '#fff')\n",
    "            _cell_colors.append(col_colors)\n",
    "        \n",
    "        fig_singlets_table = go.Figure(go.Table(\n",
    "            header=dict(\n",
    "                values=[f\"<b>{c.upper()}</b>\" for c in _df_singlets.columns],\n",
    "                fill_color=\"#4a90d9\", font=dict(color=\"white\", size=12),\n",
    "                align=\"center\", height=35,\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[_df_singlets[c] for c in _df_singlets.columns],\n",
    "                fill_color=_cell_colors,\n",
    "                font=dict(size=11), align=\"center\", height=28,\n",
    "            ),\n",
    "        ))\n",
    "        fig_singlets_table.update_layout(\n",
    "            title=\"<b>QC Singlets â€” % par fichier (RÂ² RANSAC, mÃ©thode utilisÃ©e)</b>\",\n",
    "            height=50 + 30 * (len(_df_singlets) + 1), width=900,\n",
    "            margin=dict(l=20, r=20, t=50, b=10),\n",
    "        )\n",
    "        fig_singlets_table.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 2. DENSITY SCATTER PLOTS â€” CHAQUE GATE\n",
    "    # =====================================================================\n",
    "    print(\" [2/5] Density Scatter Plots â€” Gating sÃ©quentiel\")\n",
    "\n",
    "    _gate_plots = []\n",
    "\n",
    "    # --- Gate 1 : FSC-A vs SSC-A (DÃ©bris) ---\n",
    "    if GATE_DEBRIS and _fsc_a_idx is not None and _ssc_a_idx is not None:\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 1 â€” DÃ©bris (SSC-A vs FSC-A)\",\n",
    "            \"x\": X_raw[_idx, _fsc_a_idx],\n",
    "            \"y\": X_raw[_idx, _ssc_a_idx],\n",
    "            \"mask\": _m_g1,\n",
    "            \"xlabel\": \"FSC-A (Taille)\",\n",
    "            \"ylabel\": \"SSC-A (GranularitÃ©)\",\n",
    "            \"label_in\": \"Cellules viables\",\n",
    "            \"label_out\": \"DÃ©bris\",\n",
    "        })\n",
    "\n",
    "    # --- Gate 2 : FSC-H vs FSC-A (Doublets) â€” sur les survivants de G1 ---\n",
    "    if GATE_DOUBLETS and _fsc_a_idx is not None and _fsc_h_idx is not None:\n",
    "        _g1_ok = _m_g1\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 2 â€” Doublets (FSC-H vs FSC-A) [aprÃ¨s G1]\",\n",
    "            \"x\": X_raw[_idx, _fsc_a_idx][_g1_ok],\n",
    "            \"y\": X_raw[_idx, _fsc_h_idx][_g1_ok],\n",
    "            \"mask\": mask_singlets[_idx][_g1_ok],\n",
    "            \"xlabel\": \"FSC-A (Area)\",\n",
    "            \"ylabel\": \"FSC-H (Height)\",\n",
    "            \"label_in\": \"Singlets\",\n",
    "            \"label_out\": \"Doublets\",\n",
    "        })\n",
    "\n",
    "    # --- Gate 3 : CD45 vs SSC-A (Leucocytes) â€” sur les survivants de G1+G2 ---\n",
    "    # En mode asymÃ©trique: affiche UNIQUEMENT les cellules Patho (les Sain ne sont pas gatÃ©es CD45)\n",
    "    if GATE_CD45 and _cd45_idx is not None and _ssc_a_idx is not None:\n",
    "        _g12_ok = _m_g12\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            # Filtre: montrer seulement les cellules Patho aprÃ¨s G1+G2\n",
    "            _patho_g12 = _g12_ok & (_cond_sub == \"Pathologique\")\n",
    "            _gate_plots.append({\n",
    "                \"title\": \"Gate 3 â€” CD45+ PATHO seul (Sain: pas de gate CD45)\",\n",
    "                \"x\": X_raw[_idx, _cd45_idx][_patho_g12],\n",
    "                \"y\": X_raw[_idx, _ssc_a_idx][_patho_g12],\n",
    "                \"mask\": mask_cd45[_idx][_patho_g12],\n",
    "                \"xlabel\": \"CD45 (IntensitÃ©)\",\n",
    "                \"ylabel\": \"SSC-A (GranularitÃ©)\",\n",
    "                \"label_in\": \"CD45+ Patho (conservÃ©s)\",\n",
    "                \"label_out\": \"CD45âˆ’ Patho (exclus)\",\n",
    "            })\n",
    "        else:\n",
    "            _gate_plots.append({\n",
    "                \"title\": \"Gate 3 â€” CD45+ Leucocytes (CD45 vs SSC-A) [aprÃ¨s G1+G2]\",\n",
    "                \"x\": X_raw[_idx, _cd45_idx][_g12_ok],\n",
    "                \"y\": X_raw[_idx, _ssc_a_idx][_g12_ok],\n",
    "                \"mask\": mask_cd45[_idx][_g12_ok],\n",
    "                \"xlabel\": \"CD45 (IntensitÃ©)\",\n",
    "                \"ylabel\": \"SSC-A (GranularitÃ©)\",\n",
    "                \"label_in\": \"Leucocytes CD45+\",\n",
    "                \"label_out\": \"CD45âˆ’\",\n",
    "            })\n",
    "\n",
    "    # --- Gate 4 : CD34 vs SSC-A (Blastes) â€” si activÃ© ---\n",
    "    if FILTER_BLASTS and _cd34_idx is not None and _ssc_a_idx is not None:\n",
    "        _g123_ok = _m_g123\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 4 â€” CD34+ Blastes (CD34 vs SSC-A) [aprÃ¨s G1+G2+G3]\",\n",
    "            \"x\": X_raw[_idx, _cd34_idx][_g123_ok],\n",
    "            \"y\": X_raw[_idx, _ssc_a_idx][_g123_ok],\n",
    "            \"mask\": mask_cd34[_idx][_g123_ok],\n",
    "            \"xlabel\": \"CD34 (IntensitÃ©)\",\n",
    "            \"ylabel\": \"SSC-A (GranularitÃ©)\",\n",
    "            \"label_in\": \"Blastes CD34+\",\n",
    "            \"label_out\": \"Autres leucocytes\",\n",
    "        })\n",
    "\n",
    "    # GÃ©nÃ©rer chaque subplot avec Plotly\n",
    "    n_gates = len(_gate_plots)\n",
    "    if n_gates > 0:\n",
    "        fig_gates = make_subplots(\n",
    "            rows=1, cols=n_gates,\n",
    "            subplot_titles=[g[\"title\"] for g in _gate_plots],\n",
    "            horizontal_spacing=0.06,\n",
    "        )\n",
    "\n",
    "        for col_i, gp in enumerate(_gate_plots, 1):\n",
    "            _x, _y, _mk = gp[\"x\"], gp[\"y\"], gp[\"mask\"]\n",
    "            _valid = np.isfinite(_x) & np.isfinite(_y)\n",
    "            _x, _y, _mk = _x[_valid], _y[_valid], _mk[_valid]\n",
    "\n",
    "            # Exclus (fond, semi-transparent)\n",
    "            fig_gates.add_trace(go.Scattergl(\n",
    "                x=_x[~_mk], y=_y[~_mk],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=\"#d62728\", opacity=0.25),\n",
    "                name=gp[\"label_out\"],\n",
    "                legendgroup=f\"g{col_i}_out\",\n",
    "                showlegend=(col_i == 1),\n",
    "                hovertemplate=f\"{gp['xlabel']}: %{{x:.0f}}<br>{gp['ylabel']}: %{{y:.0f}}<br>{gp['label_out']}<extra></extra>\",\n",
    "            ), row=1, col=col_i)\n",
    "\n",
    "            # ConservÃ©s (avant-plan)\n",
    "            fig_gates.add_trace(go.Scattergl(\n",
    "                x=_x[_mk], y=_y[_mk],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=\"#2ca02c\", opacity=0.4),\n",
    "                name=gp[\"label_in\"],\n",
    "                legendgroup=f\"g{col_i}_in\",\n",
    "                showlegend=(col_i == 1),\n",
    "                hovertemplate=f\"{gp['xlabel']}: %{{x:.0f}}<br>{gp['ylabel']}: %{{y:.0f}}<br>{gp['label_in']}<extra></extra>\",\n",
    "            ), row=1, col=col_i)\n",
    "\n",
    "            # Axes labels\n",
    "            fig_gates.update_xaxes(title_text=gp[\"xlabel\"], row=1, col=col_i)\n",
    "            fig_gates.update_yaxes(title_text=gp[\"ylabel\"], row=1, col=col_i)\n",
    "\n",
    "        fig_gates.update_layout(\n",
    "            title=\"<b>Gating SÃ©quentiel â€” Density Scatter (Plotly interactif)</b>\",\n",
    "            height=500,\n",
    "            width=min(500 * n_gates, 2000),\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(\n",
    "                orientation=\"h\", yanchor=\"bottom\", y=-0.22,\n",
    "                xanchor=\"center\", x=0.5,\n",
    "                font=dict(size=12),\n",
    "            ),\n",
    "            margin=dict(t=80, b=100),\n",
    "        )\n",
    "        fig_gates.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 3. HISTOGRAMMES 1D â€” DISTRIBUTIONS DES MARQUEURS CLÃ‰S\n",
    "    # =====================================================================\n",
    "    print(\" [3/5] Histogrammes 1D â€” Distributions avec seuils GMM\")\n",
    "\n",
    "    _hist_data = []\n",
    "    if _fsc_a_idx is not None:\n",
    "        _hist_data.append((\"FSC-A\", X_raw[:, _fsc_a_idx], None))\n",
    "    if _cd45_idx is not None:\n",
    "        _hist_data.append((\"CD45\", X_raw[:, _cd45_idx], \"cd45\"))\n",
    "    if FILTER_BLASTS and _cd34_idx is not None:\n",
    "        _hist_data.append((\"CD34\", X_raw[:, _cd34_idx], \"cd34\"))\n",
    "\n",
    "    if _hist_data:\n",
    "        fig_hist = make_subplots(\n",
    "            rows=1, cols=len(_hist_data),\n",
    "            subplot_titles=[h[0] for h in _hist_data],\n",
    "            horizontal_spacing=0.08,\n",
    "        )\n",
    "\n",
    "        for hi, (name, vals, marker_type) in enumerate(_hist_data, 1):\n",
    "            _v = vals[np.isfinite(vals)]\n",
    "\n",
    "            # Avant gating (toutes cellules)\n",
    "            fig_hist.add_trace(go.Histogram(\n",
    "                x=_v, nbinsx=200, name=f\"{name} (tous)\",\n",
    "                marker_color=\"rgba(100,100,100,0.4)\",\n",
    "                showlegend=(hi == 1),\n",
    "                legendgroup=\"all\",\n",
    "            ), row=1, col=hi)\n",
    "\n",
    "            # AprÃ¨s gating (conservÃ©s)\n",
    "            _v_kept = vals[mask_final & np.isfinite(vals)]\n",
    "            fig_hist.add_trace(go.Histogram(\n",
    "                x=_v_kept, nbinsx=200, name=f\"{name} (conservÃ©s)\",\n",
    "                marker_color=\"rgba(44,160,44,0.6)\",\n",
    "                showlegend=(hi == 1),\n",
    "                legendgroup=\"kept\",\n",
    "            ), row=1, col=hi)\n",
    "\n",
    "            # Annoter le seuil GMM si pertinent\n",
    "            if marker_type == \"cd45\" and GATE_CD45:\n",
    "                _cd45_vals = X_raw[:, _cd45_idx]\n",
    "                _cd45_clean = _cd45_vals[np.isfinite(_cd45_vals)]\n",
    "                _th = np.percentile(_cd45_clean, CD45_THRESHOLD_PERCENTILE)\n",
    "                fig_hist.add_vline(\n",
    "                    x=_th, line_dash=\"dash\", line_color=\"#d62728\", line_width=2,\n",
    "                    annotation_text=f\"Seuil CD45+\", annotation_position=\"top right\",\n",
    "                    row=1, col=hi,\n",
    "                )\n",
    "            elif marker_type == \"cd34\" and FILTER_BLASTS:\n",
    "                _cd34_vals = X_raw[:, _cd34_idx]\n",
    "                _cd34_clean = _cd34_vals[np.isfinite(_cd34_vals)]\n",
    "                _th34 = np.percentile(_cd34_clean, CD34_THRESHOLD_PERCENTILE)\n",
    "                fig_hist.add_vline(\n",
    "                    x=_th34, line_dash=\"dash\", line_color=\"#ff7f0e\", line_width=2,\n",
    "                    annotation_text=f\"Seuil CD34+\", annotation_position=\"top right\",\n",
    "                    row=1, col=hi,\n",
    "                )\n",
    "\n",
    "            fig_hist.update_xaxes(title_text=name, row=1, col=hi)\n",
    "            fig_hist.update_yaxes(title_text=\"Nombre d'Ã©vÃ©nements\", row=1, col=hi)\n",
    "\n",
    "        fig_hist.update_layout(\n",
    "            title=\"<b>Distributions 1D â€” Avant / AprÃ¨s Gating (seuils annotÃ©s)</b>\",\n",
    "            barmode=\"overlay\",\n",
    "            height=400,\n",
    "            width=min(550 * len(_hist_data), 1800),\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f5f5f5\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, xanchor=\"center\", x=0.5),\n",
    "            margin=dict(t=70, b=90),\n",
    "        )\n",
    "        fig_hist.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 4. COMPARAISON PATHO vs SAIN (si MODE_BLASTES_VS_NORMAL)\n",
    "    # =====================================================================\n",
    "    if MODE_BLASTES_VS_NORMAL and _cd45_idx is not None and _ssc_a_idx is not None:\n",
    "        print(\" [4/5] Comparaison Patho vs Sain â€” CD45 vs SSC-A (GATING ASYMÃ‰TRIQUE)\")\n",
    "\n",
    "        _cond = conditions[_idx]\n",
    "\n",
    "        fig_comp = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=[\n",
    "                \"Pathologique (CD45 strict appliquÃ©)\",\n",
    "                \"Sain / NBM (PAS de gate CD45)\"\n",
    "            ],\n",
    "            horizontal_spacing=0.08,\n",
    "        )\n",
    "\n",
    "        for ci, (cond_label, color_kept, color_all) in enumerate([\n",
    "            (\"Pathologique\", \"#d62728\", \"#ffcccc\"),\n",
    "            (\"Sain\", \"#2ca02c\", \"#ccffcc\"),\n",
    "        ], 1):\n",
    "            _sel = (_cond == cond_label)\n",
    "            _sel_final = _sel & _m_final\n",
    "\n",
    "            _xc = X_raw[_idx, _cd45_idx]\n",
    "            _yc = X_raw[_idx, _ssc_a_idx]\n",
    "\n",
    "            # Toutes les cellules de cette condition (fond)\n",
    "            fig_comp.add_trace(go.Scattergl(\n",
    "                x=_xc[_sel], y=_yc[_sel],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=color_all, opacity=0.15),\n",
    "                name=f\"{cond_label} (tous)\",\n",
    "                showlegend=True,\n",
    "            ), row=1, col=ci)\n",
    "\n",
    "            # Cellules conservÃ©es\n",
    "            fig_comp.add_trace(go.Scattergl(\n",
    "                x=_xc[_sel_final], y=_yc[_sel_final],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2.5, color=color_kept, opacity=0.5),\n",
    "                name=f\"{cond_label} (conservÃ©s)\",\n",
    "                showlegend=True,\n",
    "            ), row=1, col=ci)\n",
    "\n",
    "            _n_all = _sel.sum()\n",
    "            _n_kept = _sel_final.sum()\n",
    "            _gate_info = \"CD45 strict\" if cond_label == \"Pathologique\" else \"Pas de gate CD45\"\n",
    "            fig_comp.update_xaxes(title_text=\"CD45\", row=1, col=ci)\n",
    "            fig_comp.update_yaxes(title_text=\"SSC-A\", row=1, col=ci)\n",
    "\n",
    "            _xax = \"x domain\" if ci == 1 else f\"x{ci} domain\"\n",
    "            _yax = \"y domain\" if ci == 1 else f\"y{ci} domain\"\n",
    "            fig_comp.add_annotation(\n",
    "                text=f\"<b>{_n_kept:,} / {_n_all:,} ({_n_kept/_n_all*100:.1f}%)<br>{_gate_info}</b>\" if _n_all > 0 else \"N/A\",\n",
    "                xref=_xax, yref=_yax,\n",
    "                x=0.5, y=0.02, showarrow=False,\n",
    "                font=dict(size=13, color=color_kept),\n",
    "                bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "                bordercolor=color_kept, borderwidth=1, borderpad=4,\n",
    "            )\n",
    "\n",
    "        fig_comp.update_layout(\n",
    "            title=\"<b>Gating AsymÃ©trique â€” Patho (CD45 strict) vs Sain (pas de CD45)</b>\",\n",
    "            height=500,\n",
    "            width=1100,\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.2, xanchor=\"center\", x=0.5),\n",
    "            margin=dict(t=70, b=90),\n",
    "        )\n",
    "        fig_comp.show()\n",
    "    else:\n",
    "        print(\" [4/5] Comparaison Patho vs Sain â€” SKIP (MODE_BLASTES_VS_NORMAL dÃ©sactivÃ©)\")\n",
    "\n",
    "    # =====================================================================\n",
    "    # 5. OVERVIEW FINAL â€” FSC-A vs SSC-A colorÃ© par gate d'exclusion\n",
    "    # =====================================================================\n",
    "    if _fsc_a_idx is not None and _ssc_a_idx is not None:\n",
    "        print(\" [5/5] Overview Final â€” ColorÃ© par Ã©tape d'exclusion\")\n",
    "\n",
    "        _xo = X_raw[_idx, _fsc_a_idx]\n",
    "        _yo = X_raw[_idx, _ssc_a_idx]\n",
    "\n",
    "        fig_overview = go.Figure()\n",
    "\n",
    "        # Tracer chaque catÃ©gorie d'exclusion dans l'ordre\n",
    "        # â”€â”€â”€ Inclut dÃ©sormais les conservÃ©s Patho et Sain sÃ©parÃ©ment â”€â”€â”€\n",
    "        _order = [\n",
    "            \"DÃ©bris (exclu G1)\",\n",
    "            \"Doublet (exclu G2)\",\n",
    "            \"CD45- Patho (exclu G3)\",\n",
    "            \"Non-blaste (exclu G4)\",\n",
    "            \"CD45+ Patho conservÃ©s âœ“\",\n",
    "            \"ConservÃ©s sains NBM âœ“\",\n",
    "            \"ConservÃ© âœ“\",          # fallback si condition inconnue\n",
    "        ]\n",
    "        for cat in _order:\n",
    "            _sel_cat = (_labels == cat)\n",
    "            if _sel_cat.sum() == 0:\n",
    "                continue\n",
    "            _is_kept = cat.endswith(\"âœ“\")\n",
    "            fig_overview.add_trace(go.Scattergl(\n",
    "                x=_xo[_sel_cat], y=_yo[_sel_cat],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=2.5,\n",
    "                    color=_color_map.get(cat, \"#999\"),\n",
    "                    opacity=0.55 if _is_kept else 0.25,\n",
    "                ),\n",
    "                name=f\"{cat} ({_sel_cat.sum():,})\",\n",
    "                hovertemplate=f\"FSC-A: %{{x:.0f}}<br>SSC-A: %{{y:.0f}}<br>{cat}<extra></extra>\",\n",
    "            ))\n",
    "\n",
    "        fig_overview.update_layout(\n",
    "            title=\"<b>Overview â€” Ã‰vÃ©nements colorÃ©s par Ã©tape d'exclusion</b>\",\n",
    "            xaxis_title=\"FSC-A (Taille)\",\n",
    "            yaxis_title=\"SSC-A (GranularitÃ©)\",\n",
    "            height=600,\n",
    "            width=900,\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=12),\n",
    "            legend=dict(\n",
    "                title=\"CatÃ©gorie\",\n",
    "                font=dict(size=12),\n",
    "                bgcolor=\"rgba(255,255,255,0.9)\",\n",
    "                bordercolor=\"#ccc\", borderwidth=1,\n",
    "            ),\n",
    "            margin=dict(t=70, b=50),\n",
    "        )\n",
    "        fig_overview.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # RÃ‰SUMÃ‰ TABULAIRE\n",
    "    # =====================================================================\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" RÃ‰SUMÃ‰ GATING â€” TABLEAU INTERACTIF\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    _summary_df = pd.DataFrame({\n",
    "        \"Ã‰tape\": [\"Initial\", \"Gate 1 (DÃ©bris)\", \"Gate 2 (Doublets)\",\n",
    "                  \"Gate 3 (CD45+ Patho only)\" if MODE_BLASTES_VS_NORMAL else \"Gate 3 (CD45+)\"] + ([\"Gate 4 (CD34+)\"] if FILTER_BLASTS else []) + [\"Population finale\"],\n",
    "        \"Ã‰vÃ©nements\": [\n",
    "            n_before,\n",
    "            int(mask_debris.sum()),\n",
    "            int((mask_debris & mask_singlets).sum()),\n",
    "            int((mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "        ] + ([int(n_final)] if FILTER_BLASTS else []) + [int(n_final)],\n",
    "        \"RÃ©tention (%)\": [\n",
    "            100.0,\n",
    "            mask_debris.sum() / n_before * 100,\n",
    "            (mask_debris & mask_singlets).sum() / n_before * 100,\n",
    "            (mask_debris & mask_singlets & mask_cd45).sum() / n_before * 100,\n",
    "        ] + ([n_final / n_before * 100] if FILTER_BLASTS else []) + [n_final / n_before * 100],\n",
    "        \"Exclus\": [\n",
    "            0,\n",
    "            n_before - int(mask_debris.sum()),\n",
    "            int(mask_debris.sum()) - int((mask_debris & mask_singlets).sum()),\n",
    "            int((mask_debris & mask_singlets).sum()) - int((mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "        ] + ([int((mask_debris & mask_singlets & mask_cd45).sum()) - int(n_final)] if FILTER_BLASTS else []) + [n_before - int(n_final)],\n",
    "    })\n",
    "    _summary_df[\"RÃ©tention (%)\"] = _summary_df[\"RÃ©tention (%)\"].round(1)\n",
    "\n",
    "    fig_table = go.Figure(go.Table(\n",
    "        header=dict(\n",
    "            values=[f\"<b>{c}</b>\" for c in _summary_df.columns],\n",
    "            fill_color=\"#4a90d9\",\n",
    "            font=dict(color=\"white\", size=13),\n",
    "            align=\"center\", height=35,\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[_summary_df[c] for c in _summary_df.columns],\n",
    "            fill_color=[\n",
    "                [\"#f9f9f9\", \"#fff\", \"#f9f9f9\", \"#fff\"] +\n",
    "                ([\"#f9f9f9\"] if FILTER_BLASTS else []) + [\"#d4edda\"]\n",
    "            ] * 4,\n",
    "            font=dict(size=12),\n",
    "            align=\"center\", height=30,\n",
    "            format=[None, \",\", \".1f\", \",\"],\n",
    "        ),\n",
    "    ))\n",
    "    fig_table.update_layout(\n",
    "        title=\"<b>RÃ©sumÃ© du Pre-Gating â€” Statistiques par Ã©tape</b>\",\n",
    "        height=50 + 35 * (len(_summary_df) + 1),\n",
    "        width=800,\n",
    "        margin=dict(l=20, r=20, t=50, b=10),\n",
    "    )\n",
    "    fig_table.show()\n",
    "\n",
    "    # --- Tableau par condition si gating asymÃ©trique ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        _mp = (conditions == \"Pathologique\")\n",
    "        _ms = (conditions == \"Sain\")\n",
    "        _cond_df = pd.DataFrame({\n",
    "            \"Condition\": [\"Pathologique\", \"Sain / NBM\"],\n",
    "            \"Initial\": [int(_mp.sum()), int(_ms.sum())],\n",
    "            \"AprÃ¨s DÃ©bris+Doublets\": [\n",
    "                int((_mp & mask_debris & mask_singlets).sum()),\n",
    "                int((_ms & mask_debris & mask_singlets).sum()),\n",
    "            ],\n",
    "            \"AprÃ¨s Gate CD45\": [\n",
    "                int((_mp & mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "                f\"{int((_ms & mask_debris & mask_singlets).sum())} (non appliquÃ©)\",\n",
    "            ],\n",
    "            \"Final\": [int((mask_final & _mp).sum()), int((mask_final & _ms).sum())],\n",
    "            \"RÃ©tention (%)\": [\n",
    "                round((mask_final & _mp).sum() / max(_mp.sum(), 1) * 100, 1),\n",
    "                round((mask_final & _ms).sum() / max(_ms.sum(), 1) * 100, 1),\n",
    "            ],\n",
    "            \"Logique CD45\": [\"CD45 STRICT\", \"AUCUN gate CD45\"],\n",
    "        })\n",
    "\n",
    "        fig_table_cond = go.Figure(go.Table(\n",
    "            header=dict(\n",
    "                values=[f\"<b>{c}</b>\" for c in _cond_df.columns],\n",
    "                fill_color=\"#6a0dad\",\n",
    "                font=dict(color=\"white\", size=13),\n",
    "                align=\"center\", height=35,\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[_cond_df[c] for c in _cond_df.columns],\n",
    "                fill_color=[[\"#ffe6e6\", \"#e6ffe6\"]] * len(_cond_df.columns),\n",
    "                font=dict(size=12),\n",
    "                align=\"center\", height=30,\n",
    "            ),\n",
    "        ))\n",
    "        fig_table_cond.update_layout(\n",
    "            title=\"<b>Gating AsymÃ©trique â€” DÃ©tail par Condition (Patho: CD45 strict / Sain: pas de CD45)</b>\",\n",
    "            height=150,\n",
    "            width=1100,\n",
    "            margin=dict(l=20, r=20, t=50, b=10),\n",
    "        )\n",
    "        fig_table_cond.show()\n",
    "\n",
    "    print(\"\\n [OK] Dashboard CytoPy-style gÃ©nÃ©rÃ© avec succÃ¨s !\")\n",
    "    print(\"     â†’ Utilisez la souris pour zoomer, survoler, et exporter (icÃ´ne ğŸ“·)\")\n",
    "\n",
    "elif not PLOTLY_AVAILABLE:\n",
    "    print(\"[!] Plotly requis pour le dashboard interactif.\")\n",
    "    print(\"    â†’ pip install plotly\")\n",
    "else:\n",
    "\n",
    "    print(\"[!] Pre-gating dÃ©sactivÃ© â€” Aucun dashboard gÃ©nÃ©rÃ©.\")\n",
    "    print(\"[!] Pre-gating dÃ©sactivÃ© â€” Aucun dashboard gÃ©nÃ©rÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CRÃ‰ATION DU SECOND ANNDATA (avec ou sans gating)\n",
    "# =============================================================================\n",
    "\n",
    "# CrÃ©er l'AnnData filtrÃ© (ou copie complÃ¨te si pas de gating)\n",
    "combined_gated = combined_data[mask_final].copy()\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    print(f\"[OK] AnnData aprÃ¨s gating: {combined_gated.shape}\")\n",
    "    print(f\"   â†’ {combined_gated.shape[0]:,} cellules conservÃ©es\")\n",
    "    print(f\"   â†’ {combined_gated.shape[1]} marqueurs\")\n",
    "else:\n",
    "    print(f\"[OK] AnnData crÃ©Ã© (sans pre-gating): {combined_gated.shape}\")\n",
    "    print(f\"   â†’ {combined_gated.shape[0]:,} cellules (toutes conservÃ©es)\")\n",
    "    print(f\"   â†’ {combined_gated.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0e40a",
   "metadata": {},
   "source": [
    "## 6. Transformation des DonnÃ©es (Arcsinh / Logicle)\n",
    "\n",
    "Les donnÃ©es brutes de cytomÃ©trie nÃ©cessitent une transformation pour:\n",
    "- GÃ©rer les valeurs nÃ©gatives (compensation)\n",
    "- Compresser la plage dynamique\n",
    "- AmÃ©liorer la visualisation des populations faiblement exprimÃ©es\n",
    "\n",
    "### Transformations disponibles:\n",
    "- **Arcsinh (cofactor=5)**: RecommandÃ© pour flow cytometry\n",
    "- **Logicle**: Transformation biexponentielle (standard ISAC)\n",
    "- **Log10**: Transformation logarithmique simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DE LA TRANSFORMATION\n",
    "# â†’ Valeurs contrÃ´lÃ©es par le panneau interactif (cellule 2) si exÃ©cutÃ©.\n",
    "_cfg = globals().get('CONFIG', {})\n",
    "\n",
    "TRANSFORM_TYPE = _cfg.get('TRANSFORM_TYPE', 'logicle')  # Options: \"arcsinh\", \"logicle\", \"log10\", \"none\"\n",
    "COFACTOR = _cfg.get('COFACTOR', 5)  # Pour arcsinh: 5 (flow)\n",
    "APPLY_TO_SCATTER = _cfg.get('APPLY_TO_SCATTER', False)\n",
    "\n",
    "print(\"TRANSFORMATION DES DONNÃ‰ES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Type: {TRANSFORM_TYPE.upper()}\")\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"   Cofacteur: {COFACTOR}\")\n",
    "print(f\"   Appliquer au scatter: {'Oui' if APPLY_TO_SCATTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION DE LA TRANSFORMATION\n",
    "\n",
    "# Extraire les donnÃ©es\n",
    "X_gated = combined_gated.X\n",
    "if hasattr(X_gated, 'toarray'):\n",
    "    X_gated = X_gated.toarray()\n",
    "\n",
    "# Copie pour transformation\n",
    "X_transformed = X_gated.copy()\n",
    "\n",
    "# DÃ©terminer les indices des colonnes Ã  transformer\n",
    "if APPLY_TO_SCATTER:\n",
    "    cols_to_transform = list(range(len(var_names)))\n",
    "else:\n",
    "    # Exclure FSC, SSC, Time\n",
    "    scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "    cols_to_transform = [i for i, name in enumerate(var_names) \n",
    "                         if not any(p in name.upper() for p in scatter_patterns)]\n",
    "\n",
    "print(f\"\\nColonnes Ã  transformer: {len(cols_to_transform)}/{len(var_names)}\")\n",
    "\n",
    "# Appliquer la transformation\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"\\n Application Arcsinh (cofactor={COFACTOR})...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.arcsinh_transform(\n",
    "        X_gated[:, cols_to_transform], cofactor=COFACTOR\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"logicle\":\n",
    "    print(\"\\n Application Logicle...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.logicle_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"log10\":\n",
    "    print(\"\\n Application Log10...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.log_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"\\n[!] Pas de transformation appliquÃ©e\")\n",
    "\n",
    "# VÃ©rifier les rÃ©sultats\n",
    "print(f\"\\n[OK] Transformation terminÃ©e!\")\n",
    "print(f\"   Plage avant: [{X_gated[:, cols_to_transform].min():.2f}, {X_gated[:, cols_to_transform].max():.2f}]\")\n",
    "print(f\"   Plage aprÃ¨s: [{X_transformed[:, cols_to_transform].min():.2f}, {X_transformed[:, cols_to_transform].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec484f1",
   "metadata": {},
   "source": [
    "## 7. Comparaison Avant/AprÃ¨s Transformation\n",
    "\n",
    "Visualisation cÃ´te Ã  cÃ´te des distributions pour valider l'effet de la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAISON DISTRIBUTIONS AVANT/APRÃˆS\n",
    "\n",
    "# SÃ©lectionner quelques marqueurs reprÃ©sentatifs\n",
    "markers_compare = [var_names[i] for i in cols_to_transform[:6]]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(markers_compare), figsize=(4*len(markers_compare), 8))\n",
    "\n",
    "for i, marker in enumerate(markers_compare):\n",
    "    col_idx = var_names.index(marker)\n",
    "    \n",
    "    # Avant transformation\n",
    "    ax = axes[0, i]\n",
    "    data_before = X_gated[:, col_idx]\n",
    "    ax.hist(data_before, bins=80, color='#f38ba8', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{marker}\\n(Brut)', fontsize=10, fontweight='bold')\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('AVANT\\nCount', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # AprÃ¨s transformation\n",
    "    ax = axes[1, i]\n",
    "    data_after = X_transformed[:, col_idx]\n",
    "    ax.hist(data_after, bins=80, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{TRANSFORM_TYPE.upper()}', fontsize=10)\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('APRÃˆS\\nCount', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Comparaison des Distributions: Brut vs {TRANSFORM_TYPE.upper()} (cofactor={COFACTOR})', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DE DIFFÃ‰RENTS COFACTEURS (pour tuning)\n",
    "\n",
    "print(\"COMPARAISON DES COFACTEURS ARCSINH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# SÃ©lectionner un marqueur reprÃ©sentatif\n",
    "test_marker = markers_compare[0]\n",
    "test_idx = var_names.index(test_marker)\n",
    "test_data = X_gated[:, test_idx]\n",
    "\n",
    "# Tester diffÃ©rents cofacteurs\n",
    "cofactors = [1, 5, 50, 150, 500]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cofactors)+1, figsize=(4*(len(cofactors)+1), 4))\n",
    "\n",
    "# DonnÃ©es brutes\n",
    "ax = axes[0]\n",
    "ax.hist(test_data, bins=80, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "ax.set_title('Brut\\n(pas de transfo)', fontsize=10, fontweight='bold')\n",
    "ax.set_xlabel(test_marker)\n",
    "\n",
    "# Transformations avec diffÃ©rents cofacteurs\n",
    "for i, cof in enumerate(cofactors):\n",
    "    ax = axes[i+1]\n",
    "    transformed = DataTransformer.arcsinh_transform(test_data, cofactor=cof)\n",
    "    ax.hist(transformed, bins=80, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'Arcsinh\\ncofactor={cof}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(test_marker)\n",
    "\n",
    "plt.suptitle(f'Impact du Cofacteur sur la Distribution ({test_marker})', \n",
    "             fontsize=13, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087eb83",
   "metadata": {},
   "source": [
    "## 8. PrÃ©paration des DonnÃ©es pour FlowSOM\n",
    "\n",
    "SÃ©lection des colonnes pour le clustering:\n",
    "- Exclusion des paramÃ¨tres scatter (FSC, SSC) et Time\n",
    "- Conservation uniquement des marqueurs de fluorescence\n",
    "- Nettoyage final (NaN/Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÃ‰LECTION DES COLONNES POUR FLOWSOM\n",
    "# â†’ Valeurs contrÃ´lÃ©es par le panneau interactif (cellule 2) si exÃ©cutÃ©.\n",
    "_cfg = globals().get('CONFIG', {})\n",
    "\n",
    "EXCLUDE_SCATTER = _cfg.get('EXCLUDE_SCATTER', True)\n",
    "EXCLUDE_ADDITIONAL_MARKERS = _cfg.get('EXCLUDE_ADDITIONAL_MARKERS', ['CD45'])\n",
    "\n",
    "# Identifier les colonnes Ã  utiliser\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "\n",
    "# Construire la liste des colonnes pour FlowSOM\n",
    "cols_to_use = []\n",
    "excluded_additional = []\n",
    "\n",
    "for i, name in enumerate(var_names):\n",
    "    # Exclure scatter/time si demandÃ©\n",
    "    if EXCLUDE_SCATTER and any(p in name.upper() for p in scatter_patterns):\n",
    "        continue\n",
    "    # Exclure les marqueurs supplÃ©mentaires spÃ©cifiÃ©s\n",
    "    if any(excl.upper() in name.upper() for excl in EXCLUDE_ADDITIONAL_MARKERS):\n",
    "        excluded_additional.append(name)\n",
    "        continue\n",
    "    cols_to_use.append(i)\n",
    "\n",
    "used_markers = [var_names[i] for i in cols_to_use]\n",
    "\n",
    "print(\"COLONNES POUR FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Exclure scatter: {'Oui' if EXCLUDE_SCATTER else 'Non'}\")\n",
    "print(f\"   Marqueurs exclus manuellement: {EXCLUDE_ADDITIONAL_MARKERS if EXCLUDE_ADDITIONAL_MARKERS else 'Aucun'}\")\n",
    "if excluded_additional:\n",
    "    print(f\"   â†’ Marqueurs retirÃ©s du FlowSOM (mais conservÃ©s dans l'export):\")\n",
    "    for m in excluded_additional:\n",
    "        print(f\"      [X] {m}\")\n",
    "print(f\"   Colonnes sÃ©lectionnÃ©es: {len(cols_to_use)}/{len(var_names)}\")\n",
    "print(f\"\\nMarqueurs utilisÃ©s pour le FlowSOM:\")\n",
    "for i, marker in enumerate(used_markers):\n",
    "    print(f\"   [{i:2d}] {marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTRAGE PAR TYPE DE MARQUEUR (-A vs -H) - OPTIONNEL\n",
    "# =============================================================================\n",
    "# EXPLICATION:\n",
    "# - Les suffixes -A (Area) et -H (Height) dans les noms de marqueurs reprÃ©sentent\n",
    "#   des mesures diffÃ©rentes du MÃŠME signal:\n",
    "#     â€¢ -A (Area) = Aire sous la courbe du pulse â†’ plus stable\n",
    "#     â€¢ -H (Height) = Hauteur maximale du pulse â†’ plus sensible\n",
    "#\n",
    "# - En cytomÃ©trie, on utilise gÃ©nÃ©ralement:\n",
    "#     â€¢ FSC-A et SSC-A pour le gating (dÃ©bris, doublets)\n",
    "#     â€¢ Fluorescence -A pour le clustering (plus stable)\n",
    "#\n",
    "# - Ce filtre permet de DÃ‰DUPLIQUER les marqueurs redondants si vous avez\n",
    "#   Ã  la fois -A et -H pour chaque marqueur (ex: CD13 PE-A ET CD13 PE-H)\n",
    "#\n",
    "# [!] ATTENTION: Cette section ne filtre PAS les fichiers, mais les MARQUEURS!\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== ACTIVATION DU FILTRAGE =====================\n",
    "APPLY_MARKER_FILTERING = True  # [!] Mettre True pour dÃ©dupliquer (garder uniquement -A ou -H)\n",
    "\n",
    "# OPTIONS DE FILTRAGE (utilisÃ©es seulement si APPLY_MARKER_FILTERING = True)\n",
    "KEEP_AREA = True    # True = garder les marqueurs -A (Area) [RECOMMANDÃ‰]\n",
    "KEEP_HEIGHT = False # True = garder les marqueurs -H (Height)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FILTRAGE PAR TYPE DE MARQUEUR (-A vs -H)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Filtrage activÃ©: {'[OK] OUI' if APPLY_MARKER_FILTERING else '[X] NON (tous les marqueurs conservÃ©s)'}\")\n",
    "\n",
    "if APPLY_MARKER_FILTERING:\n",
    "    print(f\"   Garder -A (Area):   {'[OK] Oui' if KEEP_AREA else '[X] Non'}\")\n",
    "    print(f\"   Garder -H (Height): {'[OK] Oui' if KEEP_HEIGHT else '[X] Non'}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES/MARQUEURS AVEC -A ET -H\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ANALYSE DES MARQUEURS PAR TYPE (-A Area vs -H Height)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n[INFO] Les suffixes -A et -H sont dans les NOMS DE MARQUEURS (pas les fichiers)\")\n",
    "print(\"       -A = Area (aire du pulse) | -H = Height (hauteur du pulse)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# RÃ©cupÃ©rer les noms de colonnes\n",
    "all_columns = list(combined_gated.var_names)\n",
    "\n",
    "# SÃ©parer les colonnes avec -A, -H, ou autres\n",
    "# IMPORTANT: VÃ©rifier que -A et -H sont Ã  la FIN du nom (suffixes), pas n'importe oÃ¹\n",
    "# Exemple: \"CD19 APC-A750-H\" se termine par -H (Height), pas -A mÃªme si \"APC-A750\" contient -A\n",
    "cols_with_A = [col for col in all_columns if col.upper().endswith(\"-A\")]\n",
    "cols_with_H = [col for col in all_columns if col.upper().endswith(\"-H\")]\n",
    "cols_other = [col for col in all_columns if not col.upper().endswith(\"-A\") and not col.upper().endswith(\"-H\")]\n",
    "\n",
    "print(f\"\\nğŸ”µ MARQUEURS avec '-A' (Area - aire du pulse) - {len(cols_with_A)} au total:\")\n",
    "for col in cols_with_A:\n",
    "    print(f\"   â€¢ {col}\")\n",
    "\n",
    "print(f\"\\nğŸŸ£ MARQUEURS avec '-H' (Height - hauteur du pulse) - {len(cols_with_H)} au total:\")\n",
    "for col in cols_with_H:\n",
    "    print(f\"   â€¢ {col}\")\n",
    "\n",
    "print(f\"\\nâšª MARQUEURS sans -A/-H - {len(cols_other)} au total:\")\n",
    "for col in cols_other:\n",
    "    print(f\"   â€¢ {col}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTRAGE DES MARQUEURS (si activÃ©)\n",
    "# =============================================================================\n",
    "if APPLY_MARKER_FILTERING:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES MARQUEURS PAR TYPE (-A Area vs -H Height)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # DÃ©terminer quels marqueurs garder\n",
    "    markers_to_keep = []\n",
    "    \n",
    "    if KEEP_AREA:\n",
    "        markers_to_keep.extend(cols_with_A)\n",
    "    if KEEP_HEIGHT:\n",
    "        markers_to_keep.extend(cols_with_H)\n",
    "    \n",
    "    # Toujours garder les marqueurs sans -A/-H\n",
    "    markers_to_keep.extend(cols_other)\n",
    "    \n",
    "    # DÃ©dupliquer (au cas oÃ¹)\n",
    "    markers_to_keep = list(dict.fromkeys(markers_to_keep))\n",
    "    \n",
    "    # VÃ©rification\n",
    "    if len(markers_to_keep) == 0:\n",
    "        print(\"\\n[!] ATTENTION: Aucun marqueur sÃ©lectionnÃ©!\")\n",
    "        print(\"   â†’ KEEP_AREA et KEEP_HEIGHT sont tous les deux False\")\n",
    "        print(\"   â†’ DÃ©sactivation automatique du filtrage\")\n",
    "        APPLY_MARKER_FILTERING = False\n",
    "        markers_to_keep = all_columns\n",
    "    \n",
    "    if APPLY_MARKER_FILTERING:\n",
    "        # Afficher le rÃ©sumÃ©\n",
    "        n_before_markers = len(all_columns)\n",
    "        n_after_markers = len(markers_to_keep)\n",
    "        n_excluded_markers = n_before_markers - n_after_markers\n",
    "        \n",
    "        print(f\"\\n Marqueurs AVANT filtrage: {n_before_markers}\")\n",
    "        print(f\" Marqueurs APRÃˆS filtrage: {n_after_markers}\")\n",
    "        print(f\" Marqueurs exclus: {n_excluded_markers}\")\n",
    "        \n",
    "        if n_excluded_markers > 0:\n",
    "            print(f\"\\n Marqueurs CONSERVÃ‰S:\")\n",
    "            for m in markers_to_keep:\n",
    "                print(f\"   [OK] {m}\")\n",
    "            \n",
    "            excluded_markers = [m for m in all_columns if m not in markers_to_keep]\n",
    "            print(f\"\\n Marqueurs EXCLUS:\")\n",
    "            for m in excluded_markers:\n",
    "                print(f\"   [X] {m}\")\n",
    "            \n",
    "            # Appliquer le filtrage en sÃ©lectionnant les colonnes\n",
    "            # CrÃ©er un masque de colonnes\n",
    "            col_indices = [i for i, col in enumerate(all_columns) if col in markers_to_keep]\n",
    "            \n",
    "            # Filtrer combined_gated (AnnData)\n",
    "            combined_gated = combined_gated[:, markers_to_keep].copy()\n",
    "            \n",
    "            # Filtrer X_transformed\n",
    "            X_transformed = X_transformed[:, col_indices]\n",
    "            \n",
    "            # Mettre Ã  jour var_names\n",
    "            var_names = markers_to_keep\n",
    "            \n",
    "            print(f\"\\n[OK] Filtrage des marqueurs appliquÃ©!\")\n",
    "            print(f\"   Shape combined_gated: {combined_gated.shape}\")\n",
    "            print(f\"   Shape X_transformed: {X_transformed.shape}\")\n",
    "        else:\n",
    "            print(f\"\\n[INFO] Tous les marqueurs sont dÃ©jÃ  conservÃ©s (rien Ã  filtrer)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES MARQUEURS DÃ‰SACTIVÃ‰\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   â†’ Tous les {len(all_columns)} marqueurs sont conservÃ©s\")\n",
    "    \n",
    "    # Afficher quand mÃªme les fichiers disponibles\n",
    "    print(f\"\\n Fichiers disponibles dans le dataset:\")\n",
    "    file_counts = combined_gated.obs['file_origin'].value_counts()\n",
    "    for fname, count in file_counts.items():\n",
    "        print(f\"   {fname}: {count:,} cellules\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES UTILISÃ‰ES POUR FLOWSOM\n",
    "# =============================================================================\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\" MARQUEURS DISPONIBLES POUR FLOWSOM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTous les marqueurs actuels ({len(list(combined_gated.var_names))}):\")\n",
    "for i, col in enumerate(combined_gated.var_names):\n",
    "    marker_type = \"\"\n",
    "    if \"-A\" in col.upper():\n",
    "        marker_type = \" [Type -A = Area]\"\n",
    "    elif \"-H\" in col.upper():\n",
    "        marker_type = \" [Type -H = Height]\"\n",
    "    print(f\"   [{i:2d}] {col}{marker_type}\")\n",
    "\n",
    "print(f\"\\n[OK] DonnÃ©es prÃªtes pour la suite du pipeline\")\n",
    "print(f\"   Shape combined_gated: {combined_gated.shape}\")\n",
    "print(f\"   Shape X_transformed: {X_transformed.shape}\")\n",
    "print(f\"   Nombre de cellules: {combined_gated.shape[0]:,}\")\n",
    "print(f\"   Nombre de marqueurs: {combined_gated.shape[1]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MISE Ã€ JOUR DE cols_to_use ET used_markers APRÃˆS FILTRAGE\n",
    "# =============================================================================\n",
    "# Recalculer cols_to_use aprÃ¨s le filtrage car var_names a peut-Ãªtre Ã©tÃ© modifiÃ©\n",
    "cols_to_use = []\n",
    "excluded_additional = []\n",
    "\n",
    "for i, name in enumerate(var_names):\n",
    "    # Exclure scatter/time si demandÃ©\n",
    "    if EXCLUDE_SCATTER and any(p in name.upper() for p in scatter_patterns):\n",
    "        continue\n",
    "    # Exclure les marqueurs supplÃ©mentaires spÃ©cifiÃ©s\n",
    "    if any(excl.upper() in name.upper() for excl in EXCLUDE_ADDITIONAL_MARKERS):\n",
    "        excluded_additional.append(name)\n",
    "        continue\n",
    "    cols_to_use.append(i)\n",
    "\n",
    "used_markers = [var_names[i] for i in cols_to_use]\n",
    "\n",
    "print(f\"\\n[OK] Variables 'cols_to_use' et 'used_markers' mises Ã  jour aprÃ¨s filtrage\")\n",
    "print(f\"   Marqueurs utilisÃ©s pour FlowSOM: {len(used_markers)}\")\n",
    "if excluded_additional:\n",
    "    print(f\"   Marqueurs exclus manuellement (mais conservÃ©s dans l'export): {excluded_additional}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRÃ‰ATION DE L'ANNDATA TRANSFORMÃ‰ ET EXPLORATION POST-ARCSINH\n",
    "\n",
    "# CrÃ©er un nouvel AnnData avec les donnÃ©es transformÃ©es (X_transformed)\n",
    "import anndata as ad\n",
    "\n",
    "# CrÃ©er adata_flowsom - le nouvel AnnData pour FlowSOM avec donnÃ©es transformÃ©es\n",
    "adata_flowsom = ad.AnnData(\n",
    "    X=X_transformed,  # DonnÃ©es POST-transformation arcsinh\n",
    "    obs=combined_gated.obs.copy(),  # Copie des mÃ©tadonnÃ©es\n",
    "    var=combined_gated.var.copy() if combined_gated.var is not None else None\n",
    ")\n",
    "\n",
    "# Ajouter les noms de variables\n",
    "adata_flowsom.var_names = var_names\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CRÃ‰ATION ANNDATA POUR FLOWSOM (DONNÃ‰ES POST-ARCSINH)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n[OK] Nouvel AnnData 'adata_flowsom' crÃ©Ã© avec donnÃ©es transformÃ©es\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Observations (cellules): {adata_flowsom.n_obs:,}\")\n",
    "print(f\"   Variables (marqueurs): {adata_flowsom.n_vars}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPLORATION DU DATAFRAME POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "\n",
    "# Extraire la matrice transformÃ©e depuis le NOUVEL AnnData\n",
    "X_trans = adata_flowsom.X\n",
    "if hasattr(X_trans, 'toarray'):\n",
    "    X_trans = X_trans.toarray()\n",
    "\n",
    "# CrÃ©er un DataFrame pour exploration\n",
    "df_transformed = pd.DataFrame(X_trans, columns=var_names)\n",
    "df_transformed['condition'] = adata_flowsom.obs['condition'].values\n",
    "df_transformed['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"APERÃ‡U DES DONNÃ‰ES TRANSFORMÃ‰ES (premiÃ¨res 10 lignes)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape du DataFrame: {df_transformed.shape}\")\n",
    "display(df_transformed.head(10))\n",
    "\n",
    "# VÃ‰RIFICATION DES NaN ET Inf POST-ARCSINH\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÃ‰RIFICATION DES VALEURS NaN ET Inf POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Colonnes numÃ©riques uniquement\n",
    "numeric_cols = df_transformed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Comptage des NaN\n",
    "nan_counts = df_transformed[numeric_cols].isna().sum()\n",
    "total_nan = nan_counts.sum()\n",
    "\n",
    "# Comptage des Inf (positifs et nÃ©gatifs)\n",
    "inf_pos_counts = (df_transformed[numeric_cols] == np.inf).sum()\n",
    "inf_neg_counts = (df_transformed[numeric_cols] == -np.inf).sum()\n",
    "total_inf_pos = inf_pos_counts.sum()\n",
    "total_inf_neg = inf_neg_counts.sum()\n",
    "total_inf = total_inf_pos + total_inf_neg\n",
    "\n",
    "total_cells = df_transformed.shape[0] * len(numeric_cols)\n",
    "\n",
    "print(f\"\\nRÃ‰SUMÃ‰ GLOBAL:\")\n",
    "print(f\"   Total valeurs analysÃ©es: {total_cells:,}\")\n",
    "print(f\"   Total NaN:    {total_nan:,} ({100*total_nan/total_cells:.4f}%)\")\n",
    "print(f\"   Total +Inf:   {total_inf_pos:,} ({100*total_inf_pos/total_cells:.4f}%)\")\n",
    "print(f\"   Total -Inf:   {total_inf_neg:,} ({100*total_inf_neg/total_cells:.4f}%)\")\n",
    "\n",
    "# DÃ©tail par colonne si problÃ¨mes dÃ©tectÃ©s\n",
    "if total_nan > 0 or total_inf > 0:\n",
    "    print(f\"\\nDÃ‰TAIL PAR COLONNE AVEC PROBLÃˆMES:\")\n",
    "    print(\"-\"*60)\n",
    "    for col in numeric_cols:\n",
    "        n_nan = df_transformed[col].isna().sum()\n",
    "        n_inf_pos = (df_transformed[col] == np.inf).sum()\n",
    "        n_inf_neg = (df_transformed[col] == -np.inf).sum()\n",
    "        if n_nan > 0 or n_inf_pos > 0 or n_inf_neg > 0:\n",
    "            print(f\"   {col:30s}: NaN={n_nan:,}, +Inf={n_inf_pos:,}, -Inf={n_inf_neg:,}\")\n",
    "else:\n",
    "    print(f\"\\nAucune valeur NaN ou Inf dÃ©tectÃ©e - DonnÃ©es propres!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTIQUES DESCRIPTIVES POST-ARCSINH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTIQUES DESCRIPTIVES POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "display(df_transformed[numeric_cols].describe())\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFICATION DES RANGES POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÃ‰RIFICATION DES RANGES POST-TRANSFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"(arcsinh avec cofactor=150 donne typiquement des valeurs entre -5 et 10)\\n\")\n",
    "\n",
    "# Utiliser les colonnes numÃ©riques rÃ©ellement prÃ©sentes dans df_transformed\n",
    "markers_to_check = [col for col in var_names if col in numeric_cols][:10]\n",
    "\n",
    "for col in markers_to_check:  # Premiers 10 marqueurs numÃ©riques\n",
    "    col_min = df_transformed[col].min()\n",
    "    col_max = df_transformed[col].max()\n",
    "    col_mean = df_transformed[col].mean()\n",
    "    print(f\"   {col:30s}: min={col_min:8.3f}, max={col_max:8.3f}, mean={col_mean:8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETTOYAGE FINAL ET VALIDATION DE L'ANNDATA POUR FLOWSOM\n",
    "\n",
    "# Nettoyage final: remplacer NaN/Inf par 0 dans adata_flowsom\n",
    "X_final = adata_flowsom.X\n",
    "if hasattr(X_final, 'toarray'):\n",
    "    X_final = X_final.toarray()\n",
    "\n",
    "# VÃ©rifier et nettoyer\n",
    "nan_mask = ~np.isfinite(X_final)\n",
    "n_nan = nan_mask.sum()\n",
    "if n_nan > 0:\n",
    "    print(f\"[!] {n_nan} valeurs NaN/Inf dÃ©tectÃ©es et remplacÃ©es par 0\")\n",
    "    X_final = np.nan_to_num(X_final, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    adata_flowsom.X = X_final\n",
    "else:\n",
    "    print(\"[OK] Aucune valeur problÃ©matique - pas de nettoyage nÃ©cessaire\")\n",
    "\n",
    "print(f\"\\n[OK] AnnData 'adata_flowsom' prÃªt pour FlowSOM:\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Colonnes pour clustering: {len(cols_to_use)}\")\n",
    "\n",
    "# RÃ©sumÃ© par condition\n",
    "print(f\"\\n Distribution par condition:\")\n",
    "for condition in adata_flowsom.obs['condition'].unique():\n",
    "    n = (adata_flowsom.obs['condition'] == condition).sum()\n",
    "    print(f\"   {condition}: {n:,} cellules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08a195",
   "metadata": {},
   "source": [
    "## 9. ExÃ©cution du Clustering FlowSOM\n",
    "\n",
    "Configuration et lancement de l'analyse FlowSOM avec:\n",
    "- Grille SOM (xdim Ã— ydim)\n",
    "- Nombre de mÃ©taclusters\n",
    "- Seed pour reproductibilitÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# PARAMÃˆTRES FLOWSOM\n",
    "# ==================\n",
    "# â†’ Valeurs contrÃ´lÃ©es par le panneau interactif (cellule 2) si exÃ©cutÃ©.\n",
    "_cfg = globals().get('CONFIG', {})\n",
    "\n",
    "# Grille SOM\n",
    "XDIM = _cfg.get('XDIM', 10)\n",
    "YDIM = _cfg.get('YDIM', 10)\n",
    "\n",
    "# ItÃ©rations SOM (rlen) â€” 'auto' = âˆšN Ã— 0.1, bornÃ© [10, 100]\n",
    "RLEN = _cfg.get('RLEN', 'auto')\n",
    "\n",
    "# Nombre de mÃ©taclusters (manuel, utilisÃ© si AUTO_CLUSTER=False)\n",
    "N_CLUSTERS = _cfg.get('N_CLUSTERS', 7)\n",
    "\n",
    "# Seed pour reproductibilitÃ©\n",
    "SEED = _cfg.get('SEED', 42)\n",
    "\n",
    "# Auto-clustering multi-critÃ¨res (StabilitÃ© + Silhouette)\n",
    "AUTO_CLUSTER = _cfg.get('AUTO_CLUSTER', False)\n",
    "MIN_CLUSTERS_AUTO = _cfg.get('MIN_CLUSTERS_AUTO', 5)\n",
    "MAX_CLUSTERS_AUTO = _cfg.get('MAX_CLUSTERS_AUTO', 35)\n",
    "N_BOOTSTRAP = _cfg.get('N_BOOTSTRAP', 10)\n",
    "SAMPLE_SIZE_BOOTSTRAP = _cfg.get('SAMPLE_SIZE_BOOTSTRAP', 20000)\n",
    "MIN_STABILITY_THRESHOLD = _cfg.get('MIN_STABILITY_THRESHOLD', 0.75)\n",
    "W_STABILITY = _cfg.get('W_STABILITY', 0.65)\n",
    "W_SILHOUETTE = _cfg.get('W_SILHOUETTE', 0.35)\n",
    "\n",
    "# Ancien paramÃ¨tre silhouette (conservÃ© en fallback)\n",
    "SAMPLE_SIZE_SILHOUETTE = 10000\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PARAMÃˆTRES FLOWSOM\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Grille SOM         : {XDIM} Ã— {YDIM} = {XDIM*YDIM} nodes\")\n",
    "print(f\"   rlen (itÃ©rations)  : {RLEN}\")\n",
    "print(f\"   MÃ©taclusters       : {N_CLUSTERS} (manuel)\")\n",
    "print(f\"   Seed               : {SEED}\")\n",
    "print(f\"   Auto-clustering    : {'Oui (StabilitÃ©+Silhouette)' if AUTO_CLUSTER else 'Non'}\")\n",
    "if AUTO_CLUSTER:\n",
    "    print(f\"   Plage k testÃ©e     : {MIN_CLUSTERS_AUTO}â€“{MAX_CLUSTERS_AUTO}\")\n",
    "    print(f\"   Bootstraps         : {N_BOOTSTRAP}\")\n",
    "    print(f\"   Sample bootstrap   : {SAMPLE_SIZE_BOOTSTRAP:,}\")\n",
    "    print(f\"   Seuil stabilitÃ©    : {MIN_STABILITY_THRESHOLD}\")\n",
    "    print(f\"   Poids composite    : stabilitÃ©={W_STABILITY}, silhouette={W_SILHOUETTE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTIMISATION AUTOMATIQUE FlowSOM â€” StabilitÃ© (AMJI/ARI) + Silhouette\n",
    "# MÃ©thode littÃ©rature 2024 : stabilitÃ© > score unique (silhouette)\n",
    "# ParticuliÃ¨rement important pour MRD oÃ¹ blasts rares nÃ©cessitent haute rÃ©solution\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import time as _time\n",
    "\n",
    "\n",
    "def compute_optimal_rlen(n_cells, rlen_setting='auto'):\n",
    "    \"\"\"\n",
    "    Calcule rlen optimal basÃ© sur la taille du dataset.\n",
    "    Formule littÃ©rature: rlen âˆ âˆšN / facteur, bornÃ© [10, 100].\n",
    "    - 10k cellules  â†’ rlen â‰ˆ 10\n",
    "    - 100k cellules â†’ rlen â‰ˆ 31\n",
    "    - 500k cellules â†’ rlen â‰ˆ 70\n",
    "    - 1M cellules   â†’ rlen â‰ˆ 100\n",
    "    \"\"\"\n",
    "    if isinstance(rlen_setting, int):\n",
    "        return rlen_setting\n",
    "    return max(10, min(100, int(np.sqrt(n_cells) * 0.1)))\n",
    "\n",
    "\n",
    "def compute_optimal_grid(n_cells, xdim_setting=10, ydim_setting=10):\n",
    "    \"\"\"\n",
    "    Ajuste la grille SOM si nÃ©cessaire.\n",
    "    - >50k cellules : 10Ã—10 (100 nodes)\n",
    "    - <50k cellules : 7Ã—7 (49 nodes) recommandÃ©\n",
    "    \"\"\"\n",
    "    if n_cells < 50000 and xdim_setting == 10 and ydim_setting == 10:\n",
    "        print(f\"   [INFO] {n_cells:,} cellules < 50k â†’ grille rÃ©duite 7Ã—7 recommandÃ©e\")\n",
    "        return 7, 7\n",
    "    return xdim_setting, ydim_setting\n",
    "\n",
    "\n",
    "def phase1_silhouette_on_codebook(data, cols_to_use, xdim, ydim, rlen, seed,\n",
    "                                   k_range, verbose=True):\n",
    "    \"\"\"\n",
    "    Phase 1 : Screening rapide via silhouette sur le codebook SOM.\n",
    "    \n",
    "    Avantage : Seulement n_nodes (ex: 100) points â†’ quasi-instantanÃ©.\n",
    "    On entraÃ®ne le SOM une seule fois, puis on re-mÃ©taclustÃ¨re pour chaque k.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'â”€'*60}\")\n",
    "        print(\"PHASE 1 : Silhouette sur codebook SOM (screening rapide)\")\n",
    "        print(f\"{'â”€'*60}\")\n",
    "    \n",
    "    # EntraÃ®ner le SOM une seule fois avec k=max (on re-mÃ©taclustÃ¨rera ensuite)\n",
    "    t0 = _time.time()\n",
    "    fsom_ref = fs.FlowSOM(\n",
    "        data, cols_to_use=cols_to_use,\n",
    "        xdim=xdim, ydim=ydim, rlen=rlen,\n",
    "        n_clusters=max(k_range), seed=seed\n",
    "    )\n",
    "    t_som = _time.time() - t0\n",
    "    if verbose:\n",
    "        print(f\"   SOM entraÃ®nÃ© en {t_som:.1f}s ({xdim}Ã—{ydim}, rlen={rlen})\")\n",
    "    \n",
    "    # Extraire le codebook (vecteurs prototypes des nodes SOM)\n",
    "    cluster_data = fsom_ref.get_cluster_data()\n",
    "    codebook = cluster_data.X\n",
    "    if hasattr(codebook, 'toarray'):\n",
    "        codebook = codebook.toarray()\n",
    "    \n",
    "    # Utiliser seulement les colonnes de clustering\n",
    "    codebook_use = np.nan_to_num(codebook[:, cols_to_use], nan=0.0)\n",
    "    \n",
    "    results = []\n",
    "    for k in k_range:\n",
    "        try:\n",
    "            # Re-mÃ©taclustÃ¨rer le codebook existant (rapide!)\n",
    "            fsom_ref.metacluster(n_clusters=k)\n",
    "            node_labels = fsom_ref.get_cluster_data().obs['metaclustering'].values.astype(int)\n",
    "            \n",
    "            n_unique = len(np.unique(node_labels))\n",
    "            if n_unique > 1 and n_unique < len(codebook_use):\n",
    "                sil = silhouette_score(codebook_use, node_labels)\n",
    "            else:\n",
    "                sil = -1.0\n",
    "            \n",
    "            results.append({'k': k, 'silhouette': sil})\n",
    "            if verbose:\n",
    "                bar = 'â–ˆ' * int(max(0, sil + 1) * 20)\n",
    "                print(f\"   k={k:3d} : silhouette={sil:+.4f}  {bar}\")\n",
    "        except Exception as e:\n",
    "            results.append({'k': k, 'silhouette': -1.0})\n",
    "            if verbose:\n",
    "                print(f\"   k={k:3d} : erreur â€“ {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results), fsom_ref\n",
    "\n",
    "\n",
    "def phase2_bootstrap_stability(data, cols_to_use, xdim, ydim, rlen, seed,\n",
    "                                candidates_k, n_bootstrap=10,\n",
    "                                sample_size=20000, verbose=True):\n",
    "    \"\"\"\n",
    "    Phase 2 : Ã‰valuation de la stabilitÃ© par bootstrap (ARI moyen pairwise).\n",
    "    \n",
    "    Pour chaque k candidat :\n",
    "    - ExÃ©cuter FlowSOM n_bootstrap fois avec des seeds diffÃ©rents\n",
    "      sur un sous-Ã©chantillon fixe (mÃªme cellules, seeds SOM diffÃ©rentes)\n",
    "    - Calculer l'ARI pairwise entre toutes les paires de runs\n",
    "    - ARI moyen = score de stabilitÃ© (proxy AMJI)\n",
    "    \n",
    "    Seuil littÃ©rature : stabilitÃ© (ARI) > 0.75â€“0.80 = clustering robuste\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'â”€'*60}\")\n",
    "        print(f\"PHASE 2 : StabilitÃ© bootstrap (ARI) â€” {n_bootstrap} runs Ã— {len(candidates_k)} candidats\")\n",
    "        print(f\"{'â”€'*60}\")\n",
    "    \n",
    "    n_total = data.shape[0]\n",
    "    eval_size = min(sample_size, n_total)\n",
    "    \n",
    "    # Sous-Ã©chantillon FIXE pour Ã©valuation (mÃªme cellules Ã  chaque run)\n",
    "    np.random.seed(seed)\n",
    "    eval_idx = np.random.choice(n_total, eval_size, replace=False)\n",
    "    data_eval = data[eval_idx].copy()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"   Sous-Ã©chantillon : {eval_size:,} cellules (fixe pour tous les runs)\")\n",
    "    \n",
    "    stability_results = {}\n",
    "    \n",
    "    for k in candidates_k:\n",
    "        t0 = _time.time()\n",
    "        labels_all_runs = []\n",
    "        \n",
    "        for b in range(n_bootstrap):\n",
    "            try:\n",
    "                fsom_b = fs.FlowSOM(\n",
    "                    data_eval, cols_to_use=cols_to_use,\n",
    "                    xdim=xdim, ydim=ydim, rlen=rlen,\n",
    "                    n_clusters=k, seed=seed + 100 + b  # Seeds diffÃ©rentes\n",
    "                )\n",
    "                labels_b = fsom_b.get_cell_data().obs['metaclustering'].values.astype(int)\n",
    "                labels_all_runs.append(labels_b)\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"   [!] k={k}, boot={b}: erreur â€“ {e}\")\n",
    "        \n",
    "        # ARI pairwise entre toutes les paires de runs\n",
    "        ari_pairs = []\n",
    "        for i in range(len(labels_all_runs)):\n",
    "            for j in range(i + 1, len(labels_all_runs)):\n",
    "                ari = adjusted_rand_score(labels_all_runs[i], labels_all_runs[j])\n",
    "                ari_pairs.append(ari)\n",
    "        \n",
    "        mean_ari = np.mean(ari_pairs) if ari_pairs else 0.0\n",
    "        std_ari = np.std(ari_pairs) if ari_pairs else 0.0\n",
    "        elapsed = _time.time() - t0\n",
    "        \n",
    "        stability_results[k] = {\n",
    "            'mean_ari': mean_ari,\n",
    "            'std_ari': std_ari,\n",
    "            'n_valid_runs': len(labels_all_runs),\n",
    "            'n_pairs': len(ari_pairs),\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            status = 'âœ“' if mean_ari >= MIN_STABILITY_THRESHOLD else 'âœ—'\n",
    "            bar = 'â–ˆ' * int(mean_ari * 30)\n",
    "            print(f\"   k={k:3d} : ARI={mean_ari:.4f} Â± {std_ari:.4f}  {bar}  {status}  ({elapsed:.1f}s)\")\n",
    "    \n",
    "    return stability_results\n",
    "\n",
    "\n",
    "def phase3_composite_selection(sil_df, stability_results, w_stability=0.65,\n",
    "                                w_silhouette=0.35, min_stability=0.75,\n",
    "                                verbose=True):\n",
    "    \"\"\"\n",
    "    Phase 3 : Score composite pondÃ©rÃ© pour sÃ©lection finale.\n",
    "    \n",
    "    Score = w_stability Ã— ARI_norm + w_silhouette Ã— Sil_norm\n",
    "    \n",
    "    Avec filtrage : seuls les k avec stabilitÃ© > seuil sont considÃ©rÃ©s.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'â”€'*60}\")\n",
    "        print(\"PHASE 3 : Score composite (StabilitÃ© Ã— Silhouette)\")\n",
    "        print(f\"{'â”€'*60}\")\n",
    "    \n",
    "    # Fusionner les mÃ©triques\n",
    "    composite = sil_df.copy()\n",
    "    composite['stability'] = composite['k'].map(\n",
    "        lambda k: stability_results.get(k, {}).get('mean_ari', np.nan)\n",
    "    )\n",
    "    composite['stability_std'] = composite['k'].map(\n",
    "        lambda k: stability_results.get(k, {}).get('std_ari', np.nan)\n",
    "    )\n",
    "    \n",
    "    # Filtrer les k sans donnÃ©es de stabilitÃ©\n",
    "    valid = composite.dropna(subset=['stability']).copy()\n",
    "    \n",
    "    if valid.empty:\n",
    "        if verbose:\n",
    "            print(\"   [!] Aucun candidat avec donnÃ©es de stabilitÃ© â†’ fallback silhouette\")\n",
    "        best_k = sil_df.loc[sil_df['silhouette'].idxmax(), 'k']\n",
    "        return int(best_k), composite\n",
    "    \n",
    "    # Normaliser [0, 1] pour chaque mÃ©trique\n",
    "    sil_min, sil_max = valid['silhouette'].min(), valid['silhouette'].max()\n",
    "    sta_min, sta_max = valid['stability'].min(), valid['stability'].max()\n",
    "    \n",
    "    if sil_max > sil_min:\n",
    "        valid['sil_norm'] = (valid['silhouette'] - sil_min) / (sil_max - sil_min)\n",
    "    else:\n",
    "        valid['sil_norm'] = 0.5\n",
    "    \n",
    "    if sta_max > sta_min:\n",
    "        valid['sta_norm'] = (valid['stability'] - sta_min) / (sta_max - sta_min)\n",
    "    else:\n",
    "        valid['sta_norm'] = 0.5\n",
    "    \n",
    "    # Score composite pondÃ©rÃ©\n",
    "    valid['composite_score'] = (\n",
    "        w_stability * valid['sta_norm'] + w_silhouette * valid['sil_norm']\n",
    "    )\n",
    "    \n",
    "    # Bonus : pÃ©naliser les k avec faible stabilitÃ© (sous le seuil)\n",
    "    valid.loc[valid['stability'] < min_stability, 'composite_score'] *= 0.7\n",
    "    \n",
    "    # Affichage dÃ©taillÃ©\n",
    "    if verbose:\n",
    "        print(f\"\\n   {'k':>4}  {'Silhouette':>11}  {'StabilitÃ©':>10}  {'Score':>8}  {'Verdict':>10}\")\n",
    "        print(f\"   {'â”€'*4}  {'â”€'*11}  {'â”€'*10}  {'â”€'*8}  {'â”€'*10}\")\n",
    "        for _, row in valid.sort_values('composite_score', ascending=False).iterrows():\n",
    "            verdict = 'â˜… OPTIMAL' if row['composite_score'] == valid['composite_score'].max() else ''\n",
    "            if row['stability'] < min_stability:\n",
    "                verdict = '(instable)'\n",
    "            print(f\"   {int(row['k']):4d}  {row['silhouette']:+11.4f}  {row['stability']:10.4f}  \"\n",
    "                  f\"{row['composite_score']:8.4f}  {verdict}\")\n",
    "    \n",
    "    # SÃ©lection finale\n",
    "    best_idx = valid['composite_score'].idxmax()\n",
    "    best_k = int(valid.loc[best_idx, 'k'])\n",
    "    best_sil = valid.loc[best_idx, 'silhouette']\n",
    "    best_sta = valid.loc[best_idx, 'stability']\n",
    "    best_score = valid.loc[best_idx, 'composite_score']\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
    "        print(f\"   â•‘  OPTIMAL : k = {best_k}                               \")\n",
    "        print(f\"   â•‘  Silhouette = {best_sil:+.4f}                          \")\n",
    "        print(f\"   â•‘  StabilitÃ© ARI = {best_sta:.4f}                        \")\n",
    "        print(f\"   â•‘  Score composite = {best_score:.4f}                    \")\n",
    "        print(f\"   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    \n",
    "    return best_k, valid\n",
    "\n",
    "\n",
    "def plot_optimization_results(results_df, best_k, stability_results=None):\n",
    "    \"\"\"Visualisation des rÃ©sultats d'optimisation multi-critÃ¨res.\"\"\"\n",
    "    has_stability = stability_results and len(stability_results) > 0\n",
    "    n_plots = 3 if has_stability else 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(6 * n_plots, 5))\n",
    "    if n_plots == 2:\n",
    "        axes = [axes[0], axes[1]]\n",
    "    \n",
    "    # â”€â”€ Plot 1 : Silhouette â”€â”€\n",
    "    ax = axes[0]\n",
    "    ks = results_df['k'].values\n",
    "    sils = results_df['silhouette'].values\n",
    "    ax.plot(ks, sils, 'o-', color='#2196F3', linewidth=2, markersize=5, label='Silhouette')\n",
    "    ax.axvline(best_k, color='#F44336', linestyle='--', linewidth=2, alpha=0.7, label=f'Optimal k={best_k}')\n",
    "    ax.set_xlabel('Nombre de mÃ©taclusters (k)', fontsize=11)\n",
    "    ax.set_ylabel('Silhouette Score', fontsize=11)\n",
    "    ax.set_title('Silhouette sur Codebook SOM', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # â”€â”€ Plot 2 : StabilitÃ© ARI â”€â”€\n",
    "    if has_stability:\n",
    "        ax = axes[1]\n",
    "        stab_ks = sorted(stability_results.keys())\n",
    "        stab_aris = [stability_results[k]['mean_ari'] for k in stab_ks]\n",
    "        stab_stds = [stability_results[k]['std_ari'] for k in stab_ks]\n",
    "        \n",
    "        ax.errorbar(stab_ks, stab_aris, yerr=stab_stds, fmt='s-', color='#4CAF50',\n",
    "                     linewidth=2, markersize=6, capsize=3, label='ARI moyen Â± Ïƒ')\n",
    "        ax.axhline(MIN_STABILITY_THRESHOLD, color='#FF9800', linestyle=':', \n",
    "                    linewidth=1.5, label=f'Seuil stabilitÃ© ({MIN_STABILITY_THRESHOLD})')\n",
    "        ax.axvline(best_k, color='#F44336', linestyle='--', linewidth=2, alpha=0.7)\n",
    "        ax.set_xlabel('Nombre de mÃ©taclusters (k)', fontsize=11)\n",
    "        ax.set_ylabel('ARI moyen (stabilitÃ©)', fontsize=11)\n",
    "        ax.set_title('StabilitÃ© Bootstrap (ARI pairwise)', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 1.05)\n",
    "    \n",
    "    # â”€â”€ Plot 3 (ou 2) : Score composite â”€â”€\n",
    "    ax = axes[-1]\n",
    "    if 'composite_score' in results_df.columns:\n",
    "        valid = results_df.dropna(subset=['composite_score'])\n",
    "        ax.bar(valid['k'], valid['composite_score'], color='#9C27B0', alpha=0.7, label='Score composite')\n",
    "        ax.axvline(best_k, color='#F44336', linestyle='--', linewidth=2, alpha=0.7, label=f'Optimal k={best_k}')\n",
    "        ax.set_xlabel('Nombre de mÃ©taclusters (k)', fontsize=11)\n",
    "        ax.set_ylabel('Score composite', fontsize=11)\n",
    "        ax.set_title(f'Score Composite (w_stab={W_STABILITY}, w_sil={W_SILHOUETTE})',\n",
    "                      fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        # Fallback: juste sil avec elbow\n",
    "        diffs = np.diff(sils)\n",
    "        ax.plot(ks[1:], diffs, 'o-', color='#FF5722', linewidth=2, markersize=4)\n",
    "        ax.axvline(best_k, color='#F44336', linestyle='--', linewidth=2, alpha=0.7)\n",
    "        ax.set_xlabel('k', fontsize=11)\n",
    "        ax.set_ylabel('Î” Silhouette', fontsize=11)\n",
    "        ax.set_title('Variation Silhouette (Elbow)', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'flowsom_optimization.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"   [OK] Figure sauvegardÃ©e â†’ {OUTPUT_DIR}/flowsom_optimization.png\")\n",
    "\n",
    "\n",
    "def find_optimal_clusters_stability(data, cols_to_use, seed=42,\n",
    "                                     xdim=10, ydim=10, rlen='auto',\n",
    "                                     k_range=None, n_bootstrap=10,\n",
    "                                     sample_size_boot=20000,\n",
    "                                     w_stability=0.65, w_silhouette=0.35,\n",
    "                                     min_stability=0.75, n_top_candidates=8):\n",
    "    \"\"\"\n",
    "    Pipeline complet d'optimisation FlowSOM multi-critÃ¨res.\n",
    "    \n",
    "    MÃ©thode littÃ©rature 2024 (Weber, Van Gassen et al.):\n",
    "    StabilitÃ© > score unique comme silhouette, surtout pour MRD\n",
    "    oÃ¹ populations rares (blasts CD34+) nÃ©cessitent haute rÃ©solution.\n",
    "    \n",
    "    Ã‰tapes:\n",
    "    â”€â”€â”€â”€â”€â”€â”€\n",
    "    1. Auto-calcul rlen et grille selon N cellules\n",
    "    2. Phase 1: Silhouette sur codebook SOM (screening rapide, tous les k)\n",
    "    3. Phase 2: Bootstrap stability (ARI pairwise, top candidats)\n",
    "    4. Phase 3: Score composite pondÃ©rÃ© â†’ sÃ©lection finale\n",
    "    5. Visualisation multi-panels\n",
    "    \n",
    "    Returns:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    best_k : int â€” nombre optimal de mÃ©taclusters\n",
    "    best_rlen : int â€” rlen optimisÃ©\n",
    "    best_xdim, best_ydim : int â€” dimensions grille\n",
    "    \"\"\"\n",
    "    n_cells = data.shape[0]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"OPTIMISATION FlowSOM â€” MÃ©thode StabilitÃ© 2024\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"   Dataset : {n_cells:,} cellules Ã— {len(cols_to_use)} marqueurs\")\n",
    "    \n",
    "    # â”€â”€ Auto-paramÃ¨tres â”€â”€\n",
    "    best_rlen = compute_optimal_rlen(n_cells, rlen)\n",
    "    best_xdim, best_ydim = compute_optimal_grid(n_cells, xdim, ydim)\n",
    "    \n",
    "    print(f\"   Grille  : {best_xdim}Ã—{best_ydim} = {best_xdim*best_ydim} nodes\")\n",
    "    print(f\"   rlen    : {best_rlen} ({'auto' if rlen == 'auto' else 'manuel'})\")\n",
    "    \n",
    "    if k_range is None:\n",
    "        k_range = range(MIN_CLUSTERS_AUTO, MAX_CLUSTERS_AUTO + 1)\n",
    "    \n",
    "    # â”€â”€ Phase 1 : Silhouette rapide sur codebook â”€â”€\n",
    "    t_total = _time.time()\n",
    "    sil_df, fsom_ref = phase1_silhouette_on_codebook(\n",
    "        data, cols_to_use, best_xdim, best_ydim, best_rlen, seed, k_range\n",
    "    )\n",
    "    \n",
    "    # â”€â”€ SÃ©lection des top candidats pour bootstrap â”€â”€\n",
    "    top_n = min(n_top_candidates, len(sil_df))\n",
    "    top_candidates = sil_df.nlargest(top_n, 'silhouette')['k'].values.tolist()\n",
    "    \n",
    "    # Ajouter aussi les voisins du meilleur silhouette (Â±2) pour robustesse\n",
    "    best_sil_k = int(sil_df.loc[sil_df['silhouette'].idxmax(), 'k'])\n",
    "    for delta in [-2, -1, 1, 2]:\n",
    "        neighbor = best_sil_k + delta\n",
    "        if neighbor in list(k_range) and neighbor not in top_candidates:\n",
    "            top_candidates.append(neighbor)\n",
    "    top_candidates = sorted(set(top_candidates))\n",
    "    \n",
    "    print(f\"\\n   â†’ {len(top_candidates)} candidats retenus pour bootstrap : {top_candidates}\")\n",
    "    \n",
    "    # â”€â”€ Phase 2 : Bootstrap stability â”€â”€\n",
    "    stability_results = phase2_bootstrap_stability(\n",
    "        data, cols_to_use, best_xdim, best_ydim, best_rlen, seed,\n",
    "        top_candidates, n_bootstrap=n_bootstrap,\n",
    "        sample_size=sample_size_boot\n",
    "    )\n",
    "    \n",
    "    # â”€â”€ Phase 3 : Score composite â”€â”€\n",
    "    best_k, composite_df = phase3_composite_selection(\n",
    "        sil_df, stability_results,\n",
    "        w_stability=w_stability, w_silhouette=w_silhouette,\n",
    "        min_stability=min_stability\n",
    "    )\n",
    "    \n",
    "    elapsed_total = _time.time() - t_total\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RÃ‰SULTAT FINAL â€” Temps total : {elapsed_total:.1f}s\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   k optimal       = {best_k} mÃ©taclusters\")\n",
    "    print(f\"   rlen optimal     = {best_rlen}\")\n",
    "    print(f\"   Grille SOM       = {best_xdim}Ã—{best_ydim}\")\n",
    "    \n",
    "    # â”€â”€ Visualisation â”€â”€\n",
    "    try:\n",
    "        plot_optimization_results(composite_df, best_k, stability_results)\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Visualisation Ã©chouÃ©e : {e}\")\n",
    "    \n",
    "    return best_k, best_rlen, best_xdim, best_ydim\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EXÃ‰CUTION DE L'OPTIMISATION\n",
    "# =============================================================================\n",
    "if AUTO_CLUSTER:\n",
    "    N_CLUSTERS, RLEN_OPT, XDIM, YDIM = find_optimal_clusters_stability(\n",
    "        combined_gated, cols_to_use, seed=SEED,\n",
    "        xdim=XDIM, ydim=YDIM, rlen=RLEN,\n",
    "        n_bootstrap=N_BOOTSTRAP,\n",
    "        sample_size_boot=SAMPLE_SIZE_BOOTSTRAP,\n",
    "        w_stability=W_STABILITY,\n",
    "        w_silhouette=W_SILHOUETTE,\n",
    "        min_stability=MIN_STABILITY_THRESHOLD,\n",
    "    )\n",
    "    # Mettre Ã  jour le rlen global\n",
    "    if isinstance(RLEN, str):\n",
    "        RLEN = RLEN_OPT\n",
    "    print(f\"\\n[OK] Utilisation de {N_CLUSTERS} mÃ©taclusters (rlen={RLEN})\")\n",
    "else:\n",
    "    # Mode manuel : calculer rlen si 'auto'\n",
    "    if isinstance(RLEN, str) and RLEN == 'auto':\n",
    "        RLEN = compute_optimal_rlen(combined_gated.shape[0])\n",
    "        print(f\"   rlen auto-calculÃ© : {RLEN}\")\n",
    "    print(f\"\\n[OK] Mode manuel : {N_CLUSTERS} mÃ©taclusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXÃ‰CUTION FLOWSOM (avec paramÃ¨tres optimisÃ©s)\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Convertir RLEN en int si encore en 'auto'\n",
    "rlen_final = RLEN if isinstance(RLEN, int) else compute_optimal_rlen(adata_flowsom.shape[0])\n",
    "\n",
    "print(f\"Lancement FlowSOM avec paramÃ¨tres optimisÃ©s :\")\n",
    "print(f\"   Grille   : {XDIM}Ã—{YDIM} = {XDIM*YDIM} nodes\")\n",
    "print(f\"   rlen     : {rlen_final}\")\n",
    "print(f\"   nClus    : {N_CLUSTERS}\")\n",
    "print(f\"   Seed     : {SEED}\")\n",
    "\n",
    "# ExÃ©cuter FlowSOM avec adata_flowsom (donnÃ©es transformÃ©es arcsinh)\n",
    "fsom = fs.FlowSOM(\n",
    "    adata_flowsom,  # â† IMPORTANT: utilise les donnÃ©es POST-transformation\n",
    "    cols_to_use=cols_to_use,\n",
    "    xdim=XDIM,\n",
    "    ydim=YDIM,\n",
    "    rlen=rlen_final,\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTemps d'exÃ©cution: {elapsed:.2f} secondes\")\n",
    "\n",
    "# RÃ©cupÃ©rer les donnÃ©es de clustering\n",
    "cell_data = fsom.get_cell_data()\n",
    "cluster_data = fsom.get_cluster_data()\n",
    "\n",
    "# Ajouter les mÃ©tadonnÃ©es originales\n",
    "cell_data.obs['condition'] = adata_flowsom.obs['condition'].values\n",
    "cell_data.obs['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(f\"\\n[OK] FlowSOM terminÃ©!\")\n",
    "print(f\"   Cellules analysÃ©es: {cell_data.shape[0]:,}\")\n",
    "print(f\"   Nodes SOM: {cluster_data.shape[0]}\")\n",
    "print(f\"   MÃ©taclusters: {N_CLUSTERS}\")\n",
    "print(f\"   rlen utilisÃ©: {rlen_final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0e07e",
   "metadata": {},
   "source": [
    "## 10. Visualisation des RÃ©sultats FlowSOM\n",
    "\n",
    "GÃ©nÃ©ration des visualisations standards:\n",
    "- Heatmap d'expression par mÃ©tacluster\n",
    "- Arbre MST (Minimum Spanning Tree)\n",
    "- Star Charts\n",
    "- Distribution par condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP D'EXPRESSION PAR MÃ‰TACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" GÃ©nÃ©ration de la Heatmap d'expression...\")\n",
    "\n",
    "# RÃ©cupÃ©rer les donnÃ©es\n",
    "X = cell_data.X\n",
    "if hasattr(X, 'toarray'):\n",
    "    X = X.toarray()\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "\n",
    "# Calculer la MFI (Mean Fluorescence Intensity) par mÃ©tacluster â€” VECTORISÃ‰\n",
    "# Utilise pd.DataFrame.groupby au lieu d'une boucle O(n_cells Ã— n_clusters)\n",
    "X_markers = X[:, cols_to_use]\n",
    "_mc_series = pd.Series(metaclustering, name='mc')\n",
    "mfi_matrix = (\n",
    "    pd.DataFrame(X_markers, columns=range(len(cols_to_use)))\n",
    "    .groupby(_mc_series)\n",
    "    .mean()\n",
    "    .reindex(range(N_CLUSTERS))\n",
    "    .fillna(0)\n",
    "    .values\n",
    ")\n",
    "\n",
    "# Normalisation Z-score pour la heatmap\n",
    "mfi_normalized = (mfi_matrix - np.nanmean(mfi_matrix, axis=0)) / (np.nanstd(mfi_matrix, axis=0) + 1e-10)\n",
    "\n",
    "# CrÃ©er la heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "im = ax.imshow(mfi_normalized.T, aspect='auto', cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "\n",
    "# Labels\n",
    "ax.set_yticks(range(len(used_markers)))\n",
    "ax.set_yticklabels(used_markers, fontsize=9)\n",
    "ax.set_xticks(range(N_CLUSTERS))\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "\n",
    "ax.set_title('Heatmap - Expression par MÃ©tacluster (Z-score)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('MÃ©tacluster', fontsize=12)\n",
    "ax.set_ylabel('Marqueur', fontsize=12)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8, label='Z-score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAR CHART FLOWSOM (MST View)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"GÃ©nÃ©ration du Star Chart MST...\")\n",
    "\n",
    "try:\n",
    "    # Utiliser l'API FlowSOM pour le Star Chart\n",
    "    fig_stars = fs.pl.plot_stars(\n",
    "        fsom,\n",
    "        background_values=fsom.get_cluster_data().obs.metaclustering,\n",
    "        view=\"MST\"\n",
    "    )\n",
    "    plt.suptitle('FlowSOM Star Chart (MST View)', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur Star Chart: {e}\")\n",
    "    print(\"   Utilisation de la visualisation alternative...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION GRILLE SOM (xGrid, yGrid) - Style FlowSOM R exact\n",
    "# =============================================================================\n",
    "# PARTIE 1 : MATPLOTLIB (statique, haute rÃ©solution pour PDF/export)\n",
    "# =============================================================================\n",
    "\n",
    "print(\" VISUALISATION GRILLE SOM (style FlowSOM R avec cercles)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R)\n",
    "# =====================================================================\n",
    "def circular_jitter_viz(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re un jitter circulaire style FlowSOM R â€” VECTORISÃ‰.\n",
    "    Le rayon des cercles dÃ©pend du nombre de cellules dans le node.\n",
    "    \"\"\"\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    max_size_val = node_sizes.max()\n",
    "    \n",
    "    # Calcul vectorisÃ© des rayons (pas de boucle Python)\n",
    "    size_ratios = np.sqrt(node_sizes[cluster_ids.astype(int)] / max_size_val)\n",
    "    radii = (min_radius + (max_radius - min_radius) * size_ratios).astype(np.float32)\n",
    "    \n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "try:\n",
    "    # RÃ©cupÃ©rer les coordonnÃ©es de grille\n",
    "    grid_coords = cluster_data.obsm.get('grid', None)\n",
    "    \n",
    "    if grid_coords is not None:\n",
    "        # RÃ©cupÃ©rer les infos de clustering\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        conditions = cell_data.obs['condition'].values\n",
    "        \n",
    "        # Calculer les coordonnÃ©es de grille pour chaque cellule\n",
    "        xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "        yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "        \n",
    "        # DÃ©caler pour commencer Ã  1\n",
    "        xGrid_shifted = xGrid_base - xGrid_base.min() + 1\n",
    "        yGrid_shifted = yGrid_base - yGrid_base.min() + 1\n",
    "        \n",
    "        # MÃ©tacluster pour chaque cellule\n",
    "        metaclustering_cells = np.array([metaclustering_nodes[int(c)] for c in clustering])\n",
    "        \n",
    "        # Calculer la taille de chaque node\n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes, dtype=np.float32)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        # JITTER CIRCULAIRE style FlowSOM R\n",
    "        MAX_NODE_SIZE = 0.45\n",
    "        MIN_NODE_SIZE = 0.1\n",
    "        np.random.seed(SEED)\n",
    "        jitter_x, jitter_y = circular_jitter_viz(len(clustering), clustering, node_sizes, \n",
    "                                                  max_radius=MAX_NODE_SIZE, \n",
    "                                                  min_radius=MIN_NODE_SIZE)\n",
    "        \n",
    "        print(f\" Jitter circulaire appliquÃ© (rayon proportionnel Ã  la taille du node)\")\n",
    "        print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "        \n",
    "        # CrÃ©er la figure avec 2 sous-plots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 1: Grille SOM colorÃ©e par MÃ©tacluster\n",
    "        # =====================================================================\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        \n",
    "        scatter1 = ax1.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=metaclustering_cells,\n",
    "            cmap=cmap,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        # Ajouter les labels des mÃ©taclusters au centre de chaque node\n",
    "        for node_id in range(n_nodes):\n",
    "            if node_sizes[node_id] > 0:\n",
    "                x_pos = grid_coords[node_id, 0] - xGrid_base.min() + 1\n",
    "                y_pos = grid_coords[node_id, 1] - yGrid_base.min() + 1\n",
    "                meta_id = metaclustering_nodes[node_id]\n",
    "                ax1.annotate(\n",
    "                    str(int(meta_id + 1)),\n",
    "                    (x_pos, y_pos),\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=8, fontweight='bold',\n",
    "                    color='white',\n",
    "                    bbox=dict(boxstyle='circle,pad=0.2', facecolor=cmap(meta_id / max(n_meta - 1, 1)), edgecolor='white', alpha=0.9)\n",
    "                )\n",
    "        \n",
    "        ax1.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColorÃ© par MÃ©tacluster (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax1.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax1.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax1.set_aspect('equal')\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        cbar1 = plt.colorbar(scatter1, ax=ax1, label='MÃ©tacluster')\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 2: Grille SOM colorÃ©e par Condition\n",
    "        # =====================================================================\n",
    "        ax2 = axes[1]\n",
    "        \n",
    "        condition_num = np.array([0 if c == 'Sain' else 1 for c in conditions])\n",
    "        \n",
    "        from matplotlib.colors import ListedColormap\n",
    "        cmap_cond = ListedColormap(['#a6e3a1', '#f38ba8'])\n",
    "        \n",
    "        scatter2 = ax2.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=condition_num,\n",
    "            cmap=cmap_cond,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        ax2.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColorÃ© par Condition (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax2.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax2.set_aspect('equal')\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='#a6e3a1', edgecolor='white', label='Sain (NBM)'),\n",
    "            Patch(facecolor='#f38ba8', edgecolor='white', label='Pathologique')\n",
    "        ]\n",
    "        ax2.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Afficher les statistiques\n",
    "        print(f\"\\n STATISTIQUES DE LA GRILLE SOM:\")\n",
    "        print(f\"   Dimensions: {XDIM} x {YDIM} = {XDIM * YDIM} nodes\")\n",
    "        print(f\"   Nodes utilisÃ©s: {(node_sizes > 0).sum()} / {n_nodes}\")\n",
    "        print(f\"   xGrid range: [{xGrid_shifted.min():.1f}, {xGrid_shifted.max():.1f}]\")\n",
    "        print(f\"   yGrid range: [{yGrid_shifted.min():.1f}, {yGrid_shifted.max():.1f}]\")\n",
    "        \n",
    "        # Afficher la taille des nodes\n",
    "        print(f\"\\n Distribution des tailles de nodes:\")\n",
    "        print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "        print(f\"   Max: {node_sizes.max():.0f} cellules\")\n",
    "        print(f\"   Moyenne: {node_sizes.mean():.0f} cellules\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # PARTIE 2 : PLOTLY INTERACTIF (zoom, hover, export)\n",
    "        # =================================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" GRILLE SOM â€” VERSION PLOTLY INTERACTIVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.colors as pc_grid\n",
    "        \n",
    "        _xj = xGrid_shifted + jitter_x\n",
    "        _yj = yGrid_shifted + jitter_y\n",
    "        \n",
    "        # Sous-Ã©chantillonner si trop de points pour la fluiditÃ© Plotly\n",
    "        _max_pts = 50_000\n",
    "        if len(clustering) > _max_pts:\n",
    "            np.random.seed(SEED)\n",
    "            _sample_idx = np.random.choice(len(clustering), _max_pts, replace=False)\n",
    "        else:\n",
    "            _sample_idx = np.arange(len(clustering))\n",
    "        \n",
    "        if n_meta <= 20:\n",
    "            _mc_palette = pc_grid.qualitative.Alphabet[:n_meta]\n",
    "        else:\n",
    "            _mc_palette = [f\"hsl({int(i*360/n_meta)},70%,55%)\" for i in range(n_meta)]\n",
    "        \n",
    "        # --- Plot 1 Plotly : MÃ©tacluster ---\n",
    "        fig_grid_mc = go.Figure()\n",
    "        \n",
    "        for mc_id in range(n_meta):\n",
    "            _mask_mc = metaclustering_cells[_sample_idx] == mc_id\n",
    "            if _mask_mc.sum() == 0:\n",
    "                continue\n",
    "            _si = _sample_idx[_mask_mc]\n",
    "            fig_grid_mc.add_trace(go.Scattergl(\n",
    "                x=_xj[_si], y=_yj[_si],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=_mc_palette[mc_id % len(_mc_palette)], opacity=0.5),\n",
    "                name=f\"MC{mc_id} ({_mask_mc.sum():,})\",\n",
    "                hovertemplate=f\"MC{mc_id}<br>xGrid: %{{x:.2f}}<br>yGrid: %{{y:.2f}}<extra></extra>\",\n",
    "            ))\n",
    "        \n",
    "        _node_x = [grid_coords[i, 0] - xGrid_base.min() + 1 for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_y = [grid_coords[i, 1] - yGrid_base.min() + 1 for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_txt = [str(int(metaclustering_nodes[i]+1)) for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_sz = [node_sizes[i] for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        \n",
    "        fig_grid_mc.add_trace(go.Scatter(\n",
    "            x=_node_x, y=_node_y,\n",
    "            mode='text',\n",
    "            text=_node_txt,\n",
    "            textfont=dict(size=9, color='black', family='Arial Black'),\n",
    "            hovertemplate=[f\"Node â€” MC{t}<br>{int(s):,} cellules<extra></extra>\" for t, s in zip(_node_txt, _node_sz)],\n",
    "            showlegend=False,\n",
    "        ))\n",
    "        \n",
    "        fig_grid_mc.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Grille FlowSOM â€” {XDIM}Ã—{YDIM} nodes â€” ColorÃ© par MÃ©tacluster</b><br>\"\n",
    "                     \"<sup>Style FlowSOM R (jitter circulaire proportionnel) â€” Interactif</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xGrid\", range=[0.3, XDIM+1.7], scaleanchor=\"y\", scaleratio=1,\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            yaxis=dict(title=\"yGrid\", range=[0.3, YDIM+1.7],\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            height=700, width=800,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(title=\"MÃ©tacluster\", font=dict(size=10),\n",
    "                        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                        bordercolor=\"#ccc\", borderwidth=1,\n",
    "                        yanchor=\"top\", y=1, xanchor=\"left\", x=1.02),\n",
    "            margin=dict(t=80, b=50, l=60, r=180),\n",
    "        )\n",
    "        fig_grid_mc.show()\n",
    "        \n",
    "        # --- Plot 2 Plotly : Condition ---\n",
    "        fig_grid_cond = go.Figure()\n",
    "        \n",
    "        _cond_colors = {\"Sain\": \"#2ca02c\", \"Pathologique\": \"#d62728\"}\n",
    "        for cond_label, cond_color in _cond_colors.items():\n",
    "            _mask_c = conditions[_sample_idx] == cond_label\n",
    "            if _mask_c.sum() == 0:\n",
    "                continue\n",
    "            _si = _sample_idx[_mask_c]\n",
    "            fig_grid_cond.add_trace(go.Scattergl(\n",
    "                x=_xj[_si], y=_yj[_si],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=cond_color, opacity=0.45),\n",
    "                name=f\"{cond_label} ({_mask_c.sum():,})\",\n",
    "                hovertemplate=f\"{cond_label}<br>xGrid: %{{x:.2f}}<br>yGrid: %{{y:.2f}}<extra></extra>\",\n",
    "            ))\n",
    "        \n",
    "        fig_grid_cond.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Grille FlowSOM â€” {XDIM}Ã—{YDIM} nodes â€” ColorÃ© par Condition</b><br>\"\n",
    "                     \"<sup>Style FlowSOM R (jitter circulaire proportionnel) â€” Interactif</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xGrid\", range=[0.3, XDIM+1.7], scaleanchor=\"y\", scaleratio=1,\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            yaxis=dict(title=\"yGrid\", range=[0.3, YDIM+1.7],\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            height=700, width=800,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(title=\"Condition\", font=dict(size=12),\n",
    "                        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                        bordercolor=\"#ccc\", borderwidth=1),\n",
    "            margin=dict(t=80, b=50, l=60, r=60),\n",
    "        )\n",
    "        fig_grid_cond.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"[!] CoordonnÃ©es de grille non disponibles dans cluster_data.obsm['grid']\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur visualisation grille: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714730ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ARBRE MST â€” MATPLOTLIB (statique) + PLOTLY (interactif)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"GÃ©nÃ©ration de l'arbre MST...\")\n",
    "\n",
    "# =====================================================================\n",
    "# PARTIE 1 : MATPLOTLIB (statique, haute rÃ©solution pour PDF/export)\n",
    "# =====================================================================\n",
    "try:\n",
    "    layout = cluster_data.obsm.get('layout', None)\n",
    "    \n",
    "    if layout is not None:\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        \n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        max_size = node_sizes.max() if node_sizes.max() > 0 else 1\n",
    "        sizes = 100 + (node_sizes / max_size) * 800\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        colors = [cmap(int(m) / max(n_meta - 1, 1)) for m in metaclustering_nodes]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        scatter = ax.scatter(layout[:, 0], layout[:, 1], \n",
    "                           s=sizes, c=colors, edgecolors='white', \n",
    "                           linewidths=1.5, alpha=0.9, zorder=2)\n",
    "        \n",
    "        for i in range(n_nodes):\n",
    "            ax.annotate(str(int(metaclustering_nodes[i])), \n",
    "                       (layout[i, 0], layout[i, 1]),\n",
    "                       ha='center', va='center', fontsize=8, \n",
    "                       color='white', fontweight='bold')\n",
    "        \n",
    "        ax.set_xlabel('xNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('yNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Arbre MST - {n_nodes} nodes, {n_meta} mÃ©taclusters', \n",
    "                    fontsize=14, fontweight='bold', pad=15)\n",
    "        ax.grid(True, alpha=0.15, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        if n_meta <= 15:\n",
    "            legend_elements = [Patch(facecolor=cmap(i/max(n_meta-1, 1)), \n",
    "                                    label=f'MC {i}') for i in range(n_meta)]\n",
    "            ax.legend(handles=legend_elements, loc='center left', \n",
    "                     bbox_to_anchor=(1.02, 0.5), fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # =================================================================\n",
    "        # PARTIE 2 : PLOTLY INTERACTIF (zoom, hover, export)\n",
    "        # =================================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" ARBRE MST â€” VERSION PLOTLY INTERACTIVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.colors as pc_mst\n",
    "        \n",
    "        _bubble_sizes = 10 + (node_sizes / max_size) * 40\n",
    "        \n",
    "        if n_meta <= 20:\n",
    "            _mc_palette = pc_mst.qualitative.Alphabet[:n_meta]\n",
    "        else:\n",
    "            _mc_palette = [f\"hsl({int(i*360/n_meta)},70%,55%)\" for i in range(n_meta)]\n",
    "        \n",
    "        # RÃ©cupÃ©rer les arÃªtes du MST si disponibles\n",
    "        _edge_x, _edge_y = [], []\n",
    "        _mst_graph = None\n",
    "        try:\n",
    "            if hasattr(cluster_data, 'uns') and 'mst' in cluster_data.uns:\n",
    "                _mst_graph = cluster_data.uns['mst']\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        if _mst_graph is not None:\n",
    "            try:\n",
    "                import igraph\n",
    "                if isinstance(_mst_graph, igraph.Graph):\n",
    "                    for edge in _mst_graph.es:\n",
    "                        s, t = edge.source, edge.target\n",
    "                        if s < n_nodes and t < n_nodes:\n",
    "                            _edge_x += [layout[s, 0], layout[t, 0], None]\n",
    "                            _edge_y += [layout[s, 1], layout[t, 1], None]\n",
    "            except ImportError:\n",
    "                pass\n",
    "        \n",
    "        fig_mst = go.Figure()\n",
    "        \n",
    "        if _edge_x:\n",
    "            fig_mst.add_trace(go.Scatter(\n",
    "                x=_edge_x, y=_edge_y,\n",
    "                mode='lines',\n",
    "                line=dict(width=1.5, color='rgba(100,100,100,0.5)'),\n",
    "                hoverinfo='skip',\n",
    "                showlegend=False,\n",
    "            ))\n",
    "        \n",
    "        for mc_id in range(n_meta):\n",
    "            _mask = metaclustering_nodes == mc_id\n",
    "            if _mask.sum() == 0:\n",
    "                continue\n",
    "            _indices = np.where(_mask)[0]\n",
    "            fig_mst.add_trace(go.Scatter(\n",
    "                x=layout[_indices, 0],\n",
    "                y=layout[_indices, 1],\n",
    "                mode='markers+text',\n",
    "                marker=dict(\n",
    "                    size=_bubble_sizes[_indices],\n",
    "                    color=_mc_palette[mc_id % len(_mc_palette)],\n",
    "                    line=dict(width=1.5, color='white'),\n",
    "                    opacity=0.9,\n",
    "                ),\n",
    "                text=[str(int(mc_id)) for _ in _indices],\n",
    "                textfont=dict(size=9, color='white', family='Arial Black'),\n",
    "                textposition='middle center',\n",
    "                name=f\"MC{mc_id} ({int(node_sizes[_indices].sum()):,} cells)\",\n",
    "                hovertemplate=[\n",
    "                    f\"<b>Node {ni}</b><br>\"\n",
    "                    f\"MC {int(metaclustering_nodes[ni])}<br>\"\n",
    "                    f\"Cellules: {int(node_sizes[ni]):,}<br>\"\n",
    "                    f\"x: {layout[ni,0]:.2f}, y: {layout[ni,1]:.2f}<extra></extra>\"\n",
    "                    for ni in _indices\n",
    "                ],\n",
    "            ))\n",
    "        \n",
    "        fig_mst.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Arbre MST â€” {n_nodes} nodes, {n_meta} mÃ©taclusters</b><br>\"\n",
    "                     \"<sup>Taille des bulles âˆ nombre de cellules Â· Cliquez la lÃ©gende pour filtrer</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xNodes\", showgrid=True, gridcolor=\"rgba(0,0,0,0.06)\",\n",
    "                       zeroline=False),\n",
    "            yaxis=dict(title=\"yNodes\", showgrid=True, gridcolor=\"rgba(0,0,0,0.06)\",\n",
    "                       zeroline=False, scaleanchor=\"x\", scaleratio=1),\n",
    "            height=750, width=900,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(\n",
    "                title=\"MÃ©tacluster\",\n",
    "                font=dict(size=10),\n",
    "                bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                bordercolor=\"#ccc\", borderwidth=1,\n",
    "                yanchor=\"top\", y=1, xanchor=\"left\", x=1.02,\n",
    "            ),\n",
    "            margin=dict(t=80, b=50, l=60, r=200),\n",
    "        )\n",
    "        fig_mst.show()\n",
    "        \n",
    "        print(f\"[OK] Arbre MST â€” Matplotlib + Plotly interactif ({n_nodes} nodes, {n_meta} MC)\")\n",
    "    else:\n",
    "        print(\"[!] Layout MST non disponible\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur MST: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION PAR CONDITION (Sain vs Pathologique)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Distribution des mÃ©taclusters par condition...\")\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "conditions = cell_data.obs['condition'].values\n",
    "\n",
    "healthy_pcts = []\n",
    "patho_pcts = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask_cluster = metaclustering == i\n",
    "    \n",
    "    # Pourcentage dans Sain\n",
    "    mask_healthy = (conditions == 'Sain') & mask_cluster\n",
    "    total_healthy = (conditions == 'Sain').sum()\n",
    "    healthy_pcts.append((mask_healthy.sum() / total_healthy * 100) if total_healthy > 0 else 0)\n",
    "    \n",
    "    # Pourcentage dans Pathologique\n",
    "    mask_patho = (conditions == 'Pathologique') & mask_cluster\n",
    "    total_patho = (conditions == 'Pathologique').sum()\n",
    "    patho_pcts.append((mask_patho.sum() / total_patho * 100) if total_patho > 0 else 0)\n",
    "\n",
    "# CrÃ©er le graphique\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x = np.arange(N_CLUSTERS)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, healthy_pcts, width, label='Sain (NBM)', \n",
    "               color='#a6e3a1', edgecolor='white', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, patho_pcts, width, label='Pathologique', \n",
    "               color='#f38ba8', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('MÃ©tacluster', fontsize=12)\n",
    "ax.set_ylabel('Pourcentage (%)', fontsize=12)\n",
    "ax.set_title('Distribution des MÃ©taclusters par Condition', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    if height > 1:  # N'afficher que si > 1%\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3), textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau rÃ©capitulatif\n",
    "print(\"\\nTableau rÃ©capitulatif:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'MC':>4} | {'Sain (%)':>10} | {'Patho (%)':>10} | {'Diff':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(N_CLUSTERS):\n",
    "    diff = patho_pcts[i] - healthy_pcts[i]\n",
    "    print(f\"{i:>4} | {healthy_pcts[i]:>10.2f} | {patho_pcts[i]:>10.2f} | {diff:>+8.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acff00",
   "metadata": {},
   "source": [
    "## 11. Analyse DÃ©taillÃ©e des MÃ©taclusters\n",
    "\n",
    "Statistiques approfondies par mÃ©tacluster:\n",
    "- Nombre de cellules\n",
    "- MFI par marqueur\n",
    "- PhÃ©notype caractÃ©ristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATISTIQUES PAR MÃ‰TACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" STATISTIQUES PAR MÃ‰TACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CrÃ©er un DataFrame de statistiques\n",
    "stats_data = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    n_cells = mask.sum()\n",
    "    pct_total = n_cells / len(metaclustering) * 100\n",
    "    \n",
    "    # Calculer MFI pour chaque marqueur\n",
    "    mfi = np.nanmean(X[mask][:, cols_to_use], axis=0) if n_cells > 0 else np.zeros(len(cols_to_use))\n",
    "    \n",
    "    # Top 3 marqueurs les plus exprimÃ©s\n",
    "    top_indices = np.argsort(mfi)[::-1][:3]\n",
    "    top_markers = [used_markers[idx] for idx in top_indices]\n",
    "    \n",
    "    stats_data.append({\n",
    "        'Metacluster': i,\n",
    "        'N_Cells': n_cells,\n",
    "        'Pct_Total': pct_total,\n",
    "        'Top_Markers': ', '.join(top_markers)\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats_data)\n",
    "print(df_stats.to_string(index=False))\n",
    "\n",
    "# Graphique camembert\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Pie chart des tailles\n",
    "ax = axes[0]\n",
    "sizes = [s['N_Cells'] for s in stats_data]\n",
    "labels = [f\"MC{s['Metacluster']}\" for s in stats_data]\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, N_CLUSTERS))\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, \n",
    "                                   autopct='%1.1f%%', pctdistance=0.8)\n",
    "ax.set_title('Distribution des Cellules par MÃ©tacluster', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Bar chart des tailles\n",
    "ax = axes[1]\n",
    "ax.barh(range(N_CLUSTERS), sizes, color=colors, edgecolor='white')\n",
    "ax.set_yticks(range(N_CLUSTERS))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Nombre de cellules')\n",
    "ax.set_title('Taille des MÃ©taclusters', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c773749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROFIL D'EXPRESSION DÃ‰TAILLÃ‰ PAR MÃ‰TACLUSTER â€” SPIDER PLOT INTERACTIF\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n PROFIL D'EXPRESSION MOYEN PAR MÃ‰TACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CrÃ©er un DataFrame avec MFI par marqueur et mÃ©tacluster â€” VECTORISÃ‰\n",
    "X_markers_mfi = X[:, cols_to_use]\n",
    "_mc_mfi = pd.Series(metaclustering, name='mc')\n",
    "mfi_matrix = (\n",
    "    pd.DataFrame(X_markers_mfi, columns=range(len(used_markers)))\n",
    "    .groupby(_mc_mfi)\n",
    "    .mean()\n",
    "    .reindex(range(N_CLUSTERS))\n",
    "    .fillna(0)\n",
    "    .values\n",
    ")\n",
    "\n",
    "df_mfi = pd.DataFrame(mfi_matrix, \n",
    "                       columns=used_markers,\n",
    "                       index=[f'MC{i}' for i in range(N_CLUSTERS)])\n",
    "\n",
    "# Afficher le tableau formatÃ©\n",
    "print(df_mfi.round(2).to_string())\n",
    "\n",
    "# =============================================================================\n",
    "# SPIDER / RADAR PLOT INTERACTIF â€” TOUS LES CLUSTERS (Plotly)\n",
    "# =============================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "# Palette de couleurs suffisante pour tous les clusters\n",
    "if N_CLUSTERS <= 10:\n",
    "    _radar_palette = pc.qualitative.Set3\n",
    "elif N_CLUSTERS <= 20:\n",
    "    _radar_palette = pc.qualitative.Alphabet\n",
    "else:\n",
    "    _radar_palette = [f\"hsl({int(i*360/N_CLUSTERS)},70%,55%)\" for i in range(N_CLUSTERS)]\n",
    "\n",
    "fig_radar = go.Figure()\n",
    "\n",
    "for cluster_id in range(N_CLUSTERS):\n",
    "    values = mfi_matrix[cluster_id].copy()\n",
    "    # Normaliser entre 0 et 1 pour la visualisation\n",
    "    v_min, v_max = np.min(values), np.max(values)\n",
    "    values_norm = (values - v_min) / (v_max - v_min + 1e-10)\n",
    "\n",
    "    _c = _radar_palette[cluster_id % len(_radar_palette)]\n",
    "    _n_cells = int((metaclustering == cluster_id).sum())\n",
    "\n",
    "    # Construire une couleur de remplissage semi-transparente\n",
    "    if 'rgb' in str(_c):\n",
    "        _fill = _c.replace(')', ',0.08)').replace('rgb', 'rgba')\n",
    "    else:\n",
    "        _fill = f\"rgba(128,128,128,0.05)\"\n",
    "\n",
    "    fig_radar.add_trace(go.Scatterpolar(\n",
    "        r=np.append(values_norm, values_norm[0]),\n",
    "        theta=used_markers + [used_markers[0]],\n",
    "        fill='toself',\n",
    "        fillcolor=_fill,\n",
    "        opacity=0.85,\n",
    "        name=f\"MC{cluster_id}  ({_n_cells:,} cells)\",\n",
    "        line=dict(color=_c, width=2),\n",
    "        marker=dict(size=5),\n",
    "        customdata=np.stack([\n",
    "            np.append(mfi_matrix[cluster_id], mfi_matrix[cluster_id][0]),\n",
    "            np.append(values_norm, values_norm[0]),\n",
    "        ], axis=-1),\n",
    "        hovertemplate=(\n",
    "            f\"<b>MC{cluster_id}</b><br>\"\n",
    "            \"Marqueur: %{theta}<br>\"\n",
    "            \"MFI brute: %{customdata[0]:.2f}<br>\"\n",
    "            \"NormalisÃ©: %{customdata[1]:.3f}<extra></extra>\"\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "fig_radar.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1.05],\n",
    "            tickfont=dict(size=9),\n",
    "            gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            tickfont=dict(size=11),\n",
    "            gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "            rotation=90,\n",
    "            direction=\"clockwise\",\n",
    "        ),\n",
    "        bgcolor=\"rgba(250,250,250,0.5)\",\n",
    "    ),\n",
    "    title=dict(\n",
    "        text=f\"<b>Profil d'Expression NormalisÃ© â€” {N_CLUSTERS} MÃ©taclusters</b><br>\"\n",
    "             \"<sup>Cliquez sur la lÃ©gende pour masquer/afficher un cluster</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=\"MÃ©tacluster\",\n",
    "        font=dict(size=11),\n",
    "        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "        bordercolor=\"#ccc\", borderwidth=1,\n",
    "        yanchor=\"top\", y=1.0,\n",
    "        xanchor=\"left\", x=1.05,\n",
    "    ),\n",
    "    height=750,\n",
    "    width=950,\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=90, b=40, l=80, r=200),\n",
    ")\n",
    "\n",
    "fig_radar.show()\n",
    "print(f\"\\n[OK] Spider plot interactif â€” {N_CLUSTERS} mÃ©taclusters affichÃ©s\")\n",
    "print(\"     â†’ Cliquez sur la lÃ©gende pour isoler un mÃ©tacluster\")\n",
    "print(\"     â†’ Survolez les points pour voir les MFI brutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f58bc",
   "metadata": {},
   "source": [
    "## Visualisations Plus Lisibles pour Cliniciens\n",
    "\n",
    "**Alternatives au Spider Plot** pour faciliter l'interprÃ©tation clinique :\n",
    "\n",
    "1. **Heatmap cluster Ã— marqueur** (MFI) avec clustering hiÃ©rarchique des lignes\n",
    "2. **Barplots** par cluster montrant les marqueurs clÃ©s cÃ´te Ã  cÃ´te NBM vs Patho\n",
    "3. **Tableau \"signature phÃ©notypique\"** par mÃ©tacluster (CD34+/âˆ’, CD117+/âˆ’, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP CLUSTER Ã— MARQUEUR + BARPLOTS NBM vs PATHO + SIGNATURE PHÃ‰NOTYPIQUE\n",
    "# =============================================================================\n",
    "# Visualisations alternatives plus lisibles pour les cliniciens\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" VISUALISATIONS CLINIQUES â€” HEATMAP, BARPLOTS, SIGNATURE PHÃ‰NOTYPIQUE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. HEATMAP CLUSTER Ã— MARQUEUR (MFI normalisÃ©) avec clustering hiÃ©rarchique\n",
    "# =====================================================================\n",
    "print(\"\\n [1/3] Heatmap Cluster Ã— Marqueur (MFI, clustering hiÃ©rarchique)\")\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Utiliser la matrice MFI dÃ©jÃ  calculÃ©e (mfi_matrix: N_CLUSTERS Ã— n_markers)\n",
    "# Normaliser par marqueur (Z-score par colonne) pour mieux comparer\n",
    "mfi_zscore = (mfi_matrix - mfi_matrix.mean(axis=0)) / (mfi_matrix.std(axis=0) + 1e-10)\n",
    "\n",
    "# Clustering hiÃ©rarchique des lignes (mÃ©taclusters)\n",
    "if N_CLUSTERS > 2:\n",
    "    row_linkage = linkage(pdist(mfi_zscore, metric='euclidean'), method='ward')\n",
    "    row_order = leaves_list(row_linkage)\n",
    "else:\n",
    "    row_order = np.arange(N_CLUSTERS)\n",
    "\n",
    "# Clustering hiÃ©rarchique des colonnes (marqueurs) \n",
    "if len(used_markers) > 2:\n",
    "    col_linkage = linkage(pdist(mfi_zscore.T, metric='euclidean'), method='ward')\n",
    "    col_order = leaves_list(col_linkage)\n",
    "else:\n",
    "    col_order = np.arange(len(used_markers))\n",
    "\n",
    "# RÃ©ordonner\n",
    "mfi_ordered = mfi_zscore[row_order][:, col_order]\n",
    "markers_ordered = [used_markers[i] for i in col_order]\n",
    "mc_labels_ordered = [f\"MC{i}\" for i in row_order]\n",
    "\n",
    "# Taille des mÃ©taclusters pour annotation\n",
    "mc_sizes = [(metaclustering == i).sum() for i in range(N_CLUSTERS)]\n",
    "mc_pcts_ordered = [mc_sizes[i] / sum(mc_sizes) * 100 for i in row_order]\n",
    "\n",
    "# Heatmap Plotly avec annotation\n",
    "fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "    z=mfi_ordered,\n",
    "    x=markers_ordered,\n",
    "    y=[f\"{mc_labels_ordered[i]} ({mc_pcts_ordered[i]:.1f}%)\" for i in range(len(mc_labels_ordered))],\n",
    "    colorscale='RdBu_r',\n",
    "    zmid=0,\n",
    "    colorbar=dict(title=\"Z-score MFI\", thickness=15, len=0.8),\n",
    "    text=np.round(mfi_ordered, 2),\n",
    "    texttemplate=\"%{text:.1f}\",\n",
    "    textfont=dict(size=9),\n",
    "    hovertemplate=\"MÃ©tacluster: %{y}<br>Marqueur: %{x}<br>Z-score: %{z:.2f}<extra></extra>\",\n",
    "))\n",
    "\n",
    "fig_heatmap.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Heatmap MFI â€” MÃ©taclusters Ã— Marqueurs</b><br>\"\n",
    "             \"<sup>Z-score normalisÃ© par marqueur Â· Clustering hiÃ©rarchique (Ward)</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=11)),\n",
    "    yaxis=dict(title=\"MÃ©taclusters\", tickfont=dict(size=11), autorange=\"reversed\"),\n",
    "    height=max(400, 40 * N_CLUSTERS + 150),\n",
    "    width=max(700, 50 * len(used_markers) + 200),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=100, b=120, l=150, r=50),\n",
    ")\n",
    "fig_heatmap.show()\n",
    "print(f\"   [OK] Heatmap {N_CLUSTERS} mÃ©taclusters Ã— {len(used_markers)} marqueurs\")\n",
    "\n",
    "# =====================================================================\n",
    "# 2. HEATMAP EXPRESSION INTENSITY (+ / ++ / +++) pour cliniciens\n",
    "# =====================================================================\n",
    "print(\"\\n [1b/3] Heatmap expression qualitative (+/++/+++ lÃ©gende clinique)\")\n",
    "\n",
    "# Classifier l'expression en catÃ©gories cliniques\n",
    "def classify_expression(zscore):\n",
    "    \"\"\"Convertir Z-score en catÃ©gorie clinique.\"\"\"\n",
    "    if zscore <= -1.0:\n",
    "        return \"âˆ’\"\n",
    "    elif zscore <= -0.3:\n",
    "        return \"low\"\n",
    "    elif zscore <= 0.3:\n",
    "        return \"+\"\n",
    "    elif zscore <= 1.0:\n",
    "        return \"++\"\n",
    "    else:\n",
    "        return \"+++\"\n",
    "\n",
    "# CrÃ©er matrice de texte clinique\n",
    "clinical_text = np.vectorize(classify_expression)(mfi_ordered)\n",
    "\n",
    "# CrÃ©er aussi une heatmap numÃ©rique discrÃ©tisÃ©e\n",
    "clinical_numeric = np.zeros_like(mfi_ordered)\n",
    "for i in range(mfi_ordered.shape[0]):\n",
    "    for j in range(mfi_ordered.shape[1]):\n",
    "        val = mfi_ordered[i, j]\n",
    "        if val <= -1.0:\n",
    "            clinical_numeric[i, j] = -2\n",
    "        elif val <= -0.3:\n",
    "            clinical_numeric[i, j] = -1\n",
    "        elif val <= 0.3:\n",
    "            clinical_numeric[i, j] = 0\n",
    "        elif val <= 1.0:\n",
    "            clinical_numeric[i, j] = 1\n",
    "        else:\n",
    "            clinical_numeric[i, j] = 2\n",
    "\n",
    "fig_heatmap_clinical = go.Figure(data=go.Heatmap(\n",
    "    z=clinical_numeric,\n",
    "    x=markers_ordered,\n",
    "    y=[f\"{mc_labels_ordered[i]} ({mc_pcts_ordered[i]:.1f}%)\" for i in range(len(mc_labels_ordered))],\n",
    "    colorscale=[\n",
    "        [0.0, '#3182bd'],    # âˆ’ (nÃ©gatif fort)\n",
    "        [0.25, '#9ecae1'],   # low\n",
    "        [0.5, '#f0f0f0'],    # +\n",
    "        [0.75, '#fdae6b'],   # ++\n",
    "        [1.0, '#d62728'],    # +++\n",
    "    ],\n",
    "    text=clinical_text,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=11, color=\"black\"),\n",
    "    hovertemplate=\"MÃ©tacluster: %{y}<br>Marqueur: %{x}<br>Expression: %{text}<extra></extra>\",\n",
    "    showscale=True,\n",
    "    colorbar=dict(\n",
    "        title=\"Expression\",\n",
    "        tickvals=[-2, -1, 0, 1, 2],\n",
    "        ticktext=[\"âˆ’\", \"low\", \"+\", \"++\", \"+++\"],\n",
    "        thickness=15, len=0.8,\n",
    "    ),\n",
    "))\n",
    "\n",
    "fig_heatmap_clinical.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Expression PhÃ©notypique â€” MÃ©taclusters Ã— Marqueurs</b><br>\"\n",
    "             \"<sup>LÃ©gende clinique: âˆ’ / low / + / ++ / +++ (basÃ© sur Z-score MFI)</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=11)),\n",
    "    yaxis=dict(title=\"MÃ©taclusters\", tickfont=dict(size=11), autorange=\"reversed\"),\n",
    "    height=max(400, 40 * N_CLUSTERS + 150),\n",
    "    width=max(700, 50 * len(used_markers) + 200),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=100, b=120, l=150, r=50),\n",
    ")\n",
    "fig_heatmap_clinical.show()\n",
    "\n",
    "# =====================================================================\n",
    "# 3. BARPLOTS MARQUEURS CLÃ‰S â€” NBM vs PATHO (si COMPARE_MODE)\n",
    "# =====================================================================\n",
    "if COMPARE_MODE or MODE_BLASTES_VS_NORMAL:\n",
    "    print(\"\\n [2/3] Barplots marqueurs clÃ©s â€” NBM vs Patho par mÃ©tacluster\")\n",
    "    \n",
    "    # Marqueurs clÃ©s pour la cytomÃ©trie de flux hÃ©mato\n",
    "    _key_markers_patterns = ['CD34', 'CD117', 'CD13', 'CD33', 'HLA-DR', 'CD45', 'CD15', 'CD16', \n",
    "                              'CD38', 'CD123', 'CD7', 'CD56', 'CD19', 'CD64']\n",
    "    _key_markers_idx = []\n",
    "    _key_markers_names = []\n",
    "    for pattern in _key_markers_patterns:\n",
    "        idx = PreGating.find_marker_index(used_markers, [pattern])\n",
    "        if idx is not None:\n",
    "            _key_markers_idx.append(idx)\n",
    "            _key_markers_names.append(used_markers[idx])\n",
    "    \n",
    "    if len(_key_markers_idx) >= 2:\n",
    "        # MFI par condition et mÃ©tacluster\n",
    "        conditions_arr = adata_flowsom.obs['condition'].values if 'condition' in adata_flowsom.obs.columns else None\n",
    "        \n",
    "        if conditions_arr is not None:\n",
    "            _n_key = len(_key_markers_idx)\n",
    "            _n_mc_show = min(N_CLUSTERS, 8)  # Limiter Ã  8 pour lisibilitÃ©\n",
    "            \n",
    "            # Top mÃ©taclusters par taille\n",
    "            _mc_sizes_arr = np.array(mc_sizes)\n",
    "            _top_mc = np.argsort(_mc_sizes_arr)[::-1][:_n_mc_show]\n",
    "            \n",
    "            _n_cols_bp = min(4, _n_mc_show)\n",
    "            _n_rows_bp = int(np.ceil(_n_mc_show / _n_cols_bp))\n",
    "            \n",
    "            fig_barplots = make_subplots(\n",
    "                rows=_n_rows_bp, cols=_n_cols_bp,\n",
    "                subplot_titles=[f\"MC{mc} ({mc_sizes[mc]:,} cells)\" for mc in _top_mc],\n",
    "                horizontal_spacing=0.08, vertical_spacing=0.12,\n",
    "            )\n",
    "            \n",
    "            for bi, mc_id in enumerate(_top_mc):\n",
    "                _row_bp = bi // _n_cols_bp + 1\n",
    "                _col_bp = bi % _n_cols_bp + 1\n",
    "                \n",
    "                _mc_mask = (metaclustering == mc_id)\n",
    "                \n",
    "                for cond_label, cond_color in [(\"Sain\", \"#2ca02c\"), (\"Pathologique\", \"#d62728\")]:\n",
    "                    _cond_mask = (conditions_arr == cond_label) & _mc_mask\n",
    "                    if _cond_mask.sum() < 5:\n",
    "                        continue\n",
    "                    \n",
    "                    _mfi_cond = np.nanmean(X[_cond_mask][:, [cols_to_use[i] for i in _key_markers_idx]], axis=0)\n",
    "                    \n",
    "                    fig_barplots.add_trace(go.Bar(\n",
    "                        x=_key_markers_names,\n",
    "                        y=_mfi_cond,\n",
    "                        name=cond_label,\n",
    "                        marker_color=cond_color,\n",
    "                        opacity=0.8,\n",
    "                        showlegend=(bi == 0),\n",
    "                        legendgroup=cond_label,\n",
    "                    ), row=_row_bp, col=_col_bp)\n",
    "            \n",
    "            fig_barplots.update_layout(\n",
    "                title=dict(\n",
    "                    text=\"<b>Marqueurs ClÃ©s par MÃ©tacluster â€” NBM vs Pathologique</b>\",\n",
    "                    font=dict(size=16),\n",
    "                ),\n",
    "                barmode='group',\n",
    "                height=350 * _n_rows_bp + 100,\n",
    "                width=min(350 * _n_cols_bp, 1400),\n",
    "                paper_bgcolor=\"#fafafa\",\n",
    "                font=dict(size=10),\n",
    "                legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.15, xanchor=\"center\", x=0.5),\n",
    "                margin=dict(t=80, b=80),\n",
    "            )\n",
    "            fig_barplots.show()\n",
    "            print(f\"   [OK] Barplots {_n_mc_show} mÃ©taclusters Ã— {_n_key} marqueurs clÃ©s\")\n",
    "        else:\n",
    "            print(\"   [!] Pas de colonne 'condition' â€” barplots ignorÃ©s\")\n",
    "    else:\n",
    "        print(f\"   [!] Seulement {len(_key_markers_idx)} marqueurs clÃ©s trouvÃ©s â€” barplots ignorÃ©s\")\n",
    "else:\n",
    "    print(\"\\n [2/3] Barplots NBM vs Patho â€” Mode comparaison non activÃ© (skipped)\")\n",
    "\n",
    "# =====================================================================\n",
    "# 4. TABLEAU SIGNATURE PHÃ‰NOTYPIQUE PAR MÃ‰TACLUSTER\n",
    "# =====================================================================\n",
    "print(\"\\n [3/3] Tableau signature phÃ©notypique par mÃ©tacluster\")\n",
    "\n",
    "def generate_phenotype_summary(mfi_row, marker_names, zscore_row):\n",
    "    \"\"\"GÃ©nÃ¨re un rÃ©sumÃ© phÃ©notypique lisible Ã  partir des MFI Z-scores.\"\"\"\n",
    "    phenotype_parts = []\n",
    "    # Trier par Z-score dÃ©croissant (marqueurs les plus exprimÃ©s en premier)\n",
    "    sorted_idx = np.argsort(zscore_row)[::-1]\n",
    "    \n",
    "    for idx in sorted_idx:\n",
    "        z = zscore_row[idx]\n",
    "        name = marker_names[idx]\n",
    "        if z > 1.0:\n",
    "            phenotype_parts.append(f\"{name}+++\")\n",
    "        elif z > 0.3:\n",
    "            phenotype_parts.append(f\"{name}++\")\n",
    "        elif z > -0.3:\n",
    "            phenotype_parts.append(f\"{name}+\")\n",
    "        elif z > -1.0:\n",
    "            phenotype_parts.append(f\"{name}<sup>low</sup>\")\n",
    "        else:\n",
    "            phenotype_parts.append(f\"{name}âˆ’\")\n",
    "    \n",
    "    # Garder les 6 marqueurs les plus informatifs (top 3 + bottom 3)\n",
    "    top = phenotype_parts[:3]\n",
    "    bottom = phenotype_parts[-3:] if len(phenotype_parts) > 6 else []\n",
    "    \n",
    "    result = \" \".join(top)\n",
    "    if bottom:\n",
    "        result += \" \" + \" \".join(bottom)\n",
    "    return result\n",
    "\n",
    "# Construire le tableau\n",
    "phenotype_rows = []\n",
    "for i in range(N_CLUSTERS):\n",
    "    mc_idx = row_order[i] if i < len(row_order) else i\n",
    "    size = mc_sizes[mc_idx]\n",
    "    pct = size / sum(mc_sizes) * 100\n",
    "    \n",
    "    # Signature phÃ©notypique\n",
    "    zscore_row = mfi_zscore[mc_idx]\n",
    "    phenotype = generate_phenotype_summary(mfi_matrix[mc_idx], used_markers, zscore_row)\n",
    "    \n",
    "    phenotype_rows.append({\n",
    "        \"MÃ©tacluster\": f\"MC{mc_idx:02d}\",\n",
    "        \"Taille (%)\": f\"{pct:.1f}\",\n",
    "        \"PhÃ©notype rÃ©sumÃ©\": phenotype,\n",
    "    })\n",
    "\n",
    "# Trier par taille dÃ©croissante\n",
    "phenotype_rows.sort(key=lambda x: float(x[\"Taille (%)\"]), reverse=True)\n",
    "\n",
    "_df_phenotype = pd.DataFrame(phenotype_rows)\n",
    "\n",
    "# Afficher en tant que tableau Plotly\n",
    "fig_phenotype = go.Figure(go.Table(\n",
    "    header=dict(\n",
    "        values=[f\"<b>{c}</b>\" for c in _df_phenotype.columns],\n",
    "        fill_color=\"#4a90d9\",\n",
    "        font=dict(color=\"white\", size=13),\n",
    "        align=[\"center\", \"center\", \"left\"],\n",
    "        height=35,\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[_df_phenotype[c] for c in _df_phenotype.columns],\n",
    "        fill_color=[\n",
    "            [\"#f9f9f9\" if i % 2 == 0 else \"#fff\" for i in range(len(_df_phenotype))]\n",
    "        ] * 3,\n",
    "        font=dict(size=12),\n",
    "        align=[\"center\", \"center\", \"left\"],\n",
    "        height=30,\n",
    "    ),\n",
    "))\n",
    "fig_phenotype.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Signature PhÃ©notypique par MÃ©tacluster</b><br>\"\n",
    "             \"<sup>BasÃ© sur l'expression MFI normalisÃ©e (+++ / ++ / + / low / âˆ’)</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    height=50 + 35 * (len(_df_phenotype) + 1),\n",
    "    width=1100,\n",
    "    margin=dict(l=20, r=20, t=70, b=10),\n",
    ")\n",
    "fig_phenotype.show()\n",
    "\n",
    "# Afficher aussi en texte pour copier-coller\n",
    "print(f\"\\n   {'MÃ©tacluster':<14} {'Taille (%)':>10}   PhÃ©notype rÃ©sumÃ©\")\n",
    "print(f\"   {'â”€'*14} {'â”€'*10}   {'â”€'*50}\")\n",
    "for row in phenotype_rows:\n",
    "    # Nettoyer les tags HTML pour l'affichage console\n",
    "    pheno_clean = row['PhÃ©notype rÃ©sumÃ©'].replace('<sup>', '').replace('</sup>', '')\n",
    "    print(f\"   {row['MÃ©tacluster']:<14} {row['Taille (%)']:>10}%  {pheno_clean}\")\n",
    "\n",
    "# =====================================================================\n",
    "# STOCKER GATING REPORTS DANS combined_data.uns (si disponible)\n",
    "# =====================================================================\n",
    "try:\n",
    "    if 'combined_data' in dir() and hasattr(combined_data, 'uns'):\n",
    "        combined_data.uns[\"gating_reports\"] = [gr.to_dict() for gr in gating_reports]\n",
    "        print(f\"\\n[OK] {len(gating_reports)} gating reports stockÃ©s dans combined_data.uns['gating_reports']\")\n",
    "except Exception as e:\n",
    "    print(f\"[!] Impossible de stocker gating_reports dans combined_data.uns: {e}\")\n",
    "\n",
    "# Export du gating log JSON\n",
    "try:\n",
    "    if gating_log_entries:\n",
    "        import json\n",
    "        _output_dir = globals().get('OUTPUT_OTHER', '.')\n",
    "        _log_path = os.path.join(_output_dir, \n",
    "                                  f\"gating_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "        with open(_log_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(gating_log_entries, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"[OK] Gating log JSON exportÃ©: {_log_path} ({len(gating_log_entries)} entrÃ©es)\")\n",
    "except Exception as e:\n",
    "    print(f\"[!] Erreur export gating log: {e}\")\n",
    "\n",
    "print(\"\\n[OK] Visualisations cliniques complÃ¨tes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc989dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANALYSE DES CLUSTERS EXCLUSIFS (mono-condition)\n",
    "# =============================================================================\n",
    "# Identification des clusters contenant UNIQUEMENT des cellules d'une condition\n",
    "# Utile pour dÃ©tecter les populations pathologiques spÃ©cifiques\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" ANALYSE DES CLUSTERS EXCLUSIFS PAR CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# RÃ©cupÃ©rer les conditions des cellules\n",
    "cell_conditions = adata_flowsom.obs['condition'].values\n",
    "unique_conditions = np.unique(cell_conditions)\n",
    "\n",
    "print(f\"\\nConditions prÃ©sentes: {list(unique_conditions)}\")\n",
    "print(f\"Nombre de metaclusters: {n_meta}\")\n",
    "\n",
    "# Analyse par metacluster\n",
    "clusters_patho_only = []\n",
    "clusters_sain_only = []\n",
    "clusters_mixed = []\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\" METACLUSTERS EXCLUSIFS (100% d'une seule condition)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cluster_id in range(1, n_meta + 1):\n",
    "    mask_cluster = (metaclustering_cells == cluster_id)\n",
    "    n_cluster = mask_cluster.sum()\n",
    "    \n",
    "    if n_cluster == 0:\n",
    "        continue\n",
    "    \n",
    "    # Compter les cellules par condition dans ce cluster\n",
    "    conditions_in_cluster = cell_conditions[mask_cluster]\n",
    "    \n",
    "    # Calculer les proportions\n",
    "    condition_counts = {}\n",
    "    for cond in unique_conditions:\n",
    "        count = (conditions_in_cluster == cond).sum()\n",
    "        condition_counts[cond] = count\n",
    "    \n",
    "    # VÃ©rifier si le cluster est exclusif Ã  une condition\n",
    "    total = sum(condition_counts.values())\n",
    "    \n",
    "    # Cluster 100% pathologique\n",
    "    if \"Pathologique\" in condition_counts and condition_counts.get(\"Pathologique\", 0) == total:\n",
    "        clusters_patho_only.append((cluster_id, total))\n",
    "        print(f\"   [PATHO] Metacluster {cluster_id:2d}: {total:6,} cellules (100% Pathologique)\")\n",
    "    \n",
    "    # Cluster 100% sain\n",
    "    elif \"Sain\" in condition_counts and condition_counts.get(\"Sain\", 0) == total:\n",
    "        clusters_sain_only.append((cluster_id, total))\n",
    "        print(f\"   [SAIN]  Metacluster {cluster_id:2d}: {total:6,} cellules (100% Sain)\")\n",
    "    \n",
    "    else:\n",
    "        clusters_mixed.append(cluster_id)\n",
    "\n",
    "# RÃ©sumÃ©\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" RÃ‰SUMÃ‰\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if clusters_patho_only:\n",
    "    total_patho_exclusive = sum([c[1] for c in clusters_patho_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% PATHOLOGIQUES: {len(clusters_patho_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_patho_only]}\")\n",
    "    print(f\"    Total cellules: {total_patho_exclusive:,}\")\n",
    "    print(f\"    â†’ Ces clusters reprÃ©sentent des populations UNIQUEMENT prÃ©sentes chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement pathologique dÃ©tectÃ©\")\n",
    "\n",
    "if clusters_sain_only:\n",
    "    total_sain_exclusive = sum([c[1] for c in clusters_sain_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% SAINS: {len(clusters_sain_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_sain_only]}\")\n",
    "    print(f\"    Total cellules: {total_sain_exclusive:,}\")\n",
    "    print(f\"    â†’ Ces clusters reprÃ©sentent des populations ABSENTES chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement sain dÃ©tectÃ©\")\n",
    "\n",
    "print(f\"\\n    Clusters mixtes (partagÃ©s): {len(clusters_mixed)}\")\n",
    "\n",
    "# Visualisation si clusters exclusifs pathologiques\n",
    "if clusters_patho_only and len(clusters_patho_only) > 0:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" DÃ‰TAIL DES CLUSTERS PATHOLOGIQUES EXCLUSIFS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Calculer le MFI des marqueurs pour ces clusters\n",
    "    for cluster_id, n_cells in clusters_patho_only:\n",
    "        mask_c = (metaclustering_cells == cluster_id)\n",
    "        print(f\"\\n   Metacluster {cluster_id} ({n_cells:,} cellules):\")\n",
    "        \n",
    "        # Top 3 marqueurs les plus exprimÃ©s\n",
    "        mfi_cluster = adata_flowsom.X[mask_c].mean(axis=0)\n",
    "        top_3_idx = np.argsort(mfi_cluster)[-3:][::-1]\n",
    "        print(f\"      Top marqueurs: \", end=\"\")\n",
    "        for idx in top_3_idx:\n",
    "            marker_name = adata_flowsom.var_names[idx]\n",
    "            print(f\"{marker_name}({mfi_cluster[idx]:.2f}) \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d7d4d",
   "metadata": {},
   "source": [
    "### RÃ©cap Expression par MÃ©tacluster â€” Sain vs Pathologique\n",
    "\n",
    "Trois visualisations complÃ©mentaires pour comparer l'expression marqueur par marqueur dans chaque mÃ©tacluster :\n",
    "\n",
    "1. **Split Heatmap** â€” MFI Z-score cÃ´te Ã  cÃ´te (Sain | Patho) pour chaque mÃ©tacluster\n",
    "2. **Heatmap DiffÃ©rentiel** â€” Î”(Patho âˆ’ Sain) pour identifier les marqueurs dÃ©rÃ©gulÃ©s Ã  la hausse / baisse\n",
    "3. **Dot Plot** â€” Taille = % de cellules positives, Couleur = MFI moyen (standard single-cell / cytomÃ©trie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1addadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RÃ‰CAP EXPRESSION PAR MÃ‰TACLUSTER â€” SAIN vs PATHOLOGIQUE\n",
    "# 3 visualisations : Split Heatmap / Heatmap DiffÃ©rentiel / Dot Plot\n",
    "# =============================================================================\n",
    "# PrÃ©-requis : adata_flowsom, metaclustering_cells, cell_conditions,\n",
    "#              used_markers, cols_to_use, X, n_meta\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" RÃ‰CAP EXPRESSION PAR MÃ‰TACLUSTER â€” SAIN vs PATHOLOGIQUE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# PrÃ©parer les donnÃ©es : MFI par (mÃ©tacluster, condition, marqueur)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Utiliser les marqueurs rÃ©ellement prÃ©sents dans adata_flowsom (pas used_markers\n",
    "# qui peut Ãªtre un sous-ensemble diffÃ©rent utilisÃ© pour le clustering)\n",
    "_markers = list(adata_flowsom.var_names)\n",
    "_n_markers = len(_markers)\n",
    "_conditions_labels = [\"Sain\", \"Pathologique\"]\n",
    "_cond_arr = cell_conditions  # dÃ©jÃ  dÃ©fini dans la cellule prÃ©cÃ©dente\n",
    "\n",
    "print(f\"   Marqueurs dans adata_flowsom: {_n_markers} â†’ {_markers}\")\n",
    "\n",
    "# MFI et % positif par (MC, condition)\n",
    "_mfi_sain  = np.full((n_meta, _n_markers), np.nan)\n",
    "_mfi_patho = np.full((n_meta, _n_markers), np.nan)\n",
    "_pct_sain  = np.full((n_meta, _n_markers), np.nan)   # % cellules > seuil\n",
    "_pct_patho = np.full((n_meta, _n_markers), np.nan)\n",
    "_n_sain    = np.zeros(n_meta, dtype=int)\n",
    "_n_patho   = np.zeros(n_meta, dtype=int)\n",
    "\n",
    "# MÃ©diane globale par marqueur (calculÃ©e une seule fois)\n",
    "_data_all = adata_flowsom.X\n",
    "_global_med = np.nanmedian(_data_all, axis=0)\n",
    "\n",
    "for mc in range(n_meta):\n",
    "    # metaclustering_cells est 1-indexÃ© (range(1, n_meta+1) dans la cellule exclusive)\n",
    "    _mask_mc = (metaclustering_cells == (mc + 1))\n",
    "    \n",
    "    _mask_s = _mask_mc & (_cond_arr == \"Sain\")\n",
    "    _mask_p = _mask_mc & (_cond_arr == \"Pathologique\")\n",
    "    \n",
    "    _n_sain[mc]  = _mask_s.sum()\n",
    "    _n_patho[mc] = _mask_p.sum()\n",
    "    \n",
    "    if _n_sain[mc] >= 3:\n",
    "        _vals_s = _data_all[_mask_s]\n",
    "        _mfi_sain[mc] = np.nanmean(_vals_s, axis=0)\n",
    "        _pct_sain[mc] = np.array([(_vals_s[:, j] > _global_med[j]).mean() * 100 for j in range(_n_markers)])\n",
    "    \n",
    "    if _n_patho[mc] >= 3:\n",
    "        _vals_p = _data_all[_mask_p]\n",
    "        _mfi_patho[mc] = np.nanmean(_vals_p, axis=0)\n",
    "        _pct_patho[mc] = np.array([(_vals_p[:, j] > _global_med[j]).mean() * 100 for j in range(_n_markers)])\n",
    "\n",
    "# =====================================================================\n",
    "# 1. SPLIT HEATMAP â€” MFI Z-score cÃ´te Ã  cÃ´te (Sain | Patho)\n",
    "# =====================================================================\n",
    "print(\"\\n [1/3] Split Heatmap â€” MFI Z-score par condition\")\n",
    "\n",
    "# Normaliser ensemble (Z-score global pour comparabilitÃ©)\n",
    "_all_mfi = np.vstack([_mfi_sain, _mfi_patho])\n",
    "_mean_glob = np.nanmean(_all_mfi, axis=0)\n",
    "_std_glob  = np.nanstd(_all_mfi, axis=0) + 1e-10\n",
    "_z_sain  = (_mfi_sain  - _mean_glob) / _std_glob\n",
    "_z_patho = (_mfi_patho - _mean_glob) / _std_glob\n",
    "\n",
    "# Remplacer NaN par 0 pour l'affichage\n",
    "_z_sain_disp  = np.nan_to_num(_z_sain, nan=0.0)\n",
    "_z_patho_disp = np.nan_to_num(_z_patho, nan=0.0)\n",
    "\n",
    "_mc_labels = [f\"MC{mc+1} (S:{_n_sain[mc]:,} P:{_n_patho[mc]:,})\" for mc in range(n_meta)]\n",
    "\n",
    "fig_split = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\"<b>Sain (NBM)</b>\", \"<b>Pathologique</b>\"],\n",
    "    horizontal_spacing=0.06,\n",
    "    shared_yaxes=True,\n",
    ")\n",
    "\n",
    "# Colorscale commune\n",
    "_zmax = max(np.nanmax(np.abs(_z_sain_disp)), np.nanmax(np.abs(_z_patho_disp)), 0.1)\n",
    "\n",
    "fig_split.add_trace(go.Heatmap(\n",
    "    z=_z_sain_disp,\n",
    "    x=_markers,\n",
    "    y=_mc_labels,\n",
    "    colorscale='RdBu_r', zmid=0, zmin=-_zmax, zmax=_zmax,\n",
    "    text=np.where(np.isnan(_z_sain), \"â€”\", np.round(_z_sain_disp, 1).astype(str)),\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=9),\n",
    "    colorbar=dict(title=\"Z-score\", len=0.8, x=1.02),\n",
    "    hovertemplate=\"MC: %{y}<br>Marqueur: %{x}<br>Z-score: %{z:.2f}<extra>Sain</extra>\",\n",
    "    showscale=False,\n",
    "), row=1, col=1)\n",
    "\n",
    "fig_split.add_trace(go.Heatmap(\n",
    "    z=_z_patho_disp,\n",
    "    x=_markers,\n",
    "    y=_mc_labels,\n",
    "    colorscale='RdBu_r', zmid=0, zmin=-_zmax, zmax=_zmax,\n",
    "    text=np.where(np.isnan(_z_patho), \"â€”\", np.round(_z_patho_disp, 1).astype(str)),\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=9),\n",
    "    colorbar=dict(title=\"Z-score MFI\", thickness=15, len=0.8),\n",
    "    hovertemplate=\"MC: %{y}<br>Marqueur: %{x}<br>Z-score: %{z:.2f}<extra>Patho</extra>\",\n",
    "), row=1, col=2)\n",
    "\n",
    "fig_split.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Split Heatmap â€” Expression MFI par MÃ©tacluster Ã— Condition</b><br>\"\n",
    "             \"<sup>Z-score normalisÃ© globalement Â· S = n cellules Sain, P = n cellules Patho</sup>\",\n",
    "        font=dict(size=14),\n",
    "    ),\n",
    "    height=max(450, 38 * n_meta + 150),\n",
    "    width=max(900, 45 * _n_markers * 2 + 300),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    yaxis=dict(autorange=\"reversed\", tickfont=dict(size=10)),\n",
    "    yaxis2=dict(autorange=\"reversed\"),\n",
    "    xaxis=dict(tickangle=-45, tickfont=dict(size=10)),\n",
    "    xaxis2=dict(tickangle=-45, tickfont=dict(size=10)),\n",
    "    margin=dict(t=90, b=100, l=200, r=80),\n",
    ")\n",
    "fig_split.show()\n",
    "print(f\"   [OK] Split Heatmap {n_meta} MC Ã— {_n_markers} marqueurs (Sain | Patho)\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2. HEATMAP DIFFÃ‰RENTIEL â€” Î”(Patho âˆ’ Sain)\n",
    "# =====================================================================\n",
    "print(\"\\n [2/3] Heatmap DiffÃ©rentiel Î”(Patho âˆ’ Sain)\")\n",
    "\n",
    "_delta = _z_patho_disp - _z_sain_disp\n",
    "# Masquer les MC oÃ¹ une condition est absente\n",
    "_mask_valid = (_n_sain >= 3) & (_n_patho >= 3)\n",
    "_delta_display = _delta.copy()\n",
    "_delta_display[~_mask_valid] = np.nan\n",
    "\n",
    "_delta_text = np.full_like(_delta, \"\", dtype=object)\n",
    "for i in range(n_meta):\n",
    "    for j in range(_n_markers):\n",
    "        if _mask_valid[i]:\n",
    "            val = _delta[i, j]\n",
    "            arrow = \"â–²\" if val > 0.3 else (\"â–¼\" if val < -0.3 else \"â‰ˆ\")\n",
    "            _delta_text[i, j] = f\"{val:+.1f} {arrow}\"\n",
    "        else:\n",
    "            _delta_text[i, j] = \"n/a\"\n",
    "\n",
    "_dmax = max(np.nanmax(np.abs(_delta_display[_mask_valid])), 0.1) if _mask_valid.any() else 1.0\n",
    "\n",
    "fig_diff = go.Figure(data=go.Heatmap(\n",
    "    z=np.nan_to_num(_delta_display, nan=0),\n",
    "    x=_markers,\n",
    "    y=_mc_labels,\n",
    "    colorscale=[\n",
    "        [0.0, '#2166ac'],     # forte baisse (bleu)\n",
    "        [0.25, '#67a9cf'],\n",
    "        [0.5, '#f7f7f7'],     # pas de changement\n",
    "        [0.75, '#ef8a62'],\n",
    "        [1.0, '#b2182b'],     # forte hausse (rouge)\n",
    "    ],\n",
    "    zmid=0, zmin=-_dmax, zmax=_dmax,\n",
    "    text=_delta_text,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=9),\n",
    "    colorbar=dict(title=\"Î” Z-score<br>(Pathoâˆ’Sain)\", thickness=15, len=0.8),\n",
    "    hovertemplate=\"MC: %{y}<br>Marqueur: %{x}<br>Î”(Pathoâˆ’Sain): %{z:+.2f}<extra></extra>\",\n",
    "))\n",
    "\n",
    "fig_diff.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Heatmap DiffÃ©rentiel â€” Î” Expression (Pathologique âˆ’ Sain)</b><br>\"\n",
    "             \"<sup>â–² surexpression pathologique Â· â–¼ sous-expression pathologique Â· â‰ˆ stable</sup>\",\n",
    "        font=dict(size=14),\n",
    "    ),\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=11)),\n",
    "    yaxis=dict(title=\"MÃ©tacluster\", tickfont=dict(size=10), autorange=\"reversed\"),\n",
    "    height=max(450, 40 * n_meta + 150),\n",
    "    width=max(800, 50 * _n_markers + 250),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=90, b=100, l=200, r=80),\n",
    ")\n",
    "fig_diff.show()\n",
    "print(f\"   [OK] Heatmap DiffÃ©rentiel ({_mask_valid.sum()}/{n_meta} MC avec les deux conditions)\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3. DOT PLOT â€” Taille = % positif, Couleur = MFI moyen\n",
    "# =====================================================================\n",
    "print(\"\\n [3/3] Dot Plot â€” Taille = % positif, Couleur = MFI moyen\")\n",
    "\n",
    "# Construire le dataframe pour le dot plot\n",
    "_rows = []\n",
    "for mc in range(n_meta):\n",
    "    for j, marker in enumerate(_markers):\n",
    "        for cond_label, pct_arr, mfi_arr, n_arr in [\n",
    "            (\"Sain\",          _pct_sain,  _mfi_sain,  _n_sain),\n",
    "            (\"Pathologique\",  _pct_patho, _mfi_patho, _n_patho),\n",
    "        ]:\n",
    "            if n_arr[mc] >= 3:\n",
    "                _rows.append({\n",
    "                    \"MC\": f\"MC{mc+1}\",\n",
    "                    \"Marqueur\": marker,\n",
    "                    \"Condition\": cond_label,\n",
    "                    \"% Positif\": pct_arr[mc, j] if not np.isnan(pct_arr[mc, j]) else 0,\n",
    "                    \"MFI moyen\": mfi_arr[mc, j] if not np.isnan(mfi_arr[mc, j]) else 0,\n",
    "                    \"n_cells\": n_arr[mc],\n",
    "                })\n",
    "\n",
    "_df_dot = pd.DataFrame(_rows)\n",
    "\n",
    "if len(_df_dot) > 0:\n",
    "    # CrÃ©er un dot plot avec Plotly â€” deux sous-plots cÃ´te Ã  cÃ´te\n",
    "    fig_dot = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=[\"<b>Sain (NBM)</b>\", \"<b>Pathologique</b>\"],\n",
    "        horizontal_spacing=0.08,\n",
    "        shared_yaxes=True,\n",
    "    )\n",
    "    \n",
    "    _mc_order = [f\"MC{mc+1}\" for mc in range(n_meta)]\n",
    "    \n",
    "    # Normaliser MFI pour la couleur (0-1)\n",
    "    _mfi_all_vals = _df_dot[\"MFI moyen\"].values\n",
    "    _mfi_min = np.nanmin(_mfi_all_vals)\n",
    "    _mfi_max = np.nanmax(_mfi_all_vals)\n",
    "    _mfi_range = _mfi_max - _mfi_min if _mfi_max > _mfi_min else 1.0\n",
    "    \n",
    "    for col_i, cond in enumerate([\"Sain\", \"Pathologique\"], 1):\n",
    "        _sub = _df_dot[_df_dot[\"Condition\"] == cond]\n",
    "        if len(_sub) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Taille proportionnelle au % positif (rescale entre 4 et 22 px)\n",
    "        _sizes = _sub[\"% Positif\"].values\n",
    "        _sizes_scaled = 4 + (_sizes / 100) * 18\n",
    "        \n",
    "        # Couleur = MFI normalisÃ©\n",
    "        _color_vals = (_sub[\"MFI moyen\"].values - _mfi_min) / _mfi_range\n",
    "        \n",
    "        fig_dot.add_trace(go.Scatter(\n",
    "            x=_sub[\"Marqueur\"].values,\n",
    "            y=_sub[\"MC\"].values,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=_sizes_scaled,\n",
    "                color=_sub[\"MFI moyen\"].values,\n",
    "                colorscale='YlOrRd',\n",
    "                cmin=_mfi_min, cmax=_mfi_max,\n",
    "                showscale=(col_i == 2),\n",
    "                colorbar=dict(title=\"MFI moyen\", thickness=12, len=0.8) if col_i == 2 else None,\n",
    "                line=dict(width=0.5, color='#555'),\n",
    "            ),\n",
    "            text=[f\"MC{r['MC']}<br>{r['Marqueur']}<br>% positif: {r['% Positif']:.1f}%<br>\"\n",
    "                  f\"MFI: {r['MFI moyen']:.2f}<br>n={r['n_cells']:,}\" \n",
    "                  for _, r in _sub.iterrows()],\n",
    "            hoverinfo='text',\n",
    "            showlegend=False,\n",
    "        ), row=1, col=col_i)\n",
    "    \n",
    "    # Ordre inversÃ© pour que MC1 soit en haut\n",
    "    fig_dot.update_layout(\n",
    "        title=dict(\n",
    "            text=\"<b>Dot Plot â€” Expression par MÃ©tacluster Ã— Condition</b><br>\"\n",
    "                 \"<sup>Taille = % de cellules positives (> mÃ©diane) Â· Couleur = MFI moyen</sup>\",\n",
    "            font=dict(size=14),\n",
    "        ),\n",
    "        height=max(500, 30 * n_meta + 180),\n",
    "        width=max(950, 40 * _n_markers * 2 + 350),\n",
    "        paper_bgcolor=\"#fafafa\",\n",
    "        plot_bgcolor=\"#f9f9f9\",\n",
    "        yaxis=dict(\n",
    "            categoryorder='array',\n",
    "            categoryarray=_mc_order[::-1],\n",
    "            tickfont=dict(size=10),\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            categoryorder='array',\n",
    "            categoryarray=_mc_order[::-1],\n",
    "        ),\n",
    "        xaxis=dict(tickangle=-45, tickfont=dict(size=10)),\n",
    "        xaxis2=dict(tickangle=-45, tickfont=dict(size=10)),\n",
    "        margin=dict(t=90, b=100, l=120, r=100),\n",
    "    )\n",
    "    \n",
    "    # Ajouter une lÃ©gende custom pour la taille des dots\n",
    "    for _pct_legend, _sz_legend in [(25, 8.5), (50, 13), (75, 17.5), (100, 22)]:\n",
    "        fig_dot.add_trace(go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='markers',\n",
    "            marker=dict(size=_sz_legend, color='gray', line=dict(width=0.5, color='#555')),\n",
    "            name=f\"{_pct_legend}%\",\n",
    "            legendgroup=\"size_legend\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "    \n",
    "    fig_dot.update_layout(\n",
    "        legend=dict(\n",
    "            title=\"<b>% Positif</b>\",\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\", y=0.95,\n",
    "            xanchor=\"left\", x=1.08,\n",
    "            font=dict(size=10),\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig_dot.show()\n",
    "    print(f\"   [OK] Dot Plot {n_meta} MC Ã— {_n_markers} marqueurs Ã— 2 conditions\")\n",
    "else:\n",
    "    print(\"   [!] Pas assez de donnÃ©es pour le dot plot\")\n",
    "\n",
    "# =====================================================================\n",
    "# RÃ‰SUMÃ‰ TEXTUEL â€” top marqueurs dÃ©rÃ©gulÃ©s\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TOP MARQUEURS DÃ‰RÃ‰GULÃ‰S PAR MÃ‰TACLUSTER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for mc in range(n_meta):\n",
    "    if not _mask_valid[mc]:\n",
    "        continue\n",
    "    _d = _delta[mc]\n",
    "    _top_up = np.argsort(_d)[-3:][::-1]  # top 3 surexprimÃ©s\n",
    "    _top_dn = np.argsort(_d)[:3]          # top 3 sous-exprimÃ©s\n",
    "    \n",
    "    up_str = \", \".join([f\"{_markers[i]}(â–²{_d[i]:+.1f})\" for i in _top_up if _d[i] > 0.2])\n",
    "    dn_str = \", \".join([f\"{_markers[i]}(â–¼{_d[i]:+.1f})\" for i in _top_dn if _d[i] < -0.2])\n",
    "    \n",
    "    if up_str or dn_str:\n",
    "        print(f\"   MC{mc+1:2d} (S:{_n_sain[mc]:5,} P:{_n_patho[mc]:5,})\")\n",
    "        if up_str:\n",
    "            print(f\"         â–² SurexprimÃ©s Patho : {up_str}\")\n",
    "        if dn_str:\n",
    "            print(f\"         â–¼ Sous-exprimÃ©s Patho: {dn_str}\")\n",
    "\n",
    "print(\"\\n[OK] RÃ©cap expression cluster Ã— condition terminÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564873ae",
   "metadata": {},
   "source": [
    "### Heatmap des 100 Nodes SOM â€” MFI globale + Comparaison Sain vs Pathologique\n",
    "\n",
    "Visualisation de l'expression de **chaque node** de la grille SOM (100 nodes = 10Ã—10) :\n",
    "\n",
    "1. **Heatmap globale** â€” MFI Z-score de tous les 100 nodes Ã— marqueurs, triÃ©s par mÃ©tacluster\n",
    "2. **Split Heatmap Sain | Patho** â€” MFI par node et par condition, cÃ´te Ã  cÃ´te\n",
    "3. **Heatmap DiffÃ©rentiel** â€” Î”(Patho âˆ’ Sain) pour chacun des 100 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f166250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP DES 100 NODES SOM â€” MFI GLOBALE + SAIN vs PATHOLOGIQUE\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" HEATMAP DES 100 NODES SOM â€” MFI + COMPARAISON SAIN vs PATHO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Calcul MFI par node (global, sain, patho)\n",
    "# On utilise adata_flowsom.X = X_transformed (donnÃ©es POST-transformation\n",
    "# logicle/arcsinh/log selon TRANSFORM_TYPE choisi)\n",
    "# --------------------------------------------------------------------------\n",
    "_all_markers = list(adata_flowsom.var_names)\n",
    "_exclude_heatmap = {'Time', 'FSC-Width'}  # Exclure Time et FSC-Width car ils biaisent le Z-score\n",
    "# Exclure aussi tous les marqueurs SSC et FSC (scatter) pour ne garder que les marqueurs fluorescents\n",
    "_exclude_heatmap.update(m for m in _all_markers if m.upper().startswith(('FSC', 'SSC')))\n",
    "_keep_idx = [i for i, m in enumerate(_all_markers) if m not in _exclude_heatmap]\n",
    "_node_markers = [_all_markers[i] for i in _keep_idx]\n",
    "_n_mk = len(_node_markers)\n",
    "_data = adata_flowsom.X[:, _keep_idx]  # donnÃ©es TRANSFORMÃ‰ES sans Time\n",
    "_cond = cell_conditions\n",
    "_transform_label = globals().get('TRANSFORM_TYPE', 'arcsinh')\n",
    "\n",
    "if len(_exclude_heatmap & set(_all_markers)):\n",
    "    print(f\"   âš  Marqueurs exclus des heatmaps: {_exclude_heatmap & set(_all_markers)}\")\n",
    "\n",
    "print(f\"   Transformation appliquÃ©e: {_transform_label}\")\n",
    "print(f\"   Source: adata_flowsom.X (donnÃ©es post-{_transform_label})\")\n",
    "\n",
    "_mfi_node_all   = np.full((n_nodes, _n_mk), np.nan)\n",
    "_mfi_node_sain  = np.full((n_nodes, _n_mk), np.nan)\n",
    "_mfi_node_patho = np.full((n_nodes, _n_mk), np.nan)\n",
    "_n_node_total   = np.zeros(n_nodes, dtype=int)\n",
    "_n_node_sain    = np.zeros(n_nodes, dtype=int)\n",
    "_n_node_patho   = np.zeros(n_nodes, dtype=int)\n",
    "_mc_of_node     = metaclustering_nodes.astype(int)  # mÃ©tacluster de chaque node\n",
    "\n",
    "# DÃ©tection automatique des labels de condition\n",
    "_unique_conds = np.unique(np.asarray(_cond))\n",
    "print(f\"   Conditions dÃ©tectÃ©es: {list(_unique_conds)}\")\n",
    "_sain_label = next((c for c in _unique_conds if str(c).lower() in ('sain', 'healthy', 'normal', 'nbm')), None)\n",
    "_patho_label = next((c for c in _unique_conds if str(c).lower() in ('pathologique', 'patho', 'pathological', 'disease')), None)\n",
    "# Fallback: si 2 conditions, prendre celle qui n'est pas \"Sain\"\n",
    "if _sain_label is None and _patho_label is None and len(_unique_conds) == 2:\n",
    "    _sain_label, _patho_label = _unique_conds[0], _unique_conds[1]\n",
    "elif _sain_label is not None and _patho_label is None and len(_unique_conds) == 2:\n",
    "    _patho_label = [c for c in _unique_conds if c != _sain_label][0]\n",
    "elif _patho_label is not None and _sain_label is None and len(_unique_conds) == 2:\n",
    "    _sain_label = [c for c in _unique_conds if c != _patho_label][0]\n",
    "print(f\"   Label Sain: '{_sain_label}' | Label Patho: '{_patho_label}'\")\n",
    "\n",
    "for nd in range(n_nodes):\n",
    "    _mask_nd = (clustering == nd)\n",
    "    _n_node_total[nd] = _mask_nd.sum()\n",
    "    \n",
    "    if _n_node_total[nd] < 1:\n",
    "        continue\n",
    "    \n",
    "    _mfi_node_all[nd] = np.nanmean(_data[_mask_nd], axis=0)\n",
    "    \n",
    "    _mask_s = _mask_nd & (_cond == _sain_label) if _sain_label else np.zeros_like(_mask_nd)\n",
    "    _mask_p = _mask_nd & (_cond == _patho_label) if _patho_label else np.zeros_like(_mask_nd)\n",
    "    _n_node_sain[nd]  = _mask_s.sum()\n",
    "    _n_node_patho[nd] = _mask_p.sum()\n",
    "    \n",
    "    if _n_node_sain[nd] >= 2:\n",
    "        _mfi_node_sain[nd] = np.nanmean(_data[_mask_s], axis=0)\n",
    "    if _n_node_patho[nd] >= 2:\n",
    "        _mfi_node_patho[nd] = np.nanmean(_data[_mask_p], axis=0)\n",
    "\n",
    "# Nodes actifs (au moins 1 cellule)\n",
    "_active = _n_node_total >= 1\n",
    "_n_active = _active.sum()\n",
    "print(f\"   Nodes actifs: {_n_active}/{n_nodes}\")\n",
    "print(f\"   Nodes avec Sain â‰¥2: {(_n_node_sain >= 2).sum()} | Patho â‰¥2: {(_n_node_patho >= 2).sum()}\")\n",
    "print(f\"   Marqueurs: {_n_mk} â†’ {_node_markers}\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Trier les nodes par mÃ©tacluster puis par taille (pour regroupement visuel)\n",
    "# --------------------------------------------------------------------------\n",
    "_sort_order = np.lexsort((-_n_node_total, _mc_of_node))\n",
    "# Ne garder que les actifs\n",
    "_sort_active = [nd for nd in _sort_order if _active[nd]]\n",
    "\n",
    "_node_labels = []\n",
    "for nd in _sort_active:\n",
    "    mc_lbl = int(_mc_of_node[nd]) + 1  # 1-indexÃ© pour affichage\n",
    "    gx = int(grid_coords[nd, 0] - grid_coords[:, 0].min() + 1) if grid_coords is not None else \"?\"\n",
    "    gy = int(grid_coords[nd, 1] - grid_coords[:, 1].min() + 1) if grid_coords is not None else \"?\"\n",
    "    _node_labels.append(f\"N{nd} [MC{mc_lbl}] ({gx},{gy}) n={_n_node_total[nd]:,}\")\n",
    "\n",
    "# =====================================================================\n",
    "# 1. HEATMAP GLOBALE â€” 100 NODES Ã— MARQUEURS (MFI Z-score)\n",
    "# =====================================================================\n",
    "print(\"\\n [1/3] Heatmap globale â€” 100 nodes Ã— marqueurs\")\n",
    "\n",
    "_mfi_active = _mfi_node_all[_sort_active]\n",
    "_mean_g = np.nanmean(_mfi_active, axis=0)\n",
    "_std_g  = np.nanstd(_mfi_active, axis=0) + 1e-10\n",
    "_z_all  = (_mfi_active - _mean_g) / _std_g\n",
    "_z_all_disp = np.nan_to_num(_z_all, nan=0.0)\n",
    "\n",
    "# Clustering hiÃ©rarchique des marqueurs (colonnes)\n",
    "if _n_mk > 2:\n",
    "    _col_link = linkage(pdist(_z_all_disp.T, metric='euclidean'), method='ward')\n",
    "    _col_ord  = leaves_list(_col_link)\n",
    "else:\n",
    "    _col_ord = np.arange(_n_mk)\n",
    "\n",
    "_markers_sorted = [_node_markers[i] for i in _col_ord]\n",
    "_z_all_sorted = _z_all_disp[:, _col_ord]\n",
    "\n",
    "# Bande colorÃ©e des mÃ©taclusters (pour annotation latÃ©rale)\n",
    "_mc_colors_for_nodes = [int(_mc_of_node[nd]) for nd in _sort_active]\n",
    "_n_unique_mc = len(set(_mc_colors_for_nodes))\n",
    "\n",
    "# Palette de couleurs pour les mÃ©taclusters\n",
    "import plotly.colors as _pc\n",
    "if _n_unique_mc <= 20:\n",
    "    _mc_palette = _pc.qualitative.Alphabet[:_n_unique_mc]\n",
    "else:\n",
    "    _mc_palette = [f\"hsl({int(i*360/_n_unique_mc)},65%,50%)\" for i in range(_n_unique_mc)]\n",
    "\n",
    "_zmax_all = max(np.abs(_z_all_sorted).max(), 0.1)\n",
    "\n",
    "# --- PrÃ©-calcul des tris par marqueur (pour boutons interactifs) ---\n",
    "_sort_buttons_global = []\n",
    "# Bouton par dÃ©faut: tri mÃ©tacluster (ordre actuel)\n",
    "_sort_buttons_global.append(dict(\n",
    "    label=\"â¬¡ MÃ©tacluster\",\n",
    "    method=\"restyle\",\n",
    "    args=[{\"z\": [_z_all_sorted.tolist()], \"y\": [_node_labels]}],\n",
    "))\n",
    "# Un bouton par marqueur: tri dÃ©croissant par intensitÃ© Z-score\n",
    "for _mk_j, _mk_name in enumerate(_markers_sorted):\n",
    "    _order_j = np.argsort(-_z_all_sorted[:, _mk_j])  # dÃ©croissant\n",
    "    _sort_buttons_global.append(dict(\n",
    "        label=f\"â†“ {_mk_name}\",\n",
    "        method=\"restyle\",\n",
    "        args=[{\n",
    "            \"z\": [_z_all_sorted[_order_j].tolist()],\n",
    "            \"y\": [[_node_labels[k] for k in _order_j]],\n",
    "        }],\n",
    "    ))\n",
    "\n",
    "fig_nodes_global = go.Figure()\n",
    "\n",
    "# Heatmap principale\n",
    "fig_nodes_global.add_trace(go.Heatmap(\n",
    "    z=_z_all_sorted,\n",
    "    x=_markers_sorted,\n",
    "    y=_node_labels,\n",
    "    colorscale='RdBu_r',\n",
    "    zmid=0, zmin=-_zmax_all, zmax=_zmax_all,\n",
    "))\n",
    "\n",
    "fig_nodes_global.update_layout(\n",
    "    title=dict(\n",
    "        text=f\"<b>Heatmap MFI â€” {_n_active} Nodes SOM Ã— {_n_mk} Marqueurs</b><br>\"\n",
    "             \"<sup>Z-score normalisÃ© Â· Tri interactif par marqueur via le menu dÃ©roulant</sup>\",\n",
    "        font=dict(size=14),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type=\"dropdown\",\n",
    "        direction=\"down\",\n",
    "        x=1.02, xanchor=\"left\", y=1.0, yanchor=\"top\",\n",
    "        showactive=True,\n",
    "        active=0,\n",
    "        buttons=_sort_buttons_global,\n",
    "        font=dict(size=10),\n",
    "        bgcolor=\"#f0f0f0\",\n",
    "    )],\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=10), side=\"bottom\"),\n",
    "    yaxis=dict(\n",
    "        title=\"Nodes SOM  [MÃ©tacluster] (x,y) n=cellules\",\n",
    "        tickfont=dict(size=8),\n",
    "        autorange=\"reversed\",\n",
    "    ),\n",
    "    height=max(600, 18 * _n_active + 200),\n",
    "    width=max(800, 55 * _n_mk + 350),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=90, b=100, l=280, r=80),\n",
    ")\n",
    "fig_nodes_global.show()\n",
    "print(f\"   [OK] Heatmap globale {_n_active} nodes Ã— {_n_mk} marqueurs\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2. SPLIT HEATMAP SAIN | PATHO â€” 100 NODES\n",
    "# =====================================================================\n",
    "print(\"\\n [2/3] Split Heatmap â€” 100 nodes, Sain | Patho\")\n",
    "\n",
    "_mfi_s_active = _mfi_node_sain[_sort_active]\n",
    "_mfi_p_active = _mfi_node_patho[_sort_active]\n",
    "\n",
    "# Z-score global (sur les deux conditions ensemble)\n",
    "_all_sp = np.vstack([\n",
    "    np.nan_to_num(_mfi_s_active, nan=np.nanmean(_mfi_s_active)),\n",
    "    np.nan_to_num(_mfi_p_active, nan=np.nanmean(_mfi_p_active)),\n",
    "])\n",
    "_mean_sp = np.nanmean(_all_sp, axis=0)\n",
    "_std_sp  = np.nanstd(_all_sp, axis=0) + 1e-10\n",
    "\n",
    "_z_s = (_mfi_s_active - _mean_sp) / _std_sp\n",
    "_z_p = (_mfi_p_active - _mean_sp) / _std_sp\n",
    "_z_s_disp = np.nan_to_num(_z_s, nan=0.0)\n",
    "_z_p_disp = np.nan_to_num(_z_p, nan=0.0)\n",
    "\n",
    "# RÃ©ordonner les colonnes comme la heatmap globale\n",
    "_z_s_sorted = _z_s_disp[:, _col_ord]\n",
    "_z_p_sorted = _z_p_disp[:, _col_ord]\n",
    "\n",
    "_zmax_sp = max(np.abs(_z_s_sorted).max(), np.abs(_z_p_sorted).max(), 0.1)\n",
    "\n",
    "# Labels plus courts pour lisibilitÃ©\n",
    "_node_labels_short = []\n",
    "for nd in _sort_active:\n",
    "    mc_lbl = int(_mc_of_node[nd]) + 1\n",
    "    _node_labels_short.append(\n",
    "        f\"N{nd} [MC{mc_lbl}] S:{_n_node_sain[nd]:,} P:{_n_node_patho[nd]:,}\"\n",
    "    )\n",
    "\n",
    "fig_nodes_split = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\"<b>Sain (NBM)</b>\", \"<b>Pathologique</b>\"],\n",
    "    horizontal_spacing=0.04,\n",
    "    shared_yaxes=True,\n",
    ")\n",
    "\n",
    "# --- PrÃ©-calcul des tris par marqueur pour split heatmap ---\n",
    "_sort_buttons_split = []\n",
    "_sort_buttons_split.append(dict(\n",
    "    label=\"â¬¡ MÃ©tacluster\",\n",
    "    method=\"restyle\",\n",
    "    args=[{\n",
    "        \"z\": [_z_s_sorted.tolist(), _z_p_sorted.tolist()],\n",
    "        \"y\": [_node_labels_short, _node_labels_short],\n",
    "    }],\n",
    "))\n",
    "for _mk_j, _mk_name in enumerate(_markers_sorted):\n",
    "    # Tri basÃ© sur la moyenne des deux conditions\n",
    "    _avg_sp = (_z_s_sorted[:, _mk_j] + _z_p_sorted[:, _mk_j]) / 2\n",
    "    _order_j = np.argsort(-_avg_sp)\n",
    "    _sort_buttons_split.append(dict(\n",
    "        label=f\"â†“ {_mk_name}\",\n",
    "        method=\"restyle\",\n",
    "        args=[{\n",
    "            \"z\": [_z_s_sorted[_order_j].tolist(), _z_p_sorted[_order_j].tolist()],\n",
    "            \"y\": [[_node_labels_short[k] for k in _order_j], [_node_labels_short[k] for k in _order_j]],\n",
    "        }],\n",
    "    ))\n",
    "\n",
    "# Masquer les nodes sans cellules dans cette condition (texte \"â€”\")\n",
    "_text_s = np.where(\n",
    "    np.isnan(_z_s[:, _col_ord]),\n",
    "    \"â€”\",\n",
    "    np.char.add(np.where(_z_s_sorted > 0, \"+\", \"\"), \n",
    "                np.round(_z_s_sorted, 1).astype(str))\n",
    ")\n",
    "_text_p = np.where(\n",
    "    np.isnan(_z_p[:, _col_ord]),\n",
    "    \"â€”\",\n",
    "    np.char.add(np.where(_z_p_sorted > 0, \"+\", \"\"),\n",
    "                np.round(_z_p_sorted, 1).astype(str))\n",
    ")\n",
    "\n",
    "fig_nodes_split.add_trace(go.Heatmap(\n",
    "    z=_z_s_sorted,\n",
    "    x=_markers_sorted,\n",
    "    y=_node_labels_short,\n",
    "    colorscale='RdBu_r', zmid=0, zmin=-_zmax_sp, zmax=_zmax_sp,\n",
    "    hovertemplate=\"Node: %{y}<br>Marqueur: %{x}<br>Z-score: %{z:.2f}<extra>Sain</extra>\",\n",
    "    showscale=False,\n",
    "), row=1, col=1)\n",
    "\n",
    "fig_nodes_split.add_trace(go.Heatmap(\n",
    "    z=_z_p_sorted,\n",
    "    x=_markers_sorted,\n",
    "    y=_node_labels_short,\n",
    "    colorscale='RdBu_r', zmid=0, zmin=-_zmax_sp, zmax=_zmax_sp,\n",
    "    hovertemplate=\"Node: %{y}<br>Marqueur: %{x}<br>Z-score: %{z:.2f}<extra>Patho</extra>\",\n",
    "), row=1, col=2)\n",
    "\n",
    "fig_nodes_split.update_layout(\n",
    "    title=dict(\n",
    "        text=f\"<b>Split Heatmap â€” {_n_active} Nodes SOM Ã— {_n_mk} Marqueurs â€” Sain vs Pathologique</b><br>\"\n",
    "             \"<sup>Z-score normalisÃ© Â· Tri interactif par marqueur via le menu dÃ©roulant</sup>\",\n",
    "        font=dict(size=13),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type=\"dropdown\",\n",
    "        direction=\"down\",\n",
    "        x=1.02, xanchor=\"left\", y=1.0, yanchor=\"top\",\n",
    "        showactive=True,\n",
    "        active=0,\n",
    "        buttons=_sort_buttons_split,\n",
    "        font=dict(size=10),\n",
    "        bgcolor=\"#f0f0f0\",\n",
    "    )],\n",
    "    height=max(700, 18 * _n_active + 200),\n",
    "    width=max(1000, 50 * _n_mk * 2 + 400),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    yaxis=dict(autorange=\"reversed\", tickfont=dict(size=7)),\n",
    "    yaxis2=dict(autorange=\"reversed\"),\n",
    "    xaxis=dict(tickangle=-45, tickfont=dict(size=10)),\n",
    "    xaxis2=dict(tickangle=-45, tickfont=dict(size=10)),\n",
    "    margin=dict(t=90, b=100, l=280, r=80),\n",
    ")\n",
    "fig_nodes_split.show()\n",
    "print(f\"   [OK] Split Heatmap nodes {_n_active} Ã— {_n_mk} (Sain | Patho)\")\n",
    "\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "# 3. HEATMAP DIFFÃ‰RENTIEL â€” Î”(Patho âˆ’ Sain) par node\n",
    "# =====================================================================\n",
    "print(\"\\n [3/3] Heatmap DiffÃ©rentiel Î”(Patho âˆ’ Sain) â€” 100 nodes\")\n",
    "\n",
    "_delta_nodes = _z_p_sorted - _z_s_sorted\n",
    "\n",
    "# Masquer les nodes oÃ¹ une condition est absente (< 2 cellules)\n",
    "_n_s_active = _n_node_sain[_sort_active]\n",
    "_n_p_active = _n_node_patho[_sort_active]\n",
    "_valid_both = (_n_s_active >= 2) & (_n_p_active >= 2)\n",
    "\n",
    "_delta_masked = _delta_nodes.copy()\n",
    "_delta_masked[~_valid_both] = 0  # pas de diffÃ©rentiel si une condition manque\n",
    "\n",
    "# Texte annotÃ© avec flÃ¨ches\n",
    "_delta_txt = np.full_like(_delta_nodes, \"\", dtype=object)\n",
    "for i in range(len(_sort_active)):\n",
    "    for j in range(_n_mk):\n",
    "        if _valid_both[i]:\n",
    "            v = _delta_nodes[i, j]\n",
    "            arr = \"â–²\" if v > 0.3 else (\"â–¼\" if v < -0.3 else \"â‰ˆ\")\n",
    "            _delta_txt[i, j] = f\"{v:+.1f}{arr}\"\n",
    "        else:\n",
    "            _delta_txt[i, j] = \"â€”\"\n",
    "\n",
    "_dmax_n = max(np.abs(_delta_masked[_valid_both]).max(), 0.1) if _valid_both.any() else 1.0\n",
    "\n",
    "# --- PrÃ©-calcul des tris par marqueur pour heatmap diffÃ©rentiel ---\n",
    "_sort_buttons_diff = []\n",
    "_sort_buttons_diff.append(dict(\n",
    "    label=\"â¬¡ MÃ©tacluster\",\n",
    "    method=\"restyle\",\n",
    "    args=[{\n",
    "        \"z\": [_delta_masked.tolist()],\n",
    "        \"y\": [_node_labels_short],\n",
    "        \"text\": [_delta_txt.tolist()],\n",
    "    }],\n",
    "))\n",
    "for _mk_j, _mk_name in enumerate(_markers_sorted):\n",
    "    _order_j = np.argsort(-_delta_masked[:, _mk_j])  # dÃ©croissant par Î”\n",
    "    _sort_buttons_diff.append(dict(\n",
    "        label=f\"â†“ {_mk_name}\",\n",
    "        method=\"restyle\",\n",
    "        args=[{\n",
    "            \"z\": [_delta_masked[_order_j].tolist()],\n",
    "            \"y\": [[_node_labels_short[k] for k in _order_j]],\n",
    "            \"text\": [_delta_txt[_order_j].tolist()],\n",
    "        }],\n",
    "    ))\n",
    "\n",
    "fig_nodes_diff = go.Figure(data=go.Heatmap(\n",
    "    z=_delta_masked,\n",
    "    x=_markers_sorted,\n",
    "    y=_node_labels_short,\n",
    "    colorscale=[\n",
    "        [0.0, '#2166ac'],\n",
    "        [0.25, '#67a9cf'],\n",
    "        [0.5, '#f7f7f7'],\n",
    "        [0.75, '#ef8a62'],\n",
    "        [1.0, '#b2182b'],\n",
    "    ],\n",
    "    zmid=0, zmin=-_dmax_n, zmax=_dmax_n,\n",
    "    text=_delta_txt,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=7),\n",
    "    colorbar=dict(title=\"Î” Z-score<br>(Pathoâˆ’Sain)\", thickness=12, len=0.9),\n",
    "    hovertemplate=\"Node: %{y}<br>Marqueur: %{x}<br>Î”(Pathoâˆ’Sain): %{z:+.2f}<extra></extra>\",\n",
    "))\n",
    "\n",
    "fig_nodes_diff.update_layout(\n",
    "    title=dict(\n",
    "        text=f\"<b>Heatmap DiffÃ©rentiel ({_transform_label}) â€” Î” Expression (Patho âˆ’ Sain) â€” {_n_active} Nodes SOM</b><br>\"\n",
    "             f\"<sup>DonnÃ©es post-{_transform_label} Â· â–² surexpression patho Â· â–¼ sous-expression patho Â· Tri interactif par marqueur</sup>\",\n",
    "        font=dict(size=13),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type=\"dropdown\",\n",
    "        direction=\"down\",\n",
    "        x=1.02, xanchor=\"left\", y=1.0, yanchor=\"top\",\n",
    "        showactive=True,\n",
    "        active=0,\n",
    "        buttons=_sort_buttons_diff,\n",
    "        font=dict(size=10),\n",
    "        bgcolor=\"#f0f0f0\",\n",
    "    )],\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=10)),\n",
    "    yaxis=dict(\n",
    "        title=\"Nodes SOM [MÃ©tacluster]\",\n",
    "        tickfont=dict(size=7),\n",
    "        autorange=\"reversed\",\n",
    "    ),\n",
    "    height=max(700, 18 * _n_active + 200),\n",
    "    width=max(800, 55 * _n_mk + 350),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=90, b=100, l=280, r=80),\n",
    ")\n",
    "fig_nodes_diff.show()\n",
    "print(f\"   [OK] Heatmap DiffÃ©rentiel {_n_active} nodes ({_valid_both.sum()} avec les 2 conditions)\")\n",
    "\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "# RÃ‰SUMÃ‰ â€” Nodes avec le plus fort diffÃ©rentiel\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TOP NODES AVEC LE PLUS FORT DIFFÃ‰RENTIEL PATHO vs SAIN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if _valid_both.any():\n",
    "    # Score = max |Î”| par ligne\n",
    "    _max_delta_per_node = np.max(np.abs(_delta_nodes[_valid_both]), axis=1)\n",
    "    _valid_indices = np.where(_valid_both)[0]\n",
    "    _top10 = np.argsort(_max_delta_per_node)[-10:][::-1]\n",
    "    \n",
    "    for rank, ti in enumerate(_top10, 1):\n",
    "        nd_idx = _sort_active[_valid_indices[ti]]\n",
    "        mc_lbl = int(_mc_of_node[nd_idx]) + 1\n",
    "        _d_row = _delta_nodes[_valid_indices[ti]]\n",
    "        _top_up_idx = np.argsort(_d_row)[-2:][::-1]\n",
    "        _top_dn_idx = np.argsort(_d_row)[:2]\n",
    "        \n",
    "        up_list = [f\"{_markers_sorted[k]}(â–²{_d_row[k]:+.1f})\" for k in _top_up_idx if _d_row[k] > 0.2]\n",
    "        dn_list = [f\"{_markers_sorted[k]}(â–¼{_d_row[k]:+.1f})\" for k in _top_dn_idx if _d_row[k] < -0.2]\n",
    "        \n",
    "        print(f\"   #{rank:2d} Node {nd_idx} [MC{mc_lbl}] \"\n",
    "              f\"(S:{_n_node_sain[nd_idx]:,} P:{_n_node_patho[nd_idx]:,})\")\n",
    "        if up_list:\n",
    "            print(f\"        â–² {', '.join(up_list)}\")\n",
    "\n",
    "        if dn_list:\n",
    "            print(f\"\\n[OK] Heatmap 100 nodes SOM terminÃ©e\")\n",
    "\n",
    "            print(f\"        â–¼ {', '.join(dn_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0c0fd",
   "metadata": {},
   "source": [
    "## 12. Export des RÃ©sultats\n",
    "\n",
    "Sauvegarde des rÃ©sultats d'analyse:\n",
    "- **CSV**: Tableau avec mÃ©taclusters assignÃ©s Ã  chaque cellule\n",
    "- **FCS**: Fichier FCS avec colonne mÃ©tacluster ajoutÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT CSV/FCS AVEC COORDONNÃ‰ES SOM (style FlowSOM R EXACT)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# CrÃ©er le dossier de sortie et ses sous-dossiers\n",
    "OUTPUT_DIR = \"./output\"\n",
    "OUTPUT_FCS = os.path.join(OUTPUT_DIR, \"fcs\")\n",
    "OUTPUT_CSV = os.path.join(OUTPUT_DIR, \"csv\")\n",
    "OUTPUT_OTHER = os.path.join(OUTPUT_DIR, \"other\")\n",
    "os.makedirs(OUTPUT_FCS, exist_ok=True)\n",
    "os.makedirs(OUTPUT_CSV, exist_ok=True)\n",
    "os.makedirs(OUTPUT_OTHER, exist_ok=True)\n",
    "\n",
    "print(\" PRÃ‰PARATION DES DONNÃ‰ES POUR EXPORT (style FlowSOM R EXACT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# PARAMÃˆTRES DE JITTER - STYLE FLOWSOM R EXACT\n",
    "# Dans FlowSOM R, le jitter est CIRCULAIRE (pas carrÃ©!)\n",
    "# La taille du cercle dÃ©pend du nombre de cellules dans le cluster\n",
    "# Formule R: rnorm() * scale_factor * sqrt(node_size/max_size)\n",
    "# =====================================================================\n",
    "np.random.seed(SEED)  # Pour reproductibilitÃ©\n",
    "\n",
    "# ParamÃ¨tres FlowSOM R\n",
    "MAX_NODE_SIZE = 0.45  # Rayon maximum du cercle (quand le node est le plus grand)\n",
    "MIN_NODE_SIZE = 0.1   # Rayon minimum du cercle (pour Ã©viter que les petits nodes disparaissent)\n",
    "\n",
    "# RÃ©cupÃ©rer les coordonnÃ©es de grille et MST depuis cluster_data\n",
    "grid_coords = cluster_data.obsm.get('grid', None)\n",
    "layout_coords = cluster_data.obsm.get('layout', None)\n",
    "\n",
    "# RÃ©cupÃ©rer le clustering pour mapper les coordonnÃ©es sur chaque cellule\n",
    "clustering = cell_data.obs['clustering'].values\n",
    "n_cells = len(clustering)\n",
    "n_nodes = len(cluster_data)\n",
    "\n",
    "# Calculer la taille de chaque node (nombre de cellules) â€” VECTORISÃ‰\n",
    "node_sizes = np.bincount(clustering.astype(int), minlength=n_nodes).astype(np.float32)\n",
    "\n",
    "max_size = node_sizes.max()\n",
    "print(f\"\\n Taille des nodes:\")\n",
    "print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "print(f\"   Max: {max_size:.0f} cellules\")\n",
    "print(f\"   Total: {n_cells} cellules\")\n",
    "\n",
    "# CrÃ©er un DataFrame avec toutes les donnÃ©es\n",
    "df_export = pd.DataFrame(X, columns=var_names)\n",
    "\n",
    "# MetaCluster avec +1 pour Kaluza (Ã©viter le 0, commencer Ã  1)\n",
    "df_export['FlowSOM_metacluster'] = metaclustering + 1\n",
    "\n",
    "# FlowSOM cluster (nodes) avec +1\n",
    "df_export['FlowSOM_cluster'] = clustering + 1\n",
    "\n",
    "# Ajouter les mÃ©tadonnÃ©es si disponibles\n",
    "if 'condition' in cell_data.obs.columns:\n",
    "    df_export['Condition'] = cell_data.obs['condition'].values\n",
    "    df_export['Condition_Num'] = np.where(df_export['Condition'] == 'Sain', 1, 2)\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    df_export['File_Origin'] = cell_data.obs['file_origin'].values\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R exact)\n",
    "# GÃ©nÃ¨re des points distribuÃ©s uniformÃ©ment dans un disque\n",
    "# Le rayon dÃ©pend de la taille du cluster\n",
    "# =====================================================================\n",
    "def circular_jitter(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re un jitter circulaire style FlowSOM R.\n",
    "    \n",
    "    GÃ©nÃ¨re un jitter circulaire style FlowSOM R â€” ENTIÃˆREMENT VECTORISÃ‰.\n",
    "    dont le rayon dÃ©pend du nombre de cellules dans le node.\n",
    "    Plus un node a de cellules, plus le cercle est grand.\n",
    "    \n",
    "    MÃ©thode: \n",
    "    - Angle theta uniforme [0, 2*pi]\n",
    "    - Rayon r = sqrt(u) * max_r (pour distribution uniforme dans le disque)\n",
    "    - Le max_r dÃ©pend de la taille du node\n",
    "    \"\"\"\n",
    "    # Angle uniforme autour du cercle\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    \n",
    "    # Rayon - distribution uniforme dans le disque (sqrt pour uniformitÃ©)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    # Calculer le rayon pour chaque cellule selon la taille de son cluster\n",
    "    # Dans FlowSOM R, le rayon est proportionnel Ã  sqrt(node_size/max_size)\n",
    "    # Calculer le rayon pour chaque cellule â€” VECTORISÃ‰ (pas de boucle)\n",
    "    max_size_val = node_sizes.max()\n",
    "    radii = min_radius + (max_radius - min_radius) * np.sqrt(\n",
    "        node_sizes[cluster_ids.astype(int)] / max_size_val\n",
    "    )\n",
    "    \n",
    "    # Rayon final pour distribution uniforme dans le disque\n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    # Convertir en coordonnÃ©es cartÃ©siennes\n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONNÃ‰ES GRILLE SOM (xGrid, yGrid) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "print(f\"\\n Application du jitter CIRCULAIRE style FlowSOM R\")\n",
    "print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "\n",
    "if grid_coords is not None:\n",
    "    # GÃ©nÃ©rer jitter CIRCULAIRE dÃ©pendant de la taille du node\n",
    "    jitter_x, jitter_y = circular_jitter(n_cells, clustering, node_sizes, \n",
    "                                          max_radius=MAX_NODE_SIZE, \n",
    "                                          min_radius=MIN_NODE_SIZE)\n",
    "    \n",
    "    # Mapper les coordonnÃ©es de grille sur chaque cellule\n",
    "    xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "    yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "    \n",
    "    # Appliquer le jitter circulaire\n",
    "    xGrid_jittered = xGrid_base + jitter_x\n",
    "    yGrid_jittered = yGrid_base + jitter_y\n",
    "    \n",
    "    # DÃ©caler pour que les axes commencent Ã  1 (X ET Y)\n",
    "    # Mapper les coordonnÃ©es de grille sur chaque cellule â€” VECTORISÃ‰\n",
    "    cl_int = clustering.astype(int)\n",
    "    xGrid_base = grid_coords[cl_int, 0].astype(np.float32)\n",
    "    yGrid_base = grid_coords[cl_int, 1].astype(np.float32)\n",
    "    \n",
    "    # Appliquer le jitter circulaire\n",
    "    xGrid_jittered = xGrid_base + jitter_x\n",
    "    yGrid_jittered = yGrid_base + jitter_y\n",
    "    \n",
    "    # DÃ©caler pour que les axes commencent Ã  1 (X ET Y)\n",
    "    xGrid = xGrid_jittered - xGrid_jittered.min() + 1.0\n",
    "    yGrid = yGrid_jittered - yGrid_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xGrid'] = xGrid.astype(np.float32)\n",
    "    df_export['yGrid'] = yGrid.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xGrid: [{xGrid.min():.3f} - {xGrid.max():.3f}]\")\n",
    "    print(f\"[OK] yGrid: [{yGrid.min():.3f} - {yGrid.max():.3f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONNÃ‰ES MST (xNodes, yNodes) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "    # Mapper les coordonnÃ©es MST sur chaque cellule â€” VECTORISÃ‰\n",
    "    cl_int = clustering.astype(int)\n",
    "    xNodes_base = layout_coords[cl_int, 0].astype(np.float32)\n",
    "    yNodes_base = layout_coords[cl_int, 1].astype(np.float32)\n",
    "    \n",
    "    # Calculer l'Ã©chelle pour le jitter MST (proportionnel Ã  l'espacement moyen)\n",
    "    x_range = xNodes_base.max() - xNodes_base.min()\n",
    "    y_range = yNodes_base.max() - yNodes_base.min()\n",
    "    mst_scale = min(x_range, y_range) / (XDIM * 2)  # Proportionnel Ã  la grille\n",
    "    \n",
    "    # Jitter circulaire pour MST aussi\n",
    "    mst_jitter_x, mst_jitter_y = circular_jitter(\n",
    "        n_cells, clustering, node_sizes,\n",
    "        max_radius=mst_scale * 0.8,  # Un peu moins que Grid car MST est plus espacÃ©\n",
    "        min_radius=mst_scale * 0.2\n",
    "    )\n",
    "    \n",
    "    # Appliquer le jitter\n",
    "    xNodes_jittered = xNodes_base + mst_jitter_x\n",
    "    yNodes_jittered = yNodes_base + mst_jitter_y\n",
    "    \n",
    "    # DÃ©caler pour que les axes commencent Ã  1 (X ET Y)\n",
    "    xNodes = xNodes_jittered - xNodes_jittered.min() + 1.0\n",
    "    yNodes = yNodes_jittered - yNodes_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xNodes'] = xNodes.astype(np.float32)\n",
    "    df_export['yNodes'] = yNodes.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xNodes: [{xNodes.min():.3f} - {xNodes.max():.3f}]\")\n",
    "    print(f\"[OK] yNodes: [{yNodes.min():.3f} - {yNodes.max():.3f}]\")\n",
    "\n",
    "# TAILLE DES NODES (pour chaque cellule) â€” VECTORISÃ‰\n",
    "# TAILLE DES NODES (pour chaque cellule)\n",
    "size_col = node_sizes[clustering.astype(int)]\n",
    "size_col = np.array([node_sizes[int(c)] for c in clustering], dtype=np.float32)\n",
    "df_export['size'] = size_col\n",
    "print(f\"[OK] size: [{size_col.min():.0f} - {size_col.max():.0f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT CSV\n",
    "# =====================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_path = os.path.join(OUTPUT_DIR, f\"flowsom_results_{timestamp}.csv\")\n",
    "df_export.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n[OK] CSV exportÃ©: {csv_path}\")\n",
    "print(f\"   Shape: {df_export.shape}\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT FCS COMPATIBLE KALUZA\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“„ EXPORT FCS COMPATIBLE KALUZA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def export_to_fcs_kaluza(df, output_path):\n",
    "    \"\"\"Export FCS compatible Kaluza avec toutes les coordonnÃ©es positives.\"\"\"\n",
    "    try:\n",
    "        import fcswrite\n",
    "        \n",
    "        numeric_df = df.select_dtypes(include=[np.number])\n",
    "        data = numeric_df.values.astype(np.float32)\n",
    "        channels = list(numeric_df.columns)\n",
    "        \n",
    "        # Nettoyer NaN/Inf\n",
    "        data = np.nan_to_num(data, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "        \n",
    "        print(f\"   {data.shape[0]:,} events, {data.shape[1]} canaux\")\n",
    "        \n",
    "        fcswrite.write_fcs(output_path, channels, data, compat_chn_names=True)\n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"   [!] fcswrite non disponible (pip install fcswrite)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "# PrÃ©parer le DataFrame FCS\n",
    "df_fcs = df_export.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# VÃ©rifier les ranges\n",
    "print(f\"\\n Colonnes exportÃ©es vers FCS:\")\n",
    "for col in ['FlowSOM_metacluster', 'FlowSOM_cluster', 'xGrid', 'yGrid', 'xNodes', 'yNodes', 'size', 'Condition_Num']:\n",
    "    if col in df_fcs.columns:\n",
    "        print(f\"   [OK] {col:25s}: [{df_fcs[col].min():10.2f}, {df_fcs[col].max():10.2f}]\")\n",
    "\n",
    "# Export FCS complet â†’ dossier fcs/\n",
    "fcs_path = os.path.join(OUTPUT_FCS, f\"flowsom_results_{timestamp}.fcs\")\n",
    "if export_to_fcs_kaluza(df_fcs, fcs_path):\n",
    "    print(f\"\\n[OK] FCS exportÃ©: {fcs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT DU RAPPORT DE STATISTIQUES\n",
    "# =============================================================================\n",
    "\n",
    "# Sauvegarder le rapport de statistiques â†’ dossier csv/\n",
    "stats_path = os.path.join(OUTPUT_CSV, f\"flowsom_statistics_{timestamp}.csv\")\n",
    "df_stats.to_csv(stats_path, index=False)\n",
    "print(f\"[OK] Statistiques exportÃ©es: {stats_path}\")\n",
    "\n",
    "# Sauvegarder la matrice MFI â†’ dossier csv/\n",
    "mfi_path = os.path.join(OUTPUT_CSV, f\"flowsom_mfi_matrix_{timestamp}.csv\")\n",
    "df_mfi.to_csv(mfi_path)\n",
    "print(f\"[OK] Matrice MFI exportÃ©e: {mfi_path}\")\n",
    "\n",
    "# RÃ©sumÃ© final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RÃ‰SUMÃ‰ DE L'ANALYSE FLOWSOM\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Fichiers analysÃ©s: {len(all_adatas)}\")\n",
    "print(f\"   Cellules totales: {len(cell_data)}\")\n",
    "print(f\"   Marqueurs utilisÃ©s: {len(used_markers)}\")\n",
    "print(f\"   Nombre de mÃ©taclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Transformation: {TRANSFORM_TYPE}\")\n",
    "print(f\"   Cofacteur: {COFACTOR}\")\n",
    "if TRANSFORM_TYPE != \"none\":\n",
    "    print(f\"   âš ï¸  Export FCS: donnÃ©es BRUTES (transformation inversÃ©e pour Kaluza)\")\n",
    "print(\"=\"*80)\n",
    "print(\"[OK] Analyse FlowSOM terminÃ©e avec succÃ¨s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17109a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT JSON MÃ‰TADONNÃ‰ES - TRAÃ‡ABILITÃ‰ COMPLÃˆTE DE L'ANALYSE\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" EXPORT DES MÃ‰TADONNÃ‰ES (JSON) â†’ dossier other/\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Collecter toutes les mÃ©tadonnÃ©es de l'analyse\n",
    "metadata = {\n",
    "    \"analysis_info\": {\n",
    "        \"date\": datetime.now().isoformat(),\n",
    "        \"timestamp\": timestamp,\n",
    "        \"pipeline_version\": \"FlowSOM_Analysis_Pipeline v2.0\",\n",
    "    },\n",
    "    \"input_files\": {\n",
    "        \"total_files\": len(all_fcs_files) if 'all_fcs_files' in dir() else len(all_adatas),\n",
    "        \"healthy_files\": [str(f) for f in healthy_files] if 'healthy_files' in dir() else [],\n",
    "        \"pathological_files\": [str(f) for f in patho_files] if 'patho_files' in dir() else [],\n",
    "        \"healthy_folder\": str(HEALTHY_FOLDER) if 'HEALTHY_FOLDER' in dir() else \"N/A\",\n",
    "        \"pathological_folder\": str(PATHOLOGICAL_FOLDER) if 'PATHOLOGICAL_FOLDER' in dir() else \"N/A\",\n",
    "    },\n",
    "    \"preprocessing\": {\n",
    "        \"gating_mode\": GATING_MODE if 'GATING_MODE' in dir() else \"N/A\",\n",
    "        \"gate_doublets\": GATE_DOUBLETS if 'GATE_DOUBLETS' in dir() else \"N/A\",\n",
    "        \"gate_debris\": GATE_DEBRIS if 'GATE_DEBRIS' in dir() else \"N/A\",\n",
    "        \"gate_cd45\": GATE_CD45 if 'GATE_CD45' in dir() else \"N/A\",\n",
    "        \"filter_blasts\": FILTER_BLASTS if 'FILTER_BLASTS' in dir() else \"N/A\",\n",
    "        \"marker_filtering\": {\n",
    "            \"enabled\": APPLY_MARKER_FILTERING,\n",
    "            \"keep_area\": KEEP_AREA,\n",
    "            \"keep_height\": KEEP_HEIGHT,\n",
    "        },\n",
    "    },\n",
    "    \"transformation\": {\n",
    "        \"type\": TRANSFORM_TYPE,\n",
    "        \"cofactor\": COFACTOR,\n",
    "        \"apply_to_scatter\": APPLY_TO_SCATTER,\n",
    "        \"export_data\": \"raw (inverse transform applied)\" if TRANSFORM_TYPE != \"none\" else \"raw (no transform)\",\n",
    "    },\n",
    "    \"flowsom_parameters\": {\n",
    "        \"seed\": SEED,\n",
    "        \"xdim\": XDIM,\n",
    "        \"ydim\": YDIM,\n",
    "        \"n_clusters\": N_CLUSTERS,\n",
    "        \"total_nodes\": XDIM * YDIM,\n",
    "        \"exclude_scatter\": EXCLUDE_SCATTER,\n",
    "    },\n",
    "    \"data_summary\": {\n",
    "        \"total_cells\": int(n_cells),\n",
    "        \"total_markers\": len(var_names),\n",
    "        \"markers_used_for_clustering\": used_markers,\n",
    "        \"all_markers\": var_names,\n",
    "        \"cells_per_condition\": {\n",
    "            cond: int((cell_data.obs['condition'] == cond).sum())\n",
    "            for cond in cell_data.obs['condition'].unique()\n",
    "        } if 'condition' in cell_data.obs.columns else {},\n",
    "        \"cells_per_file\": {\n",
    "            fname: int((cell_data.obs['file_origin'] == fname).sum())\n",
    "            for fname in cell_data.obs['file_origin'].unique()\n",
    "        } if 'file_origin' in cell_data.obs.columns else {},\n",
    "    },\n",
    "    \"metacluster_summary\": {\n",
    "        f\"MC{i}\": {\n",
    "            \"n_cells\": int((metaclustering == i).sum()),\n",
    "            \"pct_total\": round(float((metaclustering == i).sum() / len(metaclustering) * 100), 2),\n",
    "        }\n",
    "        for i in range(N_CLUSTERS)\n",
    "    },\n",
    "    \"export_files\": {\n",
    "        \"fcs_complete\": fcs_path,\n",
    "        \"csv_complete\": csv_path,\n",
    "        \"statistics\": stats_path if 'stats_path' in dir() else \"N/A\",\n",
    "        \"mfi_matrix\": mfi_path if 'mfi_path' in dir() else \"N/A\",\n",
    "    },\n",
    "    \"export_folders\": {\n",
    "        \"fcs\": OUTPUT_FCS,\n",
    "        \"csv\": OUTPUT_CSV,\n",
    "        \"other\": OUTPUT_OTHER,\n",
    "    },\n",
    "    \"jitter_parameters\": {\n",
    "        \"max_node_size\": MAX_NODE_SIZE,\n",
    "        \"min_node_size\": MIN_NODE_SIZE,\n",
    "        \"method\": \"circular_jitter (style FlowSOM R)\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Sauvegarder le JSON â†’ dossier other/\n",
    "metadata_path = os.path.join(OUTPUT_OTHER, f\"flowsom_metadata_{timestamp}.json\")\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"\\n[OK] MÃ©tadonnÃ©es exportÃ©es: {metadata_path}\")\n",
    "print(f\"\\nContenu du fichier:\")\n",
    "print(f\"   - Informations d'analyse (date, version)\")\n",
    "print(f\"   - Fichiers source ({metadata['input_files']['total_files']} fichiers)\")\n",
    "print(f\"   - ParamÃ¨tres de preprocessing (gating, filtrage)\")\n",
    "print(f\"   - ParamÃ¨tres de transformation ({TRANSFORM_TYPE}, cofactor={COFACTOR})\")\n",
    "print(f\"   - ParamÃ¨tres FlowSOM (grille {XDIM}x{YDIM}, {N_CLUSTERS} mÃ©taclusters)\")\n",
    "print(f\"   - RÃ©sumÃ© des donnÃ©es ({n_cells:,} cellules, {len(used_markers)} marqueurs)\")\n",
    "print(f\"   - RÃ©sumÃ© par mÃ©tacluster\")\n",
    "print(f\"   - Chemins des fichiers exportÃ©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT PAR CONDITION (Sain vs Pathologique) + COLONNE TIMEPOINT\n",
    "# =============================================================================\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" EXPORT PAR CONDITION + TIMEPOINT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# AJOUT DE LA COLONNE TIMEPOINT (extraction depuis le nom de fichier)\n",
    "# =====================================================================\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"Extrait une date depuis un nom de fichier FCS.\"\"\"\n",
    "    patterns = [\n",
    "        r'(\\d{2}[-/]\\d{2}[-/]\\d{4})',  # DD-MM-YYYY ou DD/MM/YYYY\n",
    "        r'(\\d{4}[-/]\\d{2}[-/]\\d{2})',  # YYYY-MM-DD ou YYYY/MM/DD\n",
    "        r'(\\d{2}[-/]\\d{2}[-/]\\d{2})',  # DD-MM-YY\n",
    "        r'(\\d{8})',                      # YYYYMMDD\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, str(filename))\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return \"unknown\"\n",
    "\n",
    "# CrÃ©er la colonne timepoint\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    file_origins_arr = cell_data.obs['file_origin'].values\n",
    "    \n",
    "    unique_files = list(set(file_origins_arr))\n",
    "    file_to_date = {f: extract_date_from_filename(f) for f in unique_files}\n",
    "    \n",
    "    timepoints = np.array([file_to_date[str(f)] for f in file_origins_arr])\n",
    "    df_export['Timepoint'] = timepoints\n",
    "    \n",
    "    unique_dates = sorted(set(timepoints))\n",
    "    date_to_idx = {d: i+1 for i, d in enumerate(unique_dates)}\n",
    "    df_export['Timepoint_Num'] = np.array([date_to_idx[t] for t in timepoints])\n",
    "    \n",
    "    print(f\"\\n[OK] Colonne 'Timepoint' ajoutÃ©e\")\n",
    "    print(f\"   Dates dÃ©tectÃ©es: {len(unique_dates)}\")\n",
    "    for dt in unique_dates:\n",
    "        n_dt = (timepoints == dt).sum()\n",
    "        print(f\"   [{date_to_idx[dt]}] {dt}: {n_dt:,} cellules\")\n",
    "else:\n",
    "    print(\"[INFO] Pas de colonne 'file_origin' â€” Timepoint non crÃ©Ã©\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT SÃ‰PARÃ‰ PAR CONDITION â†’ dossiers fcs/ et csv/\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" EXPORT SÃ‰PARÃ‰ PAR CONDITION â†’ fcs/ et csv/\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'Condition' in df_export.columns:\n",
    "    conditions_list = df_export['Condition'].unique()\n",
    "    \n",
    "    for cond in conditions_list:\n",
    "        mask_cond = df_export['Condition'] == cond\n",
    "        df_cond = df_export[mask_cond].copy()\n",
    "        \n",
    "        # Export CSV par condition â†’ dossier csv/\n",
    "        cond_safe = str(cond).replace(' ', '_').replace('/', '-')\n",
    "        csv_cond_path = os.path.join(OUTPUT_CSV, f\"flowsom_{cond_safe}_{timestamp}.csv\")\n",
    "        df_cond.to_csv(csv_cond_path, index=False)\n",
    "        \n",
    "        # Export FCS par condition â†’ dossier fcs/\n",
    "        fcs_cond_path = os.path.join(OUTPUT_FCS, f\"flowsom_{cond_safe}_{timestamp}.fcs\")\n",
    "        df_cond_numeric = df_cond.select_dtypes(include=[np.number]).copy()\n",
    "        export_to_fcs_kaluza(df_cond_numeric, fcs_cond_path)\n",
    "        \n",
    "        print(f\"\\n[OK] Condition '{cond}':\")\n",
    "        print(f\"   Cellules: {len(df_cond):,}\")\n",
    "        print(f\"   CSV: {csv_cond_path}\")\n",
    "        print(f\"   FCS: {fcs_cond_path}\")\n",
    "        \n",
    "        # RÃ©sumÃ© des mÃ©taclusters par condition\n",
    "        mc_counts = df_cond['FlowSOM_metacluster'].value_counts().sort_index()\n",
    "        mc_pcts = (mc_counts / len(df_cond) * 100).round(1)\n",
    "        print(f\"   MÃ©taclusters:\")\n",
    "        for mc, (cnt, pct) in enumerate(zip(mc_counts.values, mc_pcts.values)):\n",
    "            print(f\"      MC{mc+1}: {cnt:>7,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Export aussi par fichier si plusieurs fichiers\n",
    "    if 'File_Origin' in df_export.columns:\n",
    "        unique_files_export = df_export['File_Origin'].unique()\n",
    "        if len(unique_files_export) > 1:\n",
    "            print(f\"\\n\" + \"-\"*70)\n",
    "            print(f\" EXPORT PAR FICHIER ({len(unique_files_export)} fichiers) â†’ csv/\")\n",
    "            print(f\"-\"*70)\n",
    "            \n",
    "            for fname in unique_files_export:\n",
    "                mask_file = df_export['File_Origin'] == fname\n",
    "                df_file = df_export[mask_file].copy()\n",
    "                \n",
    "                fname_safe = str(fname).replace(' ', '_').replace('/', '-').replace('.fcs', '')\n",
    "                csv_file_path = os.path.join(OUTPUT_CSV, f\"flowsom_{fname_safe}_{timestamp}.csv\")\n",
    "                df_file.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                print(f\"   [OK] {fname}: {len(df_file):,} cellules â†’ {csv_file_path}\")\n",
    "else:\n",
    "    print(\"[INFO] Pas de colonne 'Condition' â€” Export par condition non disponible\")\n",
    "\n",
    "print(f\"\\n[OK] Tous les exports par condition/fichier terminÃ©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT RAPPORT HTML COMPLET â€” VISUALISATIONS INTERACTIVES PLOTLY + IMAGES\n",
    "# =============================================================================\n",
    "# Ce rapport HTML est autonome (self-contained): il inclut toutes les\n",
    "# visualisations Plotly interactives en temps rÃ©el + les figures matplotlib\n",
    "# converties en images base64 inline. Pas de dÃ©pendance externe.\n",
    "# =============================================================================\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import plotly.io as pio\n",
    "import plotly.offline\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" GÃ‰NÃ‰RATION DU RAPPORT HTML COMPLET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# RÃ‰CUPÃ‰RATION DU BUNDLE PLOTLY.JS POUR HTML SELF-CONTAINED\n",
    "# =====================================================================\n",
    "# On embarque plotly.js directement dans le HTML pour que le rapport\n",
    "# fonctionne hors-ligne, sans dÃ©pendance CDN.\n",
    "plotly_js_bundle = plotly.offline.get_plotlyjs()\n",
    "print(f\"   [OK] Plotly.js embarquÃ© ({len(plotly_js_bundle)//1024} KB)\")\n",
    "\n",
    "# =====================================================================\n",
    "# COLLECTE DE TOUTES LES FIGURES\n",
    "# =====================================================================\n",
    "\n",
    "# --- Convertir les figures Matplotlib en base64 PNG ---\n",
    "def fig_to_base64(fig_mpl):\n",
    "    \"\"\"Convertit une figure matplotlib en string base64 PNG.\"\"\"\n",
    "    buf = BytesIO()\n",
    "    fig_mpl.savefig(buf, format='png', dpi=150, bbox_inches='tight',\n",
    "                    facecolor='white', edgecolor='none')\n",
    "    buf.seek(0)\n",
    "    return base64.b64encode(buf.read()).decode('utf-8')\n",
    "\n",
    "# --- Convertir les figures Plotly en HTML div ---\n",
    "def plotly_to_html_div(fig_plotly, fig_id=\"\"):\n",
    "    \"\"\"Convertit une figure Plotly en div HTML avec interactivitÃ©.\n",
    "    Utilise la hauteur dÃ©finie dans le layout de la figure pour prÃ©server\n",
    "    les dimensions originales (ex: spider plot 750px).\n",
    "    include_plotlyjs=False car plotly.js est embarquÃ© dans le <head>.\n",
    "    \"\"\"\n",
    "    fig_height = fig_plotly.layout.height or 500\n",
    "    fig_width_val = fig_plotly.layout.width\n",
    "    default_w = f'{fig_width_val}px' if fig_width_val else '100%'\n",
    "    return pio.to_html(\n",
    "        fig_plotly,\n",
    "        full_html=False,\n",
    "        include_plotlyjs=False,\n",
    "        div_id=fig_id if fig_id else None,\n",
    "        default_height=f'{fig_height}px',\n",
    "        default_width=default_w,\n",
    "        config={'responsive': True}\n",
    "    )\n",
    "\n",
    "# Collecter les figures matplotlib existantes\n",
    "mpl_figures = {}\n",
    "plotly_figures = {}\n",
    "\n",
    "# Chercher toutes les variables de type Figure dans le namespace\n",
    "import matplotlib.figure\n",
    "\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, matplotlib.figure.Figure):\n",
    "        try:\n",
    "            mpl_figures[name] = fig_to_base64(obj)\n",
    "            print(f\"   [OK] Figure matplotlib: {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   [!] Erreur {name}: {e}\")\n",
    "\n",
    "# Chercher toutes les figures Plotly â€” on stocke les OBJETS Figure\n",
    "# pour les convertir en HTML avec les bonnes dimensions\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly_figure_objects = {}\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, go.Figure):\n",
    "        try:\n",
    "            # VÃ©rifier que la figure contient des donnÃ©es\n",
    "            n_traces = len(obj.data)\n",
    "            plotly_figure_objects[name] = obj\n",
    "            print(f\"   [OK] Figure Plotly: {name} ({n_traces} traces, h={obj.layout.height or 'auto'})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   [!] Erreur {name}: {e}\")\n",
    "\n",
    "print(f\"\\n   Total: {len(mpl_figures)} figures matplotlib, {len(plotly_figure_objects)} figures Plotly\")\n",
    "\n",
    "# =====================================================================\n",
    "# CONSTRUCTION DU HTML\n",
    "# =====================================================================\n",
    "\n",
    "# Noms lisibles pour les figures\n",
    "figure_labels = {\n",
    "    'fig': 'AperÃ§u gÃ©nÃ©ral',\n",
    "    'fig1': 'Visualisation 1',\n",
    "    'fig2': 'Visualisation 2',\n",
    "    'fig3': 'Visualisation 3',\n",
    "    'fig4': 'Visualisation 4',\n",
    "    'fig5': 'Visualisation 5',\n",
    "    'fig_stars': 'Star Chart FlowSOM',\n",
    "    'fig_comp': 'Comparaison Conditions',\n",
    "    'fig_gates': 'Gates de prÃ©-traitement',\n",
    "    'fig_grid_mc': 'Grille SOM â€” MÃ©taclusters',\n",
    "    'fig_grid_cond': 'Grille SOM â€” Conditions',\n",
    "    'fig_hist': 'Histogrammes des marqueurs',\n",
    "    'fig_mst': 'Arbre MST',\n",
    "    'fig_overview': 'Vue d\\'ensemble',\n",
    "    'fig_radar': 'Spider Plot â€” Profils MFI',\n",
    "    'fig_sankey': 'Diagramme Sankey',\n",
    "    'fig_table': 'Tableau rÃ©sumÃ©',\n",
    "    'fig_table_cond': 'Tableau par condition',\n",
    "    'fig_ransac_qc': 'QC RANSAC â€” Scatter FSC-A vs FSC-H',\n",
    "    'fig_singlets_table': 'QC Singlets â€” Tableau par fichier',\n",
    "    'fig_heatmap': 'Heatmap MFI â€” MÃ©taclusters Ã— Marqueurs (Z-score)',\n",
    "    'fig_heatmap_clinical': 'Expression PhÃ©notypique â€” MÃ©taclusters Ã— Marqueurs',\n",
    "    'fig_barplots': 'Marqueurs ClÃ©s â€” NBM vs Pathologique',\n",
    "    'fig_phenotype': 'Signature PhÃ©notypique par MÃ©tacluster',\n",
    "}\n",
    "\n",
    "# --- Statistiques par mÃ©tacluster pour le tableau HTML ---\n",
    "mc_rows_html = \"\"\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask_mc = metaclustering == i\n",
    "    n_mc = int(mask_mc.sum())\n",
    "    pct_mc = n_mc / len(metaclustering) * 100\n",
    "    \n",
    "    # MFI top 3\n",
    "    if n_mc > 0:\n",
    "        mfi_mc = np.nanmean(X[mask_mc][:, cols_to_use], axis=0)\n",
    "        top3_idx = np.argsort(mfi_mc)[::-1][:3]\n",
    "        top3 = ', '.join([used_markers[j] for j in top3_idx])\n",
    "    else:\n",
    "        top3 = \"N/A\"\n",
    "    \n",
    "    mc_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "        <td style=\"font-weight:bold; text-align:center;\">MC{i+1}</td>\n",
    "        <td style=\"text-align:right;\">{n_mc:,}</td>\n",
    "        <td style=\"text-align:right;\">{pct_mc:.1f}%</td>\n",
    "        <td>{top3}</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# --- Cellules par condition ---\n",
    "cond_rows_html = \"\"\n",
    "if 'condition' in cell_data.obs.columns:\n",
    "    for cond in cell_data.obs['condition'].unique():\n",
    "        n_cond = int((cell_data.obs['condition'] == cond).sum())\n",
    "        pct_cond = n_cond / len(cell_data) * 100\n",
    "        cond_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "        <td style=\"font-weight:bold;\">{cond}</td>\n",
    "        <td style=\"text-align:right;\">{n_cond:,}</td>\n",
    "        <td style=\"text-align:right;\">{pct_cond:.1f}%</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# --- Fichiers source ---\n",
    "files_rows_html = \"\"\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    for fname in cell_data.obs['file_origin'].unique():\n",
    "        n_f = int((cell_data.obs['file_origin'] == fname).sum())\n",
    "        files_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "        <td>{fname}</td>\n",
    "        <td style=\"text-align:right;\">{n_f:,}</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# --- Sections Plotly (conversion des objets Figure â†’ HTML divs) ---\n",
    "plotly_sections = \"\"\n",
    "for _fig_name, _fig_iter in plotly_figure_objects.items():\n",
    "    label = figure_labels.get(_fig_name, _fig_name)\n",
    "    try:\n",
    "        div_html = plotly_to_html_div(_fig_iter, fig_id=_fig_name)\n",
    "        plotly_sections += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h2>{label}</h2>\n",
    "        <div class=\"plotly-container\">\n",
    "            {div_html}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Erreur conversion HTML pour {_fig_name}: {e}\")\n",
    "del _fig_name, _fig_iter  # Ã‰viter que la variable de boucle se retrouve comme figure\n",
    "\n",
    "# --- Sections Matplotlib ---\n",
    "mpl_sections = \"\"\n",
    "for name, b64 in mpl_figures.items():\n",
    "    label = figure_labels.get(name, name)\n",
    "    mpl_sections += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h2>{label}</h2>\n",
    "        <div style=\"text-align:center;\">\n",
    "            <img src=\"data:image/png;base64,{b64}\" style=\"max-width:100%; border-radius:8px; box-shadow:0 2px 8px rgba(0,0,0,0.1);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# --- Marqueurs utilisÃ©s ---\n",
    "markers_html = \"\"\n",
    "for i, m in enumerate(used_markers):\n",
    "    markers_html += f'<span class=\"marker-badge\">{m}</span>\\n'\n",
    "\n",
    "# =====================================================================\n",
    "# TEMPLATE HTML COMPLET\n",
    "# =====================================================================\n",
    "# Note: On utilise un placeholder __PLOTLY_JS_BUNDLE__ pour le script\n",
    "# plotly.js car le bundle fait ~3.5 MB et ne doit pas Ãªtre dans le f-string.\n",
    "# Il sera remplacÃ© aprÃ¨s la construction du template.\n",
    "\n",
    "html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>FlowSOM Analysis Report â€” {timestamp}</title>\n",
    "    <script type=\"text/javascript\">__PLOTLY_JS_BUNDLE__</script>\n",
    "    <style>\n",
    "        :root {{\n",
    "            --primary: #667eea;\n",
    "            --primary-dark: #764ba2;\n",
    "            --bg: #f8f9fa;\n",
    "            --card-bg: #ffffff;\n",
    "            --text: #2d3748;\n",
    "            --text-light: #718096;\n",
    "            --border: #e2e8f0;\n",
    "            --success: #48bb78;\n",
    "            --warning: #ed8936;\n",
    "        }}\n",
    "        \n",
    "        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n",
    "        \n",
    "        body {{\n",
    "            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;\n",
    "            background: var(--bg);\n",
    "            color: var(--text);\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "        \n",
    "        .header {{\n",
    "            background: linear-gradient(135deg, var(--primary), var(--primary-dark));\n",
    "            color: white;\n",
    "            padding: 40px 0;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "        }}\n",
    "        \n",
    "        .header h1 {{\n",
    "            font-size: 2.2em;\n",
    "            margin-bottom: 8px;\n",
    "            font-weight: 700;\n",
    "        }}\n",
    "        \n",
    "        .header .subtitle {{\n",
    "            font-size: 1.1em;\n",
    "            opacity: 0.9;\n",
    "        }}\n",
    "        \n",
    "        .container {{\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            padding: 0 20px;\n",
    "        }}\n",
    "        \n",
    "        .section {{\n",
    "            background: var(--card-bg);\n",
    "            border-radius: 12px;\n",
    "            padding: 30px;\n",
    "            margin-bottom: 24px;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.08);\n",
    "            border: 1px solid var(--border);\n",
    "        }}\n",
    "        \n",
    "        .section h2 {{\n",
    "            font-size: 1.4em;\n",
    "            color: var(--primary);\n",
    "            margin-bottom: 20px;\n",
    "            padding-bottom: 10px;\n",
    "            border-bottom: 2px solid var(--border);\n",
    "        }}\n",
    "        \n",
    "        .grid-2 {{\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr 1fr;\n",
    "            gap: 20px;\n",
    "        }}\n",
    "        \n",
    "        .grid-3 {{\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr 1fr 1fr;\n",
    "            gap: 20px;\n",
    "        }}\n",
    "        \n",
    "        .stat-card {{\n",
    "            background: linear-gradient(135deg, #f6f8ff, #f0f4ff);\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "            border: 1px solid #dde4f0;\n",
    "        }}\n",
    "        \n",
    "        .stat-card .value {{\n",
    "            font-size: 2em;\n",
    "            font-weight: 700;\n",
    "            color: var(--primary);\n",
    "        }}\n",
    "        \n",
    "        .stat-card .label {{\n",
    "            font-size: 0.9em;\n",
    "            color: var(--text-light);\n",
    "            margin-top: 4px;\n",
    "        }}\n",
    "        \n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        \n",
    "        th {{\n",
    "            background: linear-gradient(135deg, var(--primary), var(--primary-dark));\n",
    "            color: white;\n",
    "            padding: 12px 16px;\n",
    "            text-align: left;\n",
    "            font-weight: 600;\n",
    "        }}\n",
    "        \n",
    "        td {{\n",
    "            padding: 10px 16px;\n",
    "            border-bottom: 1px solid var(--border);\n",
    "        }}\n",
    "        \n",
    "        tr:nth-child(even) {{\n",
    "            background: #f7fafc;\n",
    "        }}\n",
    "        \n",
    "        tr:hover {{\n",
    "            background: #edf2f7;\n",
    "        }}\n",
    "        \n",
    "        .marker-badge {{\n",
    "            display: inline-block;\n",
    "            background: linear-gradient(135deg, #667eea22, #764ba222);\n",
    "            color: var(--primary-dark);\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 0.85em;\n",
    "            margin: 3px;\n",
    "            border: 1px solid #667eea44;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "        \n",
    "        .plotly-container {{\n",
    "            width: 100%;\n",
    "            overflow-x: auto;\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "        }}\n",
    "        \n",
    "        .plotly-container > div {{\n",
    "            min-width: 0;\n",
    "        }}\n",
    "        \n",
    "        .param-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));\n",
    "            gap: 12px;\n",
    "        }}\n",
    "        \n",
    "        .param-item {{\n",
    "            background: #f7fafc;\n",
    "            padding: 10px 15px;\n",
    "            border-radius: 8px;\n",
    "            border-left: 3px solid var(--primary);\n",
    "        }}\n",
    "        \n",
    "        .param-item .param-label {{\n",
    "            font-size: 0.8em;\n",
    "            color: var(--text-light);\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 0.5px;\n",
    "        }}\n",
    "        \n",
    "        .param-item .param-value {{\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            color: var(--text);\n",
    "        }}\n",
    "        \n",
    "        .toc {{\n",
    "            background: #f0f4ff;\n",
    "            border-radius: 10px;\n",
    "            padding: 20px 30px;\n",
    "            margin-bottom: 24px;\n",
    "        }}\n",
    "        \n",
    "        .toc h3 {{\n",
    "            margin-bottom: 10px;\n",
    "            color: var(--primary-dark);\n",
    "        }}\n",
    "        \n",
    "        .toc ul {{\n",
    "            list-style: none;\n",
    "            columns: 2;\n",
    "        }}\n",
    "        \n",
    "        .toc li {{\n",
    "            padding: 4px 0;\n",
    "        }}\n",
    "        \n",
    "        .toc a {{\n",
    "            color: var(--primary);\n",
    "            text-decoration: none;\n",
    "        }}\n",
    "        \n",
    "        .toc a:hover {{\n",
    "            text-decoration: underline;\n",
    "        }}\n",
    "        \n",
    "        .footer {{\n",
    "            text-align: center;\n",
    "            padding: 30px;\n",
    "            color: var(--text-light);\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        \n",
    "        @media (max-width: 768px) {{\n",
    "            .grid-2, .grid-3 {{ grid-template-columns: 1fr; }}\n",
    "            .toc ul {{ columns: 1; }}\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<!-- HEADER -->\n",
    "<div class=\"header\">\n",
    "    <div class=\"container\">\n",
    "        <h1>FlowSOM Analysis Report</h1>\n",
    "        <div class=\"subtitle\">\n",
    "            Analyse gÃ©nÃ©rÃ©e le {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')} â€” \n",
    "            {n_cells:,} cellules Â· {len(used_markers)} marqueurs Â· {N_CLUSTERS} mÃ©taclusters\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"container\">\n",
    "\n",
    "<!-- TABLE DES MATIÃˆRES -->\n",
    "<div class=\"toc\">\n",
    "    <h3>Table des matiÃ¨res</h3>\n",
    "    <ul>\n",
    "        <li><a href=\"#params\">1. ParamÃ¨tres de l'analyse</a></li>\n",
    "        <li><a href=\"#data\">2. RÃ©sumÃ© des donnÃ©es</a></li>\n",
    "        <li><a href=\"#markers\">3. Marqueurs utilisÃ©s</a></li>\n",
    "        <li><a href=\"#metaclusters\">4. MÃ©taclusters</a></li>\n",
    "        <li><a href=\"#plotly-viz\">5. Visualisations interactives</a></li>\n",
    "        <li><a href=\"#static-viz\">6. Visualisations statiques</a></li>\n",
    "        <li><a href=\"#exports\">7. Fichiers exportÃ©s</a></li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<!-- 1. PARAMÃˆTRES -->\n",
    "<div class=\"section\" id=\"params\">\n",
    "    <h2>1. ParamÃ¨tres de l'Analyse</h2>\n",
    "    <div class=\"param-grid\">\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Transformation</div>\n",
    "            <div class=\"param-value\">{TRANSFORM_TYPE.upper()}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Cofacteur</div>\n",
    "            <div class=\"param-value\">{COFACTOR}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Grille SOM</div>\n",
    "            <div class=\"param-value\">{XDIM} Ã— {YDIM} ({XDIM*YDIM} nodes)</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">MÃ©taclusters</div>\n",
    "            <div class=\"param-value\">{N_CLUSTERS}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Seed</div>\n",
    "            <div class=\"param-value\">{SEED}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Filtrage marqueurs</div>\n",
    "            <div class=\"param-value\">{'Area (-A)' if KEEP_AREA else ''} {'Height (-H)' if KEEP_HEIGHT else ''}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Gating mode</div>\n",
    "            <div class=\"param-value\">{GATING_MODE if 'GATING_MODE' in dir() else 'N/A'}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Exclure Scatter</div>\n",
    "            <div class=\"param-value\">{'Oui' if EXCLUDE_SCATTER else 'Non'}</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- 2. RÃ‰SUMÃ‰ DES DONNÃ‰ES -->\n",
    "<div class=\"section\" id=\"data\">\n",
    "    <h2>2. RÃ©sumÃ© des DonnÃ©es</h2>\n",
    "    <div class=\"grid-3\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"value\">{n_cells:,}</div>\n",
    "            <div class=\"label\">Cellules totales</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"value\">{len(used_markers)}</div>\n",
    "            <div class=\"label\">Marqueurs (clustering)</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"value\">{len(all_adatas) if 'all_adatas' in dir() else 'N/A'}</div>\n",
    "            <div class=\"label\">Fichiers analysÃ©s</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <h3 style=\"margin-top:25px; margin-bottom:10px;\">Par condition</h3>\n",
    "    <table>\n",
    "        <tr><th>Condition</th><th>Cellules</th><th>Pourcentage</th></tr>\n",
    "        {cond_rows_html}\n",
    "    </table>\n",
    "    \n",
    "    <h3 style=\"margin-top:25px; margin-bottom:10px;\">Par fichier source</h3>\n",
    "    <table>\n",
    "        <tr><th>Fichier</th><th>Cellules</th></tr>\n",
    "        {files_rows_html}\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<!-- 3. MARQUEURS -->\n",
    "<div class=\"section\" id=\"markers\">\n",
    "    <h2>3. Marqueurs UtilisÃ©s pour le Clustering</h2>\n",
    "    <p style=\"margin-bottom:15px; color:var(--text-light);\">\n",
    "        {len(used_markers)} marqueurs sÃ©lectionnÃ©s (scatter et Time exclus)\n",
    "    </p>\n",
    "    {markers_html}\n",
    "</div>\n",
    "\n",
    "<!-- 4. MÃ‰TACLUSTERS -->\n",
    "<div class=\"section\" id=\"metaclusters\">\n",
    "    <h2>4. RÃ©sumÃ© des MÃ©taclusters</h2>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>MÃ©tacluster</th>\n",
    "            <th>Cellules</th>\n",
    "            <th>% Total</th>\n",
    "            <th>Top 3 Marqueurs</th>\n",
    "        </tr>\n",
    "        {mc_rows_html}\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<!-- 5. VISUALISATIONS PLOTLY (INTERACTIVES) -->\n",
    "<div id=\"plotly-viz\">\n",
    "    <div class=\"section\">\n",
    "        <h2>5. Visualisations Interactives (Plotly)</h2>\n",
    "        <p style=\"color:var(--text-light); margin-bottom:10px;\">\n",
    "            {len(plotly_figure_objects)} figures interactives â€” zoom, pan, hover pour explorer les donnÃ©es\n",
    "        </p>\n",
    "    </div>\n",
    "    {plotly_sections}\n",
    "</div>\n",
    "\n",
    "<!-- 6. VISUALISATIONS MATPLOTLIB (STATIQUES) -->\n",
    "<div id=\"static-viz\">\n",
    "    <div class=\"section\">\n",
    "        <h2>6. Visualisations Statiques (Matplotlib)</h2>\n",
    "        <p style=\"color:var(--text-light); margin-bottom:10px;\">\n",
    "            {len(mpl_figures)} figures haute rÃ©solution\n",
    "        </p>\n",
    "    </div>\n",
    "    {mpl_sections}\n",
    "</div>\n",
    "\n",
    "<!-- 7. FICHIERS EXPORTÃ‰S -->\n",
    "<div class=\"section\" id=\"exports\">\n",
    "    <h2>7. Fichiers ExportÃ©s</h2>\n",
    "    <table>\n",
    "        <tr><th>Type</th><th>Fichier</th></tr>\n",
    "        <tr><td>CSV complet</td><td>{csv_path}</td></tr>\n",
    "        <tr><td>FCS (Kaluza compatible)</td><td>{fcs_path}</td></tr>\n",
    "        <tr><td>Statistiques</td><td>{stats_path if 'stats_path' in dir() else 'N/A'}</td></tr>\n",
    "        <tr><td>Matrice MFI</td><td>{mfi_path if 'mfi_path' in dir() else 'N/A'}</td></tr>\n",
    "        <tr><td>MÃ©tadonnÃ©es JSON</td><td>{metadata_path}</td></tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "<!-- FOOTER -->\n",
    "<div class=\"footer\">\n",
    "    <p>FlowSOM Analysis Pipeline v2.0 â€” Rapport gÃ©nÃ©rÃ© automatiquement le {datetime.now().strftime('%d/%m/%Y Ã  %H:%M:%S')}</p>\n",
    "    <p>Transformation: {TRANSFORM_TYPE.upper()} (cofactor={COFACTOR}) Â· Grille: {XDIM}Ã—{YDIM} Â· {N_CLUSTERS} mÃ©taclusters Â· Seed: {SEED}</p>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# =====================================================================\n",
    "# INJECTION DU BUNDLE PLOTLY.JS (self-contained, pas de CDN)\n",
    "# =====================================================================\n",
    "# On remplace le placeholder par le vrai code plotly.js.\n",
    "# Cela rend le HTML autonome (~3-4 MB de JS embarquÃ©).\n",
    "html_content = html_content.replace('__PLOTLY_JS_BUNDLE__', plotly_js_bundle)\n",
    "\n",
    "# =====================================================================\n",
    "# SAUVEGARDE DU RAPPORT HTML â†’ dossier other/\n",
    "# =====================================================================\n",
    "html_path = os.path.join(OUTPUT_OTHER, f\"flowsom_report_{timestamp}.html\")\n",
    "with open(html_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "# Taille du fichier\n",
    "html_size_mb = os.path.getsize(html_path) / (1024 * 1024)\n",
    "\n",
    "print(f\"\\n[OK] Rapport HTML exportÃ©: {html_path}\")\n",
    "print(f\"   Taille: {html_size_mb:.1f} MB (plotly.js embarquÃ© = self-contained)\")\n",
    "print(f\"   Figures Plotly interactives: {len(plotly_figure_objects)}\")\n",
    "print(f\"   Figures Matplotlib (images): {len(mpl_figures)}\")\n",
    "print(f\"\\n   Ouvrez le fichier dans un navigateur pour explorer les donnÃ©es\")\n",
    "print(f\"   Les figures Plotly sont entiÃ¨rement interactives (zoom, hover, etc.)\")\n",
    "print(f\"   Le rapport fonctionne HORS-LIGNE (pas de dÃ©pendance CDN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECTION DES VARIABLES DU NOTEBOOK\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" LISTE DES OBJETS AnnData\")\n",
    "print(\"=\"*70)\n",
    "%who AnnData\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" LISTE DES DataFrames\")\n",
    "print(\"=\"*70)\n",
    "%who DataFrame\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" DÃ‰TAILS DE adata_flowsom\")\n",
    "print(\"=\"*70)\n",
    "print(adata_flowsom)\n",
    "\n",
    "print(\"\\n- Shape:\", adata_flowsom.shape)\n",
    "print(\"- Variables (colonnes):\", list(adata_flowsom.var_names))\n",
    "print(\"- Observations (fichiers):\", adata_flowsom.obs.columns.tolist() if len(adata_flowsom.obs.columns) > 0 else \"Aucune annotation\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Statistiques de la matrice X:\")\n",
    "print(\"-\"*70)\n",
    "import pandas as pd\n",
    "stats = pd.DataFrame({\n",
    "    'Colonne': adata_flowsom.var_names,\n",
    "    'Min': adata_flowsom.X.min(axis=0),\n",
    "    'Max': adata_flowsom.X.max(axis=0),\n",
    "    'Moyenne': adata_flowsom.X.mean(axis=0),\n",
    "    'Std': adata_flowsom.X.std(axis=0)\n",
    "})\n",
    "display(stats)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- AperÃ§u des observations (.obs):\")\n",
    "print(\"-\"*70)\n",
    "if adata_flowsom.obs.shape[1] > 0:\n",
    "    display(adata_flowsom.obs.head(10))\n",
    "else:\n",
    "    print(\"Aucune annotation dans .obs\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Toutes les variables disponibles:\")\n",
    "print(\"-\"*70)\n",
    "#%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e481f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FLOWSOM SUMMARY - RAPPORT PDF COMPLET\n",
    "# =============================================================================\n",
    "# GÃ©nÃ©ration automatique d'un PDF rÃ©capitulatif avec toutes les visualisations\n",
    "# Documentation: https://flowsom.readthedocs.io/en/stable/generated/flowsom.pl.FlowSOMmary.html\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Chemin du fichier PDF de sortie â†’ dossier other/\n",
    "summary_pdf_path = os.path.join(OUTPUT_OTHER, f\"FlowSOMmary_{timestamp}.pdf\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" GÃ‰NÃ‰RATION DU RAPPORT FlowSOMmary (PDF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # GÃ©nÃ©ration du rapport FlowSOMmary\n",
    "    # Inclut: marker_diff, cluster_profiles, grid, mst\n",
    "    # Exclut: UMAP (non demandÃ©)\n",
    "    fs.pl.FlowSOMmary(\n",
    "        fsom,\n",
    "        plot_file=summary_pdf_path\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[OK] Rapport PDF gÃ©nÃ©rÃ© avec succÃ¨s!\")\n",
    "    print(f\"    Fichier: {summary_pdf_path}\")\n",
    "    print(f\"\\n    Contenu du rapport:\")\n",
    "    print(f\"    - Star plots (profils MFI par cluster)\")\n",
    "    print(f\"    - Grid SOM avec metaclusters\")\n",
    "    print(f\"    - Arbre MST avec metaclusters\")\n",
    "    print(f\"    - Heatmap des marqueurs par cluster\")\n",
    "    print(f\"    - Distribution des tailles de clusters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n[!] Erreur lors de la gÃ©nÃ©ration du FlowSOMmary:\")\n",
    "    print(f\"    {str(e)}\")\n",
    "    print(f\"\\n    Tentative de gÃ©nÃ©ration manuelle des graphiques...\")\n",
    "    \n",
    "    # Alternative: gÃ©nÃ©rer les graphiques individuellement\n",
    "    try:\n",
    "        from matplotlib.backends.backend_pdf import PdfPages\n",
    "        \n",
    "        with PdfPages(summary_pdf_path) as pdf:\n",
    "            # 1. Star plots par metacluster\n",
    "            print(\"    - GÃ©nÃ©ration des star plots...\")\n",
    "            fig_stars = fs.pl.plot_stars(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_stars, bbox_inches='tight')\n",
    "            plt.close(fig_stars)\n",
    "            \n",
    "            # 2. Grid SOM\n",
    "            print(\"    - GÃ©nÃ©ration de la grille SOM...\")\n",
    "            fig_grid = fs.pl.plot_grid(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_grid, bbox_inches='tight')\n",
    "            plt.close(fig_grid)\n",
    "            \n",
    "            # 3. Arbre MST\n",
    "            print(\"    - GÃ©nÃ©ration de l'arbre MST...\")\n",
    "            fig_mst = fs.pl.plot_mst(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_mst, bbox_inches='tight')\n",
    "            plt.close(fig_mst)\n",
    "            \n",
    "            # 4. Marker heatmap\n",
    "            print(\"    - GÃ©nÃ©ration de la heatmap des marqueurs...\")\n",
    "            fig_heatmap = fs.pl.plot_marker_heatmap(fsom)\n",
    "            pdf.savefig(fig_heatmap, bbox_inches='tight')\n",
    "            plt.close(fig_heatmap)\n",
    "            \n",
    "        print(f\"\\n[OK] Rapport PDF alternatif gÃ©nÃ©rÃ©!\")\n",
    "        print(f\"    Fichier: {summary_pdf_path}\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"\\n[X] Impossible de gÃ©nÃ©rer le rapport: {str(e2)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FIN DE L'ANALYSE FlowSOM\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
