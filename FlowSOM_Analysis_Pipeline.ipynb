{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563bddce",
   "metadata": {},
   "source": [
    "# FlowSOM Analysis Pipeline - Notebook Headless\n",
    "\n",
    "## Pipeline complète d'analyse FlowSOM pour données de cytométrie en flux\n",
    "\n",
    "Ce notebook \"miroir\" de l'application FlowSOM Analyzer permet:\n",
    "- **Debug & Introspection**: Visualiser les données à chaque étape\n",
    "- **Tuning rapide**: Tester différents paramètres sans relancer l'app\n",
    "- **Séparation des responsabilités**: Logique métier pure, sans UI\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Florian Magne\n",
    "**Version**: 1.0\n",
    "**Date**: Janvier 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4bea0",
   "metadata": {},
   "source": [
    "## 1. Import des Librairies\n",
    "\n",
    "Import de toutes les librairies nécessaires avec vérification de disponibilité des dépendances optionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# IMPORTS début du fichier\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports scientifiques de base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# CONFIGURATION PANDAS: Affichage en format linéaire (jamais exponentiel)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')  # 4 décimales max\n",
    "pd.set_option('display.max_columns', None)  # Afficher toutes les colonnes\n",
    "pd.set_option('display.width', None)  # Largeur auto\n",
    "pd.set_option('display.max_rows', 100)  # Max 100 lignes affichées\n",
    "np.set_printoptions(suppress=True, precision=4)  # Numpy aussi en linéaire\n",
    "print(\"[OK] Pandas configuré: affichage linéaire (pas de notation scientifique)\")\n",
    "\n",
    "# Imports visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['axes.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['text.color'] = \"#000000\"\n",
    "plt.rcParams['axes.labelcolor'] = \"#000000\"\n",
    "plt.rcParams['xtick.color'] = \"#000000\"\n",
    "plt.rcParams['ytick.color'] = \"#000000\"\n",
    "plt.rcParams['axes.edgecolor'] = \"#000000\"\n",
    "plt.rcParams['grid.color'] = \"#cccccc\"\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Plotly pour visualisations interactives\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    # Configuration pour affichage dans les notebooks\n",
    "    pio.renderers.default = 'notebook'\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"[OK] Plotly disponible\")\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non installé (optionnel): pip install plotly\")\n",
    "\n",
    "# IMPORTS flowsom et anndata, l'un est le package d'analyse du FlowSOM, l'autre est pour gérer les données dans des objets AnnData\n",
    "try:\n",
    "    import flowsom as fs\n",
    "    import anndata as ad\n",
    "    FLOWSOM_AVAILABLE = True\n",
    "    print(\"[OK] FlowSOM disponible\")\n",
    "except ImportError:\n",
    "    FLOWSOM_AVAILABLE = False\n",
    "    print(\"[X] FlowSOM non installé: pip install flowsom\")\n",
    "\n",
    "# Import de Scanpy pour UMAP/t-SNE\n",
    "try:\n",
    "    import scanpy as sc\n",
    "    SCANPY_AVAILABLE = True\n",
    "    print(\"[OK] Scanpy disponible\")\n",
    "except ImportError:\n",
    "    SCANPY_AVAILABLE = False\n",
    "    print(\"[!] Scanpy non installé (optionnel): pip install scanpy\")\n",
    "\n",
    "# Import de UMAP\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"[OK] UMAP disponible\")\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"[!] UMAP non installé (optionnel): pip install umap-learn\")\n",
    "\n",
    "\n",
    "# Import de t-SNE via sklearn car t-SNE trop lent à être implémenté dans Scanpy (et FlowSOM)\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"[OK] Scikit-learn disponible\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"[!] Scikit-learn non installé: pip install scikit-learn\")\n",
    "\n",
    "# FlowKit pour transformations Logicle\n",
    "try:\n",
    "    import flowkit as fk\n",
    "    FLOWKIT_AVAILABLE = True\n",
    "    # Configuration FlowKit: format linéaire pour les exports/affichages\n",
    "    # FlowKit utilise pandas en interne, donc pd.set_option s'applique\n",
    "    # Mais on configure aussi les options de logging/affichage si disponibles\n",
    "    try:\n",
    "        import logging\n",
    "        logging.getLogger('flowkit').setLevel(logging.WARNING)  # Moins de logs verbose\n",
    "    except:\n",
    "        pass\n",
    "    print(\"[OK] FlowKit disponible (transformations Logicle précise en 1 fonction)\")\n",
    "except ImportError:\n",
    "    FLOWKIT_AVAILABLE = False\n",
    "    print(\"[!] FlowKit non installé (optionnel): pip install flowkit)\")\n",
    "\n",
    "# FCSWrite pour export FCS\n",
    "try:\n",
    "    import fcswrite\n",
    "    FCSWRITE_AVAILABLE = True\n",
    "    print(\"[OK] FCSWrite disponible (export FCS)\")\n",
    "except ImportError:\n",
    "    FCSWRITE_AVAILABLE = False\n",
    "    print(\"[!] FCSWrite non installé (optionnel): pip install fcswrite\")\n",
    "\n",
    "# Scipy pour statistiques \n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import en haut de fichier des classes utilitaires permettant les transformations des fichiers ainsi que le pre-gating \n",
    "\n",
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    Transformations de données de cytométrie (Logicle, Arcsinh, etc.).\n",
    "    Classe statique réutilisable sans dépendance à l'UI.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_transform(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Arcsinh (inverse hyperbolic sine).\n",
    "        \n",
    "        Args en entrée:\n",
    "            data: Matrice de données (n_cells, n_markers)\n",
    "            cofactor: Facteur de division (5 pour flow cytometry)\n",
    "        \n",
    "        Returns:\n",
    "            Données transformées\n",
    "        \"\"\"\n",
    "        return np.arcsinh(data / cofactor)\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_inverse(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"Inverse de la transformation Arcsinh.\"\"\"\n",
    "        return np.sinh(data) * cofactor\n",
    "    \n",
    "    @staticmethod\n",
    "    def logicle_transform(data: np.ndarray, T: float = 262144.0, M: float = 4.5,\n",
    "                          W: float = 0.5, A: float = 0.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Logicle (biexponentielle).\n",
    "        \n",
    "        Args en entrée:\n",
    "            data: Matrice de données\n",
    "            T: Maximum de l'échelle linéaire (262144 = 2^18)\n",
    "            M: Décades de largeur\n",
    "            W: Linéarisation près de zéro\n",
    "            A: Décades additionnelles (négatifs)\n",
    "        \n",
    "        Returns:\n",
    "            Données transformées\n",
    "        \"\"\"\n",
    "        if FLOWKIT_AVAILABLE:\n",
    "            # Utiliser FlowKit si disponible (plus précis) avec une fonction prédéfinie\n",
    "            try:\n",
    "                xform = fk.transforms.LogicleTransform(T=T, M=M, W=W, A=A)\n",
    "                return xform.apply(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Approximation si FlowKit absent: Arcsinh modifié\n",
    "        w_val = W * np.log10(np.e)\n",
    "        return np.arcsinh(data / (T / (10 ** M))) * (M / np.log(10))\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_transform(data: np.ndarray, base: float = 10.0,\n",
    "                      min_val: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"Transformation logarithmique standard.\"\"\"\n",
    "        data_clipped = np.maximum(data, min_val)\n",
    "        return np.log(data_clipped) / np.log(base)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zscore_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Z-score (moyenne=0, std=1).\"\"\"\n",
    "        mean = np.nanmean(data, axis=0)\n",
    "        std = np.nanstd(data, axis=0)\n",
    "        std[std == 0] = 1  # Éviter division par zéro\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def min_max_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Min-Max [0, 1].\"\"\"\n",
    "        min_val = np.nanmin(data, axis=0)\n",
    "        max_val = np.nanmax(data, axis=0)\n",
    "        range_val = max_val - min_val\n",
    "        range_val[range_val == 0] = 1\n",
    "        return (data - min_val) / range_val\n",
    "\n",
    "\n",
    "class PreGating:\n",
    "    \"\"\"\n",
    "    Pre-gating automatique pour la sélection des populations d'intérêt.\n",
    "    Basé sur FSC/SSC pour exclure les débris et les doublets.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_marker_index(var_names: List[str], patterns: List[str]) -> Optional[int]:\n",
    "        \"\"\"Trouve l'index d'un marqueur parmi les patterns donnés.\"\"\"\n",
    "        var_upper = [v.upper() for v in var_names]\n",
    "        for pattern in patterns:\n",
    "            for i, name in enumerate(var_upper):\n",
    "                if pattern.upper() in name:\n",
    "                    return i\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_viable_cells(X: np.ndarray, var_names: List[str],\n",
    "                          min_percentile: float = 2.0, \n",
    "                          max_percentile: float = 98.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules viables basé sur FSC/SSC.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            min_percentile: Percentile minimum (exclusion débris)\n",
    "            max_percentile: Percentile maximum (exclusion doublets)\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des cellules viables\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        mask = np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Trouver FSC (priorité à FSC-A)\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A', 'FSC-H', 'FSC'])\n",
    "        if fsc_idx is not None:\n",
    "            fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "            fsc_vals = np.where(np.isfinite(fsc_vals), fsc_vals, np.nan)\n",
    "            low = np.nanpercentile(fsc_vals, min_percentile)\n",
    "            high = np.nanpercentile(fsc_vals, max_percentile)\n",
    "            mask &= np.isfinite(fsc_vals) & (fsc_vals >= low) & (fsc_vals <= high)\n",
    "        \n",
    "        # Trouver SSC (priorité à SSC-A)\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "        if ssc_idx is not None:\n",
    "            ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "            ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "            low = np.nanpercentile(ssc_vals, min_percentile)\n",
    "            high = np.nanpercentile(ssc_vals, max_percentile)\n",
    "            mask &= np.isfinite(ssc_vals) & (ssc_vals >= low) & (ssc_vals <= high)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_singlets(X: np.ndarray, var_names: List[str],\n",
    "                      ratio_min: float = 0.6, ratio_max: float = 1.5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les singlets basé sur le ratio FSC-A/FSC-H.\n",
    "        Les doublets ont typiquement un ratio > 1.3-1.5.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            ratio_min: Ratio minimum acceptable\n",
    "            ratio_max: Ratio maximum acceptable\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des singlets\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouvé, pas de gating singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # Valeurs minimum pour éviter division par zéro\n",
    "        min_val = 100\n",
    "        valid_h = fsc_h > min_val\n",
    "        \n",
    "        ratio = np.full(n_cells, np.nan)\n",
    "        ratio[valid_h] = fsc_a[valid_h] / fsc_h[valid_h]\n",
    "        \n",
    "        mask = np.isfinite(ratio) & (ratio >= ratio_min) & (ratio <= ratio_max)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd45_positive(X: np.ndarray, var_names: List[str],\n",
    "                           threshold_percentile: float = 10) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules CD45+ (leucocytes).\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des cellules CD45+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouvé, pas de gating CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45_vals = X[:, cd45_idx].astype(np.float64)\n",
    "        cd45_vals = np.where(np.isfinite(cd45_vals), cd45_vals, np.nan)\n",
    "        \n",
    "        threshold = np.nanpercentile(cd45_vals, threshold_percentile)\n",
    "        \n",
    "        return np.where(np.isnan(cd45_vals), False, cd45_vals > threshold)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd34_blasts(X: np.ndarray, var_names: List[str],\n",
    "                         threshold_percentile: float = 85,\n",
    "                         use_ssc_filter: bool = True,\n",
    "                         ssc_max_percentile: float = 70) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les blastes CD34+ (cellules souches/progénitrices).\n",
    "        \n",
    "        Les blastes sont typiquement:\n",
    "        - CD34 bright (haute expression)\n",
    "        - SSC low (faible granularité)\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            threshold_percentile: Percentile pour définir le seuil CD34+ (ex: 85 = top 15%)\n",
    "            use_ssc_filter: Appliquer aussi un filtre SSC pour enrichir en blastes\n",
    "            ssc_max_percentile: Percentile max de SSC pour blastes (faible granularité)\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des blastes CD34+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        # Chercher CD34 avec différents nommages possibles\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouvé, pas de gating blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34_vals = X[:, cd34_idx].astype(np.float64)\n",
    "        cd34_vals = np.where(np.isfinite(cd34_vals), cd34_vals, np.nan)\n",
    "        \n",
    "        # Seuil CD34+ (prendre les cellules avec haute expression)\n",
    "        threshold_cd34 = np.nanpercentile(cd34_vals, threshold_percentile)\n",
    "        mask_cd34 = np.where(np.isnan(cd34_vals), False, cd34_vals >= threshold_cd34)\n",
    "        \n",
    "        # Optionnel: filtrer aussi par SSC low (blastes = faible granularité)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "                ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "                threshold_ssc = np.nanpercentile(ssc_vals, ssc_max_percentile)\n",
    "                mask_ssc = np.where(np.isnan(ssc_vals), False, ssc_vals <= threshold_ssc)\n",
    "                return mask_cd34 & mask_ssc\n",
    "        \n",
    "        return mask_cd34\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_debris_polygon(X: np.ndarray, var_names: List[str],\n",
    "                            fsc_min: float = None, fsc_max: float = None,\n",
    "                            ssc_min: float = None, ssc_max: float = None,\n",
    "                            auto_percentiles: bool = True,\n",
    "                            min_pct: float = 1.0, max_pct: float = 99.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate rectangulaire/polygonal pour exclure les débris sur FSC-A vs SSC-A.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            fsc_min/fsc_max: Seuils FSC manuels (si auto_percentiles=False)\n",
    "            ssc_min/ssc_max: Seuils SSC manuels (si auto_percentiles=False)\n",
    "            auto_percentiles: Calculer automatiquement les seuils via percentiles\n",
    "            min_pct/max_pct: Percentiles pour auto-calcul\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des cellules (non-débris)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouvé pour gate débris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Calculer les seuils automatiquement si demandé\n",
    "        if auto_percentiles:\n",
    "            fsc_min = np.nanpercentile(fsc_vals, min_pct)\n",
    "            fsc_max = np.nanpercentile(fsc_vals, max_pct)\n",
    "            ssc_min = np.nanpercentile(ssc_vals, min_pct)\n",
    "            ssc_max = np.nanpercentile(ssc_vals, max_pct)\n",
    "        \n",
    "        # Appliquer le gate rectangulaire\n",
    "        mask = (\n",
    "            np.isfinite(fsc_vals) & np.isfinite(ssc_vals) &\n",
    "            (fsc_vals >= fsc_min) & (fsc_vals <= fsc_max) &\n",
    "            (ssc_vals >= ssc_min) & (ssc_vals <= ssc_max)\n",
    "        )\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "print(\"[OK] Classes DataTransformer et PreGating chargées!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715de552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLASSE AutoGating — Gating adaptatif par GMM/KDE\n",
    "# =============================================================================\n",
    "# Inspiré de CytoPy AutonomousGate (sans dépendance MongoDB)\n",
    "# Utilise scikit-learn GaussianMixture pour trouver les \"creux\" réels\n",
    "# entre les populations au lieu de couper à des percentiles fixes.\n",
    "#\n",
    "# Avantages vs PreGating (percentiles):\n",
    "#   - Si un échantillon a 10% de débris → la porte s'adapte automatiquement\n",
    "#   - Si un échantillon est propre → moins de perte de données\n",
    "#   - Pour les doublets: modélise la diagonale FSC-A/FSC-H statistiquement\n",
    "#   - Pour CD45+: trouve le creux bimodal entre CD45- et CD45+\n",
    "# =============================================================================\n",
    "\n",
    "class AutoGating:\n",
    "    \"\"\"\n",
    "    Gating automatique adaptatif basé sur des modèles de mélange gaussien (GMM)\n",
    "    et estimation de densité. Inspiré de CytoPy AutonomousGate.\n",
    "    \n",
    "    Chaque méthode utilise un GMM pour identifier les populations naturelles\n",
    "    dans les données, au lieu de seuils fixes basés sur des percentiles.\n",
    "    \n",
    "    Dépendances: scikit-learn (GaussianMixture, StandardScaler)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_debris(X: np.ndarray, var_names: List[str],\n",
    "                          n_components: int = 3,\n",
    "                          min_cluster_fraction: float = 0.02) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate débris adaptatif par GMM 2D sur FSC-A / SSC-A.\n",
    "        \n",
    "        L'algorithme identifie les clusters naturels dans l'espace FSC/SSC:\n",
    "        - Débris: événements bas en FSC-A (petites particules)\n",
    "        - Cellules: population principale (cluster dominant)  \n",
    "        - Saturés: événements très hauts (optionnel, détecté par BIC)\n",
    "        \n",
    "        Sélection automatique du nombre de composantes par BIC (2 ou 3).\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Noms des marqueurs\n",
    "            n_components: Nombre max de composantes GMM à tester\n",
    "            min_cluster_fraction: Fraction min d'événements pour inclure un cluster\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = cellule viable, False = débris/saturé)\n",
    "        \"\"\"\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouvé pour auto-gate débris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Filtrer les NaN/Inf\n",
    "        valid = np.isfinite(fsc) & np.isfinite(ssc)\n",
    "        data_2d = np.column_stack([fsc[valid], ssc[valid]])\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate débris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Standardiser avant GMM pour meilleure convergence\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(data_2d)\n",
    "        \n",
    "        # Sélection automatique du nombre de composantes par BIC\n",
    "        best_bic = np.inf\n",
    "        best_gmm = None\n",
    "        for n_comp in [2, 3]:\n",
    "            gmm_test = GaussianMixture(\n",
    "                n_components=n_comp, random_state=42,\n",
    "                covariance_type='full', n_init=3, max_iter=200\n",
    "            )\n",
    "            gmm_test.fit(data_scaled)\n",
    "            bic = gmm_test.bic(data_scaled)\n",
    "            if bic < best_bic:\n",
    "                best_bic = bic\n",
    "                best_gmm = gmm_test\n",
    "        \n",
    "        labels = best_gmm.predict(data_scaled)\n",
    "        n_comp = best_gmm.n_components\n",
    "        \n",
    "        # Statistiques par cluster (en espace original)\n",
    "        cluster_sizes = np.bincount(labels, minlength=n_comp)\n",
    "        cluster_fsc_means = np.array([data_2d[labels == i, 0].mean() for i in range(n_comp)])\n",
    "        \n",
    "        # Population principale = plus grand cluster\n",
    "        main_cluster = np.argmax(cluster_sizes)\n",
    "        \n",
    "        # Inclure les clusters avec assez d'événements et un FSC raisonnable\n",
    "        # (exclure les débris = FSC très bas)\n",
    "        mask_valid = np.zeros(valid.sum(), dtype=bool)\n",
    "        fsc_threshold = cluster_fsc_means[main_cluster] * 0.25\n",
    "        \n",
    "        for i in range(n_comp):\n",
    "            fraction = cluster_sizes[i] / len(labels)\n",
    "            if fraction >= min_cluster_fraction and cluster_fsc_means[i] >= fsc_threshold:\n",
    "                mask_valid |= (labels == i)\n",
    "        \n",
    "        # Sécurité: si aucun cluster sélectionné, garder le principal\n",
    "        if not mask_valid.any():\n",
    "            mask_valid = (labels == main_cluster)\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = mask_valid\n",
    "        \n",
    "        n_kept = mask.sum()\n",
    "        print(f\"   [Auto-GMM] {best_gmm.n_components} composantes détectées (BIC={best_bic:.0f})\")\n",
    "        for i in range(n_comp):\n",
    "            status = \"✓\" if mask_valid[labels == i].any() else \"✗\"\n",
    "            print(f\"     {status} Cluster {i}: {cluster_sizes[i]:,} evt, FSC-A moy={cluster_fsc_means[i]:.0f}\")\n",
    "        print(f\"   [Auto-GMM] → Conservés: {n_kept:,} événements\")\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_singlets(X: np.ndarray, var_names: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate singlets adaptatif par GMM sur le ratio FSC-A/FSC-H.\n",
    "        \n",
    "        Les singlets forment une diagonale sur le plot FSC-A vs FSC-H \n",
    "        avec un ratio FSC-A/FSC-H ≈ 1.0.\n",
    "        Les doublets ont un ratio plus élevé (FSC-A augmente mais pas FSC-H).\n",
    "        \n",
    "        Méthode:\n",
    "        1. Calcul du ratio FSC-A / FSC-H pour chaque événement\n",
    "        2. GMM 2 composantes sur le ratio\n",
    "        3. Le composant avec μ le plus proche de 1.0 = singlets\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Noms des marqueurs\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = singlet, False = doublet)\n",
    "        \"\"\"\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouvé pour auto-gate singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # Filtrer: valeurs valides avec FSC-H > seuil minimal (éviter division par 0)\n",
    "        valid = np.isfinite(fsc_a) & np.isfinite(fsc_h) & (fsc_h > 100) & (fsc_a > 100)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Calcul du ratio FSC-A / FSC-H\n",
    "        ratio = fsc_a[valid] / fsc_h[valid]\n",
    "        \n",
    "        # GMM 2 composantes sur le ratio\n",
    "        # Singlets: ratio ≈ 1.0 | Doublets: ratio > ~1.3-1.5\n",
    "        gmm = GaussianMixture(n_components=2, random_state=42, n_init=3)\n",
    "        gmm.fit(ratio.reshape(-1, 1))\n",
    "        \n",
    "        labels = gmm.predict(ratio.reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        \n",
    "        # Le composant singlet = celui avec μ le plus proche de 1.0\n",
    "        singlet_component = np.argmin(np.abs(means - 1.0))\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = (labels == singlet_component)\n",
    "        \n",
    "        n_singlets = mask.sum()\n",
    "        n_doublets = valid.sum() - n_singlets\n",
    "        print(f\"   [Auto-GMM] Ratio FSC-A/FSC-H — 2 composantes: μ={means.round(3)}\")\n",
    "        print(f\"   [Auto-GMM] Singlets (μ≈{means[singlet_component]:.3f}): {n_singlets:,}\")\n",
    "        print(f\"   [Auto-GMM] Doublets rejetés: {n_doublets:,}\")\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_cd45(X: np.ndarray, var_names: List[str],\n",
    "                        n_components: int = 2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate CD45+ adaptatif par GMM 1D.\n",
    "        \n",
    "        Trouve automatiquement le creux bimodal entre CD45- et CD45+\n",
    "        au lieu d'un percentile fixe. Le GMM modélise la distribution\n",
    "        bimodale et assigne chaque événement à la population la plus probable.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Noms des marqueurs\n",
    "            n_components: Nombre de composantes GMM (2 = CD45- / CD45+)\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = CD45+, False = CD45-)\n",
    "        \"\"\"\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        \n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouvé pour auto-gate CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45 = X[:, cd45_idx].astype(np.float64)\n",
    "        valid = np.isfinite(cd45)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # GMM pour séparer CD45- et CD45+\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42, n_init=3)\n",
    "        gmm.fit(cd45[valid].reshape(-1, 1))\n",
    "        \n",
    "        labels = gmm.predict(cd45[valid].reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        \n",
    "        # CD45+ = composant avec la moyenne la plus élevée\n",
    "        pos_component = np.argmax(means)\n",
    "        \n",
    "        # Calculer le seuil approximatif (intersection des 2 gaussiennes)\n",
    "        sorted_means = np.sort(means)\n",
    "        stds = np.sqrt(gmm.covariances_.flatten())\n",
    "        sorted_stds = stds[np.argsort(means)]\n",
    "        # Point d'intersection ≈ moyenne pondérée par les écarts-types\n",
    "        threshold_approx = (sorted_means[0] * sorted_stds[1] + sorted_means[1] * sorted_stds[0]) / (sorted_stds[0] + sorted_stds[1])\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = (labels == pos_component)\n",
    "        \n",
    "        n_pos = mask.sum()\n",
    "        print(f\"   [Auto-GMM] CD45: {n_components} composantes, μ={means.round(0)}\")\n",
    "        print(f\"   [Auto-GMM] Seuil adaptatif ≈ {threshold_approx:.0f} (creux entre populations)\")\n",
    "        print(f\"   [Auto-GMM] CD45+ identifiés: {n_pos:,} ({n_pos/valid.sum()*100:.1f}%)\")\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_cd34(X: np.ndarray, var_names: List[str],\n",
    "                        use_ssc_filter: bool = True,\n",
    "                        n_components: int = 2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate CD34+ blastes adaptatif par GMM.\n",
    "        \n",
    "        Identifie la population CD34 bright (blastes) par GMM au lieu d'un \n",
    "        percentile fixe. Optionnel: combine avec SSC low (blastes = faible granularité).\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Noms des marqueurs\n",
    "            use_ssc_filter: Combiner avec filtre GMM SSC low\n",
    "            n_components: Nombre de composantes GMM\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = blaste CD34+, False = autre)\n",
    "        \"\"\"\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        \n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouvé pour auto-gate blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34 = X[:, cd34_idx].astype(np.float64)\n",
    "        valid = np.isfinite(cd34)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate CD34\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # GMM pour séparer CD34- et CD34+\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42, n_init=3)\n",
    "        gmm.fit(cd34[valid].reshape(-1, 1))\n",
    "        \n",
    "        labels = gmm.predict(cd34[valid].reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        pos_component = np.argmax(means)\n",
    "        \n",
    "        mask_cd34 = np.zeros(n_cells, dtype=bool)\n",
    "        mask_cd34[valid] = (labels == pos_component)\n",
    "        \n",
    "        n_cd34_pos = mask_cd34.sum()\n",
    "        print(f\"   [Auto-GMM] CD34: μ={means.round(0)}, CD34+ cluster = μ={means[pos_component]:.0f}\")\n",
    "        \n",
    "        # Filtre SSC low optionnel (blastes = faible granularité)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc = X[:, ssc_idx].astype(np.float64)\n",
    "                valid_ssc = np.isfinite(ssc)\n",
    "                \n",
    "                if valid_ssc.sum() >= 200:\n",
    "                    gmm_ssc = GaussianMixture(n_components=2, random_state=42, n_init=3)\n",
    "                    gmm_ssc.fit(ssc[valid_ssc].reshape(-1, 1))\n",
    "                    \n",
    "                    labels_ssc = gmm_ssc.predict(ssc[valid_ssc].reshape(-1, 1))\n",
    "                    ssc_means = gmm_ssc.means_.flatten()\n",
    "                    low_ssc_component = np.argmin(ssc_means)\n",
    "                    \n",
    "                    mask_ssc = np.zeros(n_cells, dtype=bool)\n",
    "                    mask_ssc[valid_ssc] = (labels_ssc == low_ssc_component)\n",
    "                    \n",
    "                    combined = mask_cd34 & mask_ssc\n",
    "                    print(f\"   [Auto-GMM] + Filtre SSC low (μ={ssc_means[low_ssc_component]:.0f}): {combined.sum():,} blastes purs\")\n",
    "                    return combined\n",
    "        \n",
    "        print(f\"   [Auto-GMM] CD34+ blastes: {n_cd34_pos:,}\")\n",
    "        return mask_cd34\n",
    "\n",
    "\n",
    "print(\"[OK] Classe AutoGating chargée (gating adaptatif GMM/KDE)\")\n",
    "print(\"     Méthodes: auto_gate_debris, auto_gate_singlets, auto_gate_cd45, auto_gate_cd34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f742d5",
   "metadata": {},
   "source": [
    "## 2. Chargement des Fichiers FCS\n",
    "\n",
    "Chargement des fichiers FCS depuis les dossiers spécifiés. \n",
    "- **Sain (NBM)**: Moelle osseuse normale (référence)\n",
    "- **Pathologique**: Échantillons patients à analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DES CHEMINS\n",
    "# Bien modifier ces chemins selon votre environnement actuel pour le bon chargement des données\n",
    "\n",
    "# Dossier des fichiers sains (référence NBM)\n",
    "HEALTHY_FOLDER = Path(r\"C:\\Users\\Florian Travail\\Documents\\FlowSom\\Data\\BLAST110\\BLAST110\\Petit NBM\")\n",
    "\n",
    "# Dossier des fichiers pathologiques (patients)\n",
    "PATHOLOGICAL_FOLDER = Path(r\"Data/Patho\")\n",
    "\n",
    "# Mode d'analyse: \n",
    "# - True: Comparer Sain vs Pathologique\n",
    "# - False: Analyser uniquement les fichiers pathologiques\n",
    "COMPARE_MODE = True\n",
    "\n",
    "print(f\"Dossier Sain: {HEALTHY_FOLDER}\")\n",
    "print(f\"Dossier Pathologique: {PATHOLOGICAL_FOLDER}\")\n",
    "print(f\"Mode comparaison: {'Activé' if COMPARE_MODE else 'Patient seul'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTIONS DE CHARGEMENT FCS\n",
    "\n",
    "def get_fcs_files(folder: Path) -> List[str]:\n",
    "    \"\"\"Récupère la liste des fichiers FCS dans un dossier. Et renvoie une chaine de caractère\"\"\"\n",
    "    if not folder.exists():\n",
    "        print(f\"[!] Dossier non trouvé: {folder}\")\n",
    "        return []\n",
    "    \n",
    "    files = set()\n",
    "    for f in folder.glob(\"*.fcs\"):\n",
    "        files.add(str(f))\n",
    "    for f in folder.glob(\"*.FCS\"):\n",
    "        files.add(str(f))\n",
    "    \n",
    "    return sorted(list(files))\n",
    "\n",
    "\n",
    "def load_fcs_files(files: List[str], condition: str = \"Unknown\") -> List[ad.AnnData]:\n",
    "    \"\"\"\n",
    "    Charge plusieurs fichiers FCS et retourne une liste d'AnnData.\n",
    "    \n",
    "    Args:\n",
    "        files: Liste des chemins de fichiers FCS\n",
    "        condition: Label de condition (\"Sain\" ou \"Pathologique\")\n",
    "    \n",
    "    Returns:\n",
    "        Liste d'objets AnnData\n",
    "    \"\"\"\n",
    "    # La ligne suivante crée la liste vide pour stocker les AnnData puis boucle sur chaque fichier (éviter le plantage complet)\n",
    "    adatas = []\n",
    "    \n",
    "    for fpath in files:\n",
    "        try:\n",
    "            print(f\"    Chargement: {Path(fpath).name}...\", end=\" \")\n",
    "            \n",
    "            # Lecture avec la fonction de base de flowsom\n",
    "            adata = fs.io.read_FCS(fpath)\n",
    "            \n",
    "            # Ajouter les métadonnées avec un nombre de cellules qui sera égale a la forme de l'objet adata \n",
    "            n_cells = adata.shape[0]\n",
    "            adata.obs['condition'] = condition # Rajoute la condition du fichier : \"Sain\" ou \"Pathologique\"\n",
    "            adata.obs['file_origin'] = Path(fpath).name # Rajoute une observation avec Nom du fichier source (obs = One-dimensional annotation of observations)\n",
    "            \n",
    "            adatas.append(adata) # Ajoute à la liste des AnnData\n",
    "            print(f\"{n_cells:,} cellules\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur: {e}\")\n",
    "    \n",
    "    return adatas\n",
    "\n",
    "# Logs sur le cahrgement des fichiers\n",
    "print(\"=\"*60)\n",
    "print(\"CHARGEMENT DES FICHIERS FCS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fichiers sains en fonction du mode défini\n",
    "healthy_files = get_fcs_files(HEALTHY_FOLDER) if COMPARE_MODE else []\n",
    "print(f\"\\nFichiers Sains (NBM): {len(healthy_files)}\")\n",
    "\n",
    "healthy_adatas = []\n",
    "if healthy_files:\n",
    "    healthy_adatas = load_fcs_files(healthy_files, condition=\"Sain\")\n",
    "\n",
    "# Fichiers sains en fonction du mode défini\n",
    "patho_files = get_fcs_files(PATHOLOGICAL_FOLDER)\n",
    "print(f\"\\nFichiers Pathologiques: {len(patho_files)}\")\n",
    "\n",
    "patho_adatas = []\n",
    "if patho_files:\n",
    "    patho_adatas = load_fcs_files(patho_files, condition=\"Pathologique\")\n",
    "\n",
    "# Résumé\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"RÉSUMÉ DU CHARGEMENT\")\n",
    "print(f\"   Fichiers Sains chargés: {len(healthy_adatas)}\")\n",
    "print(f\"   Fichiers Pathologiques chargés: {len(patho_adatas)}\")\n",
    "# Résumé a.shape = pour chaque AnnData, prend le nombre de cellules (lignes) et concatène si nécessaire\n",
    "total_cells = sum([a.shape[0] for a in healthy_adatas + patho_adatas])\n",
    "print(f\"   Total cellules: {total_cells:,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495d578",
   "metadata": {},
   "source": [
    "## 3. Exploration de la Structure des Données Brutes\n",
    "\n",
    "Avant toute transformation, examinons la structure des données:\n",
    "- Dimensions (cellules x marqueurs)\n",
    "- Noms des colonnes (marqueurs)\n",
    "- Types de données et plages de valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de539adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATÉNATION DES DONNÉES\n",
    "\n",
    "# Combiner tous les AnnData défini dans la cellule précédente\n",
    "all_adatas = healthy_adatas + patho_adatas\n",
    "\n",
    "# Vérification\n",
    "if len(all_adatas) == 0:\n",
    "    raise ValueError(\"[X] Aucun fichier FCS chargé! Vérifiez les chemins.\")\n",
    "\n",
    "# Concaténer avec intersection des colonnes (communes à tous les fichiers) ligne par ligne\n",
    "if len(all_adatas) > 1:\n",
    "    combined_data = ad.concat(all_adatas, join='inner') # join='inner' pour ne garder que les marqueurs communs à changer par outer si on veut garder tous les marqueurs\n",
    "else:\n",
    "    combined_data = all_adatas[0].copy() # Si un seul fichier, juste copier pour éviter de mofifier l'original\n",
    "\n",
    "print(f\"Données combinées: {combined_data.shape}\")\n",
    "print(f\"   → {combined_data.shape[0]:,} cellules\")\n",
    "print(f\"   → {combined_data.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATION DE LA STRUCTURE\n",
    "print(\"=\"*70)\n",
    "print(\"STRUCTURE DES DONNÉES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Liste des marqueurs enregistré dans la varaible var_names = canaux (ici c'est bien un nom de variable)\n",
    "var_names = list(combined_data.var_names)\n",
    "print(f\"\\nMarqueurs ({len(var_names)}):\")\n",
    "for i, name in enumerate(var_names):\n",
    "    print(f\"   [{i:2d}] {name}\")\n",
    "\n",
    "# Identification des types de marqueurs car les recos indiquent d'enelever le scatter pour les analyses de clustering\n",
    "print(\"\\nClassification des marqueurs:\")\n",
    "\n",
    "#Ici le code n for n in var pose la question : \"Est-ce qu'au moins UN des motifs de la liste scatter_patterns se trouve dans le nom actuel n ?\"\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "scatter_markers = [n for n in var_names if any(p in n.upper() for p in scatter_patterns)]\n",
    "fluor_markers = [n for n in var_names if n not in scatter_markers]\n",
    "\n",
    "print(f\"   Scatter/Time: {scatter_markers}\")\n",
    "print(f\"   Fluorescence: {fluor_markers}\")\n",
    "\n",
    "# Statistiques de base\n",
    "print(\"\\nObservations (métadonnées):\")\n",
    "print(combined_data.obs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION EN DATAFRAME POUR EXPLORATION\n",
    "HEADER = True\n",
    "# Extraire la matrice de données\n",
    "X = combined_data.X # Matrice des données (n_cells, n_markers)\n",
    "if hasattr(X, 'toarray'): # Si sparse matrix, convertir en dense pour pandas\n",
    "    X = X.toarray()\n",
    "\n",
    "# Créer un DataFrame pandas pour faciliter l'exploration avec df comme commande pandas classique\n",
    "df_raw = pd.DataFrame(X, columns=var_names) # Crée le DataFrame avec les noms de colonnes \n",
    "df_raw['condition'] = combined_data.obs['condition'].values # Ajoute une colonne condition\n",
    "df_raw['file_origin'] = combined_data.obs['file_origin'].values # Ajoute une colonne file_origin\n",
    "\n",
    "print(\"DataFrame créé pour exploration\")\n",
    "print(f\"   Shape: {df_raw.shape}\")\n",
    "print(\"\\nAperçu des données brutes:\")\n",
    "df_raw.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats descriptives marqueurs de fluorescence et scatter\n",
    "print(\"Statistiques descriptives fluorescence\")\n",
    "display(df_raw[fluor_markers].describe())\n",
    "\n",
    "print(\"\\nStatistiques descriptives scatter\")\n",
    "display(df_raw[scatter_markers].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125cfaf",
   "metadata": {},
   "source": [
    "## 4. Contrôle Qualité des données- Analyse des Distributions\n",
    "\n",
    "Visualisation des distributions brutes pour identifier:\n",
    "- Outliers et valeurs aberrantes\n",
    "- Valeurs négatives (problème de compensation)\n",
    "- NaN/Inf dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérif des varaibles problématiques suite de l'exploration du dataset\n",
    "\n",
    "print(\"ANALYSE DES DONNÉES BRUTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========== MARQUEURS DE FLUORESCENCE ==========\n",
    "print(\"\\nMARQUEURS DE FLUORESCENCE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Vérifier NaN\n",
    "nan_count = df_raw[fluor_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN détecté!\")\n",
    "\n",
    "# Vérifier Inf (valeur infinie) ex sur un post log \n",
    "inf_count = np.isinf(df_raw[fluor_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf détecté!\")\n",
    "else:\n",
    "    for marker, count in inf_count.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# Vérifier valeurs négatives\n",
    "neg_count = (df_raw[fluor_markers] < 0).sum()\n",
    "print(f\"\\n➖ Valeurs négatives par marqueur:\")\n",
    "has_negatives = False\n",
    "for marker, count in neg_count.items():\n",
    "    if count > 0:\n",
    "        has_negatives = True\n",
    "        # Compter le nombre total de cellules valides (non-NaN) pour ce marqueur\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives:\n",
    "    print(\"   [OK] Aucune valeur négative!\")\n",
    "else:\n",
    "    print(\"\\n   [!] Les valeurs négatives peuvent indiquer un problème de compensation\")\n",
    "    print(\"   → La transformation Arcsinh ou Logicle peut les gérer\")\n",
    "\n",
    "# ========== MARQUEURS SCATTER/TIME ==========\n",
    "print(\"\\n\\nMARQUEURS SCATTER/TIME\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Vérifier NaN\n",
    "nan_count_scatter = df_raw[scatter_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count_scatter.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN détecté!\")\n",
    "\n",
    "# Vérifier Inf\n",
    "inf_count_scatter = np.isinf(df_raw[scatter_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf détecté!\")\n",
    "else:\n",
    "    for marker, count in inf_count_scatter.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# Vérifier valeurs négatives\n",
    "neg_count_scatter = (df_raw[scatter_markers] < 0).sum()\n",
    "print(f\"\\n➖ Valeurs négatives par marqueur:\")\n",
    "has_negatives_scatter = False\n",
    "for marker, count in neg_count_scatter.items():\n",
    "    if count > 0:\n",
    "        has_negatives_scatter = True\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives_scatter:\n",
    "    print(\"   [OK] Aucune valeur négative!\")\n",
    "else:\n",
    "    print(\"\\n   ℹ️ Les valeurs négatives dans scatter sont rares mais possibles\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des distributions brutes pour explorer visuellement les données\n",
    "\n",
    "# Sélectionner les marqueurs à visualiser (max 12 pour lisibilité)\n",
    "markers_to_plot = fluor_markers[:12] if len(fluor_markers) > 12 else fluor_markers  # Opérateur ternaire: prendre 12 premiers si > 12, sinon tous\n",
    "\n",
    "n_markers = len(markers_to_plot)  # Nombre de marqueurs à afficher\n",
    "n_cols = 4  # 4 colonnes par ligne\n",
    "n_rows = (n_markers + n_cols - 1) // n_cols  # Calcul nb lignes (division entière arrondie vers le haut)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))  # Créer grille n_rows × n_cols (largeur 20, hauteur 5 par ligne)\n",
    "axes = axes.flatten() if n_markers > 1 else [axes]  # Aplatir tableau 2D en liste 1D pour itération facile\n",
    "\n",
    "for i, marker in enumerate(markers_to_plot):  # Boucle sur chaque marqueur avec index i\n",
    "    ax = axes[i]  # Récupérer le sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Extraire données du marqueur et supprimer NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#89b4fa', alpha=0.7, edgecolor='none')  # Histogramme 100 barres, bleu, 70% opacité\n",
    "    ax.set_title(marker, fontsize=11, fontweight='bold')  # Titre = nom du marqueur\n",
    "    ax.set_xlabel('Valeur brute')  # Label axe X\n",
    "    ax.set_ylabel('Count')  # Label axe Y = nombre de cellules\n",
    "    ax.axvline(0, color='#f38ba8', linestyle='--', alpha=0.5, label='Zéro')  # Ligne verticale rouge à x=0\n",
    "    \n",
    "    # Statistiques min/max dans une boîte en haut à droite\n",
    "    ax.text(0.98, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}',  # Texte avec stats\n",
    "            transform=ax.transAxes, ha='right', va='top', fontsize=8,  # Coordonnées relatives (0-1), alignement\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))  # Boîte grise arrondie semi-transparente\n",
    "\n",
    "# Cacher les axes vides (si 10 marqueurs sur grille 3×4, cacher les 2 dernières cases)\n",
    "for i in range(n_markers, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Brutes des Marqueurs (avant transformation)',  # Titre général\n",
    "             fontsize=14, fontweight='bold', y=1.02)  # Décalé vers le haut\n",
    "plt.tight_layout()  # Ajuster espacement auto\n",
    "plt.show()  # Afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des marqueurs SCATTER/TIME pour exploration visuelle\n",
    "\n",
    "# Sélectionner tous les marqueurs scatter (généralement peu nombreux)\n",
    "scatter_to_plot = scatter_markers  # FSC, SSC, TIME\n",
    "\n",
    "n_scatter = len(scatter_to_plot)  # Nombre de marqueurs scatter\n",
    "n_cols_scatter = min(3, n_scatter)  # Max 3 colonnes pour les scatter\n",
    "n_rows_scatter = (n_scatter + n_cols_scatter - 1) // n_cols_scatter  # Calcul nb lignes\n",
    "\n",
    "fig, axes = plt.subplots(n_rows_scatter, n_cols_scatter, figsize=(18, 6*n_rows_scatter))  # Grille pour scatter (largeur 18, hauteur 6 par ligne)\n",
    "axes = axes.flatten() if n_scatter > 1 else [axes]  # Aplatir en liste 1D\n",
    "\n",
    "for i, marker in enumerate(scatter_to_plot):  # Boucle sur chaque marqueur scatter\n",
    "    ax = axes[i]  # Sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Données sans NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#a6e3a1', alpha=0.7, edgecolor='none')  # Vert pour différencier\n",
    "    ax.set_title(marker, fontsize=12, fontweight='bold')  # Titre\n",
    "    ax.set_xlabel('Valeur brute')  # Axe X\n",
    "    ax.set_ylabel('Count')  # Axe Y\n",
    "    \n",
    "    # Statistiques complètes\n",
    "    ax.text(0.02, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}\\nmean: {data.mean():.0f}\\nmedian: {data.median():.0f}',\n",
    "            transform=ax.transAxes, ha='left', va='top', fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))\n",
    "\n",
    "# Cacher axes vides\n",
    "for i in range(n_scatter, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Scatter/Time (FSC, SSC, TIME)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910ba5b",
   "metadata": {},
   "source": [
    "### Visualisation Interactive avec FlowKit + Bokeh\n",
    "\n",
    "Utilisation native de FlowKit pour visualisations interactives :\n",
    "- **Histogrammes** avec bins/ranges personnalisables\n",
    "- **Scatter plots** interactifs avec zoom/pan\n",
    "- **Contour plots** avec densité\n",
    "- Rendu Bokeh pour l'interactivité (zoom, pan, hover)\n",
    "\n",
    "📚 Documentation : https://flowkit.readthedocs.io/en/latest/index.html\n",
    "https://www.frontiersin.org/journals/immunology/articles/10.3389/fimmu.2021.768541/full\n",
    "\n",
    "---\n",
    "\n",
    "### [!] IMPORTANT : Nomenclature FCS\n",
    "\n",
    "**FlowKit utilise les PnN labels** (noms techniques), pas les PnS (descriptions).\n",
    "\n",
    "- **PnN** = Nom technique (ex: `'Horizon V500-A'`) ← À utiliser\n",
    "- **PnS** = Description bio (ex: `'CD45 KO'`) ← Non utilisable\n",
    "\n",
    "**Exemple :** Pour CD45, utiliser `'Horizon V500-A'` (pas `'CD45 KO'`).\n",
    "\n",
    "Exécutez la cellule suivante pour voir la correspondance PnN ↔ PnS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbddc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation FlowKit et Bokeh + Création du Sample\n",
    "\n",
    "if not FLOWKIT_AVAILABLE:\n",
    "    fk_sample = None\n",
    "else:\n",
    "    try:\n",
    "        from bokeh.plotting import show, output_notebook\n",
    "        from bokeh.io import export_png\n",
    "        output_notebook()\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Utiliser les fichiers FCS déjà identifiés dans le notebook\n",
    "    all_fcs_files = healthy_files + patho_files\n",
    "    \n",
    "    if all_fcs_files:\n",
    "        example_fcs = str(all_fcs_files[0])\n",
    "        fk_sample = fk.Sample(example_fcs)\n",
    "    else:\n",
    "        fk_sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHER LES NOMS DE CANAUX EXACTS DU FICHIER FCS\n",
    "\n",
    "if fk_sample is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"CANAUX DU FICHIER FCS: {Path(example_fcs).name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nPnN Labels ({len(fk_sample.pnn_labels)} canaux) - NOMS À UTILISER DANS FLOWKIT:\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pnn_labels, 1):\n",
    "        print(f\"   [{i:2d}] '{label}'\")\n",
    "    \n",
    "    # Afficher aussi les PnS labels (descriptions) si disponibles\n",
    "    print(f\"\\n\\nPnS Labels (descriptions):\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pns_labels, 1):\n",
    "        print(f\"   [{i:2d}] {label}\")\n",
    "    \n",
    "else:\n",
    "    print(\"[!] FlowKit Sample non chargé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les colonnes FSC et SSC pour les visualisations ultérieures\n",
    "fsc_col = next((c for c in var_names if 'FSC-A' in c.upper() or 'FSC' in c.upper()), None)\n",
    "ssc_col = next((c for c in var_names if 'SSC-A' in c.upper() or 'SSC' in c.upper()), None)\n",
    "\n",
    "if fsc_col:\n",
    "    print(f\"[OK] FSC détecté: {fsc_col}\")\n",
    "if ssc_col:\n",
    "    print(f\"[OK] SSC détecté: {ssc_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae982a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme basique FlowKit (échelle linéaire)\n",
    "# source='raw' = données LINÉAIRES (non transformées)\n",
    "# source='xform' = données transformées (Logicle)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    CHANNEL = 'Horizon V500-A'  # Changer ici le channel à afficher\n",
    "    \n",
    "    # Histogramme en échelle LINÉAIRE (source='raw')\n",
    "    p = fk_sample.plot_histogram(CHANNEL, source='raw', bins=256)\n",
    "    \n",
    "    # Forcer l'échelle linéaire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # Désactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Histogramme {CHANNEL} - Échelle LINÉAIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af808182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot 2D interactif (échelle linéaire)\n",
    "# source='raw' = données LINÉAIRES (non transformées)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    x_channel = 'Horizon V500-A'\n",
    "    y_channel = 'PE-A'\n",
    "    \n",
    "    # Scatter en échelle LINÉAIRE (source='raw')\n",
    "    p = fk_sample.plot_scatter(x_channel, y_channel, source='raw', color_density=True)\n",
    "    \n",
    "    # Forcer l'échelle linéaire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # Désactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Scatter {x_channel} vs {y_channel} - Échelle LINÉAIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme 1D interactif avec Plotly (zoom, pan, hover)\n",
    "# Sélectionner un marqueur à visualiser (modifiable)\n",
    "MARKER_TO_PLOT = 'CD45 KO'  # Changer ici le nom exact du marqueur à visualiser\n",
    "\n",
    "print(f\"Visualisation: {MARKER_TO_PLOT}\")\n",
    "\n",
    "# Extraire les données\n",
    "marker_data = df_raw[MARKER_TO_PLOT].dropna().values\n",
    "\n",
    "# Importer plotly pour l'interactivité\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    \n",
    "    # Configurer le renderer pour Jupyter (évite l'erreur nbformat)\n",
    "    try:\n",
    "        pio.renderers.default = 'notebook'\n",
    "    except:\n",
    "        try:\n",
    "            pio.renderers.default = 'jupyterlab'\n",
    "        except:\n",
    "            pio.renderers.default = 'browser'\n",
    "    \n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non installé - pip install plotly\")\n",
    "\n",
    "if PLOTLY_AVAILABLE:\n",
    "    # Créer une figure avec 4 subplots (2x2)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            f'{MARKER_TO_PLOT} - Brut (Linéaire)',\n",
    "            f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)',\n",
    "            f'{MARKER_TO_PLOT} - Logicle/Arcsinh',\n",
    "            f'{MARKER_TO_PLOT} - Log10'\n",
    "        ),\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # 1. Données brutes\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_data, nbinsx=200, name='Brut',\n",
    "                     marker_color='#89b4fa', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.1f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Arcsinh cofactor=5\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_arcsinh, nbinsx=200, name='Arcsinh (5)',\n",
    "                     marker_color='#a6e3a1', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Logicle ou Arcsinh cofactor=150\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        transform_name = 'Logicle'\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        transform_name = 'Arcsinh (150)'\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_logicle, nbinsx=200, name=transform_name,\n",
    "                     marker_color='#f9e2af', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Log10\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_log, nbinsx=200, name='Log10',\n",
    "                     marker_color='#cba6f7', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Mise en page\n",
    "    fig.update_xaxes(title_text=\"Intensité brute\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Intensité transformée\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Intensité transformée\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Intensité log10\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=2, col=2)\n",
    "    \n",
    "    # Thème sombre et configuration\n",
    "    fig.update_layout(\n",
    "        title_text=f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)',\n",
    "        title_font_size=16,\n",
    "        height=900,\n",
    "        showlegend=False,\n",
    "        template='plotly_dark',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Afficher avec gestion d'erreur\n",
    "    try:\n",
    "        fig.show()\n",
    "        print(f\"\\n[OK] Visualisation interactive générée\")\n",
    "        print(f\"    Utilisez les outils Plotly: Zoom (box select), Pan, Reset, Download\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!] Erreur affichage Plotly: {e}\")\n",
    "        print(\"   → Affichage en HTML dans le notebook...\")\n",
    "        \n",
    "        # Alternative: Afficher le HTML directement dans le notebook\n",
    "        try:\n",
    "            from IPython.display import HTML, display\n",
    "            html_str = fig.to_html(include_plotlyjs='cdn', include_mathjax='cdn')\n",
    "            display(HTML(html_str))\n",
    "            print(f\"   [OK] Graphique affiché en HTML (pleinement interactif)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   [X] Erreur HTML: {e2}\")\n",
    "            # Dernier recours: sauvegarder en fichier\n",
    "            html_file = 'plotly_visualization.html'\n",
    "            fig.write_html(html_file)\n",
    "            print(f\"   → Fichier sauvegardé: {html_file}\")\n",
    "            print(f\"   → Ouvrez ce fichier dans votre navigateur pour l'interactivité complète\")\n",
    "    \n",
    "    print(f\"   Cellules: {len(marker_data):,}\")\n",
    "    print(f\"   Min brut: {marker_data.min():.2f} | Max brut: {marker_data.max():.2f}\")\n",
    "else:\n",
    "    # Fallback matplotlib si Plotly non disponible\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.hist(marker_data, bins=200, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Brut (Linéaire)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité brute')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    ax.hist(marker_arcsinh, bins=200, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité transformée')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    ax = axes[2]\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Logicle', fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=150)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité transformée')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    ax = axes[3]\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    ax.hist(marker_log, bins=200, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Log10', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité transformée (log10)')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    plt.suptitle(f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95bf80",
   "metadata": {},
   "source": [
    "## 5. Pre-Gating: Élimination des Débris, Doublets et Sélection des Populations\n",
    "\n",
    "Application du pre-gating séquentiel en 4 étapes:\n",
    "\n",
    "1. **Gate 1 - Débris (SSC-A vs FSC-A)**: Exclusion des débris et événements hors-limites\n",
    "2. **Gate 2 - Doublets (FSC-H vs FSC-A)**: Exclusion des agrégats cellulaires\n",
    "3. **Gate 3 - Leucocytes CD45+ (CD45 vs SSC-A)**: Sélection des leucocytes — **Gate principal**\n",
    "4. **Gate 4 - Blastes CD34+ (optionnel)**: Sous-sélection CD34 bright + SSC low\n",
    "\n",
    "### Choix du mode de gating : `GATING_MODE`\n",
    "\n",
    "| Mode | Méthode | Avantage | Inconvénient |\n",
    "|------|---------|----------|-------------|\n",
    "| `\"manual\"` | Percentiles fixes (PreGating) | Reproductible, rapide | Seuils arbitraires, perte si échantillon propre |\n",
    "| `\"auto\"` | GMM adaptatif (AutoGating) | Trouve le creux réel entre populations, s'adapte | Dépend de la forme des distributions |\n",
    "\n",
    "### Stratégie de gating classique en cytométrie:\n",
    "```\n",
    "Événements totaux\n",
    "    └── Gate Débris (SSC-A vs FSC-A) → Cellules viables\n",
    "            └── Gate Singlets (FSC-H vs FSC-A) → Cellules individuelles\n",
    "                    └── Gate CD45+ (CD45 vs SSC-A) → Leucocytes\n",
    "                            └── [optionnel] Gate CD34+ (CD34 vs SSC-A) → Blastes\n",
    "```\n",
    "\n",
    "### Paramètres:\n",
    "- **`GATING_MODE`**: `\"manual\"` (percentiles) ou `\"auto\"` (GMM adaptatif)\n",
    "- **`FILTER_BLASTS`**: True = sous-filtrage CD34+ | False = tous les CD45+ conservés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ba663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLICATION DU PRE-GATING SÉQUENTIEL (4 ÉTAPES)\n",
    "# =============================================================================\n",
    "# Stratégie de gating hiérarchique:\n",
    "# 1. SSC-A vs FSC-A → Exclure débris\n",
    "# 2. FSC-H vs FSC-A → Exclure doublets (singlets line)\n",
    "# 3. CD45 vs SSC-A  → Sélectionner leucocytes (GATE PRINCIPAL)\n",
    "# 4. CD34 vs SSC-A  → Sélectionner blastes (optionnel, si FILTER_BLASTS=True)\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== OPTIONS DE PRE-GATING =====================\n",
    "APPLY_PREGATING = True  # Activer/désactiver le pre-gating complet\n",
    "\n",
    "# =================================================================\n",
    "# MODE DE GATING: MANUEL (percentiles) ou AUTOMATIQUE (GMM adaptatif)\n",
    "# =================================================================\n",
    "# \"manual\" : Seuils fixes basés sur les percentiles (classe PreGating)\n",
    "#            → Coupe toujours aux mêmes percentiles, peu importe la distribution\n",
    "#            → Rapide et reproductible, mais perd des données si échantillon propre\n",
    "#\n",
    "# \"auto\"   : Gating adaptatif par modèles de mélange gaussien (classe AutoGating)\n",
    "#            → Trouve le \"creux\" réel entre les populations (débris vs cellules)\n",
    "#            → S'adapte automatiquement: 10% de débris → porte à 10%, pas 2%\n",
    "#            → Pour les doublets: modélise la diagonale FSC-A/FSC-H statistiquement\n",
    "#            → Inspiré de CytoPy AutonomousGate (GMM/KDE)\n",
    "# =================================================================\n",
    "GATING_MODE = \"auto\"  # ← CHANGER ICI: \"manual\" ou \"auto\"\n",
    "\n",
    "# =================================================================\n",
    "# MODE SPÉCIAL: BLASTES CD34+ (PATHO) vs MOELLE NORMALE (SAIN)\n",
    "# =================================================================\n",
    "# Si activé:\n",
    "#   - Fichier PATHOLOGIQUE: Gate complet (débris + doublets + CD45+ + éventuellement CD34+)\n",
    "#   - Fichier SAIN: Gate partiel (débris + doublets + CD45+ UNIQUEMENT, pas de CD34+)\n",
    "# Résultat: Population sélectionnée du patient + Leucocytes normaux de la moelle saine\n",
    "# =================================================================\n",
    "MODE_BLASTES_VS_NORMAL = True  # [!] ACTIVER POUR CE MODE SPÉCIAL\n",
    "\n",
    "# Gate 1: Débris (SSC-A vs FSC-A) - True/False\n",
    "GATE_DEBRIS = True\n",
    "DEBRIS_MIN_PERCENTILE = 1.0   # [Manual] Exclure les 1% les plus bas (débris/bruit)\n",
    "DEBRIS_MAX_PERCENTILE = 99.0  # [Manual] Exclure les 1% les plus hauts (saturés)\n",
    "\n",
    "# Gate 2: Doublets (FSC-H vs FSC-A) - True/False\n",
    "GATE_DOUBLETS = True\n",
    "RATIO_MIN = 0.6   # [Manual] Ratio FSC-A/FSC-H minimum (cellules trop petites)\n",
    "RATIO_MAX = 1.4   # [Manual] Ratio FSC-A/FSC-H maximum (doublets/agrégats)\n",
    "\n",
    "# Gate 3: Leucocytes CD45+ (CD45 vs SSC-A) - GATE PRINCIPAL\n",
    "GATE_CD45 = True  # [!] Sélectionner les leucocytes CD45+\n",
    "CD45_THRESHOLD_PERCENTILE = 10  # [Manual] Seuil CD45+ (exclure les 10% les plus bas)\n",
    "\n",
    "# Gate 4: Blastes CD34+ (CD34 vs SSC-A) - OPTIONNEL (sous-population des CD45+)\n",
    "# =================================================================\n",
    "# FILTER_BLASTS: Contrôle le sous-filtrage CD34+ après le gate CD45+\n",
    "#   - True:  Après CD45+, applique un gate CD34+ → Blastes uniquement\n",
    "#   - False: Conserve TOUS les leucocytes CD45+ pour FlowSOM\n",
    "# =================================================================\n",
    "FILTER_BLASTS = False  # [!] Mettre False pour garder tous les leucocytes CD45+\n",
    "\n",
    "# Paramètres CD34 (utilisés uniquement si FILTER_BLASTS=True)\n",
    "CD34_THRESHOLD_PERCENTILE = 85  # [Manual] Seuil CD34+ (top 15% = percentile 85)\n",
    "USE_SSC_FILTER_FOR_BLASTS = True  # Combiner avec SSC low pour blastes purs\n",
    "SSC_MAX_PERCENTILE_BLASTS = 60  # [Manual] SSC maximum pour blastes (faible granularité)\n",
    "\n",
    "# =================================================================\n",
    "# VALIDATION DES PARAMÈTRES\n",
    "# =================================================================\n",
    "assert GATING_MODE in (\"manual\", \"auto\"), f\"GATING_MODE doit être 'manual' ou 'auto', reçu: '{GATING_MODE}'\"\n",
    "\n",
    "if GATING_MODE == \"auto\" and not SKLEARN_AVAILABLE:\n",
    "    print(\"[!] ATTENTION: scikit-learn requis pour GATING_MODE='auto'\")\n",
    "    print(\"    → Fallback automatique vers mode 'manual'\")\n",
    "    GATING_MODE = \"manual\"\n",
    "\n",
    "# Vérification de cohérence pour MODE_BLASTES_VS_NORMAL\n",
    "if MODE_BLASTES_VS_NORMAL and not COMPARE_MODE:\n",
    "    print(\"[!] ATTENTION: MODE_BLASTES_VS_NORMAL nécessite COMPARE_MODE=True\")\n",
    "    print(\"    → Le mode a besoin de fichiers Sain + Patho pour fonctionner\")\n",
    "    print(\"    → Désactivation automatique du mode différentiel\")\n",
    "    MODE_BLASTES_VS_NORMAL = False\n",
    "\n",
    "# Données avant gating\n",
    "X_raw = combined_data.X\n",
    "if hasattr(X_raw, 'toarray'):\n",
    "    X_raw = X_raw.toarray()\n",
    "n_before = X_raw.shape[0]\n",
    "\n",
    "# Récupérer le vecteur de conditions pour le mode différentiel\n",
    "conditions = combined_data.obs['condition'].values\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" PRE-GATING SÉQUENTIEL - STRATÉGIE EN 4 ÉTAPES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n Événements initiaux: {n_before:,}\")\n",
    "\n",
    "# Affichage du mode de gating\n",
    "mode_label = \"AUTOMATIQUE (GMM adaptatif)\" if GATING_MODE == \"auto\" else \"MANUEL (percentiles fixes)\"\n",
    "print(f\"\\n Mode de gating: {mode_label}\")\n",
    "if GATING_MODE == \"auto\":\n",
    "    print(\"    → Les seuils sont calculés automatiquement par modèle de mélange gaussien\")\n",
    "    print(\"    → Les paramètres [Manual] ci-dessus sont IGNORÉS\")\n",
    "else:\n",
    "    print(\"    → Seuils basés sur les percentiles configurés ci-dessus\")\n",
    "\n",
    "# Affichage mode spécial\n",
    "if MODE_BLASTES_VS_NORMAL:\n",
    "    print(\"\\n [!] MODE BLASTES vs MOELLE NORMALE ACTIVÉ (GATING ASYMÉTRIQUE)\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"     - Patho: Gate complet (débris + doublets + CD45+ + CD34+) → Blastes seuls\")\n",
    "    else:\n",
    "        print(\"     - Patho: Gate (débris + doublets + CD45+) → Leucocytes CD45+ stricts\")\n",
    "    print(\"     - Sain:  Gate (débris + doublets UNIQUEMENT) → Toutes les cellules conservées (pas de gate CD45)\")\n",
    "    n_patho = (conditions == \"Pathologique\").sum()\n",
    "    n_sain = (conditions == \"Sain\").sum()\n",
    "    print(f\"     - Cellules Patho: {n_patho:,}\")\n",
    "    print(f\"     - Cellules Sain: {n_sain:,}\")\n",
    "\n",
    "print(f\"\\n Configuration:\")\n",
    "print(f\"   [Gate 1] Débris (SSC-A/FSC-A):     {'[OK] ACTIVÉ' if GATE_DEBRIS else '[X] DÉSACTIVÉ'}\")\n",
    "print(f\"   [Gate 2] Doublets (FSC-H/FSC-A):   {'[OK] ACTIVÉ' if GATE_DOUBLETS else '[X] DÉSACTIVÉ'}\")\n",
    "if MODE_BLASTES_VS_NORMAL and GATE_CD45:\n",
    "    print(f\"   [Gate 3] Leucocytes CD45+:         [OK] PATHO UNIQUEMENT (gating asymétrique — Sain: pas de gate CD45)\")\n",
    "else:\n",
    "    print(f\"   [Gate 3] Leucocytes CD45+:         {'[OK] ACTIVÉ' if GATE_CD45 else '[X] DÉSACTIVÉ'}\")\n",
    "if FILTER_BLASTS:\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        print(f\"   [Gate 4] Blastes CD34+:            [OK] PATHO UNIQUEMENT (mode différentiel)\")\n",
    "    else:\n",
    "        print(f\"   [Gate 4] Blastes CD34+:            [OK] ACTIVÉ (FILTER_BLASTS=True)\")\n",
    "else:\n",
    "    print(f\"   [Gate 4] Blastes CD34+:            [X] DÉSACTIVÉ (FILTER_BLASTS=False → tous les CD45+ conservés)\")\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    # Initialisation des masques\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    \n",
    "    # ========== GATE 1: DÉBRIS (SSC-A vs FSC-A) ==========\n",
    "    if GATE_DEBRIS:\n",
    "        print(f\"\\n GATE 1: Exclusion des débris (SSC-A vs FSC-A) [{GATING_MODE.upper()}]\")\n",
    "        if GATING_MODE == \"auto\":\n",
    "            mask_debris = AutoGating.auto_gate_debris(X_raw, var_names)\n",
    "        else:\n",
    "            mask_debris = PreGating.gate_debris_polygon(\n",
    "                X_raw, var_names,\n",
    "                auto_percentiles=True,\n",
    "                min_pct=DEBRIS_MIN_PERCENTILE,\n",
    "                max_pct=DEBRIS_MAX_PERCENTILE\n",
    "            )\n",
    "        n_after_debris = mask_debris.sum()\n",
    "        n_excluded_debris = n_before - n_after_debris\n",
    "        if GATING_MODE == \"manual\":\n",
    "            print(f\"   Percentiles: [{DEBRIS_MIN_PERCENTILE}%, {DEBRIS_MAX_PERCENTILE}%]\")\n",
    "        print(f\"   → Conservés: {n_after_debris:,} ({n_after_debris/n_before*100:.1f}%)\")\n",
    "        print(f\"   → Exclus (débris): {n_excluded_debris:,} ({n_excluded_debris/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n GATE 1: Débris - SKIP\")\n",
    "    \n",
    "    # ========== GATE 2: DOUBLETS (FSC-H vs FSC-A) ==========\n",
    "    if GATE_DOUBLETS:\n",
    "        print(f\"\\n GATE 2: Exclusion des doublets (FSC-H vs FSC-A) [{GATING_MODE.upper()}]\")\n",
    "        if GATING_MODE == \"auto\":\n",
    "            mask_singlets = AutoGating.auto_gate_singlets(X_raw, var_names)\n",
    "        else:\n",
    "            mask_singlets = PreGating.gate_singlets(\n",
    "                X_raw, var_names,\n",
    "                ratio_min=RATIO_MIN,\n",
    "                ratio_max=RATIO_MAX\n",
    "            )\n",
    "        # Appliquer sur les cellules déjà filtrées par gate 1\n",
    "        mask_after_g1_g2 = mask_debris & mask_singlets\n",
    "        n_after_singlets = mask_after_g1_g2.sum()\n",
    "        n_doublets = mask_debris.sum() - n_after_singlets\n",
    "        if GATING_MODE == \"manual\":\n",
    "            print(f\"   Ratio FSC-A/FSC-H: [{RATIO_MIN}, {RATIO_MAX}]\")\n",
    "        print(f\"   → Conservés (singlets): {n_after_singlets:,}\")\n",
    "        print(f\"   → Exclus (doublets): {n_doublets:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 2: Doublets - SKIP\")\n",
    "    \n",
    "    # ========== GATE 3: LEUCOCYTES CD45+ (CD45 vs SSC-A) — GATE PRINCIPAL ==========\n",
    "    # LOGIQUE ASYMÉTRIQUE: Pathologique → CD45 strict | Sain → Pas de gate CD45\n",
    "    if GATE_CD45:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n GATE 3: Sélection ASYMÉTRIQUE CD45+ [{GATING_MODE.upper()}]\")\n",
    "            print(\"   → Patho: Gate CD45+ STRICT appliqué (élimination CD45-)\")\n",
    "            print(\"   → Sain:  Gate CD45+ IGNORÉ (toutes cellules conservées — progéniteurs, CD45 low/neg inclus)\")\n",
    "            \n",
    "            # Calculer le masque CD45+ sur TOUTES les données\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd45_full = AutoGating.auto_gate_cd45(X_raw, var_names)\n",
    "            else:\n",
    "                mask_cd45_full = PreGating.gate_cd45_positive(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD45_THRESHOLD_PERCENTILE\n",
    "                )\n",
    "            \n",
    "            # Appliquer le gate CD45 UNIQUEMENT aux cellules pathologiques\n",
    "            mask_patho_cd45 = (conditions == \"Pathologique\")\n",
    "            mask_sain_cd45 = (conditions == \"Sain\")\n",
    "            \n",
    "            # Masque CD45: True pour Sain (on garde tout), mask_cd45_full pour Patho\n",
    "            mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "            mask_cd45[mask_patho_cd45] = mask_cd45_full[mask_patho_cd45]\n",
    "            # Sain: mask_cd45 reste True → aucun filtrage CD45\n",
    "            \n",
    "            # Stats par condition\n",
    "            n_patho_g12 = (mask_patho_cd45 & mask_debris & mask_singlets).sum()\n",
    "            n_patho_cd45_kept = (mask_patho_cd45 & mask_debris & mask_singlets & mask_cd45).sum()\n",
    "            n_patho_cd45_excl = n_patho_g12 - n_patho_cd45_kept\n",
    "            n_sain_g12 = (mask_sain_cd45 & mask_debris & mask_singlets).sum()\n",
    "            \n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD45+: percentile {CD45_THRESHOLD_PERCENTILE} (appliqué PATHO uniquement)\")\n",
    "            print(f\"   → Patho CD45+ conservés: {n_patho_cd45_kept:,} / {n_patho_g12:,} ({n_patho_cd45_kept/max(n_patho_g12,1)*100:.1f}%)\")\n",
    "            print(f\"   → Patho CD45- exclus:    {n_patho_cd45_excl:,}\")\n",
    "            print(f\"   → Sain conservés (100%):  {n_sain_g12:,} / {n_sain_g12:,} (aucun gate CD45)\")\n",
    "            \n",
    "            mask_after_g1_g2_g3 = mask_debris & mask_singlets & mask_cd45\n",
    "            n_after_cd45 = mask_after_g1_g2_g3.sum()\n",
    "            n_cd45_excluded = (mask_debris & mask_singlets).sum() - n_after_cd45\n",
    "            print(f\"   → Total après Gate 3: {n_after_cd45:,} (exclus CD45: {n_cd45_excluded:,} — Patho uniquement)\")\n",
    "        else:\n",
    "            print(f\"\\n GATE 3: Sélection des leucocytes CD45+ (GATE PRINCIPAL) [{GATING_MODE.upper()}]\")\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd45 = AutoGating.auto_gate_cd45(X_raw, var_names)\n",
    "            else:\n",
    "                mask_cd45 = PreGating.gate_cd45_positive(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD45_THRESHOLD_PERCENTILE\n",
    "                )\n",
    "            mask_after_g1_g2_g3 = mask_debris & mask_singlets & mask_cd45\n",
    "            n_after_cd45 = mask_after_g1_g2_g3.sum()\n",
    "            n_cd45_excluded = (mask_debris & mask_singlets).sum() - n_after_cd45\n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD45+: percentile {CD45_THRESHOLD_PERCENTILE} (exclure les {CD45_THRESHOLD_PERCENTILE}% les plus bas)\")\n",
    "            print(f\"   → Leucocytes CD45+ conservés: {n_after_cd45:,}\")\n",
    "            print(f\"   → Exclus (CD45-): {n_cd45_excluded:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 3: CD45+ - SKIP\")\n",
    "    \n",
    "    # ========== GATE 4: BLASTES CD34+ (optionnel, conditionné par FILTER_BLASTS) ==========\n",
    "    if FILTER_BLASTS:\n",
    "        # Mode différentiel: appliquer CD34+ gate UNIQUEMENT sur les cellules pathologiques\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n GATE 4: Sélection DIFFÉRENTIELLE des blastes CD34+ [{GATING_MODE.upper()}]\")\n",
    "            print(\"   → Patho: Gate CD34+ appliqué (blastes uniquement)\")\n",
    "            print(\"   → Sain: Gate CD34+ IGNORÉ (tous les leucocytes CD45+ conservés)\")\n",
    "            \n",
    "            # Calculer le masque CD34+ sur TOUTES les données\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd34_full = AutoGating.auto_gate_cd34(\n",
    "                    X_raw, var_names,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS\n",
    "                )\n",
    "            else:\n",
    "                mask_cd34_full = PreGating.gate_cd34_blasts(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "                    ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "                )\n",
    "            \n",
    "            # Appliquer le gate CD34+ UNIQUEMENT aux cellules pathologiques\n",
    "            mask_patho = (conditions == \"Pathologique\")\n",
    "            mask_sain = (conditions == \"Sain\")\n",
    "            \n",
    "            # Masque CD34: True pour sain (on garde tout), mask_cd34_full pour patho\n",
    "            mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "            mask_cd34[mask_patho] = mask_cd34_full[mask_patho]\n",
    "            \n",
    "            # Stats\n",
    "            n_patho_before = mask_patho.sum()\n",
    "            n_patho_cd34 = (mask_patho & mask_cd34_full).sum()\n",
    "            n_sain_kept = mask_sain.sum()\n",
    "            \n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    print(f\"   Filtre SSC low: ≤ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "            print(f\"   → Patho: {n_patho_cd34:,} blastes / {n_patho_before:,} ({n_patho_cd34/n_patho_before*100:.1f}%)\")\n",
    "            print(f\"   → Sain: {n_sain_kept:,} leucocytes conservés (100%)\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n GATE 4: Sélection des blastes CD34+ (toutes conditions) [{GATING_MODE.upper()}]\")\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd34 = AutoGating.auto_gate_cd34(\n",
    "                    X_raw, var_names,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS\n",
    "                )\n",
    "            else:\n",
    "                mask_cd34 = PreGating.gate_cd34_blasts(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "                    ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "                )\n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    print(f\"   Filtre SSC low: ≤ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 4: Blastes CD34+ - SKIP (FILTER_BLASTS=False)\")\n",
    "        print(\"   → Tous les leucocytes CD45+ seront conservés pour FlowSOM\")\n",
    "    \n",
    "    # ========== MASQUE FINAL COMBINÉ ==========\n",
    "    mask_final = mask_debris & mask_singlets & mask_cd45 & mask_cd34\n",
    "    n_final = mask_final.sum()\n",
    "    n_excluded = n_before - n_final\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\" RÉSUMÉ DU PRE-GATING [{mode_label}]\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Événements initiaux:       {n_before:,}\")\n",
    "    print(f\"   Après Gate 1 (débris):     {mask_debris.sum():,}\")\n",
    "    print(f\"   Après Gate 2 (doublets):   {(mask_debris & mask_singlets).sum():,}\")\n",
    "    print(f\"   Après Gate 3 (CD45+):      {(mask_debris & mask_singlets & mask_cd45).sum():,}\")\n",
    "    \n",
    "    # --- Détails par condition si MODE_BLASTES_VS_NORMAL ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        mask_patho = (conditions == \"Pathologique\")\n",
    "        mask_sain = (conditions == \"Sain\")\n",
    "        n_patho_total = mask_patho.sum()\n",
    "        n_sain_total = mask_sain.sum()\n",
    "        n_patho_final = (mask_final & mask_patho).sum()\n",
    "        n_sain_final = (mask_final & mask_sain).sum()\n",
    "        \n",
    "        print(f\"\\n   {'─'*55}\")\n",
    "        print(f\"   DÉTAIL PAR CONDITION (GATING ASYMÉTRIQUE)\")\n",
    "        print(f\"   {'─'*55}\")\n",
    "        print(f\"   PATHOLOGIQUE (CD45 strict):\")\n",
    "        print(f\"     Initial:                 {n_patho_total:,}\")\n",
    "        print(f\"     Après débris+doublets:   {(mask_patho & mask_debris & mask_singlets).sum():,}\")\n",
    "        print(f\"     Après CD45+ (strict):    {(mask_patho & mask_debris & mask_singlets & mask_cd45).sum():,}\")\n",
    "        print(f\"     Final conservé:          {n_patho_final:,} ({n_patho_final/max(n_patho_total,1)*100:.1f}%)\")\n",
    "        print(f\"   SAIN / NBM (pas de gate CD45):\")\n",
    "        print(f\"     Initial:                 {n_sain_total:,}\")\n",
    "        print(f\"     Après débris+doublets:   {(mask_sain & mask_debris & mask_singlets).sum():,}\")\n",
    "        print(f\"     CD45 gate:               NON APPLIQUÉ (toutes cellules conservées)\")\n",
    "        print(f\"     Final conservé:          {n_sain_final:,} ({n_sain_final/max(n_sain_total,1)*100:.1f}%)\")\n",
    "        print(f\"   {'─'*55}\")\n",
    "    \n",
    "    if FILTER_BLASTS:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"   Après Gate 4 (CD34+ patho): {n_final:,}\")\n",
    "            print(f\"\\n   [MODE BLASTES vs MOELLE NORMALE]\")\n",
    "            print(f\"   Blastes CD34+ (patho):     {n_patho_final:,}\")\n",
    "            print(f\"   Cellules normales (sain):  {n_sain_final:,}\")\n",
    "            print(f\"   ─────────────────────────────────────\")\n",
    "            print(f\"   [OK] TOTAL CONSERVÉ:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   → Prêt pour FlowSOM: Blastes purs + Cellules normales (moelle saine complète)\")\n",
    "        else:\n",
    "            print(f\"   Après Gate 4 (CD34+):      {n_final:,}\")\n",
    "            print(f\"\\n   [OK] ÉVÉNEMENTS CONSERVÉS: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] ÉVÉNEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n   [MODE ASYMÉTRIQUE — LEUCOCYTES vs MOELLE NORMALE]\")\n",
    "            print(f\"   Patho (CD45+ stricts):     {n_patho_final:,} ({n_patho_final/max(n_patho_total,1)*100:.1f}% du fichier patient)\")\n",
    "            print(f\"   Sain (toutes cellules):    {n_sain_final:,} ({n_sain_final/max(n_sain_total,1)*100:.1f}% du fichier NBM)\")\n",
    "            print(f\"   ─────────────────────────────────────\")\n",
    "            print(f\"   [OK] TOTAL CONSERVÉ:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   → Prêt pour FlowSOM: Leucocytes CD45+ (patho) + Moelle normale complète (sain)\")\n",
    "        else:\n",
    "            population_type = \"Leucocytes CD45+\" if GATE_CD45 else \"Cellules\"\n",
    "            print(f\"\\n   [OK] {population_type} CONSERVÉS: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] ÉVÉNEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   → Prêt pour FlowSOM: Population CD45+ complète (pas de sous-sélection CD34+)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n PRE-GATING COMPLÈTEMENT DÉSACTIVÉ\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   → Toutes les {n_before:,} cellules seront conservées\")\n",
    "    mask_final = np.ones(n_before, dtype=bool)\n",
    "    n_final = n_before\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7672363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION PROFESSIONNELLE DES ÉTAPES DE GATING\n",
    "# =============================================================================\n",
    "# Graphiques SÉPARÉS et BIEN DÉFINIS pour chaque étape\n",
    "# Style professionnel type FlowJo/Kaluza\n",
    "# =============================================================================\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "# =============================================================================\n",
    "# FONCTIONS DE VISUALISATION\n",
    "# =============================================================================\n",
    "\n",
    "def format_axis(value, pos):\n",
    "    \"\"\"Format intelligent des axes (K pour milliers, M pour millions)\"\"\"\n",
    "    if abs(value) >= 1e6:\n",
    "        return f'{value/1e6:.1f}M'\n",
    "    elif abs(value) >= 1e3:\n",
    "        return f'{value/1e3:.0f}K'\n",
    "    return f'{value:.0f}'\n",
    "\n",
    "\n",
    "def plot_density(ax, x, y, title, xlabel, ylabel, n_bins=120):\n",
    "    \"\"\"Scatter plot avec densité 2D (style FlowJo)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[valid], y[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'Données insuffisantes', ha='center', va='center', \n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    \n",
    "    # Colormap densité\n",
    "    cmap = LinearSegmentedColormap.from_list('density', \n",
    "        ['#0d0d0d', '#1a1a2e', '#0077b6', '#00b4d8', '#90e0ef', '#f9e2af', '#ffffff'])\n",
    "    \n",
    "    # Histogramme 2D\n",
    "    h = ax.hist2d(x, y, bins=n_bins, \n",
    "                  range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                  cmap=cmap, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(h[3], ax=ax, shrink=0.85)\n",
    "    cbar.ax.tick_params(colors='white', labelsize=9)\n",
    "    cbar.set_label('Densité', color='white', fontsize=11)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "def plot_gating(ax, x, y, mask, title, xlabel, ylabel, \n",
    "                label_in='Conservés', label_out='Exclus', max_pts=100000):\n",
    "    \"\"\"Scatter plot avec overlay gating (vert=conservés, rouge=exclus)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y, mask = x[valid], y[valid], mask[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'Données insuffisantes', ha='center', va='center',\n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Sous-échantillonner\n",
    "    if len(x) > max_pts:\n",
    "        idx = np.random.choice(len(x), max_pts, replace=False)\n",
    "        x, y, mask = x[idx], y[idx], mask[idx]\n",
    "    \n",
    "    # Couleurs\n",
    "    c_out = '#f38ba8'  # Rouge pastel\n",
    "    c_in = '#a6e3a1'   # Vert pastel\n",
    "    \n",
    "    # Tracer exclus (fond)\n",
    "    ax.scatter(x[~mask], y[~mask], s=4, c=c_out, alpha=0.3, \n",
    "               label=label_out, edgecolors='none', rasterized=True)\n",
    "    # Tracer conservés (avant-plan)\n",
    "    ax.scatter(x[mask], y[mask], s=5, c=c_in, alpha=0.5, \n",
    "               label=label_in, edgecolors='none', rasterized=True)\n",
    "    \n",
    "    # Stats\n",
    "    n_tot = len(x)\n",
    "    n_in = mask.sum()\n",
    "    pct = n_in / n_tot * 100 if n_tot > 0 else 0\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(f'{title}\\n{n_in:,} / {n_tot:,} ({pct:.1f}%)', \n",
    "                fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=10, markerscale=3,\n",
    "              facecolor='#313244', labelcolor='white', edgecolor='#45475a')\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    ax.set_xlim(x_lo - (x_hi-x_lo)*0.05, x_hi + (x_hi-x_lo)*0.05)\n",
    "    ax.set_ylim(y_lo - (y_hi-y_lo)*0.05, y_hi + (y_hi-y_lo)*0.05)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GÉNÉRATION DES GRAPHIQUES (UN PAR UN)\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\" VISUALISATION DU PRE-GATING - GRAPHIQUES SÉPARÉS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Indices des canaux\n",
    "    fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "    cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "    \n",
    "    # Sous-échantillonner\n",
    "    n_sample = min(60000, n_before)\n",
    "    np.random.seed(42)\n",
    "    idx_s = np.random.choice(n_before, n_sample, replace=False)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 1 : VUE D'ENSEMBLE (FSC-A vs SSC-A)\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"─\"*50)\n",
    "    print(\" GRAPHIQUE 1 : VUE D'ENSEMBLE\")\n",
    "    print(\"─\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "        \n",
    "        plot_density(ax1, \n",
    "                     X_raw[idx_s, fsc_a_idx], \n",
    "                     X_raw[idx_s, ssc_a_idx],\n",
    "                     f'VUE D\\'ENSEMBLE\\n{n_before:,} événements totaux',\n",
    "                     'FSC-A (Forward Scatter - Taille)',\n",
    "                     'SSC-A (Side Scatter - Granularité)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_01_overview.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] Sauvegardé: gating_01_overview.png\")\n",
    "    else:\n",
    "        print(\"   [!] FSC-A ou SSC-A non trouvé dans les données\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 2 : GATE DÉBRIS (FSC-A vs SSC-A avec overlay)\n",
    "    # =========================================================================\n",
    "    if GATE_DEBRIS:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 2 : GATE DÉBRIS\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "            fig2, ax2 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            plot_gating(ax2,\n",
    "                        X_raw[idx_s, fsc_a_idx],\n",
    "                        X_raw[idx_s, ssc_a_idx],\n",
    "                        mask_debris[idx_s],\n",
    "                        'GATE 1 : Exclusion des Débris',\n",
    "                        'FSC-A (Taille)',\n",
    "                        'SSC-A (Granularité)',\n",
    "                        'Cellules viables', 'Débris/Bruit')\n",
    "            \n",
    "            # Rectangle de gate\n",
    "            fsc_lo = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            fsc_hi = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            ssc_lo = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            ssc_hi = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            \n",
    "            rect = Rectangle((fsc_lo, ssc_lo), fsc_hi-fsc_lo, ssc_hi-ssc_lo,\n",
    "                             fill=False, edgecolor='#f9e2af', linewidth=3, linestyle='--')\n",
    "            ax2.add_patch(rect)\n",
    "            ax2.text(fsc_lo + (fsc_hi-fsc_lo)/2, ssc_hi, ' Zone de sélection',\n",
    "                    ha='center', va='bottom', fontsize=11, color='#f9e2af', fontweight='bold')\n",
    "            \n",
    "            # Stats\n",
    "            n_kept = mask_debris.sum()\n",
    "            print(f\"   → Événements conservés: {n_kept:,} ({n_kept/n_before*100:.1f}%)\")\n",
    "            print(f\"   → Débris exclus: {n_before - n_kept:,}\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('gating_02_debris.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"   [OK] Sauvegardé: gating_02_debris.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 3 : GATE SINGLETS (FSC-H vs FSC-A)\n",
    "    # =========================================================================\n",
    "    if GATE_DOUBLETS:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 3 : GATE SINGLETS (Doublets)\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and fsc_h_idx is not None:\n",
    "            fig3, ax3 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Après gate 1\n",
    "            m_g1 = mask_debris[idx_s]\n",
    "            x3 = X_raw[idx_s, fsc_a_idx][m_g1]\n",
    "            y3 = X_raw[idx_s, fsc_h_idx][m_g1]\n",
    "            m3 = mask_singlets[idx_s][m_g1]\n",
    "            \n",
    "            if len(x3) > 100:\n",
    "                plot_gating(ax3, x3, y3, m3,\n",
    "                            'GATE 2 : Exclusion des Doublets',\n",
    "                            'FSC-A (Area)',\n",
    "                            'FSC-H (Height)',\n",
    "                            'Singlets', 'Doublets/Agrégats')\n",
    "                \n",
    "                # Lignes de ratio\n",
    "                x_range = np.linspace(np.nanpercentile(x3, 1), np.nanpercentile(x3, 99), 100)\n",
    "                ax3.plot(x_range, x_range, 'w-', lw=2, alpha=0.7, label='Ratio 1:1')\n",
    "                ax3.plot(x_range, x_range * RATIO_MIN, '--', color='#f9e2af', lw=2)\n",
    "                ax3.plot(x_range, x_range * RATIO_MAX, '--', color='#f9e2af', lw=2)\n",
    "                ax3.fill_between(x_range, x_range * RATIO_MIN, x_range * RATIO_MAX,\n",
    "                                alpha=0.1, color='#f9e2af')\n",
    "                \n",
    "                # Stats\n",
    "                n_after_g2 = (mask_debris & mask_singlets).sum()\n",
    "                n_doublets = mask_debris.sum() - n_after_g2\n",
    "                print(f\"   → Singlets conservés: {n_after_g2:,}\")\n",
    "                print(f\"   → Doublets exclus: {n_doublets:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_03_singlets.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegardé: gating_03_singlets.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 4 : GATE CD45+ (CD45 vs SSC-A) — GATE PRINCIPAL\n",
    "    # =========================================================================\n",
    "    if GATE_CD45:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 4 : GATE CD45+ (Leucocytes) — GATE PRINCIPAL\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if cd45_idx is not None and ssc_a_idx is not None:\n",
    "            fig4, ax4 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Après gates 1+2\n",
    "            m_g12 = (mask_debris & mask_singlets)[idx_s]\n",
    "            x4 = X_raw[idx_s, cd45_idx][m_g12]\n",
    "            y4 = X_raw[idx_s, ssc_a_idx][m_g12]\n",
    "            m4 = mask_cd45[idx_s][m_g12]\n",
    "            \n",
    "            if len(x4) > 100:\n",
    "                plot_gating(ax4, x4, y4, m4,\n",
    "                            'GATE 3 : Sélection des Leucocytes CD45+',\n",
    "                            'CD45 (Intensité)',\n",
    "                            'SSC-A (Granularité)',\n",
    "                            'Leucocytes CD45+', 'Cellules CD45-')\n",
    "                \n",
    "                # Seuil CD45\n",
    "                cd45_th = np.nanpercentile(X_raw[:, cd45_idx], CD45_THRESHOLD_PERCENTILE)\n",
    "                ax4.axvline(x=cd45_th, color='#89b4fa', lw=3, ls='--')\n",
    "                ax4.text(cd45_th, ax4.get_ylim()[1], f' Seuil CD45+\\n (P{CD45_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#89b4fa', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                n_cd45_kept = (mask_debris & mask_singlets & mask_cd45).sum()\n",
    "                print(f\"   → Leucocytes CD45+ conservés: {n_cd45_kept:,}\")\n",
    "                print(f\"   → CD45- exclus: {(mask_debris & mask_singlets).sum() - n_cd45_kept:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_04_cd45.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegardé: gating_04_cd45.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD45 non trouvé - Gate CD45+ ignoré\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 5 : GATE CD34+ (CD34 vs SSC-A) — OPTIONNEL\n",
    "    # =========================================================================\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 5 : GATE CD34+ (Blastes) — Sous-population des CD45+\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if cd34_idx is not None and ssc_a_idx is not None:\n",
    "            fig_cd34, ax_cd34 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Après gates 1+2+3 (CD45+)\n",
    "            m_g123 = (mask_debris & mask_singlets & mask_cd45)[idx_s]\n",
    "            x5 = X_raw[idx_s, cd34_idx][m_g123]\n",
    "            y5 = X_raw[idx_s, ssc_a_idx][m_g123]\n",
    "            m5 = mask_cd34[idx_s][m_g123]\n",
    "            \n",
    "            if len(x5) > 100:\n",
    "                plot_gating(ax_cd34, x5, y5, m5,\n",
    "                            'GATE 4 : Sélection des Blastes CD34+ (parmi CD45+)',\n",
    "                            'CD34 (Intensité)',\n",
    "                            'SSC-A (Granularité)',\n",
    "                            'Blastes CD34+', 'Autres leucocytes')\n",
    "                \n",
    "                # Seuils\n",
    "                cd34_th = np.nanpercentile(X_raw[:, cd34_idx], CD34_THRESHOLD_PERCENTILE)\n",
    "                ax_cd34.axvline(x=cd34_th, color='#f9e2af', lw=3, ls='--')\n",
    "                ax_cd34.text(cd34_th, ax_cd34.get_ylim()[1], f' Seuil CD34\\n (P{CD34_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#f9e2af', fontweight='bold')\n",
    "                \n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    ssc_th = np.nanpercentile(X_raw[:, ssc_a_idx], SSC_MAX_PERCENTILE_BLASTS)\n",
    "                    ax_cd34.axhline(y=ssc_th, color='#fab387', lw=3, ls='--')\n",
    "                    ax_cd34.text(ax_cd34.get_xlim()[1], ssc_th, f' SSC max (P{SSC_MAX_PERCENTILE_BLASTS}) ',\n",
    "                            va='bottom', ha='right', fontsize=10, color='#fab387', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                print(f\"   → Blastes CD34+ sélectionnés: {n_final:,}\")\n",
    "                print(f\"   → Autres leucocytes exclus: {(mask_debris & mask_singlets & mask_cd45).sum() - n_final:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_05_cd34.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegardé: gating_05_cd34.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD34 non trouvé - Gate CD34+ ignoré\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 6 : COMPARAISON AVANT / APRÈS\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"─\"*50)\n",
    "    print(\" GRAPHIQUE 6 : COMPARAISON AVANT / APRÈS\")\n",
    "    print(\"─\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig5, (ax5a, ax5b) = plt.subplots(1, 2, figsize=(16, 7), facecolor='#1e1e2e')\n",
    "        \n",
    "        # AVANT\n",
    "        cmap_red = LinearSegmentedColormap.from_list('reds', \n",
    "            ['#1a1a2e', '#7f1d1d', '#dc2626', '#fca5a5', '#ffffff'])\n",
    "        \n",
    "        valid = np.isfinite(X_raw[idx_s, fsc_a_idx]) & np.isfinite(X_raw[idx_s, ssc_a_idx])\n",
    "        x_bef = X_raw[idx_s, fsc_a_idx][valid]\n",
    "        y_bef = X_raw[idx_s, ssc_a_idx][valid]\n",
    "        \n",
    "        x_lo, x_hi = np.percentile(x_bef, [0.5, 99.5])\n",
    "        y_lo, y_hi = np.percentile(y_bef, [0.5, 99.5])\n",
    "        \n",
    "        h1 = ax5a.hist2d(x_bef, y_bef, bins=100, \n",
    "                         range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                         cmap=cmap_red, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        ax5a.set_title(f'AVANT Gating\\n{n_before:,} événements', fontsize=14, fontweight='bold', color='white')\n",
    "        ax5a.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_facecolor('#1e1e2e')\n",
    "        ax5a.tick_params(colors='white')\n",
    "        ax5a.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5a.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5a.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        # APRÈS\n",
    "        cmap_green = LinearSegmentedColormap.from_list('greens', \n",
    "            ['#1a1a2e', '#14532d', '#22c55e', '#86efac', '#ffffff'])\n",
    "        \n",
    "        m_final = mask_final[idx_s]\n",
    "        x_aft = X_raw[idx_s, fsc_a_idx][m_final]\n",
    "        y_aft = X_raw[idx_s, ssc_a_idx][m_final]\n",
    "        \n",
    "        if len(x_aft) > 100:\n",
    "            h2 = ax5b.hist2d(x_aft, y_aft, bins=100,\n",
    "                             range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                             cmap=cmap_green, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        \n",
    "        pct_final = n_final / n_before * 100\n",
    "        population_label = \"Blastes CD34+\" if FILTER_BLASTS else \"Leucocytes CD45+\"\n",
    "        ax5b.set_title(f'APRÈS Gating ({population_label})\\n{n_final:,} événements ({pct_final:.1f}%)', \n",
    "                      fontsize=14, fontweight='bold', color='white')\n",
    "        ax5b.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_facecolor('#1e1e2e')\n",
    "        ax5b.tick_params(colors='white')\n",
    "        ax5b.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5b.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5b.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_06_comparison.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] Sauvegardé: gating_06_comparison.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RÉSUMÉ FINAL\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" RÉSUMÉ DU PRE-GATING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ret_g1 = mask_debris.sum() / n_before * 100\n",
    "    ret_g2 = (mask_debris & mask_singlets).sum() / n_before * 100\n",
    "    ret_g3 = (mask_debris & mask_singlets & mask_cd45).sum() / n_before * 100\n",
    "    ret_final = n_final / n_before * 100\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    ┌─────────────────────────────────────────────────────────────┐\n",
    "    │                    STATISTIQUES DE RÉTENTION                │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  Étape                        Cellules        Rétention     │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │   Initial                   {n_before:>10,}        100.0%     │\n",
    "    │  - Gate 1 (Débris)           {mask_debris.sum():>10,}        {ret_g1:>5.1f}%     │\n",
    "    │  - Gate 2 (Doublets)         {(mask_debris & mask_singlets).sum():>10,}        {ret_g2:>5.1f}%     │\n",
    "    │  - Gate 3 (CD45+)            {(mask_debris & mask_singlets & mask_cd45).sum():>10,}        {ret_g3:>5.1f}%     │\"\"\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(f\"    │  - Gate 4 (CD34+)            {n_final:>10,}        {ret_final:>5.1f}%     │\")\n",
    "    print(f\"\"\"    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  [OK] CELLULES CONSERVÉES       {n_final:>10,}        {ret_final:>5.1f}%     │\n",
    "    │  [X] CELLULES EXCLUES          {n_before - n_final:>10,}        {100-ret_final:>5.1f}%     │\n",
    "    └─────────────────────────────────────────────────────────────┘\n",
    "    \"\"\")\n",
    "    \n",
    "    # --- Détail par condition si gating asymétrique ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        _mask_patho = (conditions == \"Pathologique\")\n",
    "        _mask_sain = (conditions == \"Sain\")\n",
    "        _n_patho_tot = _mask_patho.sum()\n",
    "        _n_sain_tot = _mask_sain.sum()\n",
    "        _n_patho_fin = (mask_final & _mask_patho).sum()\n",
    "        _n_sain_fin = (mask_final & _mask_sain).sum()\n",
    "        _ret_patho = _n_patho_fin / max(_n_patho_tot, 1) * 100\n",
    "        _ret_sain = _n_sain_fin / max(_n_sain_tot, 1) * 100\n",
    "        print(f\"\"\"\n",
    "    ┌─────────────────────────────────────────────────────────────┐\n",
    "    │          DÉTAIL GATING ASYMÉTRIQUE PAR CONDITION            │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  PATHOLOGIQUE (CD45 strict appliqué):                       │\n",
    "    │    Initial:          {_n_patho_tot:>10,}                              │\n",
    "    │    Conservé:         {_n_patho_fin:>10,}   ({_ret_patho:>5.1f}%)                   │\n",
    "    │    Gates: Débris + Doublets + CD45+ strict                  │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  SAIN / NBM (PAS de gate CD45):                             │\n",
    "    │    Initial:          {_n_sain_tot:>10,}                              │\n",
    "    │    Conservé:         {_n_sain_fin:>10,}   ({_ret_sain:>5.1f}%)                   │\n",
    "    │    Gates: Débris + Doublets UNIQUEMENT                      │\n",
    "    └─────────────────────────────────────────────────────────────┘\n",
    "        \"\"\")\n",
    "    \n",
    "    population_desc = \"Blastes CD34+ (parmi CD45+)\" if FILTER_BLASTS else (\"Leucocytes CD45+ (patho) + Moelle normale complète (sain)\" if MODE_BLASTES_VS_NORMAL else \"Leucocytes CD45+ (population complète)\")\n",
    "    print(f\" Population finale: {population_desc}\")\n",
    "    \n",
    "    print(\"\\n Fichiers générés:\")\n",
    "    print(\"   - gating_01_overview.png    - Vue d'ensemble\")\n",
    "    print(\"   - gating_02_debris.png      - Gate débris\")\n",
    "    print(\"   - gating_03_singlets.png    - Gate singlets\")\n",
    "    print(\"   - gating_04_cd45.png        - Gate CD45+ (leucocytes)\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"   - gating_05_cd34.png        - Gate CD34+ (blastes)\")\n",
    "    print(\"   - gating_06_comparison.png  - Avant/Après\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n Pre-gating désactivé - Aucun graphique généré\")\n",
    "    print(\"   → Activez APPLY_PREGATING = True pour visualiser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f56b5b",
   "metadata": {},
   "source": [
    "## Visualisation Interactive du Pre-Gating — Style CytoPy\n",
    "\n",
    "Dashboard interactif Plotly pour inspecter chaque étape du gating séquentiel :\n",
    "\n",
    "1. **Sankey Diagram** : Flux des événements à travers les 4 gates (rétention vs exclusion)\n",
    "2. **Density Plots Interactifs** : Scatter 2D avec contours de densité pour chaque gate\n",
    "3. **Histogrammes 1D** : Distribution des marqueurs clés avec seuils GMM annotés\n",
    "4. **Comparaison Patho / Sain** (si `MODE_BLASTES_VS_NORMAL`)\n",
    "\n",
    "> *Inspiré de CytoPy AutonomousGate — tous les graphiques sont interactifs (zoom, hover, export)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION INTERACTIVE STYLE CYTOPY — DASHBOARD DE GATING\n",
    "# =============================================================================\n",
    "# Utilise Plotly pour des graphiques interactifs (zoom, hover, export)\n",
    "# Inspiré de CytoPy AutonomousGate et FlowJo hierarchical gating\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING and PLOTLY_AVAILABLE:\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\" CYTOPY-STYLE GATING DASHBOARD — VISUALISATION INTERACTIVE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # =====================================================================\n",
    "    # 0. PRÉPARATION DES DONNÉES\n",
    "    # =====================================================================\n",
    "    _fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    _fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    _ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    _cd45_idx  = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "    _cd34_idx  = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "\n",
    "    # Sous-échantillonner pour fluidité Plotly\n",
    "    _n_pts = min(40_000, n_before)\n",
    "    np.random.seed(42)\n",
    "    _idx = np.random.choice(n_before, _n_pts, replace=False)\n",
    "\n",
    "    # Masques cumulatifs appliqués séquentiellement\n",
    "    _m_g1     = mask_debris[_idx]\n",
    "    _m_g12    = (mask_debris & mask_singlets)[_idx]\n",
    "    _m_g123   = (mask_debris & mask_singlets & mask_cd45)[_idx]\n",
    "    _m_final  = mask_final[_idx]\n",
    "\n",
    "    # Vecteur de conditions pour le sous-échantillon\n",
    "    _cond_sub = conditions[_idx]\n",
    "    _is_sain_sub = (_cond_sub == \"Sain\")\n",
    "\n",
    "    # Labels de gate pour chaque événement (gating asymétrique)\n",
    "    # ─── LÉGENDE DÉTAILLÉE : sépare Patho conservés / Sain NBM conservés ───\n",
    "    def _gate_label(i):\n",
    "        if not _m_g1[i]:\n",
    "            return \"Débris (exclu G1)\"\n",
    "        if not _m_g12[i]:\n",
    "            return \"Doublet (exclu G2)\"\n",
    "        if not _m_g123[i]:\n",
    "            # En mode asymétrique, seuls les Patho peuvent être exclus par CD45\n",
    "            return \"CD45- Patho (exclu G3)\"\n",
    "        if FILTER_BLASTS and not _m_final[i]:\n",
    "            return \"Non-blaste (exclu G4)\"\n",
    "        # Cellule conservée → distinguer Patho CD45+ vs Sain NBM\n",
    "        if _cond_sub[i] == \"Pathologique\":\n",
    "            return \"CD45+ Patho conservés ✓\"\n",
    "        elif _cond_sub[i] == \"Sain\":\n",
    "            return \"Conservés sains NBM ✓\"\n",
    "        return \"Conservé ✓\"\n",
    "\n",
    "    _labels = np.array([_gate_label(i) for i in range(_n_pts)])\n",
    "\n",
    "    # Palette CytoPy-style (avec catégories détaillées pour conservés)\n",
    "    _color_map = {\n",
    "        \"Débris (exclu G1)\":        \"#636363\",\n",
    "        \"Doublet (exclu G2)\":       \"#e6550d\",\n",
    "        \"CD45- Patho (exclu G3)\":   \"#fd8d3c\",\n",
    "        \"Non-blaste (exclu G4)\":    \"#fdae6b\",\n",
    "        \"CD45+ Patho conservés ✓\":  \"#d62728\",   # rouge – patho conservés\n",
    "        \"Conservés sains NBM ✓\":    \"#2ca02c\",   # vert  – sains NBM conservés\n",
    "        \"Conservé ✓\":               \"#31a354\",   # fallback\n",
    "    }\n",
    "\n",
    "    # =====================================================================\n",
    "    # 1. SANKEY DIAGRAM — FLUX DES ÉVÉNEMENTS\n",
    "    # =====================================================================\n",
    "    print(\"\\n [1/5] Sankey Diagram — Flux du gating hiérarchique\")\n",
    "\n",
    "    _n_total   = n_before\n",
    "    _n_g1_pass = int(mask_debris.sum())\n",
    "    _n_g1_fail = _n_total - _n_g1_pass\n",
    "    _n_g2_pass = int((mask_debris & mask_singlets).sum())\n",
    "    _n_g2_fail = _n_g1_pass - _n_g2_pass\n",
    "    _n_g3_pass = int((mask_debris & mask_singlets & mask_cd45).sum())\n",
    "    _n_g3_fail = _n_g2_pass - _n_g3_pass\n",
    "    _n_g4_pass = int(n_final)\n",
    "    _n_g4_fail = _n_g3_pass - _n_g4_pass\n",
    "\n",
    "    _sankey_labels = [\n",
    "        f\"Événements<br>totaux<br>{_n_total:,}\",              # 0\n",
    "        f\"Gate 1<br>Débris<br>{_n_g1_pass:,}\",                # 1\n",
    "        f\"Débris<br>exclus<br>{_n_g1_fail:,}\",                # 2\n",
    "        f\"Gate 2<br>Singlets<br>{_n_g2_pass:,}\",              # 3\n",
    "        f\"Doublets<br>exclus<br>{_n_g2_fail:,}\",              # 4\n",
    "        f\"Gate 3<br>CD45+ (Patho)<br>{_n_g3_pass:,}\",         # 5\n",
    "        f\"CD45- Patho<br>exclus<br>{_n_g3_fail:,}\",           # 6\n",
    "    ]\n",
    "\n",
    "    _src  = [0, 0, 1, 1, 3, 3]\n",
    "    _tgt  = [1, 2, 3, 4, 5, 6]\n",
    "    _vals = [_n_g1_pass, _n_g1_fail, _n_g2_pass, _n_g2_fail, _n_g3_pass, _n_g3_fail]\n",
    "    _link_colors = [\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(99,99,99,0.3)\",\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(230,85,13,0.3)\",\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(253,141,60,0.3)\",\n",
    "    ]\n",
    "\n",
    "    if FILTER_BLASTS:\n",
    "        _sankey_labels.append(f\"Gate 4<br>CD34+<br>{_n_g4_pass:,}\")   # 7\n",
    "        _sankey_labels.append(f\"Non-blastes<br>exclus<br>{_n_g4_fail:,}\")  # 8\n",
    "        _src  += [5, 5]\n",
    "        _tgt  += [7, 8]\n",
    "        _vals += [_n_g4_pass, _n_g4_fail]\n",
    "        _link_colors += [\"rgba(49,163,84,0.4)\", \"rgba(253,174,107,0.3)\"]\n",
    "        _final_label = f\"Population<br>finale<br>{_n_g4_pass:,}\"\n",
    "        _sankey_labels.append(_final_label)  # 9\n",
    "        _src.append(7)\n",
    "        _tgt.append(9)\n",
    "        _vals.append(_n_g4_pass)\n",
    "        _link_colors.append(\"rgba(49,163,84,0.6)\")\n",
    "    else:\n",
    "        _final_label = f\"Population<br>finale<br>{_n_g3_pass:,}\"\n",
    "        _sankey_labels.append(_final_label)  # 7\n",
    "        _src.append(5)\n",
    "        _tgt.append(7)\n",
    "        _vals.append(_n_g3_pass)\n",
    "        _link_colors.append(\"rgba(49,163,84,0.6)\")\n",
    "\n",
    "    _node_colors = [\"#4a90d9\"] + [\"#31a354\", \"#636363\"] * 1 + \\\n",
    "                   [\"#31a354\", \"#e6550d\", \"#31a354\", \"#fd8d3c\"]\n",
    "    if FILTER_BLASTS:\n",
    "        _node_colors += [\"#31a354\", \"#fdae6b\", \"#2ca02c\"]\n",
    "    else:\n",
    "        _node_colors += [\"#2ca02c\"]\n",
    "\n",
    "    fig_sankey = go.Figure(go.Sankey(\n",
    "        arrangement=\"snap\",\n",
    "        node=dict(\n",
    "            pad=20,\n",
    "            thickness=25,\n",
    "            line=dict(color=\"#333\", width=1),\n",
    "            label=_sankey_labels,\n",
    "            color=_node_colors[:len(_sankey_labels)],\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=_src,\n",
    "            target=_tgt,\n",
    "            value=_vals,\n",
    "            color=_link_colors,\n",
    "        ),\n",
    "    ))\n",
    "    fig_sankey.update_layout(\n",
    "        title=dict(\n",
    "            text=\"<b>Gating Hierarchy — Flux des Événements</b>\",\n",
    "            font=dict(size=18),\n",
    "        ),\n",
    "        font=dict(size=13, color=\"#222\"),\n",
    "        paper_bgcolor=\"#fafafa\",\n",
    "        height=450,\n",
    "        margin=dict(l=20, r=20, t=60, b=20),\n",
    "    )\n",
    "    fig_sankey.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 2. DENSITY SCATTER PLOTS — CHAQUE GATE\n",
    "    # =====================================================================\n",
    "    print(\" [2/5] Density Scatter Plots — Gating séquentiel\")\n",
    "\n",
    "    _gate_plots = []\n",
    "\n",
    "    # --- Gate 1 : FSC-A vs SSC-A (Débris) ---\n",
    "    if GATE_DEBRIS and _fsc_a_idx is not None and _ssc_a_idx is not None:\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 1 — Débris (SSC-A vs FSC-A)\",\n",
    "            \"x\": X_raw[_idx, _fsc_a_idx],\n",
    "            \"y\": X_raw[_idx, _ssc_a_idx],\n",
    "            \"mask\": _m_g1,\n",
    "            \"xlabel\": \"FSC-A (Taille)\",\n",
    "            \"ylabel\": \"SSC-A (Granularité)\",\n",
    "            \"label_in\": \"Cellules viables\",\n",
    "            \"label_out\": \"Débris\",\n",
    "        })\n",
    "\n",
    "    # --- Gate 2 : FSC-H vs FSC-A (Doublets) — sur les survivants de G1 ---\n",
    "    if GATE_DOUBLETS and _fsc_a_idx is not None and _fsc_h_idx is not None:\n",
    "        _g1_ok = _m_g1\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 2 — Doublets (FSC-H vs FSC-A) [après G1]\",\n",
    "            \"x\": X_raw[_idx, _fsc_a_idx][_g1_ok],\n",
    "            \"y\": X_raw[_idx, _fsc_h_idx][_g1_ok],\n",
    "            \"mask\": mask_singlets[_idx][_g1_ok],\n",
    "            \"xlabel\": \"FSC-A (Area)\",\n",
    "            \"ylabel\": \"FSC-H (Height)\",\n",
    "            \"label_in\": \"Singlets\",\n",
    "            \"label_out\": \"Doublets\",\n",
    "        })\n",
    "\n",
    "    # --- Gate 3 : CD45 vs SSC-A (Leucocytes) — sur les survivants de G1+G2 ---\n",
    "    # En mode asymétrique: affiche UNIQUEMENT les cellules Patho (les Sain ne sont pas gatées CD45)\n",
    "    if GATE_CD45 and _cd45_idx is not None and _ssc_a_idx is not None:\n",
    "        _g12_ok = _m_g12\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            # Filtre: montrer seulement les cellules Patho après G1+G2\n",
    "            _patho_g12 = _g12_ok & (_cond_sub == \"Pathologique\")\n",
    "            _gate_plots.append({\n",
    "                \"title\": \"Gate 3 — CD45+ PATHO seul (Sain: pas de gate CD45)\",\n",
    "                \"x\": X_raw[_idx, _cd45_idx][_patho_g12],\n",
    "                \"y\": X_raw[_idx, _ssc_a_idx][_patho_g12],\n",
    "                \"mask\": mask_cd45[_idx][_patho_g12],\n",
    "                \"xlabel\": \"CD45 (Intensité)\",\n",
    "                \"ylabel\": \"SSC-A (Granularité)\",\n",
    "                \"label_in\": \"CD45+ Patho (conservés)\",\n",
    "                \"label_out\": \"CD45− Patho (exclus)\",\n",
    "            })\n",
    "        else:\n",
    "            _gate_plots.append({\n",
    "                \"title\": \"Gate 3 — CD45+ Leucocytes (CD45 vs SSC-A) [après G1+G2]\",\n",
    "                \"x\": X_raw[_idx, _cd45_idx][_g12_ok],\n",
    "                \"y\": X_raw[_idx, _ssc_a_idx][_g12_ok],\n",
    "                \"mask\": mask_cd45[_idx][_g12_ok],\n",
    "                \"xlabel\": \"CD45 (Intensité)\",\n",
    "                \"ylabel\": \"SSC-A (Granularité)\",\n",
    "                \"label_in\": \"Leucocytes CD45+\",\n",
    "                \"label_out\": \"CD45−\",\n",
    "            })\n",
    "\n",
    "    # --- Gate 4 : CD34 vs SSC-A (Blastes) — si activé ---\n",
    "    if FILTER_BLASTS and _cd34_idx is not None and _ssc_a_idx is not None:\n",
    "        _g123_ok = _m_g123\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 4 — CD34+ Blastes (CD34 vs SSC-A) [après G1+G2+G3]\",\n",
    "            \"x\": X_raw[_idx, _cd34_idx][_g123_ok],\n",
    "            \"y\": X_raw[_idx, _ssc_a_idx][_g123_ok],\n",
    "            \"mask\": mask_cd34[_idx][_g123_ok],\n",
    "            \"xlabel\": \"CD34 (Intensité)\",\n",
    "            \"ylabel\": \"SSC-A (Granularité)\",\n",
    "            \"label_in\": \"Blastes CD34+\",\n",
    "            \"label_out\": \"Autres leucocytes\",\n",
    "        })\n",
    "\n",
    "    # Générer chaque subplot avec Plotly\n",
    "    n_gates = len(_gate_plots)\n",
    "    if n_gates > 0:\n",
    "        fig_gates = make_subplots(\n",
    "            rows=1, cols=n_gates,\n",
    "            subplot_titles=[g[\"title\"] for g in _gate_plots],\n",
    "            horizontal_spacing=0.06,\n",
    "        )\n",
    "\n",
    "        for col_i, gp in enumerate(_gate_plots, 1):\n",
    "            _x, _y, _mk = gp[\"x\"], gp[\"y\"], gp[\"mask\"]\n",
    "            _valid = np.isfinite(_x) & np.isfinite(_y)\n",
    "            _x, _y, _mk = _x[_valid], _y[_valid], _mk[_valid]\n",
    "\n",
    "            # Exclus (fond, semi-transparent)\n",
    "            fig_gates.add_trace(go.Scattergl(\n",
    "                x=_x[~_mk], y=_y[~_mk],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=\"#d62728\", opacity=0.25),\n",
    "                name=gp[\"label_out\"],\n",
    "                legendgroup=f\"g{col_i}_out\",\n",
    "                showlegend=(col_i == 1),\n",
    "                hovertemplate=f\"{gp['xlabel']}: %{{x:.0f}}<br>{gp['ylabel']}: %{{y:.0f}}<br>{gp['label_out']}<extra></extra>\",\n",
    "            ), row=1, col=col_i)\n",
    "\n",
    "            # Conservés (avant-plan)\n",
    "            fig_gates.add_trace(go.Scattergl(\n",
    "                x=_x[_mk], y=_y[_mk],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=\"#2ca02c\", opacity=0.4),\n",
    "                name=gp[\"label_in\"],\n",
    "                legendgroup=f\"g{col_i}_in\",\n",
    "                showlegend=(col_i == 1),\n",
    "                hovertemplate=f\"{gp['xlabel']}: %{{x:.0f}}<br>{gp['ylabel']}: %{{y:.0f}}<br>{gp['label_in']}<extra></extra>\",\n",
    "            ), row=1, col=col_i)\n",
    "\n",
    "            # Axes labels\n",
    "            fig_gates.update_xaxes(title_text=gp[\"xlabel\"], row=1, col=col_i)\n",
    "            fig_gates.update_yaxes(title_text=gp[\"ylabel\"], row=1, col=col_i)\n",
    "\n",
    "        fig_gates.update_layout(\n",
    "            title=\"<b>Gating Séquentiel — Density Scatter (Plotly interactif)</b>\",\n",
    "            height=500,\n",
    "            width=min(500 * n_gates, 2000),\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(\n",
    "                orientation=\"h\", yanchor=\"bottom\", y=-0.22,\n",
    "                xanchor=\"center\", x=0.5,\n",
    "                font=dict(size=12),\n",
    "            ),\n",
    "            margin=dict(t=80, b=100),\n",
    "        )\n",
    "        fig_gates.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 3. HISTOGRAMMES 1D — DISTRIBUTIONS DES MARQUEURS CLÉS\n",
    "    # =====================================================================\n",
    "    print(\" [3/5] Histogrammes 1D — Distributions avec seuils GMM\")\n",
    "\n",
    "    _hist_data = []\n",
    "    if _fsc_a_idx is not None:\n",
    "        _hist_data.append((\"FSC-A\", X_raw[:, _fsc_a_idx], None))\n",
    "    if _cd45_idx is not None:\n",
    "        _hist_data.append((\"CD45\", X_raw[:, _cd45_idx], \"cd45\"))\n",
    "    if FILTER_BLASTS and _cd34_idx is not None:\n",
    "        _hist_data.append((\"CD34\", X_raw[:, _cd34_idx], \"cd34\"))\n",
    "\n",
    "    if _hist_data:\n",
    "        fig_hist = make_subplots(\n",
    "            rows=1, cols=len(_hist_data),\n",
    "            subplot_titles=[h[0] for h in _hist_data],\n",
    "            horizontal_spacing=0.08,\n",
    "        )\n",
    "\n",
    "        for hi, (name, vals, marker_type) in enumerate(_hist_data, 1):\n",
    "            _v = vals[np.isfinite(vals)]\n",
    "\n",
    "            # Avant gating (toutes cellules)\n",
    "            fig_hist.add_trace(go.Histogram(\n",
    "                x=_v, nbinsx=200, name=f\"{name} (tous)\",\n",
    "                marker_color=\"rgba(100,100,100,0.4)\",\n",
    "                showlegend=(hi == 1),\n",
    "                legendgroup=\"all\",\n",
    "            ), row=1, col=hi)\n",
    "\n",
    "            # Après gating (conservés)\n",
    "            _v_kept = vals[mask_final & np.isfinite(vals)]\n",
    "            fig_hist.add_trace(go.Histogram(\n",
    "                x=_v_kept, nbinsx=200, name=f\"{name} (conservés)\",\n",
    "                marker_color=\"rgba(44,160,44,0.6)\",\n",
    "                showlegend=(hi == 1),\n",
    "                legendgroup=\"kept\",\n",
    "            ), row=1, col=hi)\n",
    "\n",
    "            # Annoter le seuil GMM si pertinent\n",
    "            if marker_type == \"cd45\" and GATE_CD45:\n",
    "                _cd45_vals = X_raw[:, _cd45_idx]\n",
    "                _cd45_clean = _cd45_vals[np.isfinite(_cd45_vals)]\n",
    "                _th = np.percentile(_cd45_clean, CD45_THRESHOLD_PERCENTILE)\n",
    "                fig_hist.add_vline(\n",
    "                    x=_th, line_dash=\"dash\", line_color=\"#d62728\", line_width=2,\n",
    "                    annotation_text=f\"Seuil CD45+\", annotation_position=\"top right\",\n",
    "                    row=1, col=hi,\n",
    "                )\n",
    "            elif marker_type == \"cd34\" and FILTER_BLASTS:\n",
    "                _cd34_vals = X_raw[:, _cd34_idx]\n",
    "                _cd34_clean = _cd34_vals[np.isfinite(_cd34_vals)]\n",
    "                _th34 = np.percentile(_cd34_clean, CD34_THRESHOLD_PERCENTILE)\n",
    "                fig_hist.add_vline(\n",
    "                    x=_th34, line_dash=\"dash\", line_color=\"#ff7f0e\", line_width=2,\n",
    "                    annotation_text=f\"Seuil CD34+\", annotation_position=\"top right\",\n",
    "                    row=1, col=hi,\n",
    "                )\n",
    "\n",
    "            fig_hist.update_xaxes(title_text=name, row=1, col=hi)\n",
    "            fig_hist.update_yaxes(title_text=\"Nombre d'événements\", row=1, col=hi)\n",
    "\n",
    "        fig_hist.update_layout(\n",
    "            title=\"<b>Distributions 1D — Avant / Après Gating (seuils annotés)</b>\",\n",
    "            barmode=\"overlay\",\n",
    "            height=400,\n",
    "            width=min(550 * len(_hist_data), 1800),\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f5f5f5\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, xanchor=\"center\", x=0.5),\n",
    "            margin=dict(t=70, b=90),\n",
    "        )\n",
    "        fig_hist.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 4. COMPARAISON PATHO vs SAIN (si MODE_BLASTES_VS_NORMAL)\n",
    "    # =====================================================================\n",
    "    if MODE_BLASTES_VS_NORMAL and _cd45_idx is not None and _ssc_a_idx is not None:\n",
    "        print(\" [4/5] Comparaison Patho vs Sain — CD45 vs SSC-A (GATING ASYMÉTRIQUE)\")\n",
    "\n",
    "        _cond = conditions[_idx]\n",
    "\n",
    "        fig_comp = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=[\n",
    "                \"Pathologique (CD45 strict appliqué)\",\n",
    "                \"Sain / NBM (PAS de gate CD45)\"\n",
    "            ],\n",
    "            horizontal_spacing=0.08,\n",
    "        )\n",
    "\n",
    "        for ci, (cond_label, color_kept, color_all) in enumerate([\n",
    "            (\"Pathologique\", \"#d62728\", \"#ffcccc\"),\n",
    "            (\"Sain\", \"#2ca02c\", \"#ccffcc\"),\n",
    "        ], 1):\n",
    "            _sel = (_cond == cond_label)\n",
    "            _sel_final = _sel & _m_final\n",
    "\n",
    "            _xc = X_raw[_idx, _cd45_idx]\n",
    "            _yc = X_raw[_idx, _ssc_a_idx]\n",
    "\n",
    "            # Toutes les cellules de cette condition (fond)\n",
    "            fig_comp.add_trace(go.Scattergl(\n",
    "                x=_xc[_sel], y=_yc[_sel],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=color_all, opacity=0.15),\n",
    "                name=f\"{cond_label} (tous)\",\n",
    "                showlegend=True,\n",
    "            ), row=1, col=ci)\n",
    "\n",
    "            # Cellules conservées\n",
    "            fig_comp.add_trace(go.Scattergl(\n",
    "                x=_xc[_sel_final], y=_yc[_sel_final],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2.5, color=color_kept, opacity=0.5),\n",
    "                name=f\"{cond_label} (conservés)\",\n",
    "                showlegend=True,\n",
    "            ), row=1, col=ci)\n",
    "\n",
    "            _n_all = _sel.sum()\n",
    "            _n_kept = _sel_final.sum()\n",
    "            _gate_info = \"CD45 strict\" if cond_label == \"Pathologique\" else \"Pas de gate CD45\"\n",
    "            fig_comp.update_xaxes(title_text=\"CD45\", row=1, col=ci)\n",
    "            fig_comp.update_yaxes(title_text=\"SSC-A\", row=1, col=ci)\n",
    "\n",
    "            _xax = \"x domain\" if ci == 1 else f\"x{ci} domain\"\n",
    "            _yax = \"y domain\" if ci == 1 else f\"y{ci} domain\"\n",
    "            fig_comp.add_annotation(\n",
    "                text=f\"<b>{_n_kept:,} / {_n_all:,} ({_n_kept/_n_all*100:.1f}%)<br>{_gate_info}</b>\" if _n_all > 0 else \"N/A\",\n",
    "                xref=_xax, yref=_yax,\n",
    "                x=0.5, y=0.02, showarrow=False,\n",
    "                font=dict(size=13, color=color_kept),\n",
    "                bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "                bordercolor=color_kept, borderwidth=1, borderpad=4,\n",
    "            )\n",
    "\n",
    "        fig_comp.update_layout(\n",
    "            title=\"<b>Gating Asymétrique — Patho (CD45 strict) vs Sain (pas de CD45)</b>\",\n",
    "            height=500,\n",
    "            width=1100,\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.2, xanchor=\"center\", x=0.5),\n",
    "            margin=dict(t=70, b=90),\n",
    "        )\n",
    "        fig_comp.show()\n",
    "    else:\n",
    "        print(\" [4/5] Comparaison Patho vs Sain — SKIP (MODE_BLASTES_VS_NORMAL désactivé)\")\n",
    "\n",
    "    # =====================================================================\n",
    "    # 5. OVERVIEW FINAL — FSC-A vs SSC-A coloré par gate d'exclusion\n",
    "    # =====================================================================\n",
    "    if _fsc_a_idx is not None and _ssc_a_idx is not None:\n",
    "        print(\" [5/5] Overview Final — Coloré par étape d'exclusion\")\n",
    "\n",
    "        _xo = X_raw[_idx, _fsc_a_idx]\n",
    "        _yo = X_raw[_idx, _ssc_a_idx]\n",
    "\n",
    "        fig_overview = go.Figure()\n",
    "\n",
    "        # Tracer chaque catégorie d'exclusion dans l'ordre\n",
    "        # ─── Inclut désormais les conservés Patho et Sain séparément ───\n",
    "        _order = [\n",
    "            \"Débris (exclu G1)\",\n",
    "            \"Doublet (exclu G2)\",\n",
    "            \"CD45- Patho (exclu G3)\",\n",
    "            \"Non-blaste (exclu G4)\",\n",
    "            \"CD45+ Patho conservés ✓\",\n",
    "            \"Conservés sains NBM ✓\",\n",
    "            \"Conservé ✓\",          # fallback si condition inconnue\n",
    "        ]\n",
    "        for cat in _order:\n",
    "            _sel_cat = (_labels == cat)\n",
    "            if _sel_cat.sum() == 0:\n",
    "                continue\n",
    "            _is_kept = cat.endswith(\"✓\")\n",
    "            fig_overview.add_trace(go.Scattergl(\n",
    "                x=_xo[_sel_cat], y=_yo[_sel_cat],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=2.5,\n",
    "                    color=_color_map.get(cat, \"#999\"),\n",
    "                    opacity=0.55 if _is_kept else 0.25,\n",
    "                ),\n",
    "                name=f\"{cat} ({_sel_cat.sum():,})\",\n",
    "                hovertemplate=f\"FSC-A: %{{x:.0f}}<br>SSC-A: %{{y:.0f}}<br>{cat}<extra></extra>\",\n",
    "            ))\n",
    "\n",
    "        fig_overview.update_layout(\n",
    "            title=\"<b>Overview — Événements colorés par étape d'exclusion</b>\",\n",
    "            xaxis_title=\"FSC-A (Taille)\",\n",
    "            yaxis_title=\"SSC-A (Granularité)\",\n",
    "            height=600,\n",
    "            width=900,\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=12),\n",
    "            legend=dict(\n",
    "                title=\"Catégorie\",\n",
    "                font=dict(size=12),\n",
    "                bgcolor=\"rgba(255,255,255,0.9)\",\n",
    "                bordercolor=\"#ccc\", borderwidth=1,\n",
    "            ),\n",
    "            margin=dict(t=70, b=50),\n",
    "        )\n",
    "        fig_overview.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # RÉSUMÉ TABULAIRE\n",
    "    # =====================================================================\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" RÉSUMÉ GATING — TABLEAU INTERACTIF\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    _summary_df = pd.DataFrame({\n",
    "        \"Étape\": [\"Initial\", \"Gate 1 (Débris)\", \"Gate 2 (Doublets)\",\n",
    "                  \"Gate 3 (CD45+ Patho only)\" if MODE_BLASTES_VS_NORMAL else \"Gate 3 (CD45+)\"] + ([\"Gate 4 (CD34+)\"] if FILTER_BLASTS else []) + [\"Population finale\"],\n",
    "        \"Événements\": [\n",
    "            n_before,\n",
    "            int(mask_debris.sum()),\n",
    "            int((mask_debris & mask_singlets).sum()),\n",
    "            int((mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "        ] + ([int(n_final)] if FILTER_BLASTS else []) + [int(n_final)],\n",
    "        \"Rétention (%)\": [\n",
    "            100.0,\n",
    "            mask_debris.sum() / n_before * 100,\n",
    "            (mask_debris & mask_singlets).sum() / n_before * 100,\n",
    "            (mask_debris & mask_singlets & mask_cd45).sum() / n_before * 100,\n",
    "        ] + ([n_final / n_before * 100] if FILTER_BLASTS else []) + [n_final / n_before * 100],\n",
    "        \"Exclus\": [\n",
    "            0,\n",
    "            n_before - int(mask_debris.sum()),\n",
    "            int(mask_debris.sum()) - int((mask_debris & mask_singlets).sum()),\n",
    "            int((mask_debris & mask_singlets).sum()) - int((mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "        ] + ([int((mask_debris & mask_singlets & mask_cd45).sum()) - int(n_final)] if FILTER_BLASTS else []) + [n_before - int(n_final)],\n",
    "    })\n",
    "    _summary_df[\"Rétention (%)\"] = _summary_df[\"Rétention (%)\"].round(1)\n",
    "\n",
    "    fig_table = go.Figure(go.Table(\n",
    "        header=dict(\n",
    "            values=[f\"<b>{c}</b>\" for c in _summary_df.columns],\n",
    "            fill_color=\"#4a90d9\",\n",
    "            font=dict(color=\"white\", size=13),\n",
    "            align=\"center\", height=35,\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[_summary_df[c] for c in _summary_df.columns],\n",
    "            fill_color=[\n",
    "                [\"#f9f9f9\", \"#fff\", \"#f9f9f9\", \"#fff\"] +\n",
    "                ([\"#f9f9f9\"] if FILTER_BLASTS else []) + [\"#d4edda\"]\n",
    "            ] * 4,\n",
    "            font=dict(size=12),\n",
    "            align=\"center\", height=30,\n",
    "            format=[None, \",\", \".1f\", \",\"],\n",
    "        ),\n",
    "    ))\n",
    "    fig_table.update_layout(\n",
    "        title=\"<b>Résumé du Pre-Gating — Statistiques par étape</b>\",\n",
    "        height=50 + 35 * (len(_summary_df) + 1),\n",
    "        width=800,\n",
    "        margin=dict(l=20, r=20, t=50, b=10),\n",
    "    )\n",
    "    fig_table.show()\n",
    "\n",
    "    # --- Tableau par condition si gating asymétrique ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        _mp = (conditions == \"Pathologique\")\n",
    "        _ms = (conditions == \"Sain\")\n",
    "        _cond_df = pd.DataFrame({\n",
    "            \"Condition\": [\"Pathologique\", \"Sain / NBM\"],\n",
    "            \"Initial\": [int(_mp.sum()), int(_ms.sum())],\n",
    "            \"Après Débris+Doublets\": [\n",
    "                int((_mp & mask_debris & mask_singlets).sum()),\n",
    "                int((_ms & mask_debris & mask_singlets).sum()),\n",
    "            ],\n",
    "            \"Après Gate CD45\": [\n",
    "                int((_mp & mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "                f\"{int((_ms & mask_debris & mask_singlets).sum())} (non appliqué)\",\n",
    "            ],\n",
    "            \"Final\": [int((mask_final & _mp).sum()), int((mask_final & _ms).sum())],\n",
    "            \"Rétention (%)\": [\n",
    "                round((mask_final & _mp).sum() / max(_mp.sum(), 1) * 100, 1),\n",
    "                round((mask_final & _ms).sum() / max(_ms.sum(), 1) * 100, 1),\n",
    "            ],\n",
    "            \"Logique CD45\": [\"CD45 STRICT\", \"AUCUN gate CD45\"],\n",
    "        })\n",
    "\n",
    "        fig_table_cond = go.Figure(go.Table(\n",
    "            header=dict(\n",
    "                values=[f\"<b>{c}</b>\" for c in _cond_df.columns],\n",
    "                fill_color=\"#6a0dad\",\n",
    "                font=dict(color=\"white\", size=13),\n",
    "                align=\"center\", height=35,\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[_cond_df[c] for c in _cond_df.columns],\n",
    "                fill_color=[[\"#ffe6e6\", \"#e6ffe6\"]] * len(_cond_df.columns),\n",
    "                font=dict(size=12),\n",
    "                align=\"center\", height=30,\n",
    "            ),\n",
    "        ))\n",
    "        fig_table_cond.update_layout(\n",
    "            title=\"<b>Gating Asymétrique — Détail par Condition (Patho: CD45 strict / Sain: pas de CD45)</b>\",\n",
    "            height=150,\n",
    "            width=1100,\n",
    "            margin=dict(l=20, r=20, t=50, b=10),\n",
    "        )\n",
    "        fig_table_cond.show()\n",
    "\n",
    "    print(\"\\n [OK] Dashboard CytoPy-style généré avec succès !\")\n",
    "    print(\"     → Utilisez la souris pour zoomer, survoler, et exporter (icône 📷)\")\n",
    "\n",
    "elif not PLOTLY_AVAILABLE:\n",
    "    print(\"[!] Plotly requis pour le dashboard interactif.\")\n",
    "    print(\"    → pip install plotly\")\n",
    "else:\n",
    "    print(\"[!] Pre-gating désactivé — Aucun dashboard généré.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CRÉATION DU SECOND ANNDATA (avec ou sans gating)\n",
    "# =============================================================================\n",
    "\n",
    "# Créer l'AnnData filtré (ou copie complète si pas de gating)\n",
    "combined_gated = combined_data[mask_final].copy()\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    print(f\"[OK] AnnData après gating: {combined_gated.shape}\")\n",
    "    print(f\"   → {combined_gated.shape[0]:,} cellules conservées\")\n",
    "    print(f\"   → {combined_gated.shape[1]} marqueurs\")\n",
    "else:\n",
    "    print(f\"[OK] AnnData créé (sans pre-gating): {combined_gated.shape}\")\n",
    "    print(f\"   → {combined_gated.shape[0]:,} cellules (toutes conservées)\")\n",
    "    print(f\"   → {combined_gated.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0e40a",
   "metadata": {},
   "source": [
    "## 6. Transformation des Données (Arcsinh / Logicle)\n",
    "\n",
    "Les données brutes de cytométrie nécessitent une transformation pour:\n",
    "- Gérer les valeurs négatives (compensation)\n",
    "- Compresser la plage dynamique\n",
    "- Améliorer la visualisation des populations faiblement exprimées\n",
    "\n",
    "### Transformations disponibles:\n",
    "- **Arcsinh (cofactor=5)**: Recommandé pour flow cytometry\n",
    "- **Logicle**: Transformation biexponentielle (standard ISAC)\n",
    "- **Log10**: Transformation logarithmique simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DE LA TRANSFORMATION\n",
    "\n",
    "# Choix de la transformation\n",
    "TRANSFORM_TYPE = \"none\"  # Options: \"arcsinh\", \"logicle\", \"log10\", \"none\"\n",
    "COFACTOR = 5  # Pour arcsinh: 5 (flow)\n",
    "\n",
    "# Appliquer uniquement aux marqueurs de fluorescence (pas FSC/SSC/Time)\n",
    "APPLY_TO_SCATTER = False\n",
    "\n",
    "print(\"TRANSFORMATION DES DONNÉES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Type: {TRANSFORM_TYPE.upper()}\")\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"   Cofacteur: {COFACTOR}\")\n",
    "print(f\"   Appliquer au scatter: {'Oui' if APPLY_TO_SCATTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION DE LA TRANSFORMATION\n",
    "\n",
    "# Extraire les données\n",
    "X_gated = combined_gated.X\n",
    "if hasattr(X_gated, 'toarray'):\n",
    "    X_gated = X_gated.toarray()\n",
    "\n",
    "# Copie pour transformation\n",
    "X_transformed = X_gated.copy()\n",
    "\n",
    "# Déterminer les indices des colonnes à transformer\n",
    "if APPLY_TO_SCATTER:\n",
    "    cols_to_transform = list(range(len(var_names)))\n",
    "else:\n",
    "    # Exclure FSC, SSC, Time\n",
    "    scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "    cols_to_transform = [i for i, name in enumerate(var_names) \n",
    "                         if not any(p in name.upper() for p in scatter_patterns)]\n",
    "\n",
    "print(f\"\\nColonnes à transformer: {len(cols_to_transform)}/{len(var_names)}\")\n",
    "\n",
    "# Appliquer la transformation\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"\\n Application Arcsinh (cofactor={COFACTOR})...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.arcsinh_transform(\n",
    "        X_gated[:, cols_to_transform], cofactor=COFACTOR\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"logicle\":\n",
    "    print(\"\\n Application Logicle...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.logicle_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"log10\":\n",
    "    print(\"\\n Application Log10...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.log_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"\\n[!] Pas de transformation appliquée\")\n",
    "\n",
    "# Vérifier les résultats\n",
    "print(f\"\\n[OK] Transformation terminée!\")\n",
    "print(f\"   Plage avant: [{X_gated[:, cols_to_transform].min():.2f}, {X_gated[:, cols_to_transform].max():.2f}]\")\n",
    "print(f\"   Plage après: [{X_transformed[:, cols_to_transform].min():.2f}, {X_transformed[:, cols_to_transform].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec484f1",
   "metadata": {},
   "source": [
    "## 7. Comparaison Avant/Après Transformation\n",
    "\n",
    "Visualisation côte à côte des distributions pour valider l'effet de la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAISON DISTRIBUTIONS AVANT/APRÈS\n",
    "\n",
    "# Sélectionner quelques marqueurs représentatifs\n",
    "markers_compare = [var_names[i] for i in cols_to_transform[:6]]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(markers_compare), figsize=(4*len(markers_compare), 8))\n",
    "\n",
    "for i, marker in enumerate(markers_compare):\n",
    "    col_idx = var_names.index(marker)\n",
    "    \n",
    "    # Avant transformation\n",
    "    ax = axes[0, i]\n",
    "    data_before = X_gated[:, col_idx]\n",
    "    ax.hist(data_before, bins=80, color='#f38ba8', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{marker}\\n(Brut)', fontsize=10, fontweight='bold')\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('AVANT\\nCount', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Après transformation\n",
    "    ax = axes[1, i]\n",
    "    data_after = X_transformed[:, col_idx]\n",
    "    ax.hist(data_after, bins=80, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{TRANSFORM_TYPE.upper()}', fontsize=10)\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('APRÈS\\nCount', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Comparaison des Distributions: Brut vs {TRANSFORM_TYPE.upper()} (cofactor={COFACTOR})', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DE DIFFÉRENTS COFACTEURS (pour tuning)\n",
    "\n",
    "print(\"COMPARAISON DES COFACTEURS ARCSINH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sélectionner un marqueur représentatif\n",
    "test_marker = markers_compare[0]\n",
    "test_idx = var_names.index(test_marker)\n",
    "test_data = X_gated[:, test_idx]\n",
    "\n",
    "# Tester différents cofacteurs\n",
    "cofactors = [1, 5, 50, 150, 500]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cofactors)+1, figsize=(4*(len(cofactors)+1), 4))\n",
    "\n",
    "# Données brutes\n",
    "ax = axes[0]\n",
    "ax.hist(test_data, bins=80, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "ax.set_title('Brut\\n(pas de transfo)', fontsize=10, fontweight='bold')\n",
    "ax.set_xlabel(test_marker)\n",
    "\n",
    "# Transformations avec différents cofacteurs\n",
    "for i, cof in enumerate(cofactors):\n",
    "    ax = axes[i+1]\n",
    "    transformed = DataTransformer.arcsinh_transform(test_data, cofactor=cof)\n",
    "    ax.hist(transformed, bins=80, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'Arcsinh\\ncofactor={cof}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(test_marker)\n",
    "\n",
    "plt.suptitle(f'Impact du Cofacteur sur la Distribution ({test_marker})', \n",
    "             fontsize=13, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087eb83",
   "metadata": {},
   "source": [
    "## 8. Préparation des Données pour FlowSOM\n",
    "\n",
    "Sélection des colonnes pour le clustering:\n",
    "- Exclusion des paramètres scatter (FSC, SSC) et Time\n",
    "- Conservation uniquement des marqueurs de fluorescence\n",
    "- Nettoyage final (NaN/Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÉLECTION DES COLONNES POUR FLOWSOM\n",
    "\n",
    "# Option: exclure FSC/SSC/Time\n",
    "EXCLUDE_SCATTER = True\n",
    "\n",
    "# Identifier les colonnes à utiliser\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "\n",
    "if EXCLUDE_SCATTER:\n",
    "    cols_to_use = [i for i, name in enumerate(var_names) \n",
    "                   if not any(p in name.upper() for p in scatter_patterns)]\n",
    "else:\n",
    "    cols_to_use = list(range(len(var_names)))\n",
    "\n",
    "used_markers = [var_names[i] for i in cols_to_use]\n",
    "\n",
    "print(\"COLONNES POUR FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Exclure scatter: {'Oui' if EXCLUDE_SCATTER else 'Non'}\")\n",
    "print(f\"   Colonnes sélectionnées: {len(cols_to_use)}/{len(var_names)}\")\n",
    "print(f\"\\nMarqueurs utilisés:\")\n",
    "for i, marker in enumerate(used_markers):\n",
    "    print(f\"   [{i:2d}] {marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTRAGE PAR TYPE D'ÉCHANTILLON (-A ou -H) - OPTIONNEL\n",
    "# =============================================================================\n",
    "# Ce filtre permet de sélectionner uniquement les cellules provenant de fichiers\n",
    "# dont le nom contient \"-A\" (ex: échantillons de type A) ou \"-H\" (ex: échantillons de type H)\n",
    "# \n",
    "# [!] IMPORTANT: Si tes fichiers n'ont pas ces suffixes, désactive le filtrage!\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== ACTIVATION DU FILTRAGE =====================\n",
    "APPLY_FILE_FILTERING = False  # [!] Mettre True pour activer, False pour DÉSACTIVER\n",
    "\n",
    "# OPTIONS DE FILTRAGE (utilisées seulement si APPLY_FILE_FILTERING = True)\n",
    "INCLUDE_A = True   # Inclure les échantillons avec \"-A\" dans le nom\n",
    "INCLUDE_H = False  # Inclure les échantillons avec \"-H\" dans le nom\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FILTRAGE PAR TYPE D'ÉCHANTILLON (-A / -H)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Filtrage activé: {'[OK] OUI' if APPLY_FILE_FILTERING else '[X] NON (toutes les données conservées)'}\")\n",
    "\n",
    "if APPLY_FILE_FILTERING:\n",
    "    print(f\"   Inclure -A: {'[OK] Oui' if INCLUDE_A else '[X] Non'}\")\n",
    "    print(f\"   Inclure -H: {'[OK] Oui' if INCLUDE_H else '[X] Non'}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES/MARQUEURS AVEC -A ET -H\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ANALYSE DES COLONNES (MARQUEURS) PAR TYPE -A / -H\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Récupérer les noms de colonnes\n",
    "all_columns = list(combined_gated.var_names)\n",
    "\n",
    "# Séparer les colonnes avec -A, -H, ou autres\n",
    "cols_with_A = [col for col in all_columns if \"-A\" in col.upper()]\n",
    "cols_with_H = [col for col in all_columns if \"-H\" in col.upper()]\n",
    "cols_other = [col for col in all_columns if \"-A\" not in col.upper() and \"-H\" not in col.upper()]\n",
    "\n",
    "print(f\"\\n🔵 COLONNES avec '-A' ({len(cols_with_A)}):\")\n",
    "for col in cols_with_A:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "print(f\"\\n[+] COLONNES avec '-H' ({len(cols_with_H)}):\")\n",
    "for col in cols_with_H:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "print(f\"\\n⚪ COLONNES sans -A/-H ({len(cols_other)}):\")\n",
    "for col in cols_other:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTRAGE DES FICHIERS (si activé)\n",
    "# =============================================================================\n",
    "if APPLY_FILE_FILTERING:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES FICHIERS PAR TYPE -A / -H\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Afficher les fichiers disponibles avant filtrage\n",
    "    print(f\"\\n Fichiers disponibles AVANT filtrage:\")\n",
    "    file_counts_before = combined_gated.obs['file_origin'].value_counts()\n",
    "\n",
    "    files_A = []\n",
    "    files_H = []\n",
    "    files_other = []\n",
    "\n",
    "    for fname, count in file_counts_before.items():\n",
    "        has_A = \"-A\" in fname.upper()\n",
    "        has_H = \"-H\" in fname.upper()\n",
    "        type_label = []\n",
    "        if has_A:\n",
    "            type_label.append(\"-A\")\n",
    "            files_A.append((fname, count))\n",
    "        if has_H:\n",
    "            type_label.append(\"-H\")\n",
    "            files_H.append((fname, count))\n",
    "        if not has_A and not has_H:\n",
    "            files_other.append((fname, count))\n",
    "        type_str = \", \".join(type_label) if type_label else \"(autre)\"\n",
    "        print(f\"   {fname}: {count:,} cellules [{type_str}]\")\n",
    "\n",
    "    print(f\"\\n Résumé des fichiers:\")\n",
    "    print(f\"   Fichiers -A: {len(files_A)} ({sum(c for _, c in files_A):,} cellules)\")\n",
    "    print(f\"   Fichiers -H: {len(files_H)} ({sum(c for _, c in files_H):,} cellules)\")\n",
    "    print(f\"   Fichiers autres: {len(files_other)} ({sum(c for _, c in files_other):,} cellules)\")\n",
    "\n",
    "    # Créer le masque de filtrage\n",
    "    file_names = combined_gated.obs['file_origin'].values.astype(str)\n",
    "\n",
    "    # Initialiser le masque à False (aucun échantillon inclus par défaut)\n",
    "    mask_A = np.zeros(len(file_names), dtype=bool)\n",
    "    mask_H = np.zeros(len(file_names), dtype=bool)\n",
    "\n",
    "    # Appliquer les filtres\n",
    "    for i, fname in enumerate(file_names):\n",
    "        fname_upper = fname.upper()\n",
    "        if \"-A\" in fname_upper:\n",
    "            mask_A[i] = True\n",
    "        if \"-H\" in fname_upper:\n",
    "            mask_H[i] = True\n",
    "\n",
    "    # Combiner selon les options\n",
    "    if INCLUDE_A and INCLUDE_H:\n",
    "        filter_mask = mask_A | mask_H\n",
    "        filter_description = \"échantillons -A ET -H\"\n",
    "    elif INCLUDE_A and not INCLUDE_H:\n",
    "        filter_mask = mask_A\n",
    "        filter_description = \"échantillons -A uniquement\"\n",
    "    elif not INCLUDE_A and INCLUDE_H:\n",
    "        filter_mask = mask_H\n",
    "        filter_description = \"échantillons -H uniquement\"\n",
    "    else:\n",
    "        print(\"\\n[!] ATTENTION: INCLUDE_A et INCLUDE_H sont tous les deux False!\")\n",
    "        print(\"   → Garde tous les échantillons par défaut\")\n",
    "        filter_mask = np.ones(len(file_names), dtype=bool)\n",
    "        filter_description = \"tous les échantillons (aucun filtre)\"\n",
    "\n",
    "    # [!] VÉRIFICATION: Si aucune cellule ne correspond, désactiver le filtrage\n",
    "    n_matching = filter_mask.sum()\n",
    "    if n_matching == 0:\n",
    "        print(\"\\n\" + \"!\"*70)\n",
    "        print(\"[!] ATTENTION: AUCUN FICHIER NE CORRESPOND AU FILTRE!\")\n",
    "        print(\"!\"*70)\n",
    "        print(f\"   → Tes fichiers n'ont pas de suffixe -A ou -H\")\n",
    "        print(f\"   → FILTRAGE DÉSACTIVÉ AUTOMATIQUEMENT\")\n",
    "        print(f\"   → Toutes les cellules sont conservées\")\n",
    "        filter_mask = np.ones(len(file_names), dtype=bool)\n",
    "        filter_description = \"AUCUN (auto-désactivé - pas de fichiers correspondants)\"\n",
    "\n",
    "    # Appliquer le filtre\n",
    "    n_before = combined_gated.shape[0]\n",
    "    combined_gated_filtered = combined_gated[filter_mask].copy()\n",
    "    n_after = combined_gated_filtered.shape[0]\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(f\" RÉSULTAT DU FILTRAGE ({filter_description})\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Cellules avant filtrage: {n_before:,}\")\n",
    "    print(f\"   Cellules après filtrage: {n_after:,}\")\n",
    "    if n_before > 0:\n",
    "        print(f\"   Cellules exclues: {n_before - n_after:,} ({100*(n_before-n_after)/n_before:.1f}%)\")\n",
    "\n",
    "    # Afficher les fichiers restants après filtrage\n",
    "    if n_after > 0:\n",
    "        print(f\"\\n Fichiers CONSERVÉS après filtrage:\")\n",
    "        file_counts_after = combined_gated_filtered.obs['file_origin'].value_counts()\n",
    "        for fname, count in file_counts_after.items():\n",
    "            print(f\"   [OK] {fname}: {count:,} cellules\")\n",
    "\n",
    "    # Mettre à jour X_transformed\n",
    "    X_transformed = X_transformed[filter_mask]\n",
    "    combined_gated = combined_gated_filtered\n",
    "\n",
    "else:\n",
    "    # FILTRAGE DÉSACTIVÉ - garder toutes les données\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES FICHIERS DÉSACTIVÉ\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   → Toutes les {combined_gated.shape[0]:,} cellules sont conservées\")\n",
    "    \n",
    "    # Afficher quand même les fichiers disponibles\n",
    "    print(f\"\\n Fichiers disponibles:\")\n",
    "    file_counts = combined_gated.obs['file_origin'].value_counts()\n",
    "    for fname, count in file_counts.items():\n",
    "        has_A = \"-A\" in fname.upper()\n",
    "        has_H = \"-H\" in fname.upper()\n",
    "        type_label = []\n",
    "        if has_A:\n",
    "            type_label.append(\"-A\")\n",
    "        if has_H:\n",
    "            type_label.append(\"-H\")\n",
    "        type_str = \", \".join(type_label) if type_label else \"(pas de suffixe -A/-H)\"\n",
    "        print(f\"   {fname}: {count:,} cellules [{type_str}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES UTILISÉES POUR FLOWSOM\n",
    "# =============================================================================\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\" COLONNES DISPONIBLES POUR FLOWSOM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nToutes les colonnes ({len(list(combined_gated.var_names))}):\")\n",
    "for i, col in enumerate(combined_gated.var_names):\n",
    "    marker_type = \"\"\n",
    "    if \"-A\" in col.upper():\n",
    "        marker_type = \" [Type -A]\"\n",
    "    elif \"-H\" in col.upper():\n",
    "        marker_type = \" [Type -H]\"\n",
    "    print(f\"   [{i:2d}] {col}{marker_type}\")\n",
    "\n",
    "print(f\"\\n[OK] Données prêtes pour la suite du pipeline\")\n",
    "print(f\"   Shape combined_gated: {combined_gated.shape}\")\n",
    "print(f\"   Shape X_transformed: {X_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRÉATION DE L'ANNDATA TRANSFORMÉ ET EXPLORATION POST-ARCSINH\n",
    "\n",
    "# Créer un nouvel AnnData avec les données transformées (X_transformed)\n",
    "import anndata as ad\n",
    "\n",
    "# Créer adata_flowsom - le nouvel AnnData pour FlowSOM avec données transformées\n",
    "adata_flowsom = ad.AnnData(\n",
    "    X=X_transformed,  # Données POST-transformation arcsinh\n",
    "    obs=combined_gated.obs.copy(),  # Copie des métadonnées\n",
    "    var=combined_gated.var.copy() if combined_gated.var is not None else None\n",
    ")\n",
    "\n",
    "# Ajouter les noms de variables\n",
    "adata_flowsom.var_names = var_names\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CRÉATION ANNDATA POUR FLOWSOM (DONNÉES POST-ARCSINH)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n[OK] Nouvel AnnData 'adata_flowsom' créé avec données transformées\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Observations (cellules): {adata_flowsom.n_obs:,}\")\n",
    "print(f\"   Variables (marqueurs): {adata_flowsom.n_vars}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPLORATION DU DATAFRAME POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "\n",
    "# Extraire la matrice transformée depuis le NOUVEL AnnData\n",
    "X_trans = adata_flowsom.X\n",
    "if hasattr(X_trans, 'toarray'):\n",
    "    X_trans = X_trans.toarray()\n",
    "\n",
    "# Créer un DataFrame pour exploration\n",
    "df_transformed = pd.DataFrame(X_trans, columns=var_names)\n",
    "df_transformed['condition'] = adata_flowsom.obs['condition'].values\n",
    "df_transformed['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"APERÇU DES DONNÉES TRANSFORMÉES (premières 10 lignes)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape du DataFrame: {df_transformed.shape}\")\n",
    "display(df_transformed.head(10))\n",
    "\n",
    "# VÉRIFICATION DES NaN ET Inf POST-ARCSINH\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÉRIFICATION DES VALEURS NaN ET Inf POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Colonnes numériques uniquement\n",
    "numeric_cols = df_transformed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Comptage des NaN\n",
    "nan_counts = df_transformed[numeric_cols].isna().sum()\n",
    "total_nan = nan_counts.sum()\n",
    "\n",
    "# Comptage des Inf (positifs et négatifs)\n",
    "inf_pos_counts = (df_transformed[numeric_cols] == np.inf).sum()\n",
    "inf_neg_counts = (df_transformed[numeric_cols] == -np.inf).sum()\n",
    "total_inf_pos = inf_pos_counts.sum()\n",
    "total_inf_neg = inf_neg_counts.sum()\n",
    "total_inf = total_inf_pos + total_inf_neg\n",
    "\n",
    "total_cells = df_transformed.shape[0] * len(numeric_cols)\n",
    "\n",
    "print(f\"\\nRÉSUMÉ GLOBAL:\")\n",
    "print(f\"   Total valeurs analysées: {total_cells:,}\")\n",
    "print(f\"   Total NaN:    {total_nan:,} ({100*total_nan/total_cells:.4f}%)\")\n",
    "print(f\"   Total +Inf:   {total_inf_pos:,} ({100*total_inf_pos/total_cells:.4f}%)\")\n",
    "print(f\"   Total -Inf:   {total_inf_neg:,} ({100*total_inf_neg/total_cells:.4f}%)\")\n",
    "\n",
    "# Détail par colonne si problèmes détectés\n",
    "if total_nan > 0 or total_inf > 0:\n",
    "    print(f\"\\nDÉTAIL PAR COLONNE AVEC PROBLÈMES:\")\n",
    "    print(\"-\"*60)\n",
    "    for col in numeric_cols:\n",
    "        n_nan = df_transformed[col].isna().sum()\n",
    "        n_inf_pos = (df_transformed[col] == np.inf).sum()\n",
    "        n_inf_neg = (df_transformed[col] == -np.inf).sum()\n",
    "        if n_nan > 0 or n_inf_pos > 0 or n_inf_neg > 0:\n",
    "            print(f\"   {col:30s}: NaN={n_nan:,}, +Inf={n_inf_pos:,}, -Inf={n_inf_neg:,}\")\n",
    "else:\n",
    "    print(f\"\\nAucune valeur NaN ou Inf détectée - Données propres!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTIQUES DESCRIPTIVES POST-ARCSINH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTIQUES DESCRIPTIVES POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "display(df_transformed[numeric_cols].describe())\n",
    "\n",
    "# ============================================================================\n",
    "# VÉRIFICATION DES RANGES POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÉRIFICATION DES RANGES POST-TRANSFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"(arcsinh avec cofactor=150 donne typiquement des valeurs entre -5 et 10)\\n\")\n",
    "\n",
    "for col in used_markers[:10]:  # Premiers 10 marqueurs utilisés\n",
    "    col_min = df_transformed[col].min()\n",
    "    col_max = df_transformed[col].max()\n",
    "    col_mean = df_transformed[col].mean()\n",
    "    print(f\"   {col:30s}: min={col_min:8.3f}, max={col_max:8.3f}, mean={col_mean:8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETTOYAGE FINAL ET VALIDATION DE L'ANNDATA POUR FLOWSOM\n",
    "\n",
    "# Nettoyage final: remplacer NaN/Inf par 0 dans adata_flowsom\n",
    "X_final = adata_flowsom.X\n",
    "if hasattr(X_final, 'toarray'):\n",
    "    X_final = X_final.toarray()\n",
    "\n",
    "# Vérifier et nettoyer\n",
    "nan_mask = ~np.isfinite(X_final)\n",
    "n_nan = nan_mask.sum()\n",
    "if n_nan > 0:\n",
    "    print(f\"[!] {n_nan} valeurs NaN/Inf détectées et remplacées par 0\")\n",
    "    X_final = np.nan_to_num(X_final, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    adata_flowsom.X = X_final\n",
    "else:\n",
    "    print(\"[OK] Aucune valeur problématique - pas de nettoyage nécessaire\")\n",
    "\n",
    "print(f\"\\n[OK] AnnData 'adata_flowsom' prêt pour FlowSOM:\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Colonnes pour clustering: {len(cols_to_use)}\")\n",
    "\n",
    "# Résumé par condition\n",
    "print(f\"\\n Distribution par condition:\")\n",
    "for condition in adata_flowsom.obs['condition'].unique():\n",
    "    n = (adata_flowsom.obs['condition'] == condition).sum()\n",
    "    print(f\"   {condition}: {n:,} cellules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08a195",
   "metadata": {},
   "source": [
    "## 9. Exécution du Clustering FlowSOM\n",
    "\n",
    "Configuration et lancement de l'analyse FlowSOM avec:\n",
    "- Grille SOM (xdim × ydim)\n",
    "- Nombre de métaclusters\n",
    "- Seed pour reproductibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMÈTRES FLOWSOM\n",
    "\n",
    "# Dimensions de la grille SOM\n",
    "XDIM = 10\n",
    "YDIM = 10\n",
    "\n",
    "# Nombre de métaclusters\n",
    "N_CLUSTERS = 7\n",
    "\n",
    "# Seed pour reproductibilité\n",
    "SEED = 42\n",
    "\n",
    "# Auto-clustering avec silhouette score?\n",
    "AUTO_CLUSTER = False\n",
    "MAX_CLUSTERS_AUTO = 20\n",
    "\n",
    "print(\"PARAMÈTRES FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Grille SOM: {XDIM} × {YDIM} = {XDIM*YDIM} nodes\")\n",
    "print(f\"   Métaclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "print(f\"   Auto-clustering: {'Oui' if AUTO_CLUSTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR TROUVER LE NOMBRE OPTIMAL DE CLUSTERS (optionnel)\n",
    "# [!] Le silhouette score nécessite une matrice N×N → impossible avec 1M cellules\n",
    "# Solution: Sous-échantillonner pour l'évaluation silhouette uniquement\n",
    "\n",
    "SAMPLE_SIZE_SILHOUETTE = 10000  # Taille de l'échantillon pour silhouette\n",
    "\n",
    "def find_optimal_clusters(data, cols_to_use, seed, max_clusters=20, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Trouve le nombre optimal de métaclusters via silhouette score.\n",
    "    Utilise un échantillon représentatif pour éviter l'explosion mémoire.\n",
    "    \"\"\"\n",
    "    print(\"Recherche du nombre optimal de clusters...\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = data.X\n",
    "    if hasattr(X, 'toarray'):\n",
    "        X = X.toarray()\n",
    "    \n",
    "    X_full = X[:, cols_to_use]\n",
    "    X_full = np.nan_to_num(X_full, nan=0.0)\n",
    "    \n",
    "    n_total = X_full.shape[0]\n",
    "    \n",
    "    # Sous-échantillonner pour silhouette (sinon O(N²) mémoire)\n",
    "    if n_total > sample_size:\n",
    "        print(f\"   [!] {n_total:,} cellules → échantillon de {sample_size:,} pour silhouette\")\n",
    "        idx = np.random.choice(n_total, sample_size, replace=False)\n",
    "        X_sample = X_full[idx]\n",
    "    else:\n",
    "        print(f\"   Utilisation de {n_total:,} cellules\")\n",
    "        X_sample = X_full\n",
    "    \n",
    "    scores = []\n",
    "    cluster_range = range(2, min(max_clusters + 1, len(X_sample) // 10))\n",
    "    \n",
    "    for k in cluster_range:\n",
    "        try:\n",
    "            clustering = AgglomerativeClustering(n_clusters=k)\n",
    "            labels = clustering.fit_predict(X_sample)\n",
    "            score = silhouette_score(X_sample, labels)\n",
    "            scores.append((k, score))\n",
    "            print(f\"   k={k}: silhouette={score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   k={k}: erreur - {e}\")\n",
    "    \n",
    "    if scores:\n",
    "        best_k, best_score = max(scores, key=lambda x: x[1])\n",
    "        print(f\"\\n[OK] Nombre optimal: {best_k} (silhouette={best_score:.4f})\")\n",
    "        return best_k\n",
    "    \n",
    "    return 10  # Valeur par défaut\n",
    "\n",
    "# Exécuter si AUTO_CLUSTER est activé\n",
    "if AUTO_CLUSTER:\n",
    "    N_CLUSTERS = find_optimal_clusters(\n",
    "        combined_gated, cols_to_use, SEED, \n",
    "        MAX_CLUSTERS_AUTO, SAMPLE_SIZE_SILHOUETTE\n",
    "    )\n",
    "    print(f\"\\n Utilisation de {N_CLUSTERS} métaclusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXÉCUTION FLOWSOM\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Exécuter FlowSOM avec adata_flowsom (données transformées arcsinh)\n",
    "fsom = fs.FlowSOM(\n",
    "    adata_flowsom,  # ← IMPORTANT: utilise les données POST-transformation\n",
    "    cols_to_use=cols_to_use,\n",
    "    xdim=XDIM,\n",
    "    ydim=YDIM,\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTemps d'exécution: {elapsed:.2f} secondes\")\n",
    "\n",
    "# Récupérer les données de clustering\n",
    "cell_data = fsom.get_cell_data()\n",
    "cluster_data = fsom.get_cluster_data()\n",
    "\n",
    "# Ajouter les métadonnées originales\n",
    "cell_data.obs['condition'] = adata_flowsom.obs['condition'].values\n",
    "cell_data.obs['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(f\"\\n[OK] FlowSOM terminé!\")\n",
    "print(f\"   Cellules analysées: {cell_data.shape[0]:,}\")\n",
    "print(f\"   Nodes SOM: {cluster_data.shape[0]}\")\n",
    "print(f\"   Métaclusters: {N_CLUSTERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0e07e",
   "metadata": {},
   "source": [
    "## 10. Visualisation des Résultats FlowSOM\n",
    "\n",
    "Génération des visualisations standards:\n",
    "- Heatmap d'expression par métacluster\n",
    "- Arbre MST (Minimum Spanning Tree)\n",
    "- Star Charts\n",
    "- Distribution par condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP D'EXPRESSION PAR MÉTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" Génération de la Heatmap d'expression...\")\n",
    "\n",
    "# Récupérer les données\n",
    "X = cell_data.X\n",
    "if hasattr(X, 'toarray'):\n",
    "    X = X.toarray()\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "\n",
    "# Calculer la MFI (Mean Fluorescence Intensity) par métacluster\n",
    "mfi_matrix = np.zeros((N_CLUSTERS, len(cols_to_use)))\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    if mask.sum() > 0:\n",
    "        mfi_matrix[i, :] = np.nanmean(X[mask][:, cols_to_use], axis=0)\n",
    "\n",
    "# Normalisation Z-score pour la heatmap\n",
    "mfi_normalized = (mfi_matrix - np.nanmean(mfi_matrix, axis=0)) / (np.nanstd(mfi_matrix, axis=0) + 1e-10)\n",
    "\n",
    "# Créer la heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "im = ax.imshow(mfi_normalized.T, aspect='auto', cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "\n",
    "# Labels\n",
    "ax.set_yticks(range(len(used_markers)))\n",
    "ax.set_yticklabels(used_markers, fontsize=9)\n",
    "ax.set_xticks(range(N_CLUSTERS))\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "\n",
    "ax.set_title('Heatmap - Expression par Métacluster (Z-score)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('Métacluster', fontsize=12)\n",
    "ax.set_ylabel('Marqueur', fontsize=12)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8, label='Z-score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAR CHART FLOWSOM (MST View)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Génération du Star Chart MST...\")\n",
    "\n",
    "try:\n",
    "    # Utiliser l'API FlowSOM pour le Star Chart\n",
    "    fig_stars = fs.pl.plot_stars(\n",
    "        fsom,\n",
    "        background_values=fsom.get_cluster_data().obs.metaclustering,\n",
    "        view=\"MST\"\n",
    "    )\n",
    "    plt.suptitle('FlowSOM Star Chart (MST View)', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur Star Chart: {e}\")\n",
    "    print(\"   Utilisation de la visualisation alternative...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION GRILLE SOM (xGrid, yGrid) - Style FlowSOM R exact\n",
    "# =============================================================================\n",
    "# PARTIE 1 : MATPLOTLIB (statique, haute résolution pour PDF/export)\n",
    "# =============================================================================\n",
    "\n",
    "print(\" VISUALISATION GRILLE SOM (style FlowSOM R avec cercles)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R)\n",
    "# =====================================================================\n",
    "def circular_jitter_viz(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    Génère un jitter circulaire style FlowSOM R.\n",
    "    Le rayon des cercles dépend du nombre de cellules dans le node.\n",
    "    \"\"\"\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    max_size_val = node_sizes.max()\n",
    "    \n",
    "    radii = np.zeros(n_points, dtype=np.float32)\n",
    "    for i in range(n_points):\n",
    "        node_id = int(cluster_ids[i])\n",
    "        node_size = node_sizes[node_id]\n",
    "        size_ratio = np.sqrt(node_size / max_size_val)\n",
    "        node_radius = min_radius + (max_radius - min_radius) * size_ratio\n",
    "        radii[i] = node_radius\n",
    "    \n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "try:\n",
    "    # Récupérer les coordonnées de grille\n",
    "    grid_coords = cluster_data.obsm.get('grid', None)\n",
    "    \n",
    "    if grid_coords is not None:\n",
    "        # Récupérer les infos de clustering\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        conditions = cell_data.obs['condition'].values\n",
    "        \n",
    "        # Calculer les coordonnées de grille pour chaque cellule\n",
    "        xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "        yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "        \n",
    "        # Décaler pour commencer à 1\n",
    "        xGrid_shifted = xGrid_base - xGrid_base.min() + 1\n",
    "        yGrid_shifted = yGrid_base - yGrid_base.min() + 1\n",
    "        \n",
    "        # Métacluster pour chaque cellule\n",
    "        metaclustering_cells = np.array([metaclustering_nodes[int(c)] for c in clustering])\n",
    "        \n",
    "        # Calculer la taille de chaque node\n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes, dtype=np.float32)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        # JITTER CIRCULAIRE style FlowSOM R\n",
    "        MAX_NODE_SIZE = 0.45\n",
    "        MIN_NODE_SIZE = 0.1\n",
    "        np.random.seed(SEED)\n",
    "        jitter_x, jitter_y = circular_jitter_viz(len(clustering), clustering, node_sizes, \n",
    "                                                  max_radius=MAX_NODE_SIZE, \n",
    "                                                  min_radius=MIN_NODE_SIZE)\n",
    "        \n",
    "        print(f\" Jitter circulaire appliqué (rayon proportionnel à la taille du node)\")\n",
    "        print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "        \n",
    "        # Créer la figure avec 2 sous-plots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 1: Grille SOM colorée par Métacluster\n",
    "        # =====================================================================\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        \n",
    "        scatter1 = ax1.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=metaclustering_cells,\n",
    "            cmap=cmap,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        # Ajouter les labels des métaclusters au centre de chaque node\n",
    "        for node_id in range(n_nodes):\n",
    "            if node_sizes[node_id] > 0:\n",
    "                x_pos = grid_coords[node_id, 0] - xGrid_base.min() + 1\n",
    "                y_pos = grid_coords[node_id, 1] - yGrid_base.min() + 1\n",
    "                meta_id = metaclustering_nodes[node_id]\n",
    "                ax1.annotate(\n",
    "                    str(int(meta_id + 1)),\n",
    "                    (x_pos, y_pos),\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=8, fontweight='bold',\n",
    "                    color='white',\n",
    "                    bbox=dict(boxstyle='circle,pad=0.2', facecolor=cmap(meta_id / max(n_meta - 1, 1)), edgecolor='white', alpha=0.9)\n",
    "                )\n",
    "        \n",
    "        ax1.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColoré par Métacluster (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax1.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax1.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax1.set_aspect('equal')\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        cbar1 = plt.colorbar(scatter1, ax=ax1, label='Métacluster')\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 2: Grille SOM colorée par Condition\n",
    "        # =====================================================================\n",
    "        ax2 = axes[1]\n",
    "        \n",
    "        condition_num = np.array([0 if c == 'Sain' else 1 for c in conditions])\n",
    "        \n",
    "        from matplotlib.colors import ListedColormap\n",
    "        cmap_cond = ListedColormap(['#a6e3a1', '#f38ba8'])\n",
    "        \n",
    "        scatter2 = ax2.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=condition_num,\n",
    "            cmap=cmap_cond,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        ax2.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColoré par Condition (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax2.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax2.set_aspect('equal')\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='#a6e3a1', edgecolor='white', label='Sain (NBM)'),\n",
    "            Patch(facecolor='#f38ba8', edgecolor='white', label='Pathologique')\n",
    "        ]\n",
    "        ax2.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Afficher les statistiques\n",
    "        print(f\"\\n STATISTIQUES DE LA GRILLE SOM:\")\n",
    "        print(f\"   Dimensions: {XDIM} x {YDIM} = {XDIM * YDIM} nodes\")\n",
    "        print(f\"   Nodes utilisés: {(node_sizes > 0).sum()} / {n_nodes}\")\n",
    "        print(f\"   xGrid range: [{xGrid_shifted.min():.1f}, {xGrid_shifted.max():.1f}]\")\n",
    "        print(f\"   yGrid range: [{yGrid_shifted.min():.1f}, {yGrid_shifted.max():.1f}]\")\n",
    "        \n",
    "        # Afficher la taille des nodes\n",
    "        print(f\"\\n Distribution des tailles de nodes:\")\n",
    "        print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "        print(f\"   Max: {node_sizes.max():.0f} cellules\")\n",
    "        print(f\"   Moyenne: {node_sizes.mean():.0f} cellules\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # PARTIE 2 : PLOTLY INTERACTIF (zoom, hover, export)\n",
    "        # =================================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" GRILLE SOM — VERSION PLOTLY INTERACTIVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.colors as pc_grid\n",
    "        \n",
    "        _xj = xGrid_shifted + jitter_x\n",
    "        _yj = yGrid_shifted + jitter_y\n",
    "        \n",
    "        # Sous-échantillonner si trop de points pour la fluidité Plotly\n",
    "        _max_pts = 50_000\n",
    "        if len(clustering) > _max_pts:\n",
    "            np.random.seed(SEED)\n",
    "            _sample_idx = np.random.choice(len(clustering), _max_pts, replace=False)\n",
    "        else:\n",
    "            _sample_idx = np.arange(len(clustering))\n",
    "        \n",
    "        if n_meta <= 20:\n",
    "            _mc_palette = pc_grid.qualitative.Alphabet[:n_meta]\n",
    "        else:\n",
    "            _mc_palette = [f\"hsl({int(i*360/n_meta)},70%,55%)\" for i in range(n_meta)]\n",
    "        \n",
    "        # --- Plot 1 Plotly : Métacluster ---\n",
    "        fig_grid_mc = go.Figure()\n",
    "        \n",
    "        for mc_id in range(n_meta):\n",
    "            _mask_mc = metaclustering_cells[_sample_idx] == mc_id\n",
    "            if _mask_mc.sum() == 0:\n",
    "                continue\n",
    "            _si = _sample_idx[_mask_mc]\n",
    "            fig_grid_mc.add_trace(go.Scattergl(\n",
    "                x=_xj[_si], y=_yj[_si],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=_mc_palette[mc_id % len(_mc_palette)], opacity=0.5),\n",
    "                name=f\"MC{mc_id} ({_mask_mc.sum():,})\",\n",
    "                hovertemplate=f\"MC{mc_id}<br>xGrid: %{{x:.2f}}<br>yGrid: %{{y:.2f}}<extra></extra>\",\n",
    "            ))\n",
    "        \n",
    "        _node_x = [grid_coords[i, 0] - xGrid_base.min() + 1 for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_y = [grid_coords[i, 1] - yGrid_base.min() + 1 for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_txt = [str(int(metaclustering_nodes[i]+1)) for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_sz = [node_sizes[i] for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        \n",
    "        fig_grid_mc.add_trace(go.Scatter(\n",
    "            x=_node_x, y=_node_y,\n",
    "            mode='text',\n",
    "            text=_node_txt,\n",
    "            textfont=dict(size=9, color='black', family='Arial Black'),\n",
    "            hovertemplate=[f\"Node — MC{t}<br>{int(s):,} cellules<extra></extra>\" for t, s in zip(_node_txt, _node_sz)],\n",
    "            showlegend=False,\n",
    "        ))\n",
    "        \n",
    "        fig_grid_mc.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Grille FlowSOM — {XDIM}×{YDIM} nodes — Coloré par Métacluster</b><br>\"\n",
    "                     \"<sup>Style FlowSOM R (jitter circulaire proportionnel) — Interactif</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xGrid\", range=[0.3, XDIM+1.7], scaleanchor=\"y\", scaleratio=1,\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            yaxis=dict(title=\"yGrid\", range=[0.3, YDIM+1.7],\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            height=700, width=800,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(title=\"Métacluster\", font=dict(size=10),\n",
    "                        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                        bordercolor=\"#ccc\", borderwidth=1,\n",
    "                        yanchor=\"top\", y=1, xanchor=\"left\", x=1.02),\n",
    "            margin=dict(t=80, b=50, l=60, r=180),\n",
    "        )\n",
    "        fig_grid_mc.show()\n",
    "        \n",
    "        # --- Plot 2 Plotly : Condition ---\n",
    "        fig_grid_cond = go.Figure()\n",
    "        \n",
    "        _cond_colors = {\"Sain\": \"#2ca02c\", \"Pathologique\": \"#d62728\"}\n",
    "        for cond_label, cond_color in _cond_colors.items():\n",
    "            _mask_c = conditions[_sample_idx] == cond_label\n",
    "            if _mask_c.sum() == 0:\n",
    "                continue\n",
    "            _si = _sample_idx[_mask_c]\n",
    "            fig_grid_cond.add_trace(go.Scattergl(\n",
    "                x=_xj[_si], y=_yj[_si],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=cond_color, opacity=0.45),\n",
    "                name=f\"{cond_label} ({_mask_c.sum():,})\",\n",
    "                hovertemplate=f\"{cond_label}<br>xGrid: %{{x:.2f}}<br>yGrid: %{{y:.2f}}<extra></extra>\",\n",
    "            ))\n",
    "        \n",
    "        fig_grid_cond.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Grille FlowSOM — {XDIM}×{YDIM} nodes — Coloré par Condition</b><br>\"\n",
    "                     \"<sup>Style FlowSOM R (jitter circulaire proportionnel) — Interactif</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xGrid\", range=[0.3, XDIM+1.7], scaleanchor=\"y\", scaleratio=1,\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            yaxis=dict(title=\"yGrid\", range=[0.3, YDIM+1.7],\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            height=700, width=800,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(title=\"Condition\", font=dict(size=12),\n",
    "                        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                        bordercolor=\"#ccc\", borderwidth=1),\n",
    "            margin=dict(t=80, b=50, l=60, r=60),\n",
    "        )\n",
    "        fig_grid_cond.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"[!] Coordonnées de grille non disponibles dans cluster_data.obsm['grid']\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur visualisation grille: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714730ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ARBRE MST — MATPLOTLIB (statique) + PLOTLY (interactif)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Génération de l'arbre MST...\")\n",
    "\n",
    "# =====================================================================\n",
    "# PARTIE 1 : MATPLOTLIB (statique, haute résolution pour PDF/export)\n",
    "# =====================================================================\n",
    "try:\n",
    "    layout = cluster_data.obsm.get('layout', None)\n",
    "    \n",
    "    if layout is not None:\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        \n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        max_size = node_sizes.max() if node_sizes.max() > 0 else 1\n",
    "        sizes = 100 + (node_sizes / max_size) * 800\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        colors = [cmap(int(m) / max(n_meta - 1, 1)) for m in metaclustering_nodes]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        scatter = ax.scatter(layout[:, 0], layout[:, 1], \n",
    "                           s=sizes, c=colors, edgecolors='white', \n",
    "                           linewidths=1.5, alpha=0.9, zorder=2)\n",
    "        \n",
    "        for i in range(n_nodes):\n",
    "            ax.annotate(str(int(metaclustering_nodes[i])), \n",
    "                       (layout[i, 0], layout[i, 1]),\n",
    "                       ha='center', va='center', fontsize=8, \n",
    "                       color='white', fontweight='bold')\n",
    "        \n",
    "        ax.set_xlabel('xNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('yNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Arbre MST - {n_nodes} nodes, {n_meta} métaclusters', \n",
    "                    fontsize=14, fontweight='bold', pad=15)\n",
    "        ax.grid(True, alpha=0.15, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        if n_meta <= 15:\n",
    "            legend_elements = [Patch(facecolor=cmap(i/max(n_meta-1, 1)), \n",
    "                                    label=f'MC {i}') for i in range(n_meta)]\n",
    "            ax.legend(handles=legend_elements, loc='center left', \n",
    "                     bbox_to_anchor=(1.02, 0.5), fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # =================================================================\n",
    "        # PARTIE 2 : PLOTLY INTERACTIF (zoom, hover, export)\n",
    "        # =================================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" ARBRE MST — VERSION PLOTLY INTERACTIVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.colors as pc_mst\n",
    "        \n",
    "        _bubble_sizes = 10 + (node_sizes / max_size) * 40\n",
    "        \n",
    "        if n_meta <= 20:\n",
    "            _mc_palette = pc_mst.qualitative.Alphabet[:n_meta]\n",
    "        else:\n",
    "            _mc_palette = [f\"hsl({int(i*360/n_meta)},70%,55%)\" for i in range(n_meta)]\n",
    "        \n",
    "        # Récupérer les arêtes du MST si disponibles\n",
    "        _edge_x, _edge_y = [], []\n",
    "        _mst_graph = None\n",
    "        try:\n",
    "            if hasattr(cluster_data, 'uns') and 'mst' in cluster_data.uns:\n",
    "                _mst_graph = cluster_data.uns['mst']\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        if _mst_graph is not None:\n",
    "            try:\n",
    "                import igraph\n",
    "                if isinstance(_mst_graph, igraph.Graph):\n",
    "                    for edge in _mst_graph.es:\n",
    "                        s, t = edge.source, edge.target\n",
    "                        if s < n_nodes and t < n_nodes:\n",
    "                            _edge_x += [layout[s, 0], layout[t, 0], None]\n",
    "                            _edge_y += [layout[s, 1], layout[t, 1], None]\n",
    "            except ImportError:\n",
    "                pass\n",
    "        \n",
    "        fig_mst = go.Figure()\n",
    "        \n",
    "        if _edge_x:\n",
    "            fig_mst.add_trace(go.Scatter(\n",
    "                x=_edge_x, y=_edge_y,\n",
    "                mode='lines',\n",
    "                line=dict(width=1.5, color='rgba(100,100,100,0.5)'),\n",
    "                hoverinfo='skip',\n",
    "                showlegend=False,\n",
    "            ))\n",
    "        \n",
    "        for mc_id in range(n_meta):\n",
    "            _mask = metaclustering_nodes == mc_id\n",
    "            if _mask.sum() == 0:\n",
    "                continue\n",
    "            _indices = np.where(_mask)[0]\n",
    "            fig_mst.add_trace(go.Scatter(\n",
    "                x=layout[_indices, 0],\n",
    "                y=layout[_indices, 1],\n",
    "                mode='markers+text',\n",
    "                marker=dict(\n",
    "                    size=_bubble_sizes[_indices],\n",
    "                    color=_mc_palette[mc_id % len(_mc_palette)],\n",
    "                    line=dict(width=1.5, color='white'),\n",
    "                    opacity=0.9,\n",
    "                ),\n",
    "                text=[str(int(mc_id)) for _ in _indices],\n",
    "                textfont=dict(size=9, color='white', family='Arial Black'),\n",
    "                textposition='middle center',\n",
    "                name=f\"MC{mc_id} ({int(node_sizes[_indices].sum()):,} cells)\",\n",
    "                hovertemplate=[\n",
    "                    f\"<b>Node {ni}</b><br>\"\n",
    "                    f\"MC {int(metaclustering_nodes[ni])}<br>\"\n",
    "                    f\"Cellules: {int(node_sizes[ni]):,}<br>\"\n",
    "                    f\"x: {layout[ni,0]:.2f}, y: {layout[ni,1]:.2f}<extra></extra>\"\n",
    "                    for ni in _indices\n",
    "                ],\n",
    "            ))\n",
    "        \n",
    "        fig_mst.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Arbre MST — {n_nodes} nodes, {n_meta} métaclusters</b><br>\"\n",
    "                     \"<sup>Taille des bulles ∝ nombre de cellules · Cliquez la légende pour filtrer</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xNodes\", showgrid=True, gridcolor=\"rgba(0,0,0,0.06)\",\n",
    "                       zeroline=False),\n",
    "            yaxis=dict(title=\"yNodes\", showgrid=True, gridcolor=\"rgba(0,0,0,0.06)\",\n",
    "                       zeroline=False, scaleanchor=\"x\", scaleratio=1),\n",
    "            height=750, width=900,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(\n",
    "                title=\"Métacluster\",\n",
    "                font=dict(size=10),\n",
    "                bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                bordercolor=\"#ccc\", borderwidth=1,\n",
    "                yanchor=\"top\", y=1, xanchor=\"left\", x=1.02,\n",
    "            ),\n",
    "            margin=dict(t=80, b=50, l=60, r=200),\n",
    "        )\n",
    "        fig_mst.show()\n",
    "        \n",
    "        print(f\"[OK] Arbre MST — Matplotlib + Plotly interactif ({n_nodes} nodes, {n_meta} MC)\")\n",
    "    else:\n",
    "        print(\"[!] Layout MST non disponible\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur MST: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION PAR CONDITION (Sain vs Pathologique)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Distribution des métaclusters par condition...\")\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "conditions = cell_data.obs['condition'].values\n",
    "\n",
    "healthy_pcts = []\n",
    "patho_pcts = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask_cluster = metaclustering == i\n",
    "    \n",
    "    # Pourcentage dans Sain\n",
    "    mask_healthy = (conditions == 'Sain') & mask_cluster\n",
    "    total_healthy = (conditions == 'Sain').sum()\n",
    "    healthy_pcts.append((mask_healthy.sum() / total_healthy * 100) if total_healthy > 0 else 0)\n",
    "    \n",
    "    # Pourcentage dans Pathologique\n",
    "    mask_patho = (conditions == 'Pathologique') & mask_cluster\n",
    "    total_patho = (conditions == 'Pathologique').sum()\n",
    "    patho_pcts.append((mask_patho.sum() / total_patho * 100) if total_patho > 0 else 0)\n",
    "\n",
    "# Créer le graphique\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x = np.arange(N_CLUSTERS)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, healthy_pcts, width, label='Sain (NBM)', \n",
    "               color='#a6e3a1', edgecolor='white', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, patho_pcts, width, label='Pathologique', \n",
    "               color='#f38ba8', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Métacluster', fontsize=12)\n",
    "ax.set_ylabel('Pourcentage (%)', fontsize=12)\n",
    "ax.set_title('Distribution des Métaclusters par Condition', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    if height > 1:  # N'afficher que si > 1%\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3), textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau récapitulatif\n",
    "print(\"\\nTableau récapitulatif:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'MC':>4} | {'Sain (%)':>10} | {'Patho (%)':>10} | {'Diff':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(N_CLUSTERS):\n",
    "    diff = patho_pcts[i] - healthy_pcts[i]\n",
    "    print(f\"{i:>4} | {healthy_pcts[i]:>10.2f} | {patho_pcts[i]:>10.2f} | {diff:>+8.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acff00",
   "metadata": {},
   "source": [
    "## 11. Analyse Détaillée des Métaclusters\n",
    "\n",
    "Statistiques approfondies par métacluster:\n",
    "- Nombre de cellules\n",
    "- MFI par marqueur\n",
    "- Phénotype caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATISTIQUES PAR MÉTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" STATISTIQUES PAR MÉTACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer un DataFrame de statistiques\n",
    "stats_data = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    n_cells = mask.sum()\n",
    "    pct_total = n_cells / len(metaclustering) * 100\n",
    "    \n",
    "    # Calculer MFI pour chaque marqueur\n",
    "    mfi = np.nanmean(X[mask][:, cols_to_use], axis=0) if n_cells > 0 else np.zeros(len(cols_to_use))\n",
    "    \n",
    "    # Top 3 marqueurs les plus exprimés\n",
    "    top_indices = np.argsort(mfi)[::-1][:3]\n",
    "    top_markers = [used_markers[idx] for idx in top_indices]\n",
    "    \n",
    "    stats_data.append({\n",
    "        'Metacluster': i,\n",
    "        'N_Cells': n_cells,\n",
    "        'Pct_Total': pct_total,\n",
    "        'Top_Markers': ', '.join(top_markers)\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats_data)\n",
    "print(df_stats.to_string(index=False))\n",
    "\n",
    "# Graphique camembert\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Pie chart des tailles\n",
    "ax = axes[0]\n",
    "sizes = [s['N_Cells'] for s in stats_data]\n",
    "labels = [f\"MC{s['Metacluster']}\" for s in stats_data]\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, N_CLUSTERS))\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, \n",
    "                                   autopct='%1.1f%%', pctdistance=0.8)\n",
    "ax.set_title('Distribution des Cellules par Métacluster', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Bar chart des tailles\n",
    "ax = axes[1]\n",
    "ax.barh(range(N_CLUSTERS), sizes, color=colors, edgecolor='white')\n",
    "ax.set_yticks(range(N_CLUSTERS))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Nombre de cellules')\n",
    "ax.set_title('Taille des Métaclusters', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c773749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROFIL D'EXPRESSION DÉTAILLÉ PAR MÉTACLUSTER — SPIDER PLOT INTERACTIF\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n PROFIL D'EXPRESSION MOYEN PAR MÉTACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer un DataFrame avec MFI par marqueur et métacluster\n",
    "mfi_matrix = np.zeros((N_CLUSTERS, len(used_markers)))\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    if mask.sum() > 0:\n",
    "        mfi_matrix[i] = np.nanmean(X[mask][:, cols_to_use], axis=0)\n",
    "\n",
    "df_mfi = pd.DataFrame(mfi_matrix, \n",
    "                       columns=used_markers,\n",
    "                       index=[f'MC{i}' for i in range(N_CLUSTERS)])\n",
    "\n",
    "# Afficher le tableau formaté\n",
    "print(df_mfi.round(2).to_string())\n",
    "\n",
    "# =============================================================================\n",
    "# SPIDER / RADAR PLOT INTERACTIF — TOUS LES CLUSTERS (Plotly)\n",
    "# =============================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "# Palette de couleurs suffisante pour tous les clusters\n",
    "if N_CLUSTERS <= 10:\n",
    "    _radar_palette = pc.qualitative.Set3\n",
    "elif N_CLUSTERS <= 20:\n",
    "    _radar_palette = pc.qualitative.Alphabet\n",
    "else:\n",
    "    _radar_palette = [f\"hsl({int(i*360/N_CLUSTERS)},70%,55%)\" for i in range(N_CLUSTERS)]\n",
    "\n",
    "fig_radar = go.Figure()\n",
    "\n",
    "for cluster_id in range(N_CLUSTERS):\n",
    "    values = mfi_matrix[cluster_id].copy()\n",
    "    # Normaliser entre 0 et 1 pour la visualisation\n",
    "    v_min, v_max = np.min(values), np.max(values)\n",
    "    values_norm = (values - v_min) / (v_max - v_min + 1e-10)\n",
    "\n",
    "    _c = _radar_palette[cluster_id % len(_radar_palette)]\n",
    "    _n_cells = int((metaclustering == cluster_id).sum())\n",
    "\n",
    "    # Construire une couleur de remplissage semi-transparente\n",
    "    if 'rgb' in str(_c):\n",
    "        _fill = _c.replace(')', ',0.08)').replace('rgb', 'rgba')\n",
    "    else:\n",
    "        _fill = f\"rgba(128,128,128,0.05)\"\n",
    "\n",
    "    fig_radar.add_trace(go.Scatterpolar(\n",
    "        r=np.append(values_norm, values_norm[0]),\n",
    "        theta=used_markers + [used_markers[0]],\n",
    "        fill='toself',\n",
    "        fillcolor=_fill,\n",
    "        opacity=0.85,\n",
    "        name=f\"MC{cluster_id}  ({_n_cells:,} cells)\",\n",
    "        line=dict(color=_c, width=2),\n",
    "        marker=dict(size=5),\n",
    "        customdata=np.stack([\n",
    "            np.append(mfi_matrix[cluster_id], mfi_matrix[cluster_id][0]),\n",
    "            np.append(values_norm, values_norm[0]),\n",
    "        ], axis=-1),\n",
    "        hovertemplate=(\n",
    "            f\"<b>MC{cluster_id}</b><br>\"\n",
    "            \"Marqueur: %{theta}<br>\"\n",
    "            \"MFI brute: %{customdata[0]:.2f}<br>\"\n",
    "            \"Normalisé: %{customdata[1]:.3f}<extra></extra>\"\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "fig_radar.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1.05],\n",
    "            tickfont=dict(size=9),\n",
    "            gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            tickfont=dict(size=11),\n",
    "            gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "            rotation=90,\n",
    "            direction=\"clockwise\",\n",
    "        ),\n",
    "        bgcolor=\"rgba(250,250,250,0.5)\",\n",
    "    ),\n",
    "    title=dict(\n",
    "        text=f\"<b>Profil d'Expression Normalisé — {N_CLUSTERS} Métaclusters</b><br>\"\n",
    "             \"<sup>Cliquez sur la légende pour masquer/afficher un cluster</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=\"Métacluster\",\n",
    "        font=dict(size=11),\n",
    "        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "        bordercolor=\"#ccc\", borderwidth=1,\n",
    "        yanchor=\"top\", y=1.0,\n",
    "        xanchor=\"left\", x=1.05,\n",
    "    ),\n",
    "    height=750,\n",
    "    width=950,\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=90, b=40, l=80, r=200),\n",
    ")\n",
    "\n",
    "fig_radar.show()\n",
    "print(f\"\\n[OK] Spider plot interactif — {N_CLUSTERS} métaclusters affichés\")\n",
    "print(\"     → Cliquez sur la légende pour isoler un métacluster\")\n",
    "print(\"     → Survolez les points pour voir les MFI brutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc989dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANALYSE DES CLUSTERS EXCLUSIFS (mono-condition)\n",
    "# =============================================================================\n",
    "# Identification des clusters contenant UNIQUEMENT des cellules d'une condition\n",
    "# Utile pour détecter les populations pathologiques spécifiques\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" ANALYSE DES CLUSTERS EXCLUSIFS PAR CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Récupérer les conditions des cellules\n",
    "cell_conditions = adata_flowsom.obs['condition'].values\n",
    "unique_conditions = np.unique(cell_conditions)\n",
    "\n",
    "print(f\"\\nConditions présentes: {list(unique_conditions)}\")\n",
    "print(f\"Nombre de metaclusters: {n_meta}\")\n",
    "\n",
    "# Analyse par metacluster\n",
    "clusters_patho_only = []\n",
    "clusters_sain_only = []\n",
    "clusters_mixed = []\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\" METACLUSTERS EXCLUSIFS (100% d'une seule condition)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cluster_id in range(1, n_meta + 1):\n",
    "    mask_cluster = (metaclustering_cells == cluster_id)\n",
    "    n_cluster = mask_cluster.sum()\n",
    "    \n",
    "    if n_cluster == 0:\n",
    "        continue\n",
    "    \n",
    "    # Compter les cellules par condition dans ce cluster\n",
    "    conditions_in_cluster = cell_conditions[mask_cluster]\n",
    "    \n",
    "    # Calculer les proportions\n",
    "    condition_counts = {}\n",
    "    for cond in unique_conditions:\n",
    "        count = (conditions_in_cluster == cond).sum()\n",
    "        condition_counts[cond] = count\n",
    "    \n",
    "    # Vérifier si le cluster est exclusif à une condition\n",
    "    total = sum(condition_counts.values())\n",
    "    \n",
    "    # Cluster 100% pathologique\n",
    "    if \"Pathologique\" in condition_counts and condition_counts.get(\"Pathologique\", 0) == total:\n",
    "        clusters_patho_only.append((cluster_id, total))\n",
    "        print(f\"   [PATHO] Metacluster {cluster_id:2d}: {total:6,} cellules (100% Pathologique)\")\n",
    "    \n",
    "    # Cluster 100% sain\n",
    "    elif \"Sain\" in condition_counts and condition_counts.get(\"Sain\", 0) == total:\n",
    "        clusters_sain_only.append((cluster_id, total))\n",
    "        print(f\"   [SAIN]  Metacluster {cluster_id:2d}: {total:6,} cellules (100% Sain)\")\n",
    "    \n",
    "    else:\n",
    "        clusters_mixed.append(cluster_id)\n",
    "\n",
    "# Résumé\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" RÉSUMÉ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if clusters_patho_only:\n",
    "    total_patho_exclusive = sum([c[1] for c in clusters_patho_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% PATHOLOGIQUES: {len(clusters_patho_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_patho_only]}\")\n",
    "    print(f\"    Total cellules: {total_patho_exclusive:,}\")\n",
    "    print(f\"    → Ces clusters représentent des populations UNIQUEMENT présentes chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement pathologique détecté\")\n",
    "\n",
    "if clusters_sain_only:\n",
    "    total_sain_exclusive = sum([c[1] for c in clusters_sain_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% SAINS: {len(clusters_sain_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_sain_only]}\")\n",
    "    print(f\"    Total cellules: {total_sain_exclusive:,}\")\n",
    "    print(f\"    → Ces clusters représentent des populations ABSENTES chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement sain détecté\")\n",
    "\n",
    "print(f\"\\n    Clusters mixtes (partagés): {len(clusters_mixed)}\")\n",
    "\n",
    "# Visualisation si clusters exclusifs pathologiques\n",
    "if clusters_patho_only and len(clusters_patho_only) > 0:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" DÉTAIL DES CLUSTERS PATHOLOGIQUES EXCLUSIFS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Calculer le MFI des marqueurs pour ces clusters\n",
    "    for cluster_id, n_cells in clusters_patho_only:\n",
    "        mask_c = (metaclustering_cells == cluster_id)\n",
    "        print(f\"\\n   Metacluster {cluster_id} ({n_cells:,} cellules):\")\n",
    "        \n",
    "        # Top 3 marqueurs les plus exprimés\n",
    "        mfi_cluster = adata_flowsom.X[mask_c].mean(axis=0)\n",
    "        top_3_idx = np.argsort(mfi_cluster)[-3:][::-1]\n",
    "        print(f\"      Top marqueurs: \", end=\"\")\n",
    "        for idx in top_3_idx:\n",
    "            marker_name = adata_flowsom.var_names[idx]\n",
    "            print(f\"{marker_name}({mfi_cluster[idx]:.2f}) \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0c0fd",
   "metadata": {},
   "source": [
    "## 12. Export des Résultats\n",
    "\n",
    "Sauvegarde des résultats d'analyse:\n",
    "- **CSV**: Tableau avec métaclusters assignés à chaque cellule\n",
    "- **FCS**: Fichier FCS avec colonne métacluster ajoutée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT CSV/FCS AVEC COORDONNÉES SOM (style FlowSOM R EXACT)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Créer le dossier de sortie\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\" PRÉPARATION DES DONNÉES POUR EXPORT (style FlowSOM R EXACT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# PARAMÈTRES DE JITTER - STYLE FLOWSOM R EXACT\n",
    "# Dans FlowSOM R, le jitter est CIRCULAIRE (pas carré!)\n",
    "# La taille du cercle dépend du nombre de cellules dans le cluster\n",
    "# Formule R: rnorm() * scale_factor * sqrt(node_size/max_size)\n",
    "# =====================================================================\n",
    "np.random.seed(SEED)  # Pour reproductibilité\n",
    "\n",
    "# Paramètres FlowSOM R\n",
    "MAX_NODE_SIZE = 0.45  # Rayon maximum du cercle (quand le node est le plus grand)\n",
    "MIN_NODE_SIZE = 0.1   # Rayon minimum du cercle (pour éviter que les petits nodes disparaissent)\n",
    "\n",
    "# Récupérer les coordonnées de grille et MST depuis cluster_data\n",
    "grid_coords = cluster_data.obsm.get('grid', None)\n",
    "layout_coords = cluster_data.obsm.get('layout', None)\n",
    "\n",
    "# Récupérer le clustering pour mapper les coordonnées sur chaque cellule\n",
    "clustering = cell_data.obs['clustering'].values\n",
    "n_cells = len(clustering)\n",
    "n_nodes = len(cluster_data)\n",
    "\n",
    "# Calculer la taille de chaque node (nombre de cellules)\n",
    "node_sizes = np.zeros(n_nodes, dtype=np.float32)\n",
    "for i in range(n_nodes):\n",
    "    node_sizes[i] = (clustering == i).sum()\n",
    "\n",
    "max_size = node_sizes.max()\n",
    "print(f\"\\n Taille des nodes:\")\n",
    "print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "print(f\"   Max: {max_size:.0f} cellules\")\n",
    "print(f\"   Total: {n_cells} cellules\")\n",
    "\n",
    "# Créer un DataFrame avec toutes les données\n",
    "df_export = pd.DataFrame(X, columns=var_names)\n",
    "\n",
    "# MetaCluster avec +1 pour Kaluza (éviter le 0, commencer à 1)\n",
    "df_export['FlowSOM_metacluster'] = metaclustering + 1\n",
    "\n",
    "# FlowSOM cluster (nodes) avec +1\n",
    "df_export['FlowSOM_cluster'] = clustering + 1\n",
    "\n",
    "# Ajouter les métadonnées si disponibles\n",
    "if 'condition' in cell_data.obs.columns:\n",
    "    df_export['Condition'] = cell_data.obs['condition'].values\n",
    "    df_export['Condition_Num'] = np.where(df_export['Condition'] == 'Sain', 1, 2)\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    df_export['File_Origin'] = cell_data.obs['file_origin'].values\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R exact)\n",
    "# Génère des points distribués uniformément dans un disque\n",
    "# Le rayon dépend de la taille du cluster\n",
    "# =====================================================================\n",
    "def circular_jitter(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    Génère un jitter circulaire style FlowSOM R.\n",
    "    \n",
    "    Dans FlowSOM R, les cellules sont distribuées dans des cercles\n",
    "    dont le rayon dépend du nombre de cellules dans le node.\n",
    "    Plus un node a de cellules, plus le cercle est grand.\n",
    "    \n",
    "    Méthode: \n",
    "    - Angle theta uniforme [0, 2*pi]\n",
    "    - Rayon r = sqrt(u) * max_r (pour distribution uniforme dans le disque)\n",
    "    - Le max_r dépend de la taille du node\n",
    "    \"\"\"\n",
    "    # Angle uniforme autour du cercle\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    \n",
    "    # Rayon - distribution uniforme dans le disque (sqrt pour uniformité)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    # Calculer le rayon pour chaque cellule selon la taille de son cluster\n",
    "    # Dans FlowSOM R, le rayon est proportionnel à sqrt(node_size/max_size)\n",
    "    max_size_val = node_sizes.max()\n",
    "    \n",
    "    # Rayon pour chaque cellule\n",
    "    radii = np.zeros(n_points, dtype=np.float32)\n",
    "    for i in range(n_points):\n",
    "        node_id = int(cluster_ids[i])\n",
    "        node_size = node_sizes[node_id]\n",
    "        # Rayon proportionnel à sqrt(taille relative)\n",
    "        size_ratio = np.sqrt(node_size / max_size_val)\n",
    "        # Interpolation entre min et max radius\n",
    "        node_radius = min_radius + (max_radius - min_radius) * size_ratio\n",
    "        radii[i] = node_radius\n",
    "    \n",
    "    # Rayon final pour distribution uniforme dans le disque\n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    # Convertir en coordonnées cartésiennes\n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONNÉES GRILLE SOM (xGrid, yGrid) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "print(f\"\\n Application du jitter CIRCULAIRE style FlowSOM R\")\n",
    "print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "\n",
    "if grid_coords is not None:\n",
    "    # Générer jitter CIRCULAIRE dépendant de la taille du node\n",
    "    jitter_x, jitter_y = circular_jitter(n_cells, clustering, node_sizes, \n",
    "                                          max_radius=MAX_NODE_SIZE, \n",
    "                                          min_radius=MIN_NODE_SIZE)\n",
    "    \n",
    "    # Mapper les coordonnées de grille sur chaque cellule\n",
    "    xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "    yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "    \n",
    "    # Appliquer le jitter circulaire\n",
    "    xGrid_jittered = xGrid_base + jitter_x\n",
    "    yGrid_jittered = yGrid_base + jitter_y\n",
    "    \n",
    "    # Décaler pour que les axes commencent à 1 (X ET Y)\n",
    "    xGrid = xGrid_jittered - xGrid_jittered.min() + 1.0\n",
    "    yGrid = yGrid_jittered - yGrid_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xGrid'] = xGrid.astype(np.float32)\n",
    "    df_export['yGrid'] = yGrid.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xGrid: [{xGrid.min():.3f} - {xGrid.max():.3f}]\")\n",
    "    print(f\"[OK] yGrid: [{yGrid.min():.3f} - {yGrid.max():.3f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONNÉES MST (xNodes, yNodes) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "if layout_coords is not None:\n",
    "    # Mapper les coordonnées MST sur chaque cellule\n",
    "    xNodes_base = np.array([layout_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "    yNodes_base = np.array([layout_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "    \n",
    "    # Calculer l'échelle pour le jitter MST (proportionnel à l'espacement moyen)\n",
    "    x_range = xNodes_base.max() - xNodes_base.min()\n",
    "    y_range = yNodes_base.max() - yNodes_base.min()\n",
    "    mst_scale = min(x_range, y_range) / (XDIM * 2)  # Proportionnel à la grille\n",
    "    \n",
    "    # Jitter circulaire pour MST aussi\n",
    "    mst_jitter_x, mst_jitter_y = circular_jitter(\n",
    "        n_cells, clustering, node_sizes,\n",
    "        max_radius=mst_scale * 0.8,  # Un peu moins que Grid car MST est plus espacé\n",
    "        min_radius=mst_scale * 0.2\n",
    "    )\n",
    "    \n",
    "    # Appliquer le jitter\n",
    "    xNodes_jittered = xNodes_base + mst_jitter_x\n",
    "    yNodes_jittered = yNodes_base + mst_jitter_y\n",
    "    \n",
    "    # Décaler pour que les axes commencent à 1 (X ET Y)\n",
    "    xNodes = xNodes_jittered - xNodes_jittered.min() + 1.0\n",
    "    yNodes = yNodes_jittered - yNodes_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xNodes'] = xNodes.astype(np.float32)\n",
    "    df_export['yNodes'] = yNodes.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xNodes: [{xNodes.min():.3f} - {xNodes.max():.3f}]\")\n",
    "    print(f\"[OK] yNodes: [{yNodes.min():.3f} - {yNodes.max():.3f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# TAILLE DES NODES (pour chaque cellule)\n",
    "# =====================================================================\n",
    "size_col = np.array([node_sizes[int(c)] for c in clustering], dtype=np.float32)\n",
    "df_export['size'] = size_col\n",
    "print(f\"[OK] size: [{size_col.min():.0f} - {size_col.max():.0f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT CSV\n",
    "# =====================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_path = os.path.join(OUTPUT_DIR, f\"flowsom_results_{timestamp}.csv\")\n",
    "df_export.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n[OK] CSV exporté: {csv_path}\")\n",
    "print(f\"   Shape: {df_export.shape}\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT FCS COMPATIBLE KALUZA\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📄 EXPORT FCS COMPATIBLE KALUZA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def export_to_fcs_kaluza(df, output_path):\n",
    "    \"\"\"Export FCS compatible Kaluza avec toutes les coordonnées positives.\"\"\"\n",
    "    try:\n",
    "        import fcswrite\n",
    "        \n",
    "        numeric_df = df.select_dtypes(include=[np.number])\n",
    "        data = numeric_df.values.astype(np.float32)\n",
    "        channels = list(numeric_df.columns)\n",
    "        \n",
    "        # Nettoyer NaN/Inf\n",
    "        data = np.nan_to_num(data, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "        \n",
    "        print(f\"   {data.shape[0]:,} events, {data.shape[1]} canaux\")\n",
    "        \n",
    "        fcswrite.write_fcs(output_path, channels, data, compat_chn_names=True)\n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"   [!] fcswrite non disponible (pip install fcswrite)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "# Préparer le DataFrame FCS\n",
    "df_fcs = df_export.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Vérifier les ranges\n",
    "print(f\"\\n Colonnes exportées vers FCS:\")\n",
    "for col in ['FlowSOM_metacluster', 'FlowSOM_cluster', 'xGrid', 'yGrid', 'xNodes', 'yNodes', 'size', 'Condition_Num']:\n",
    "    if col in df_fcs.columns:\n",
    "        print(f\"   [OK] {col:25s}: [{df_fcs[col].min():10.2f}, {df_fcs[col].max():10.2f}]\")\n",
    "\n",
    "# Export\n",
    "fcs_path = os.path.join(OUTPUT_DIR, f\"flowsom_results_{timestamp}.fcs\")\n",
    "if export_to_fcs_kaluza(df_fcs, fcs_path):\n",
    "    print(f\"\\n[OK] FCS exporté: {fcs_path}\")\n",
    "    print(f\"\\n Dans Kaluza/FlowJo:\")\n",
    "    print(f\"   - xGrid vs yGrid → visualisation grille SOM (cercles style FlowSOM R)\")\n",
    "    print(f\"   - xNodes vs yNodes → visualisation arbre MST\")\n",
    "    print(f\"   - La taille des cercles = proportionnelle au nombre de cellules\")\n",
    "    print(f\"   - Colorez par FlowSOM_metacluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT DU RAPPORT DE STATISTIQUES\n",
    "# =============================================================================\n",
    "\n",
    "# Sauvegarder le rapport de statistiques\n",
    "stats_path = os.path.join(OUTPUT_DIR, f\"flowsom_statistics_{timestamp}.csv\")\n",
    "df_stats.to_csv(stats_path, index=False)\n",
    "print(f\"[OK] Statistiques exportées: {stats_path}\")\n",
    "\n",
    "# Sauvegarder la matrice MFI\n",
    "mfi_path = os.path.join(OUTPUT_DIR, f\"flowsom_mfi_matrix_{timestamp}.csv\")\n",
    "df_mfi.to_csv(mfi_path)\n",
    "print(f\"[OK] Matrice MFI exportée: {mfi_path}\")\n",
    "\n",
    "# Résumé final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RÉSUMÉ DE L'ANALYSE FLOWSOM\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Fichiers analysés: {len(all_adatas)}\")\n",
    "print(f\"   Cellules totales: {len(cell_data)}\")\n",
    "print(f\"   Marqueurs utilisés: {len(used_markers)}\")\n",
    "print(f\"   Nombre de métaclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Transformation: {TRANSFORM_TYPE}\")\n",
    "print(f\"   Cofacteur: {COFACTOR}\")\n",
    "print(\"=\"*80)\n",
    "print(\"[OK] Analyse FlowSOM terminée avec succès!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECTION DES VARIABLES DU NOTEBOOK\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" LISTE DES OBJETS AnnData\")\n",
    "print(\"=\"*70)\n",
    "%who AnnData\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" LISTE DES DataFrames\")\n",
    "print(\"=\"*70)\n",
    "%who DataFrame\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" DÉTAILS DE adata_flowsom\")\n",
    "print(\"=\"*70)\n",
    "print(adata_flowsom)\n",
    "\n",
    "print(\"\\n- Shape:\", adata_flowsom.shape)\n",
    "print(\"- Variables (colonnes):\", list(adata_flowsom.var_names))\n",
    "print(\"- Observations (fichiers):\", adata_flowsom.obs.columns.tolist() if len(adata_flowsom.obs.columns) > 0 else \"Aucune annotation\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Statistiques de la matrice X:\")\n",
    "print(\"-\"*70)\n",
    "import pandas as pd\n",
    "stats = pd.DataFrame({\n",
    "    'Colonne': adata_flowsom.var_names,\n",
    "    'Min': adata_flowsom.X.min(axis=0),\n",
    "    'Max': adata_flowsom.X.max(axis=0),\n",
    "    'Moyenne': adata_flowsom.X.mean(axis=0),\n",
    "    'Std': adata_flowsom.X.std(axis=0)\n",
    "})\n",
    "display(stats)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Aperçu des observations (.obs):\")\n",
    "print(\"-\"*70)\n",
    "if adata_flowsom.obs.shape[1] > 0:\n",
    "    display(adata_flowsom.obs.head(10))\n",
    "else:\n",
    "    print(\"Aucune annotation dans .obs\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Toutes les variables disponibles:\")\n",
    "print(\"-\"*70)\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e481f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FLOWSOM SUMMARY - RAPPORT PDF COMPLET\n",
    "# =============================================================================\n",
    "# Génération automatique d'un PDF récapitulatif avec toutes les visualisations\n",
    "# Documentation: https://flowsom.readthedocs.io/en/stable/generated/flowsom.pl.FlowSOMmary.html\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Chemin du fichier PDF de sortie\n",
    "summary_pdf_path = os.path.join(OUTPUT_DIR, f\"FlowSOMmary_{timestamp}.pdf\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" GÉNÉRATION DU RAPPORT FlowSOMmary (PDF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Génération du rapport FlowSOMmary\n",
    "    # Inclut: marker_diff, cluster_profiles, grid, mst\n",
    "    # Exclut: UMAP (non demandé)\n",
    "    fs.pl.FlowSOMmary(\n",
    "        fsom,\n",
    "        plot_file=summary_pdf_path\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[OK] Rapport PDF généré avec succès!\")\n",
    "    print(f\"    Fichier: {summary_pdf_path}\")\n",
    "    print(f\"\\n    Contenu du rapport:\")\n",
    "    print(f\"    - Star plots (profils MFI par cluster)\")\n",
    "    print(f\"    - Grid SOM avec metaclusters\")\n",
    "    print(f\"    - Arbre MST avec metaclusters\")\n",
    "    print(f\"    - Heatmap des marqueurs par cluster\")\n",
    "    print(f\"    - Distribution des tailles de clusters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n[!] Erreur lors de la génération du FlowSOMmary:\")\n",
    "    print(f\"    {str(e)}\")\n",
    "    print(f\"\\n    Tentative de génération manuelle des graphiques...\")\n",
    "    \n",
    "    # Alternative: générer les graphiques individuellement\n",
    "    try:\n",
    "        from matplotlib.backends.backend_pdf import PdfPages\n",
    "        \n",
    "        with PdfPages(summary_pdf_path) as pdf:\n",
    "            # 1. Star plots par metacluster\n",
    "            print(\"    - Génération des star plots...\")\n",
    "            fig_stars = fs.pl.plot_stars(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_stars, bbox_inches='tight')\n",
    "            plt.close(fig_stars)\n",
    "            \n",
    "            # 2. Grid SOM\n",
    "            print(\"    - Génération de la grille SOM...\")\n",
    "            fig_grid = fs.pl.plot_grid(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_grid, bbox_inches='tight')\n",
    "            plt.close(fig_grid)\n",
    "            \n",
    "            # 3. Arbre MST\n",
    "            print(\"    - Génération de l'arbre MST...\")\n",
    "            fig_mst = fs.pl.plot_mst(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_mst, bbox_inches='tight')\n",
    "            plt.close(fig_mst)\n",
    "            \n",
    "            # 4. Marker heatmap\n",
    "            print(\"    - Génération de la heatmap des marqueurs...\")\n",
    "            fig_heatmap = fs.pl.plot_marker_heatmap(fsom)\n",
    "            pdf.savefig(fig_heatmap, bbox_inches='tight')\n",
    "            plt.close(fig_heatmap)\n",
    "            \n",
    "        print(f\"\\n[OK] Rapport PDF alternatif généré!\")\n",
    "        print(f\"    Fichier: {summary_pdf_path}\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"\\n[X] Impossible de générer le rapport: {str(e2)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FIN DE L'ANALYSE FlowSOM\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
