{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563bddce",
   "metadata": {},
   "source": [
    "# FlowSOM Analysis Pipeline - Notebook Headless\n",
    "\n",
    "## Pipeline complète d'analyse FlowSOM pour données de cytométrie en flux\n",
    "\n",
    "Ce notebook \"miroir\" de l'application FlowSOM Analyzer permet:\n",
    "- **Debug & Introspection**: Visualiser les données à chaque étape\n",
    "- **Tuning rapide**: Tester différents paramètres sans relancer l'app\n",
    "- **Séparation des responsabilités**: Logique métier pure, sans UI\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur**: Florian Magne\n",
    "**Version**: 1.0\n",
    "**Date**: Janvier 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4bea0",
   "metadata": {},
   "source": [
    "## 1. Import des Librairies\n",
    "\n",
    "Import de toutes les librairies nécessaires avec vérification de disponibilité des dépendances optionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# IMPORTS début du fichier\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports scientifiques de base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# CONFIGURATION PANDAS: Affichage en format linéaire (jamais exponentiel)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')  # 4 décimales max\n",
    "pd.set_option('display.max_columns', None)  # Afficher toutes les colonnes\n",
    "pd.set_option('display.width', None)  # Largeur auto\n",
    "pd.set_option('display.max_rows', 100)  # Max 100 lignes affichées\n",
    "np.set_printoptions(suppress=True, precision=4)  # Numpy aussi en linéaire\n",
    "print(\"[OK] Pandas configuré: affichage linéaire (pas de notation scientifique)\")\n",
    "\n",
    "# Imports visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['axes.facecolor'] = \"#ffffff\"\n",
    "plt.rcParams['text.color'] = \"#000000\"\n",
    "plt.rcParams['axes.labelcolor'] = \"#000000\"\n",
    "plt.rcParams['xtick.color'] = \"#000000\"\n",
    "plt.rcParams['ytick.color'] = \"#000000\"\n",
    "plt.rcParams['axes.edgecolor'] = \"#000000\"\n",
    "plt.rcParams['grid.color'] = \"#cccccc\"\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Plotly pour visualisations interactives\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    # Configuration pour affichage dans les notebooks\n",
    "    try:\n",
    "        # Essayer d'abord notebook_connected (meilleur pour Jupyter Lab/Notebook moderne)\n",
    "        pio.renderers.default = 'notebook_connected'\n",
    "    except:\n",
    "        # Sinon fallback sur notebook\n",
    "        pio.renderers.default = 'notebook'\n",
    "    # Alternative: forcer l'affichage inline\n",
    "    from plotly.offline import init_notebook_mode\n",
    "    init_notebook_mode(connected=True)\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"[OK] Plotly disponible\")\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non installé (optionnel): pip install plotly\")\n",
    "\n",
    "# IMPORTS flowsom et anndata, l'un est le package d'analyse du FlowSOM, l'autre est pour gérer les données dans des objets AnnData\n",
    "try:\n",
    "    import flowsom as fs\n",
    "    import anndata as ad\n",
    "    FLOWSOM_AVAILABLE = True\n",
    "    print(\"[OK] FlowSOM disponible\")\n",
    "except ImportError:\n",
    "    FLOWSOM_AVAILABLE = False\n",
    "    print(\"[X] FlowSOM non installé: pip install flowsom\")\n",
    "\n",
    "# Import de Scanpy pour UMAP/t-SNE\n",
    "try:\n",
    "    import scanpy as sc\n",
    "    SCANPY_AVAILABLE = True\n",
    "    print(\"[OK] Scanpy disponible\")\n",
    "except ImportError:\n",
    "    SCANPY_AVAILABLE = False\n",
    "    print(\"[!] Scanpy non installé (optionnel): pip install scanpy\")\n",
    "\n",
    "# Import de UMAP\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"[OK] UMAP disponible\")\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"[!] UMAP non installé (optionnel): pip install umap-learn\")\n",
    "\n",
    "\n",
    "# Import de t-SNE via sklearn car t-SNE trop lent à être implémenté dans Scanpy (et FlowSOM)\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.metrics import silhouette_score, r2_score\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"[OK] Scikit-learn disponible\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"[!] Scikit-learn non installé: pip install scikit-learn\")\n",
    "\n",
    "# FlowKit pour transformations Logicle\n",
    "try:\n",
    "    import flowkit as fk\n",
    "    FLOWKIT_AVAILABLE = True\n",
    "    # Configuration FlowKit: format linéaire pour les exports/affichages\n",
    "    # FlowKit utilise pandas en interne, donc pd.set_option s'applique\n",
    "    # Mais on configure aussi les options de logging/affichage si disponibles\n",
    "    try:\n",
    "        import logging\n",
    "        logging.getLogger('flowkit').setLevel(logging.WARNING)  # Moins de logs verbose\n",
    "    except:\n",
    "        pass\n",
    "    print(\"[OK] FlowKit disponible (transformations Logicle précise en 1 fonction)\")\n",
    "except ImportError:\n",
    "    FLOWKIT_AVAILABLE = False\n",
    "    print(\"[!] FlowKit non installé (optionnel): pip install flowkit)\")\n",
    "\n",
    "# FCSWrite pour export FCS\n",
    "try:\n",
    "    import fcswrite\n",
    "    FCSWRITE_AVAILABLE = True\n",
    "    print(\"[OK] FCSWrite disponible (export FCS)\")\n",
    "except ImportError:\n",
    "    FCSWRITE_AVAILABLE = False\n",
    "    print(\"[!] FCSWrite non installé (optionnel): pip install fcswrite\")\n",
    "\n",
    "# Scipy pour statistiques \n",
    "from scipy import stats\n",
    "\n",
    "# =============================================================================\n",
    "# GATERESULT — Structure de retour pour chaque fonction de gating\n",
    "# =============================================================================\n",
    "@dataclass\n",
    "class GateResult:\n",
    "    \"\"\"\n",
    "    Résultat structuré d'une opération de gating.\n",
    "    Stocké dans combined_data.uns[\"gating_reports\"] pour audit et rapport HTML.\n",
    "    \"\"\"\n",
    "    mask: np.ndarray\n",
    "    n_kept: int\n",
    "    n_total: int\n",
    "    method: str\n",
    "    gate_name: str = \"\"\n",
    "    details: Dict[str, Any] = field(default_factory=dict)\n",
    "    warnings: List[str] = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def pct_kept(self) -> float:\n",
    "        return (self.n_kept / max(self.n_total, 1)) * 100\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Sérialisation JSON-safe (sans le mask numpy).\"\"\"\n",
    "        return {\n",
    "            \"gate_name\": self.gate_name,\n",
    "            \"method\": self.method,\n",
    "            \"n_kept\": self.n_kept,\n",
    "            \"n_total\": self.n_total,\n",
    "            \"pct_kept\": round(self.pct_kept, 2),\n",
    "            \"details\": self.details,\n",
    "            \"warnings\": self.warnings,\n",
    "        }\n",
    "\n",
    "# Liste globale pour collecter les rapports de gating\n",
    "gating_reports: List[GateResult] = []\n",
    "\n",
    "# =============================================================================\n",
    "# LOGGING STRUCTURÉ — gating_log.json\n",
    "# =============================================================================\n",
    "gating_log_entries: List[Dict[str, Any]] = []\n",
    "\n",
    "def log_gating_event(gate_name: str, method: str, status: str, \n",
    "                     details: Dict[str, Any] = None, warning_msg: str = None):\n",
    "    \"\"\"Log structuré d'un événement de gating (JSON exportable).\"\"\"\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"gate_name\": gate_name,\n",
    "        \"method\": method,\n",
    "        \"status\": status,  # \"success\", \"fallback\", \"warning\", \"error\"\n",
    "        \"details\": details or {},\n",
    "    }\n",
    "    if warning_msg:\n",
    "        entry[\"warning\"] = warning_msg\n",
    "        print(f\"   [WARNING] {gate_name}: {warning_msg}\")\n",
    "    gating_log_entries.append(entry)\n",
    "\n",
    "print(\"\\n[OK] GateResult dataclass + logging structuré chargés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import en haut de fichier des classes utilitaires permettant les transformations des fichiers ainsi que le pre-gating \n",
    "\n",
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    Transformations de données de cytométrie (Logicle, Arcsinh, etc.).\n",
    "    Classe statique réutilisable sans dépendance à l'UI.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_transform(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Arcsinh (inverse hyperbolic sine).\n",
    "        \n",
    "        Args en entrée:\n",
    "            data: Matrice de données (n_cells, n_markers)\n",
    "            cofactor: Facteur de division (5 pour flow cytometry)\n",
    "        \n",
    "        Returns:\n",
    "            Données transformées\n",
    "        \"\"\"\n",
    "        return np.arcsinh(data / cofactor)\n",
    "    \n",
    "    @staticmethod\n",
    "    def arcsinh_inverse(data: np.ndarray, cofactor: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"Inverse de la transformation Arcsinh.\"\"\"\n",
    "        return np.sinh(data) * cofactor\n",
    "    \n",
    "    @staticmethod\n",
    "    def logicle_transform(data: np.ndarray, T: float = 262144.0, M: float = 4.5,\n",
    "                          W: float = 0.5, A: float = 0.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transformation Logicle (biexponentielle).\n",
    "        \n",
    "        Args en entrée:\n",
    "            data: Matrice de données\n",
    "            T: Maximum de l'échelle linéaire (262144 = 2^18)\n",
    "            M: Décades de largeur\n",
    "            W: Linéarisation près de zéro\n",
    "            A: Décades additionnelles (négatifs)\n",
    "        \n",
    "        Returns:\n",
    "            Données transformées\n",
    "        \"\"\"\n",
    "        if FLOWKIT_AVAILABLE:\n",
    "            # Utiliser FlowKit si disponible (plus précis) avec une fonction prédéfinie\n",
    "            try:\n",
    "                xform = fk.transforms.LogicleTransform(T=T, M=M, W=W, A=A)\n",
    "                return xform.apply(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Approximation si FlowKit absent: Arcsinh modifié\n",
    "        w_val = W * np.log10(np.e)\n",
    "        return np.arcsinh(data / (T / (10 ** M))) * (M / np.log(10))\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_transform(data: np.ndarray, base: float = 10.0,\n",
    "                      min_val: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"Transformation logarithmique standard.\"\"\"\n",
    "        data_clipped = np.maximum(data, min_val)\n",
    "        return np.log(data_clipped) / np.log(base)\n",
    "    \n",
    "    @staticmethod\n",
    "    def zscore_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Z-score (moyenne=0, std=1).\"\"\"\n",
    "        mean = np.nanmean(data, axis=0)\n",
    "        std = np.nanstd(data, axis=0)\n",
    "        std[std == 0] = 1  # Éviter division par zéro\n",
    "        return (data - mean) / std\n",
    "    \n",
    "    @staticmethod\n",
    "    def min_max_normalize(data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalisation Min-Max [0, 1].\"\"\"\n",
    "        min_val = np.nanmin(data, axis=0)\n",
    "        max_val = np.nanmax(data, axis=0)\n",
    "        range_val = max_val - min_val\n",
    "        range_val[range_val == 0] = 1\n",
    "        return (data - min_val) / range_val\n",
    "\n",
    "\n",
    "class PreGating:\n",
    "    \"\"\"\n",
    "    Pre-gating automatique pour la sélection des populations d'intérêt.\n",
    "    Basé sur FSC/SSC pour exclure les débris et les doublets.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_marker_index(var_names: List[str], patterns: List[str]) -> Optional[int]:\n",
    "        \"\"\"Trouve l'index d'un marqueur parmi les patterns donnés.\"\"\"\n",
    "        var_upper = [v.upper() for v in var_names]\n",
    "        for pattern in patterns:\n",
    "            for i, name in enumerate(var_upper):\n",
    "                if pattern.upper() in name:\n",
    "                    return i\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_viable_cells(X: np.ndarray, var_names: List[str],\n",
    "                          min_percentile: float = 2.0, \n",
    "                          max_percentile: float = 98.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules viables basé sur FSC/SSC.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            min_percentile: Percentile minimum (exclusion débris)\n",
    "            max_percentile: Percentile maximum (exclusion doublets)\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des cellules viables\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        mask = np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Trouver FSC (priorité à FSC-A)\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A', 'FSC-H', 'FSC'])\n",
    "        if fsc_idx is not None:\n",
    "            fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "            fsc_vals = np.where(np.isfinite(fsc_vals), fsc_vals, np.nan)\n",
    "            low = np.nanpercentile(fsc_vals, min_percentile)\n",
    "            high = np.nanpercentile(fsc_vals, max_percentile)\n",
    "            mask &= np.isfinite(fsc_vals) & (fsc_vals >= low) & (fsc_vals <= high)\n",
    "        \n",
    "        # Trouver SSC (priorité à SSC-A)\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "        if ssc_idx is not None:\n",
    "            ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "            ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "            low = np.nanpercentile(ssc_vals, min_percentile)\n",
    "            high = np.nanpercentile(ssc_vals, max_percentile)\n",
    "            mask &= np.isfinite(ssc_vals) & (ssc_vals >= low) & (ssc_vals <= high)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_singlets(X: np.ndarray, var_names: List[str],\n",
    "                      ratio_min: float = 0.6, ratio_max: float = 1.5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les singlets basé sur le ratio FSC-A/FSC-H.\n",
    "        Les doublets ont typiquement un ratio > 1.3-1.5.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            ratio_min: Ratio minimum acceptable\n",
    "            ratio_max: Ratio maximum acceptable\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des singlets\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouvé, pas de gating singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # Valeurs minimum pour éviter division par zéro\n",
    "        min_val = 100\n",
    "        valid_h = fsc_h > min_val\n",
    "        \n",
    "        ratio = np.full(n_cells, np.nan)\n",
    "        ratio[valid_h] = fsc_a[valid_h] / fsc_h[valid_h]\n",
    "        \n",
    "        mask = np.isfinite(ratio) & (ratio >= ratio_min) & (ratio <= ratio_max)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd45_positive(X: np.ndarray, var_names: List[str],\n",
    "                           threshold_percentile: float = 10) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les cellules CD45+ (leucocytes).\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des cellules CD45+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouvé, pas de gating CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45_vals = X[:, cd45_idx].astype(np.float64)\n",
    "        cd45_vals = np.where(np.isfinite(cd45_vals), cd45_vals, np.nan)\n",
    "        \n",
    "        threshold = np.nanpercentile(cd45_vals, threshold_percentile)\n",
    "        \n",
    "        return np.where(np.isnan(cd45_vals), False, cd45_vals > threshold)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_cd34_blasts(X: np.ndarray, var_names: List[str],\n",
    "                         threshold_percentile: float = 85,\n",
    "                         use_ssc_filter: bool = True,\n",
    "                         ssc_max_percentile: float = 70) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate les blastes CD34+ (cellules souches/progénitrices).\n",
    "        \n",
    "        Les blastes sont typiquement:\n",
    "        - CD34 bright (haute expression)\n",
    "        - SSC low (faible granularité)\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            threshold_percentile: Percentile pour définir le seuil CD34+ (ex: 85 = top 15%)\n",
    "            use_ssc_filter: Appliquer aussi un filtre SSC pour enrichir en blastes\n",
    "            ssc_max_percentile: Percentile max de SSC pour blastes (faible granularité)\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des blastes CD34+\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        # Chercher CD34 avec différents nommages possibles\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouvé, pas de gating blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34_vals = X[:, cd34_idx].astype(np.float64)\n",
    "        cd34_vals = np.where(np.isfinite(cd34_vals), cd34_vals, np.nan)\n",
    "        \n",
    "        # Seuil CD34+ (prendre les cellules avec haute expression)\n",
    "        threshold_cd34 = np.nanpercentile(cd34_vals, threshold_percentile)\n",
    "        mask_cd34 = np.where(np.isnan(cd34_vals), False, cd34_vals >= threshold_cd34)\n",
    "        \n",
    "        # Optionnel: filtrer aussi par SSC low (blastes = faible granularité)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "                ssc_vals = np.where(np.isfinite(ssc_vals), ssc_vals, np.nan)\n",
    "                threshold_ssc = np.nanpercentile(ssc_vals, ssc_max_percentile)\n",
    "                mask_ssc = np.where(np.isnan(ssc_vals), False, ssc_vals <= threshold_ssc)\n",
    "                return mask_cd34 & mask_ssc\n",
    "        \n",
    "        return mask_cd34\n",
    "    \n",
    "    @staticmethod\n",
    "    def gate_debris_polygon(X: np.ndarray, var_names: List[str],\n",
    "                            fsc_min: float = None, fsc_max: float = None,\n",
    "                            ssc_min: float = None, ssc_max: float = None,\n",
    "                            auto_percentiles: bool = True,\n",
    "                            min_pct: float = 1.0, max_pct: float = 99.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate rectangulaire/polygonal pour exclure les débris sur FSC-A vs SSC-A.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Liste des noms de marqueurs\n",
    "            fsc_min/fsc_max: Seuils FSC manuels (si auto_percentiles=False)\n",
    "            ssc_min/ssc_max: Seuils SSC manuels (si auto_percentiles=False)\n",
    "            auto_percentiles: Calculer automatiquement les seuils via percentiles\n",
    "            min_pct/max_pct: Percentiles pour auto-calcul\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen des cellules (non-débris)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        \n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouvé pour gate débris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_vals = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc_vals = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Calculer les seuils automatiquement si demandé\n",
    "        if auto_percentiles:\n",
    "            fsc_min = np.nanpercentile(fsc_vals, min_pct)\n",
    "            fsc_max = np.nanpercentile(fsc_vals, max_pct)\n",
    "            ssc_min = np.nanpercentile(ssc_vals, min_pct)\n",
    "            ssc_max = np.nanpercentile(ssc_vals, max_pct)\n",
    "        \n",
    "        # Appliquer le gate rectangulaire\n",
    "        mask = (\n",
    "            np.isfinite(fsc_vals) & np.isfinite(ssc_vals) &\n",
    "            (fsc_vals >= fsc_min) & (fsc_vals <= fsc_max) &\n",
    "            (ssc_vals >= ssc_min) & (ssc_vals <= ssc_max)\n",
    "        )\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "print(\"[OK] Classes DataTransformer et PreGating chargées!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715de552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLASSE AutoGating — Gating adaptatif par GMM/KDE\n",
    "# =============================================================================\n",
    "# Inspiré de CytoPy AutonomousGate (sans dépendance MongoDB)\n",
    "# Utilise scikit-learn GaussianMixture pour trouver les \"creux\" réels\n",
    "# entre les populations au lieu de couper à des percentiles fixes.\n",
    "#\n",
    "# Avantages vs PreGating (percentiles):\n",
    "#   - Si un échantillon a 10% de débris → la porte s'adapte automatiquement\n",
    "#   - Si un échantillon est propre → moins de perte de données\n",
    "#   - Pour les doublets: modélise la diagonale FSC-A/FSC-H statistiquement\n",
    "#   - Pour CD45+: trouve le creux bimodal entre CD45- et CD45+\n",
    "#\n",
    "# [V2 AMÉLIORATIONS]:\n",
    "#   - safe_fit_gmm: sous-échantillonnage à 200k points max avant fit\n",
    "#   - auto_gate_singlets: contrôle R² RANSAC + fallback ratio si R² < 0.85\n",
    "#   - Toutes les fonctions retournent un GateResult structuré\n",
    "#   - Scatter FSC-A vs FSC-H par fichier + tableau % singlets stockés\n",
    "#   - Log structuré JSON pour audit automatique des runs\n",
    "# =============================================================================\n",
    "\n",
    "# Stockage global des scatter data RANSAC par fichier (pour le rapport HTML)\n",
    "ransac_scatter_data = {}  # {file_name: {fsc_h, fsc_a, pred, inlier_mask, r2, slope, intercept, pct_singlets}}\n",
    "singlets_summary_per_file = []  # Liste de dicts pour tableau \"% singlets par fichier\"\n",
    "\n",
    "class AutoGating:\n",
    "    \"\"\"\n",
    "    Gating automatique adaptatif basé sur des modèles de mélange gaussien (GMM)\n",
    "    et estimation de densité. Inspiré de CytoPy AutonomousGate.\n",
    "    \n",
    "    Chaque méthode utilise un GMM pour identifier les populations naturelles\n",
    "    dans les données, au lieu de seuils fixes basés sur des percentiles.\n",
    "    \n",
    "    Dépendances: scikit-learn (GaussianMixture, StandardScaler)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Seuil R² minimal pour la régression RANSAC (en dessous → fallback ratio)\n",
    "    RANSAC_R2_THRESHOLD = 0.85\n",
    "    # Sous-échantillonnage max avant GMM (convergence + performance)\n",
    "    GMM_MAX_SAMPLES = 200_000\n",
    "    \n",
    "    @staticmethod\n",
    "    def _subsample_for_gmm(data: np.ndarray, max_samples: int = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Sous-échantillonne les données si elles dépassent max_samples.\n",
    "        Améliore la convergence et évite les timeouts implicites sur gros jeux.\n",
    "        \n",
    "        Args:\n",
    "            data: Données (n_samples, n_features)\n",
    "            max_samples: Nombre max de points (défaut: GMM_MAX_SAMPLES)\n",
    "        \n",
    "        Returns:\n",
    "            data_subsampled: Données sous-échantillonnées (ou originales si < max)\n",
    "        \"\"\"\n",
    "        if max_samples is None:\n",
    "            max_samples = AutoGating.GMM_MAX_SAMPLES\n",
    "        if data.shape[0] > max_samples:\n",
    "            idx = np.random.choice(data.shape[0], size=max_samples, replace=False)\n",
    "            print(f\"      [GMM] Sous-échantillonnage: {data.shape[0]:,} → {max_samples:,} points\")\n",
    "            return data[idx]\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def safe_fit_gmm(data: np.ndarray, n_components: int = 2,\n",
    "                     n_init: int = 3, max_retries: int = 5,\n",
    "                     random_state: int = 42,\n",
    "                     covariance_type: str = 'full',\n",
    "                     max_iter: int = 200,\n",
    "                     subsample: bool = True) -> Any:\n",
    "        \"\"\"\n",
    "        Wrapper robuste pour le fitting GMM avec gestion d'erreurs.\n",
    "        \n",
    "        Tente le fit plusieurs fois avec différentes initialisations.\n",
    "        En cas d'échec total sur n_components > 1, fallback sur 1 composante.\n",
    "        Vérifie la convergence et émet des warnings si nécessaire.\n",
    "        \n",
    "        [V2] Sous-échantillonnage automatique à 200k points max avant fit.\n",
    "        \n",
    "        Args:\n",
    "            data: Données à fitter (n_samples, n_features) ou (n_samples, 1)\n",
    "            n_components: Nombre de composantes GMM\n",
    "            n_init: Nombre d'initialisations par tentative\n",
    "            max_retries: Nombre max de tentatives avant fallback\n",
    "            random_state: Seed pour reproductibilité\n",
    "            covariance_type: Type de covariance ('full', 'diag', 'spherical', 'tied')\n",
    "            max_iter: Nombre max d'itérations EM\n",
    "            subsample: Si True, sous-échantillonne avant fit (défaut True)\n",
    "        \n",
    "        Returns:\n",
    "            GaussianMixture fitté\n",
    "        \n",
    "        Raises:\n",
    "            RuntimeError: Si le fit échoue après toutes les tentatives (y compris fallback)\n",
    "        \"\"\"\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        \n",
    "        # Sous-échantillonnage pour convergence rapide sur gros jeux de données\n",
    "        if subsample:\n",
    "            data_fit = AutoGating._subsample_for_gmm(data)\n",
    "        else:\n",
    "            data_fit = data\n",
    "        \n",
    "        last_error = None\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=n_components,\n",
    "                    random_state=random_state + attempt,\n",
    "                    n_init=n_init,\n",
    "                    covariance_type=covariance_type,\n",
    "                    max_iter=max_iter\n",
    "                )\n",
    "                gmm.fit(data_fit)\n",
    "                if not gmm.converged_:\n",
    "                    warnings.warn(f\"GMM non-convergé (n={n_components}, tentative {attempt+1}/{max_retries})\")\n",
    "                    log_gating_event(\"GMM\", f\"n_components={n_components}\", \"warning\",\n",
    "                                     {\"attempt\": attempt+1},\n",
    "                                     f\"Non-convergé tentative {attempt+1}/{max_retries}\")\n",
    "                    continue\n",
    "                return gmm\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                log_gating_event(\"GMM\", f\"n_components={n_components}\", \"error\",\n",
    "                                 {\"attempt\": attempt+1, \"error\": str(e)})\n",
    "                continue\n",
    "        \n",
    "        # Fallback: tenter avec 1 composante si n_components > 1\n",
    "        if n_components > 1:\n",
    "            warn_msg = f\"GMM fallback unimodal après {max_retries} échecs (dernière erreur: {last_error})\"\n",
    "            warnings.warn(warn_msg)\n",
    "            log_gating_event(\"GMM\", \"fallback_unimodal\", \"fallback\",\n",
    "                             {\"original_n_components\": n_components, \"error\": str(last_error)},\n",
    "                             warn_msg)\n",
    "            try:\n",
    "                gmm = GaussianMixture(\n",
    "                    n_components=1,\n",
    "                    random_state=random_state,\n",
    "                    n_init=1,\n",
    "                    covariance_type=covariance_type,\n",
    "                    max_iter=max_iter\n",
    "                )\n",
    "                gmm.fit(data_fit)\n",
    "                return gmm\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\n",
    "                    f\"GMM fit échoué après {max_retries} tentatives + fallback unimodal: {e}\"\n",
    "                )\n",
    "        \n",
    "        raise RuntimeError(\n",
    "            f\"GMM fit échoué après {max_retries} tentatives: {last_error}\"\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_debris(X: np.ndarray, var_names: List[str],\n",
    "                          n_components: int = 3,\n",
    "                          min_cluster_fraction: float = 0.02) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate débris adaptatif par GMM 2D sur FSC-A / SSC-A.\n",
    "        \n",
    "        L'algorithme identifie les clusters naturels dans l'espace FSC/SSC:\n",
    "        - Débris: événements bas en FSC-A (petites particules)\n",
    "        - Cellules: population principale (cluster dominant)  \n",
    "        - Saturés: événements très hauts (optionnel, détecté par BIC)\n",
    "        \n",
    "        Sélection automatique du nombre de composantes par BIC (2 ou 3).\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Noms des marqueurs\n",
    "            n_components: Nombre max de composantes GMM à tester\n",
    "            min_cluster_fraction: Fraction min d'événements pour inclure un cluster\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = cellule viable, False = débris/saturé)\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        fsc_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A'])\n",
    "        \n",
    "        if fsc_idx is None or ssc_idx is None:\n",
    "            print(\"[!] FSC-A ou SSC-A non trouvé pour auto-gate débris\")\n",
    "            log_gating_event(\"debris\", \"auto_gmm\", \"error\", warning_msg=\"FSC-A ou SSC-A non trouvé\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc = X[:, fsc_idx].astype(np.float64)\n",
    "        ssc = X[:, ssc_idx].astype(np.float64)\n",
    "        \n",
    "        # Filtrer les NaN/Inf\n",
    "        valid = np.isfinite(fsc) & np.isfinite(ssc)\n",
    "        data_2d = np.column_stack([fsc[valid], ssc[valid]])\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate débris\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Standardiser avant GMM pour meilleure convergence\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(data_2d)\n",
    "        \n",
    "        # Sélection automatique du nombre de composantes par BIC\n",
    "        best_bic = np.inf\n",
    "        best_gmm = None\n",
    "        for n_comp in [2, 3]:\n",
    "            try:\n",
    "                gmm_test = AutoGating.safe_fit_gmm(\n",
    "                    data_scaled, n_components=n_comp,\n",
    "                    covariance_type='full', n_init=3, max_iter=200\n",
    "                )\n",
    "                bic = gmm_test.bic(data_scaled if data_scaled.shape[0] <= AutoGating.GMM_MAX_SAMPLES \n",
    "                                   else AutoGating._subsample_for_gmm(data_scaled))\n",
    "                if bic < best_bic:\n",
    "                    best_bic = bic\n",
    "                    best_gmm = gmm_test\n",
    "            except RuntimeError as e:\n",
    "                print(f\"   [!] GMM {n_comp} composantes échoué: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if best_gmm is None:\n",
    "            print(\"   [!] Aucun GMM n'a convergé, conservation de tous les événements\")\n",
    "            log_gating_event(\"debris\", \"auto_gmm\", \"fallback\",\n",
    "                             warning_msg=\"Aucun GMM convergé, toutes cellules conservées\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        labels = best_gmm.predict(data_scaled)\n",
    "        n_comp = best_gmm.n_components\n",
    "        \n",
    "        # Statistiques par cluster (en espace original)\n",
    "        cluster_sizes = np.bincount(labels, minlength=n_comp)\n",
    "        cluster_fsc_means = np.array([data_2d[labels == i, 0].mean() for i in range(n_comp)])\n",
    "        \n",
    "        # Population principale = plus grand cluster\n",
    "        main_cluster = np.argmax(cluster_sizes)\n",
    "        \n",
    "        # Inclure les clusters avec assez d'événements et un FSC raisonnable\n",
    "        # (exclure les débris = FSC très bas)\n",
    "        mask_valid = np.zeros(valid.sum(), dtype=bool)\n",
    "        fsc_threshold = cluster_fsc_means[main_cluster] * 0.25\n",
    "        \n",
    "        for i in range(n_comp):\n",
    "            fraction = cluster_sizes[i] / len(labels)\n",
    "            if fraction >= min_cluster_fraction and cluster_fsc_means[i] >= fsc_threshold:\n",
    "                mask_valid |= (labels == i)\n",
    "        \n",
    "        # Sécurité: si aucun cluster sélectionné, garder le principal\n",
    "        if not mask_valid.any():\n",
    "            mask_valid = (labels == main_cluster)\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = mask_valid\n",
    "        \n",
    "        n_kept = mask.sum()\n",
    "        print(f\"   [Auto-GMM] {best_gmm.n_components} composantes détectées (BIC={best_bic:.0f})\")\n",
    "        for i in range(n_comp):\n",
    "            status = \"✓\" if mask_valid[labels == i].any() else \"✗\"\n",
    "            print(f\"     {status} Cluster {i}: {cluster_sizes[i]:,} evt, FSC-A moy={cluster_fsc_means[i]:.0f}\")\n",
    "        print(f\"   [Auto-GMM] → Conservés: {n_kept:,} événements\")\n",
    "        \n",
    "        # Log structuré\n",
    "        log_gating_event(\"debris\", \"auto_gmm\", \"success\", {\n",
    "            \"n_components\": int(n_comp), \"bic\": float(best_bic),\n",
    "            \"n_kept\": int(n_kept), \"n_total\": int(n_cells),\n",
    "            \"cluster_sizes\": cluster_sizes.tolist(),\n",
    "        })\n",
    "        \n",
    "        # Construire GateResult\n",
    "        gate_result = GateResult(\n",
    "            mask=mask, n_kept=int(n_kept), n_total=int(n_cells),\n",
    "            method=\"auto_gmm_debris\", gate_name=\"G1_debris\",\n",
    "            details={\"n_components\": int(n_comp), \"bic\": float(best_bic),\n",
    "                     \"cluster_fsc_means\": cluster_fsc_means.tolist()},\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_singlets(X: np.ndarray, var_names: List[str], \n",
    "                          file_origin: Optional[np.ndarray] = None,\n",
    "                          per_file: bool = True,\n",
    "                          r2_threshold: float = 0.85) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate singlets adaptatif par régression linéaire robuste (RANSAC).\n",
    "        \n",
    "        Les singlets forment une diagonale sur le plot FSC-A vs FSC-H.\n",
    "        Les doublets se situent au-dessus de cette diagonale (FSC-A augmente mais pas FSC-H).\n",
    "        \n",
    "        Méthode améliorée (V2):\n",
    "        1. Pré-filtre viable (FSC/SSC 1-99%) pour exclure les outliers extrêmes\n",
    "        2. Régression linéaire robuste RANSAC sur FSC-A vs FSC-H\n",
    "        3. Contrôle qualité R² sur les inliers RANSAC\n",
    "        4. Si R² < seuil (0.85): fallback vers gating ratio FSC-A/FSC-H simple\n",
    "        5. Stockage des scatter data par fichier pour le rapport HTML\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données (n_cells, n_markers)\n",
    "            var_names: Noms des marqueurs\n",
    "            file_origin: Array contenant l'origine de chaque cellule (pour gating par fichier)\n",
    "            per_file: Si True, applique le gating séparément par fichier\n",
    "            r2_threshold: Seuil R² minimum (défaut 0.85). En dessous → fallback ratio\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = singlet, False = doublet)\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import RANSACRegressor\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        n_cells = X.shape[0]\n",
    "        fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "        fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "        \n",
    "        if fsc_a_idx is None or fsc_h_idx is None:\n",
    "            print(\"[!] FSC-A ou FSC-H non trouvé pour auto-gate singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        fsc_a = X[:, fsc_a_idx].astype(np.float64)\n",
    "        fsc_h = X[:, fsc_h_idx].astype(np.float64)\n",
    "        \n",
    "        # Pré-filtre viable (FSC/SSC 1-99%) pour réduire l'impact des outliers\n",
    "        # extrêmes (blastes matures, granulocytes agrégés) sur la régression RANSAC\n",
    "        viable = PreGating.gate_viable_cells(X, var_names, min_percentile=1.0, max_percentile=99.0)\n",
    "        \n",
    "        # Filtrer: valeurs valides avec FSC > seuil minimal + viabilité\n",
    "        valid = viable & np.isfinite(fsc_a) & np.isfinite(fsc_h) & (fsc_h > 100) & (fsc_a > 100)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate singlets\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        \n",
    "        # ─── Helper interne: fallback ratio FSC-A/FSC-H ───\n",
    "        def _fallback_ratio_gating(fsc_a_local, fsc_h_local, ratio_min=0.6, ratio_max=1.5):\n",
    "            \"\"\"Gating simple par ratio FSC-A/FSC-H (ancienne méthode).\"\"\"\n",
    "            ratio = fsc_a_local.ravel() / np.maximum(fsc_h_local.ravel(), 1.0)\n",
    "            return (ratio >= ratio_min) & (ratio <= ratio_max)\n",
    "        \n",
    "        # Gating par fichier si demandé et si file_origin fourni\n",
    "        if per_file and file_origin is not None:\n",
    "            unique_files = np.unique(file_origin)\n",
    "            print(f\"   [Auto-RANSAC] Gating par fichier ({len(unique_files)} fichiers)\")\n",
    "            \n",
    "            total_singlets = 0\n",
    "            total_doublets = 0\n",
    "            \n",
    "            for file_name in unique_files:\n",
    "                # Sélectionner les cellules de ce fichier\n",
    "                file_mask = (file_origin == file_name) & valid\n",
    "                \n",
    "                if file_mask.sum() < 50:\n",
    "                    # Trop peu de cellules, garder toutes\n",
    "                    mask[file_mask] = True\n",
    "                    singlets_summary_per_file.append({\n",
    "                        \"file\": str(file_name), \"n_total\": int(file_mask.sum()),\n",
    "                        \"n_singlets\": int(file_mask.sum()), \"pct_singlets\": 100.0,\n",
    "                        \"method\": \"skip_too_few\", \"r2\": None,\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                fsc_a_file = fsc_a[file_mask].reshape(-1, 1)\n",
    "                fsc_h_file = fsc_h[file_mask].reshape(-1, 1)\n",
    "                \n",
    "                # Régression RANSAC pour trouver la diagonale des singlets\n",
    "                try:\n",
    "                    ransac = RANSACRegressor(\n",
    "                        estimator=LinearRegression(),\n",
    "                        min_samples=50,\n",
    "                        residual_threshold=None,  # Auto (MAD)\n",
    "                        random_state=42,\n",
    "                        max_trials=100\n",
    "                    )\n",
    "                    ransac.fit(fsc_h_file, fsc_a_file.ravel())\n",
    "                    \n",
    "                    # ─── CONTRÔLE QUALITÉ R² SUR INLIERS RANSAC ───\n",
    "                    inlier_mask = ransac.inlier_mask_\n",
    "                    r2_val = None\n",
    "                    used_method = \"ransac\"\n",
    "                    \n",
    "                    if inlier_mask is not None and inlier_mask.sum() > 50:\n",
    "                        r2_val = r2_score(\n",
    "                            fsc_a_file[inlier_mask].ravel(),\n",
    "                            ransac.predict(fsc_h_file[inlier_mask])\n",
    "                        )\n",
    "                        \n",
    "                        if r2_val < r2_threshold:\n",
    "                            # ─── FALLBACK: gating ratio simple ───\n",
    "                            warn_msg = f\"R² faible pour {file_name} (R²={r2_val:.2f} < {r2_threshold}), fallback gating ratio\"\n",
    "                            print(f\"      [!] {warn_msg}\")\n",
    "                            log_gating_event(\"singlets\", \"ransac_fallback_ratio\", \"fallback\",\n",
    "                                             {\"file\": str(file_name), \"r2\": float(r2_val)}, warn_msg)\n",
    "                            \n",
    "                            singlets_file = _fallback_ratio_gating(fsc_a_file, fsc_h_file)\n",
    "                            used_method = \"ratio_fallback\"\n",
    "                            \n",
    "                            # Appliquer\n",
    "                            file_indices = np.where(file_mask)[0]\n",
    "                            mask[file_indices] = singlets_file\n",
    "                            \n",
    "                            n_sing = int(singlets_file.sum())\n",
    "                            n_doub = len(singlets_file) - n_sing\n",
    "                            total_singlets += n_sing\n",
    "                            total_doublets += n_doub\n",
    "                            \n",
    "                            file_short = file_name if len(file_name) <= 25 else file_name[:22] + \"...\"\n",
    "                            print(f\"      • {file_short}: {n_sing:,} singlets / {n_sing+n_doub:,} ({n_sing/(n_sing+n_doub)*100:.1f}%) - RATIO FALLBACK (R²={r2_val:.2f})\")\n",
    "                            \n",
    "                            # Stocker les scatter data (même si fallback, pour diagnostic)\n",
    "                            n_sample_pts = min(2000, len(fsc_a_file))\n",
    "                            sample_idx = np.random.choice(len(fsc_a_file), n_sample_pts, replace=False)\n",
    "                            ransac_scatter_data[str(file_name)] = {\n",
    "                                \"fsc_h\": fsc_h_file[sample_idx].ravel().tolist(),\n",
    "                                \"fsc_a\": fsc_a_file[sample_idx].ravel().tolist(),\n",
    "                                \"pred\": ransac.predict(fsc_h_file[sample_idx]).tolist(),\n",
    "                                \"r2\": float(r2_val),\n",
    "                                \"method\": \"ratio_fallback\",\n",
    "                                \"slope\": float(ransac.estimator_.coef_[0]),\n",
    "                                \"intercept\": float(ransac.estimator_.intercept_),\n",
    "                            }\n",
    "                            singlets_summary_per_file.append({\n",
    "                                \"file\": str(file_name), \"n_total\": int(len(singlets_file)),\n",
    "                                \"n_singlets\": n_sing, \"pct_singlets\": round(n_sing/(n_sing+n_doub)*100, 1),\n",
    "                                \"method\": \"ratio_fallback\", \"r2\": round(float(r2_val), 3),\n",
    "                            })\n",
    "                            continue\n",
    "                    \n",
    "                    # ─── R² OK (ou pas de inlier_mask): utiliser RANSAC normal ───\n",
    "                    # Prédiction sur la droite\n",
    "                    fsc_a_pred = ransac.predict(fsc_h_file)\n",
    "                    \n",
    "                    # Distance verticale (résidus) - doublets au-dessus de la ligne\n",
    "                    residuals = fsc_a_file.ravel() - fsc_a_pred\n",
    "                    \n",
    "                    # Seuil adaptatif basé sur MAD (Median Absolute Deviation)\n",
    "                    median_residual = np.median(residuals)\n",
    "                    mad = np.median(np.abs(residuals - median_residual))\n",
    "                    \n",
    "                    # Seuil: médiane + 3 * MAD\n",
    "                    threshold_upper = median_residual + 3.0 * mad\n",
    "                    \n",
    "                    # Singlets: points près de la diagonale (pas trop au-dessus)\n",
    "                    singlets_file = residuals <= threshold_upper\n",
    "                    \n",
    "                    # Appliquer le masque local\n",
    "                    file_indices = np.where(file_mask)[0]\n",
    "                    mask[file_indices] = singlets_file\n",
    "                    \n",
    "                    n_sing = int(singlets_file.sum())\n",
    "                    n_doub = len(singlets_file) - n_sing\n",
    "                    total_singlets += n_sing\n",
    "                    total_doublets += n_doub\n",
    "                    \n",
    "                    # Affichage compact par fichier\n",
    "                    slope = ransac.estimator_.coef_[0]\n",
    "                    intercept = ransac.estimator_.intercept_\n",
    "                    file_short = file_name if len(file_name) <= 25 else file_name[:22] + \"...\"\n",
    "                    r2_str = f\", R²={r2_val:.3f}\" if r2_val is not None else \"\"\n",
    "                    print(f\"      • {file_short}: {n_sing:,} singlets / {n_sing+n_doub:,} ({n_sing/(n_sing+n_doub)*100:.1f}%) - y={slope:.3f}x+{intercept:.0f}{r2_str}\")\n",
    "                    \n",
    "                    # Stocker scatter data pour le rapport HTML (échantillonné)\n",
    "                    n_sample_pts = min(2000, len(fsc_a_file))\n",
    "                    sample_idx = np.random.choice(len(fsc_a_file), n_sample_pts, replace=False)\n",
    "                    ransac_scatter_data[str(file_name)] = {\n",
    "                        \"fsc_h\": fsc_h_file[sample_idx].ravel().tolist(),\n",
    "                        \"fsc_a\": fsc_a_file[sample_idx].ravel().tolist(),\n",
    "                        \"pred\": ransac.predict(fsc_h_file[sample_idx]).tolist(),\n",
    "                        \"r2\": float(r2_val) if r2_val is not None else None,\n",
    "                        \"method\": \"ransac\",\n",
    "                        \"slope\": float(slope),\n",
    "                        \"intercept\": float(intercept),\n",
    "                    }\n",
    "                    singlets_summary_per_file.append({\n",
    "                        \"file\": str(file_name), \"n_total\": int(len(singlets_file)),\n",
    "                        \"n_singlets\": n_sing, \"pct_singlets\": round(n_sing/(n_sing+n_doub)*100, 1),\n",
    "                        \"method\": \"ransac\", \"r2\": round(float(r2_val), 3) if r2_val is not None else None,\n",
    "                    })\n",
    "                    \n",
    "                    # Log structuré\n",
    "                    log_gating_event(\"singlets\", \"ransac\", \"success\", {\n",
    "                        \"file\": str(file_name), \"r2\": float(r2_val) if r2_val else None,\n",
    "                        \"slope\": float(slope), \"intercept\": float(intercept),\n",
    "                        \"n_singlets\": n_sing, \"n_doublets\": n_doub,\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      [!] Échec RANSAC pour {file_name}: {e}\")\n",
    "                    log_gating_event(\"singlets\", \"ransac\", \"error\",\n",
    "                                     {\"file\": str(file_name), \"error\": str(e)},\n",
    "                                     f\"Échec RANSAC pour {file_name}: {e}\")\n",
    "                    # En cas d'échec, garder toutes les cellules du fichier\n",
    "                    mask[file_mask] = True\n",
    "                    total_singlets += file_mask.sum()\n",
    "                    singlets_summary_per_file.append({\n",
    "                        \"file\": str(file_name), \"n_total\": int(file_mask.sum()),\n",
    "                        \"n_singlets\": int(file_mask.sum()), \"pct_singlets\": 100.0,\n",
    "                        \"method\": \"error_keep_all\", \"r2\": None,\n",
    "                    })\n",
    "            \n",
    "            print(f\"   [Auto-RANSAC] Total: {total_singlets:,} singlets, {total_doublets:,} doublets exclus\")\n",
    "            \n",
    "            # Résumé tableau % singlets par fichier\n",
    "            if singlets_summary_per_file:\n",
    "                print(f\"\\n   {'Fichier':<30} {'Méthode':<18} {'R²':>6} {'% Singlets':>12}\")\n",
    "                print(f\"   {'─'*30} {'─'*18} {'─'*6} {'─'*12}\")\n",
    "                for row in singlets_summary_per_file:\n",
    "                    r2_disp = f\"{row['r2']:.3f}\" if row['r2'] is not None else \"N/A\"\n",
    "                    fname_short = row['file'] if len(row['file']) <= 30 else row['file'][:27] + \"...\"\n",
    "                    print(f\"   {fname_short:<30} {row['method']:<18} {r2_disp:>6} {row['pct_singlets']:>10.1f}%\")\n",
    "            \n",
    "        else:\n",
    "            # Gating global (ancien comportement)\n",
    "            print(f\"   [Auto-RANSAC] Gating global sur toutes les données\")\n",
    "            \n",
    "            fsc_a_valid = fsc_a[valid].reshape(-1, 1)\n",
    "            fsc_h_valid = fsc_h[valid].reshape(-1, 1)\n",
    "            \n",
    "            # Régression RANSAC\n",
    "            ransac = RANSACRegressor(\n",
    "                estimator=LinearRegression(),\n",
    "                min_samples=100,\n",
    "                residual_threshold=None,\n",
    "                random_state=42,\n",
    "                max_trials=100\n",
    "            )\n",
    "            ransac.fit(fsc_h_valid, fsc_a_valid.ravel())\n",
    "            \n",
    "            # ─── CONTRÔLE QUALITÉ R² GLOBAL ───\n",
    "            inlier_mask = ransac.inlier_mask_\n",
    "            r2_val = None\n",
    "            if inlier_mask is not None and inlier_mask.sum() > 50:\n",
    "                r2_val = r2_score(\n",
    "                    fsc_a_valid[inlier_mask].ravel(),\n",
    "                    ransac.predict(fsc_h_valid[inlier_mask])\n",
    "                )\n",
    "                if r2_val < r2_threshold:\n",
    "                    warn_msg = f\"R² faible global (R²={r2_val:.2f} < {r2_threshold}), fallback gating ratio\"\n",
    "                    print(f\"   [!] {warn_msg}\")\n",
    "                    log_gating_event(\"singlets\", \"ransac_fallback_ratio\", \"fallback\",\n",
    "                                     {\"r2\": float(r2_val)}, warn_msg)\n",
    "                    \n",
    "                    singlets_mask = _fallback_ratio_gating(fsc_a_valid, fsc_h_valid)\n",
    "                    mask[valid] = singlets_mask\n",
    "                    \n",
    "                    n_singlets = mask.sum()\n",
    "                    n_doublets = valid.sum() - n_singlets\n",
    "                    print(f\"   [RATIO FALLBACK] Singlets: {n_singlets:,} ({n_singlets/valid.sum()*100:.1f}%)\")\n",
    "                    \n",
    "                    gate_result = GateResult(\n",
    "                        mask=mask, n_kept=int(n_singlets), n_total=int(n_cells),\n",
    "                        method=\"ratio_fallback_global\", gate_name=\"G2_singlets\",\n",
    "                        details={\"r2\": float(r2_val)},\n",
    "                        warnings=[warn_msg],\n",
    "                    )\n",
    "                    gating_reports.append(gate_result)\n",
    "                    return mask\n",
    "            \n",
    "            # Prédiction et résidus\n",
    "            fsc_a_pred = ransac.predict(fsc_h_valid)\n",
    "            residuals = fsc_a_valid.ravel() - fsc_a_pred\n",
    "            \n",
    "            # Seuil adaptatif MAD\n",
    "            median_residual = np.median(residuals)\n",
    "            mad = np.median(np.abs(residuals - median_residual))\n",
    "            threshold_upper = median_residual + 3.0 * mad\n",
    "            \n",
    "            # Masque singlets\n",
    "            singlets_mask = residuals <= threshold_upper\n",
    "            mask[valid] = singlets_mask\n",
    "            \n",
    "            n_singlets = mask.sum()\n",
    "            n_doublets = valid.sum() - n_singlets\n",
    "            slope = ransac.estimator_.coef_[0]\n",
    "            intercept = ransac.estimator_.intercept_\n",
    "            \n",
    "            r2_str = f\", R²={r2_val:.3f}\" if r2_val is not None else \"\"\n",
    "            print(f\"   [Auto-RANSAC] Droite: y = {slope:.3f}x + {intercept:.0f}{r2_str}\")\n",
    "            print(f\"   [Auto-RANSAC] Seuil MAD: médiane + {3.0:.1f}×MAD = {threshold_upper:.0f}\")\n",
    "            print(f\"   [Auto-RANSAC] Singlets: {n_singlets:,} ({n_singlets/valid.sum()*100:.1f}%)\")\n",
    "            print(f\"   [Auto-RANSAC] Doublets rejetés: {n_doublets:,} ({n_doublets/valid.sum()*100:.1f}%)\")\n",
    "        \n",
    "        # GateResult structuré\n",
    "        gate_result = GateResult(\n",
    "            mask=mask, n_kept=int(mask.sum()), n_total=int(n_cells),\n",
    "            method=\"ransac_singlets\", gate_name=\"G2_singlets\",\n",
    "            details={\n",
    "                \"per_file\": per_file,\n",
    "                \"n_files\": len(singlets_summary_per_file) if per_file else 1,\n",
    "                \"files_summary\": singlets_summary_per_file if per_file else [],\n",
    "            },\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_cd45(X: np.ndarray, var_names: List[str],\n",
    "                        n_components: int = 2,\n",
    "                        uniform_gating: bool = False,\n",
    "                        threshold_percentile: float = 5.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate CD45+ adaptatif par GMM 1D.\n",
    "        \n",
    "        Trouve automatiquement le creux bimodal entre CD45- et CD45+\n",
    "        au lieu d'un percentile fixe. Le GMM modélise la distribution\n",
    "        bimodale et assigne chaque événement à la population la plus probable.\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Noms des marqueurs\n",
    "            n_components: Nombre de composantes GMM (2 = CD45- / CD45+)\n",
    "            uniform_gating: Si True, applique un seuil soft (percentile)\n",
    "            threshold_percentile: Percentile pour le seuil soft CD45\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = CD45+, False = CD45-)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "        \n",
    "        if cd45_idx is None:\n",
    "            print(\"[!] CD45 non trouvé pour auto-gate CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd45 = X[:, cd45_idx].astype(np.float64)\n",
    "        valid = np.isfinite(cd45)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate CD45+\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # Mode uniform_gating: seuil soft par percentile (pas de GMM)\n",
    "        if uniform_gating:\n",
    "            threshold = np.nanpercentile(cd45[valid], threshold_percentile)\n",
    "            mask = np.zeros(n_cells, dtype=bool)\n",
    "            mask[valid] = cd45[valid] > threshold\n",
    "            n_pos = mask.sum()\n",
    "            print(f\"   [Uniform-CD45] Seuil soft: {threshold:.0f} (percentile {threshold_percentile}%)\")\n",
    "            print(f\"   [Uniform-CD45] CD45+ identifiés: {n_pos:,} ({n_pos/valid.sum()*100:.1f}%)\")\n",
    "            \n",
    "            gate_result = GateResult(\n",
    "                mask=mask, n_kept=int(n_pos), n_total=int(valid.sum()),\n",
    "                method=\"gmm_cd45_uniform\", gate_name=\"G3_cd45\",\n",
    "                details={\"threshold\": float(threshold), \"percentile\": threshold_percentile, \"fallback\": False},\n",
    "            )\n",
    "            gating_reports.append(gate_result)\n",
    "            log_gating_event(\"cd45\", \"uniform_percentile\", \"success\",\n",
    "                             {\"threshold\": float(threshold), \"n_pos\": int(n_pos)})\n",
    "            return mask\n",
    "        \n",
    "        # GMM pour séparer CD45- et CD45+\n",
    "        try:\n",
    "            gmm = AutoGating.safe_fit_gmm(\n",
    "                cd45[valid].reshape(-1, 1),\n",
    "                n_components=n_components, n_init=3\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            warn_msg = f\"GMM CD45 échoué: {e} — fallback percentile\"\n",
    "            print(f\"   [!] {warn_msg}\")\n",
    "            log_gating_event(\"cd45\", \"gmm_fallback_percentile\", \"fallback\",\n",
    "                             {\"error\": str(e)}, warn_msg)\n",
    "            threshold = np.nanpercentile(cd45[valid], threshold_percentile)\n",
    "            mask = np.zeros(n_cells, dtype=bool)\n",
    "            mask[valid] = cd45[valid] > threshold\n",
    "            \n",
    "            gate_result = GateResult(\n",
    "                mask=mask, n_kept=int(mask.sum()), n_total=int(valid.sum()),\n",
    "                method=\"gmm_cd45_fallback_percentile\", gate_name=\"G3_cd45\",\n",
    "                details={\"threshold\": float(threshold), \"fallback\": True},\n",
    "                warnings=[warn_msg],\n",
    "            )\n",
    "            gating_reports.append(gate_result)\n",
    "            return mask\n",
    "        \n",
    "        labels = gmm.predict(cd45[valid].reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        \n",
    "        # CD45+ = composant avec la moyenne la plus élevée\n",
    "        pos_component = np.argmax(means)\n",
    "        \n",
    "        # Calculer le seuil approximatif (intersection des 2 gaussiennes)\n",
    "        sorted_means = np.sort(means)\n",
    "        stds = np.sqrt(gmm.covariances_.flatten())\n",
    "        sorted_stds = stds[np.argsort(means)]\n",
    "        threshold_approx = (sorted_means[0] * sorted_stds[1] + sorted_means[1] * sorted_stds[0]) / (sorted_stds[0] + sorted_stds[1])\n",
    "        \n",
    "        mask = np.zeros(n_cells, dtype=bool)\n",
    "        mask[valid] = (labels == pos_component)\n",
    "        \n",
    "        n_pos = mask.sum()\n",
    "        print(f\"   [Auto-GMM] CD45: {n_components} composantes, μ={means.round(0)}\")\n",
    "        print(f\"   [Auto-GMM] Seuil adaptatif ≈ {threshold_approx:.0f} (creux entre populations)\")\n",
    "        print(f\"   [Auto-GMM] CD45+ identifiés: {n_pos:,} ({n_pos/valid.sum()*100:.1f}%)\")\n",
    "        \n",
    "        gate_result = GateResult(\n",
    "            mask=mask, n_kept=int(n_pos), n_total=int(valid.sum()),\n",
    "            method=\"gmm_cd45\", gate_name=\"G3_cd45\",\n",
    "            details={\n",
    "                \"means\": means.tolist(), \"threshold\": float(threshold_approx),\n",
    "                \"n_components\": int(n_components), \"fallback\": False,\n",
    "            },\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        log_gating_event(\"cd45\", \"gmm\", \"success\", {\n",
    "            \"means\": means.tolist(), \"threshold\": float(threshold_approx), \"n_pos\": int(n_pos),\n",
    "        })\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def auto_gate_cd34(X: np.ndarray, var_names: List[str],\n",
    "                        use_ssc_filter: bool = True,\n",
    "                        n_components: int = 2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gate CD34+ blastes adaptatif par GMM.\n",
    "        \n",
    "        Identifie la population CD34 bright (blastes) par GMM au lieu d'un \n",
    "        percentile fixe. Optionnel: combine avec SSC low (blastes = faible granularité).\n",
    "        \n",
    "        Args:\n",
    "            X: Matrice des données\n",
    "            var_names: Noms des marqueurs\n",
    "            use_ssc_filter: Combiner avec filtre GMM SSC low\n",
    "            n_components: Nombre de composantes GMM\n",
    "        \n",
    "        Returns:\n",
    "            Masque booléen (True = blaste CD34+, False = autre)\n",
    "        \"\"\"\n",
    "        n_cells = X.shape[0]\n",
    "        cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC', 'CD34-PECY7'])\n",
    "        \n",
    "        if cd34_idx is None:\n",
    "            print(\"[!] CD34 non trouvé pour auto-gate blastes\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        cd34 = X[:, cd34_idx].astype(np.float64)\n",
    "        valid = np.isfinite(cd34)\n",
    "        \n",
    "        if valid.sum() < 200:\n",
    "            print(\"[!] Pas assez de données valides pour auto-gate CD34\")\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        # GMM pour séparer CD34- et CD34+\n",
    "        try:\n",
    "            gmm = AutoGating.safe_fit_gmm(\n",
    "                cd34[valid].reshape(-1, 1),\n",
    "                n_components=n_components, n_init=3\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            warn_msg = f\"GMM CD34 échoué: {e} — conservation de toutes les cellules\"\n",
    "            print(f\"   [!] {warn_msg}\")\n",
    "            log_gating_event(\"cd34\", \"gmm\", \"error\", {\"error\": str(e)}, warn_msg)\n",
    "            return np.ones(n_cells, dtype=bool)\n",
    "        \n",
    "        labels = gmm.predict(cd34[valid].reshape(-1, 1))\n",
    "        means = gmm.means_.flatten()\n",
    "        pos_component = np.argmax(means)\n",
    "        \n",
    "        mask_cd34 = np.zeros(n_cells, dtype=bool)\n",
    "        mask_cd34[valid] = (labels == pos_component)\n",
    "        \n",
    "        n_cd34_pos = mask_cd34.sum()\n",
    "        print(f\"   [Auto-GMM] CD34: μ={means.round(0)}, CD34+ cluster = μ={means[pos_component]:.0f}\")\n",
    "        \n",
    "        # Filtre SSC low optionnel (blastes = faible granularité)\n",
    "        if use_ssc_filter:\n",
    "            ssc_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "            if ssc_idx is not None:\n",
    "                ssc = X[:, ssc_idx].astype(np.float64)\n",
    "                valid_ssc = np.isfinite(ssc)\n",
    "                \n",
    "                if valid_ssc.sum() >= 200:\n",
    "                    try:\n",
    "                        gmm_ssc = AutoGating.safe_fit_gmm(\n",
    "                            ssc[valid_ssc].reshape(-1, 1),\n",
    "                            n_components=2, n_init=3\n",
    "                        )\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"   [!] GMM SSC échoué: {e} — filtre SSC ignoré\")\n",
    "                        print(f\"   [Auto-GMM] CD34+ blastes: {n_cd34_pos:,}\")\n",
    "                        gate_result = GateResult(\n",
    "                            mask=mask_cd34, n_kept=int(n_cd34_pos), n_total=int(valid.sum()),\n",
    "                            method=\"gmm_cd34_no_ssc\", gate_name=\"G4_cd34\",\n",
    "                            details={\"means\": means.tolist(), \"ssc_filter\": False},\n",
    "                            warnings=[f\"GMM SSC échoué: {e}\"],\n",
    "                        )\n",
    "                        gating_reports.append(gate_result)\n",
    "                        return mask_cd34\n",
    "                    \n",
    "                    labels_ssc = gmm_ssc.predict(ssc[valid_ssc].reshape(-1, 1))\n",
    "                    ssc_means = gmm_ssc.means_.flatten()\n",
    "                    low_ssc_component = np.argmin(ssc_means)\n",
    "                    \n",
    "                    mask_ssc = np.zeros(n_cells, dtype=bool)\n",
    "                    mask_ssc[valid_ssc] = (labels_ssc == low_ssc_component)\n",
    "                    \n",
    "                    combined = mask_cd34 & mask_ssc\n",
    "                    print(f\"   [Auto-GMM] + Filtre SSC low (μ={ssc_means[low_ssc_component]:.0f}): {combined.sum():,} blastes purs\")\n",
    "                    \n",
    "                    gate_result = GateResult(\n",
    "                        mask=combined, n_kept=int(combined.sum()), n_total=int(valid.sum()),\n",
    "                        method=\"gmm_cd34_ssc\", gate_name=\"G4_cd34\",\n",
    "                        details={\"cd34_means\": means.tolist(), \"ssc_means\": ssc_means.tolist(),\n",
    "                                 \"ssc_filter\": True},\n",
    "                    )\n",
    "                    gating_reports.append(gate_result)\n",
    "                    log_gating_event(\"cd34\", \"gmm+ssc\", \"success\", {\n",
    "                        \"cd34_means\": means.tolist(), \"ssc_means\": ssc_means.tolist(),\n",
    "                        \"n_blastes\": int(combined.sum()),\n",
    "                    })\n",
    "                    return combined\n",
    "        \n",
    "        print(f\"   [Auto-GMM] CD34+ blastes: {n_cd34_pos:,}\")\n",
    "        gate_result = GateResult(\n",
    "            mask=mask_cd34, n_kept=int(n_cd34_pos), n_total=int(valid.sum()),\n",
    "            method=\"gmm_cd34\", gate_name=\"G4_cd34\",\n",
    "            details={\"means\": means.tolist()},\n",
    "        )\n",
    "        gating_reports.append(gate_result)\n",
    "        return mask_cd34\n",
    "\n",
    "\n",
    "print(\"[OK] Classe AutoGating chargée (gating adaptatif)\")\n",
    "print(\"     Méthodes disponibles:\")\n",
    "print(\"       • safe_fit_gmm:       Wrapper robuste GMM (retry + fallback unimodal + sous-échantillonnage)\")\n",
    "print(\"       • auto_gate_debris:   GMM 2D sur FSC-A/SSC-A (détection adaptative débris)\")\n",
    "print(\"       • auto_gate_singlets: RANSAC robuste FSC-A vs FSC-H + contrôle R² + fallback ratio\")\n",
    "print(\"       • auto_gate_cd45:     GMM 1D bimodal CD45- / CD45+ (+ uniform_gating)\")\n",
    "print(\"       • auto_gate_cd34:     GMM 1D + optionnel SSC low pour blastes\")\n",
    "print(\"     \")\n",
    "print(\"     [AMÉLIORATIONS V2]\")\n",
    "print(\"       → safe_fit_gmm: sous-échantillonnage 200k pts + retry + fallback unimodal\")\n",
    "print(\"       → RANSAC singlets: contrôle R² inliers + fallback ratio si R² < 0.85\")\n",
    "print(\"       → Scatter FSC-A vs FSC-H par fichier + tableau % singlets stockés\")\n",
    "print(\"       → GateResult structuré retourné par chaque fonction\")\n",
    "print(\"       → Log structuré JSON (gating_log_entries) pour audit automatique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f742d5",
   "metadata": {},
   "source": [
    "## 2. Chargement des Fichiers FCS\n",
    "\n",
    "Chargement des fichiers FCS depuis les dossiers spécifiés. \n",
    "- **Sain (NBM)**: Moelle osseuse normale (référence)\n",
    "- **Pathologique**: Échantillons patients à analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DES CHEMINS\n",
    "# Bien modifier ces chemins selon votre environnement actuel pour le bon chargement des données\n",
    "\n",
    "# Dossier des fichiers sains (référence NBM)\n",
    "HEALTHY_FOLDER = Path(r\"C:\\Users\\Florian Travail\\Documents\\FlowSom\\Data\\Moelle normale\")\n",
    "\n",
    "# Dossier des fichiers pathologiques (patients)\n",
    "PATHOLOGICAL_FOLDER = Path(r\"Data/Patho\")\n",
    "\n",
    "# Mode d'analyse: \n",
    "# - True: Comparer Sain vs Pathologique\n",
    "# - False: Analyser uniquement les fichiers pathologiques\n",
    "COMPARE_MODE = True\n",
    "\n",
    "print(f\"Dossier Sain: {HEALTHY_FOLDER}\")\n",
    "print(f\"Dossier Pathologique: {PATHOLOGICAL_FOLDER}\")\n",
    "print(f\"Mode comparaison: {'Activé' if COMPARE_MODE else 'Patient seul'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTIONS DE CHARGEMENT FCS\n",
    "\n",
    "def get_fcs_files(folder: Path) -> List[str]:\n",
    "    \"\"\"Récupère la liste des fichiers FCS dans un dossier. Et renvoie une chaine de caractère\"\"\"\n",
    "    if not folder.exists():\n",
    "        print(f\"[!] Dossier non trouvé: {folder}\")\n",
    "        return []\n",
    "    \n",
    "    files = set()\n",
    "    for f in folder.glob(\"*.fcs\"):\n",
    "        files.add(str(f))\n",
    "    for f in folder.glob(\"*.FCS\"):\n",
    "        files.add(str(f))\n",
    "    \n",
    "    return sorted(list(files))\n",
    "\n",
    "\n",
    "def load_fcs_files(files: List[str], condition: str = \"Unknown\") -> List[ad.AnnData]:\n",
    "    \"\"\"\n",
    "    Charge plusieurs fichiers FCS et retourne une liste d'AnnData.\n",
    "    \n",
    "    Args:\n",
    "        files: Liste des chemins de fichiers FCS\n",
    "        condition: Label de condition (\"Sain\" ou \"Pathologique\")\n",
    "    \n",
    "    Returns:\n",
    "        Liste d'objets AnnData\n",
    "    \"\"\"\n",
    "    # La ligne suivante crée la liste vide pour stocker les AnnData puis boucle sur chaque fichier (éviter le plantage complet)\n",
    "    adatas = []\n",
    "    \n",
    "    for fpath in files:\n",
    "        try:\n",
    "            print(f\"    Chargement: {Path(fpath).name}...\", end=\" \")\n",
    "            \n",
    "            # Lecture avec la fonction de base de flowsom\n",
    "            adata = fs.io.read_FCS(fpath)\n",
    "            \n",
    "            # Ajouter les métadonnées avec un nombre de cellules qui sera égale a la forme de l'objet adata \n",
    "            n_cells = adata.shape[0]\n",
    "            adata.obs['condition'] = condition # Rajoute la condition du fichier : \"Sain\" ou \"Pathologique\"\n",
    "            adata.obs['file_origin'] = Path(fpath).name # Rajoute une observation avec Nom du fichier source (obs = One-dimensional annotation of observations)\n",
    "            \n",
    "            adatas.append(adata) # Ajoute à la liste des AnnData\n",
    "            print(f\"{n_cells:,} cellules\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur: {e}\")\n",
    "    \n",
    "    return adatas\n",
    "\n",
    "# Logs sur le cahrgement des fichiers\n",
    "print(\"=\"*60)\n",
    "print(\"CHARGEMENT DES FICHIERS FCS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fichiers sains en fonction du mode défini\n",
    "healthy_files = get_fcs_files(HEALTHY_FOLDER) if COMPARE_MODE else []\n",
    "print(f\"\\nFichiers Sains (NBM): {len(healthy_files)}\")\n",
    "\n",
    "healthy_adatas = []\n",
    "if healthy_files:\n",
    "    healthy_adatas = load_fcs_files(healthy_files, condition=\"Sain\")\n",
    "\n",
    "# Fichiers sains en fonction du mode défini\n",
    "patho_files = get_fcs_files(PATHOLOGICAL_FOLDER)\n",
    "print(f\"\\nFichiers Pathologiques: {len(patho_files)}\")\n",
    "\n",
    "patho_adatas = []\n",
    "if patho_files:\n",
    "    patho_adatas = load_fcs_files(patho_files, condition=\"Pathologique\")\n",
    "\n",
    "# Résumé\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"RÉSUMÉ DU CHARGEMENT\")\n",
    "print(f\"   Fichiers Sains chargés: {len(healthy_adatas)}\")\n",
    "print(f\"   Fichiers Pathologiques chargés: {len(patho_adatas)}\")\n",
    "# Résumé a.shape = pour chaque AnnData, prend le nombre de cellules (lignes) et concatène si nécessaire\n",
    "total_cells = sum([a.shape[0] for a in healthy_adatas + patho_adatas])\n",
    "print(f\"   Total cellules: {total_cells:,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495d578",
   "metadata": {},
   "source": [
    "## 3. Exploration de la Structure des Données Brutes\n",
    "\n",
    "Avant toute transformation, examinons la structure des données:\n",
    "- Dimensions (cellules x marqueurs)\n",
    "- Noms des colonnes (marqueurs)\n",
    "- Types de données et plages de valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de539adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATÉNATION DES DONNÉES\n",
    "\n",
    "# Combiner tous les AnnData défini dans la cellule précédente\n",
    "all_adatas = healthy_adatas + patho_adatas\n",
    "\n",
    "# Vérification\n",
    "if len(all_adatas) == 0:\n",
    "    raise ValueError(\"[X] Aucun fichier FCS chargé! Vérifiez les chemins.\")\n",
    "\n",
    "# Concaténer avec intersection des colonnes (communes à tous les fichiers) ligne par ligne\n",
    "if len(all_adatas) > 1:\n",
    "    combined_data = ad.concat(all_adatas, join='inner') # join='inner' pour ne garder que les marqueurs communs à changer par outer si on veut garder tous les marqueurs\n",
    "else:\n",
    "    combined_data = all_adatas[0].copy() # Si un seul fichier, juste copier pour éviter de mofifier l'original\n",
    "\n",
    "print(f\"Données combinées: {combined_data.shape}\")\n",
    "print(f\"   → {combined_data.shape[0]:,} cellules\")\n",
    "print(f\"   → {combined_data.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATION DE LA STRUCTURE\n",
    "print(\"=\"*70)\n",
    "print(\"STRUCTURE DES DONNÉES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Liste des marqueurs enregistré dans la varaible var_names = canaux (ici c'est bien un nom de variable)\n",
    "var_names = list(combined_data.var_names)\n",
    "print(f\"\\nMarqueurs ({len(var_names)}):\")\n",
    "for i, name in enumerate(var_names):\n",
    "    print(f\"   [{i:2d}] {name}\")\n",
    "\n",
    "# Identification des types de marqueurs car les recos indiquent d'enelever le scatter pour les analyses de clustering\n",
    "print(\"\\nClassification des marqueurs:\")\n",
    "\n",
    "#Ici le code n for n in var pose la question : \"Est-ce qu'au moins UN des motifs de la liste scatter_patterns se trouve dans le nom actuel n ?\"\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "scatter_markers = [n for n in var_names if any(p in n.upper() for p in scatter_patterns)]\n",
    "fluor_markers = [n for n in var_names if n not in scatter_markers]\n",
    "\n",
    "print(f\"   Scatter/Time: {scatter_markers}\")\n",
    "print(f\"   Fluorescence: {fluor_markers}\")\n",
    "\n",
    "# Statistiques de base\n",
    "print(\"\\nObservations (métadonnées):\")\n",
    "print(combined_data.obs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION EN DATAFRAME POUR EXPLORATION\n",
    "HEADER = True\n",
    "# Extraire la matrice de données\n",
    "X = combined_data.X # Matrice des données (n_cells, n_markers)\n",
    "if hasattr(X, 'toarray'): # Si sparse matrix, convertir en dense pour pandas\n",
    "    X = X.toarray()\n",
    "\n",
    "# Créer un DataFrame pandas pour faciliter l'exploration avec df comme commande pandas classique\n",
    "df_raw = pd.DataFrame(X, columns=var_names) # Crée le DataFrame avec les noms de colonnes \n",
    "df_raw['condition'] = combined_data.obs['condition'].values # Ajoute une colonne condition\n",
    "df_raw['file_origin'] = combined_data.obs['file_origin'].values # Ajoute une colonne file_origin\n",
    "\n",
    "print(\"DataFrame créé pour exploration\")\n",
    "print(f\"   Shape: {df_raw.shape}\")\n",
    "print(\"\\nAperçu des données brutes:\")\n",
    "df_raw.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats descriptives marqueurs de fluorescence et scatter\n",
    "print(\"Statistiques descriptives fluorescence\")\n",
    "display(df_raw[fluor_markers].describe())\n",
    "\n",
    "print(\"\\nStatistiques descriptives scatter\")\n",
    "display(df_raw[scatter_markers].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125cfaf",
   "metadata": {},
   "source": [
    "## 4. Contrôle Qualité des données- Analyse des Distributions\n",
    "\n",
    "Visualisation des distributions brutes pour identifier:\n",
    "- Outliers et valeurs aberrantes\n",
    "- Valeurs négatives (problème de compensation)\n",
    "- NaN/Inf dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérif des varaibles problématiques suite de l'exploration du dataset\n",
    "\n",
    "print(\"ANALYSE DES DONNÉES BRUTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========== MARQUEURS DE FLUORESCENCE ==========\n",
    "print(\"\\nMARQUEURS DE FLUORESCENCE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Vérifier NaN\n",
    "nan_count = df_raw[fluor_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN détecté!\")\n",
    "\n",
    "# Vérifier Inf (valeur infinie) ex sur un post log \n",
    "inf_count = np.isinf(df_raw[fluor_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf détecté!\")\n",
    "else:\n",
    "    for marker, count in inf_count.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# Vérifier valeurs négatives\n",
    "neg_count = (df_raw[fluor_markers] < 0).sum()\n",
    "print(f\"\\n➖ Valeurs négatives par marqueur:\")\n",
    "has_negatives = False\n",
    "for marker, count in neg_count.items():\n",
    "    if count > 0:\n",
    "        has_negatives = True\n",
    "        # Compter le nombre total de cellules valides (non-NaN) pour ce marqueur\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives:\n",
    "    print(\"   [OK] Aucune valeur négative!\")\n",
    "else:\n",
    "    print(\"\\n   [!] Les valeurs négatives peuvent indiquer un problème de compensation\")\n",
    "    print(\"   → La transformation Arcsinh ou Logicle peut les gérer\")\n",
    "\n",
    "# ========== MARQUEURS SCATTER/TIME ==========\n",
    "print(\"\\n\\nMARQUEURS SCATTER/TIME\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Vérifier NaN\n",
    "nan_count_scatter = df_raw[scatter_markers].isna().sum()\n",
    "print(f\"\\nValeurs NaN par marqueur:\")\n",
    "for marker, count in nan_count_scatter.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {marker}: {count:,} ({count/len(df_raw)*100:.2f}%)\")\n",
    "    \n",
    "if nan_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun NaN détecté!\")\n",
    "\n",
    "# Vérifier Inf\n",
    "inf_count_scatter = np.isinf(df_raw[scatter_markers]).sum()\n",
    "print(f\"\\nValeurs Inf par marqueur:\")\n",
    "if inf_count_scatter.sum() == 0:\n",
    "    print(\"   [OK] Aucun Inf détecté!\")\n",
    "else:\n",
    "    for marker, count in inf_count_scatter.items():\n",
    "        if count > 0:\n",
    "            print(f\"   {marker}: {count:,}\")\n",
    "\n",
    "# Vérifier valeurs négatives\n",
    "neg_count_scatter = (df_raw[scatter_markers] < 0).sum()\n",
    "print(f\"\\n➖ Valeurs négatives par marqueur:\")\n",
    "has_negatives_scatter = False\n",
    "for marker, count in neg_count_scatter.items():\n",
    "    if count > 0:\n",
    "        has_negatives_scatter = True\n",
    "        total_valid = df_raw[marker].notna().sum()\n",
    "        print(f\"   {marker}: {count:,} / {total_valid:,} ({count/total_valid*100:.2f}%)\")\n",
    "        \n",
    "if not has_negatives_scatter:\n",
    "    print(\"   [OK] Aucune valeur négative!\")\n",
    "else:\n",
    "    print(\"\\n   ℹ️ Les valeurs négatives dans scatter sont rares mais possibles\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des distributions brutes pour explorer visuellement les données\n",
    "\n",
    "# Sélectionner les marqueurs à visualiser (max 12 pour lisibilité)\n",
    "markers_to_plot = fluor_markers[:12] if len(fluor_markers) > 12 else fluor_markers  # Opérateur ternaire: prendre 12 premiers si > 12, sinon tous\n",
    "\n",
    "n_markers = len(markers_to_plot)  # Nombre de marqueurs à afficher\n",
    "n_cols = 4  # 4 colonnes par ligne\n",
    "n_rows = (n_markers + n_cols - 1) // n_cols  # Calcul nb lignes (division entière arrondie vers le haut)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))  # Créer grille n_rows × n_cols (largeur 20, hauteur 5 par ligne)\n",
    "axes = axes.flatten() if n_markers > 1 else [axes]  # Aplatir tableau 2D en liste 1D pour itération facile\n",
    "\n",
    "for i, marker in enumerate(markers_to_plot):  # Boucle sur chaque marqueur avec index i\n",
    "    ax = axes[i]  # Récupérer le sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Extraire données du marqueur et supprimer NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#89b4fa', alpha=0.7, edgecolor='none')  # Histogramme 100 barres, bleu, 70% opacité\n",
    "    ax.set_title(marker, fontsize=11, fontweight='bold')  # Titre = nom du marqueur\n",
    "    ax.set_xlabel('Valeur brute')  # Label axe X\n",
    "    ax.set_ylabel('Count')  # Label axe Y = nombre de cellules\n",
    "    ax.axvline(0, color='#f38ba8', linestyle='--', alpha=0.5, label='Zéro')  # Ligne verticale rouge à x=0\n",
    "    \n",
    "    # Statistiques min/max dans une boîte en haut à droite\n",
    "    ax.text(0.98, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}',  # Texte avec stats\n",
    "            transform=ax.transAxes, ha='right', va='top', fontsize=8,  # Coordonnées relatives (0-1), alignement\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))  # Boîte grise arrondie semi-transparente\n",
    "\n",
    "# Cacher les axes vides (si 10 marqueurs sur grille 3×4, cacher les 2 dernières cases)\n",
    "for i in range(n_markers, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Brutes des Marqueurs (avant transformation)',  # Titre général\n",
    "             fontsize=14, fontweight='bold', y=1.02)  # Décalé vers le haut\n",
    "plt.tight_layout()  # Ajuster espacement auto\n",
    "plt.show()  # Afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des marqueurs SCATTER/TIME pour exploration visuelle\n",
    "\n",
    "# Sélectionner tous les marqueurs scatter (généralement peu nombreux)\n",
    "scatter_to_plot = scatter_markers  # FSC, SSC, TIME\n",
    "\n",
    "n_scatter = len(scatter_to_plot)  # Nombre de marqueurs scatter\n",
    "n_cols_scatter = min(3, n_scatter)  # Max 3 colonnes pour les scatter\n",
    "n_rows_scatter = (n_scatter + n_cols_scatter - 1) // n_cols_scatter  # Calcul nb lignes\n",
    "\n",
    "fig, axes = plt.subplots(n_rows_scatter, n_cols_scatter, figsize=(18, 6*n_rows_scatter))  # Grille pour scatter (largeur 18, hauteur 6 par ligne)\n",
    "axes = axes.flatten() if n_scatter > 1 else [axes]  # Aplatir en liste 1D\n",
    "\n",
    "for i, marker in enumerate(scatter_to_plot):  # Boucle sur chaque marqueur scatter\n",
    "    ax = axes[i]  # Sous-graphique i\n",
    "    data = df_raw[marker].dropna()  # Données sans NaN\n",
    "    \n",
    "    ax.hist(data, bins=100, color='#a6e3a1', alpha=0.7, edgecolor='none')  # Vert pour différencier\n",
    "    ax.set_title(marker, fontsize=12, fontweight='bold')  # Titre\n",
    "    ax.set_xlabel('Valeur brute')  # Axe X\n",
    "    ax.set_ylabel('Count')  # Axe Y\n",
    "    \n",
    "    # Statistiques complètes\n",
    "    ax.text(0.02, 0.95, f'min: {data.min():.0f}\\nmax: {data.max():.0f}\\nmean: {data.mean():.0f}\\nmedian: {data.median():.0f}',\n",
    "            transform=ax.transAxes, ha='left', va='top', fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor=\"#FFFFFF\", alpha=0.8))\n",
    "\n",
    "# Cacher axes vides\n",
    "for i in range(n_scatter, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distributions Scatter/Time (FSC, SSC, TIME)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910ba5b",
   "metadata": {},
   "source": [
    "### Visualisation Interactive avec FlowKit + Bokeh\n",
    "\n",
    "Utilisation native de FlowKit pour visualisations interactives :\n",
    "- **Histogrammes** avec bins/ranges personnalisables\n",
    "- **Scatter plots** interactifs avec zoom/pan\n",
    "- **Contour plots** avec densité\n",
    "- Rendu Bokeh pour l'interactivité (zoom, pan, hover)\n",
    "\n",
    "📚 Documentation : https://flowkit.readthedocs.io/en/latest/index.html\n",
    "https://www.frontiersin.org/journals/immunology/articles/10.3389/fimmu.2021.768541/full\n",
    "\n",
    "---\n",
    "\n",
    "### [!] IMPORTANT : Nomenclature FCS\n",
    "\n",
    "**FlowKit utilise les PnN labels** (noms techniques), pas les PnS (descriptions).\n",
    "\n",
    "- **PnN** = Nom technique (ex: `'Horizon V500-A'`) ← À utiliser\n",
    "- **PnS** = Description bio (ex: `'CD45 KO'`) ← Non utilisable\n",
    "\n",
    "**Exemple :** Pour CD45, utiliser `'Horizon V500-A'` (pas `'CD45 KO'`).\n",
    "\n",
    "Exécutez la cellule suivante pour voir la correspondance PnN ↔ PnS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbddc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation FlowKit et Bokeh + Création du Sample\n",
    "\n",
    "if not FLOWKIT_AVAILABLE:\n",
    "    fk_sample = None\n",
    "else:\n",
    "    try:\n",
    "        from bokeh.plotting import show, output_notebook\n",
    "        from bokeh.io import export_png\n",
    "        output_notebook()\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Utiliser les fichiers FCS déjà identifiés dans le notebook\n",
    "    all_fcs_files = healthy_files + patho_files\n",
    "    \n",
    "    if all_fcs_files:\n",
    "        example_fcs = str(all_fcs_files[0])\n",
    "        fk_sample = fk.Sample(example_fcs)\n",
    "    else:\n",
    "        fk_sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHER LES NOMS DE CANAUX EXACTS DU FICHIER FCS\n",
    "\n",
    "if fk_sample is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"CANAUX DU FICHIER FCS: {Path(example_fcs).name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nPnN Labels ({len(fk_sample.pnn_labels)} canaux) - NOMS À UTILISER DANS FLOWKIT:\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pnn_labels, 1):\n",
    "        print(f\"   [{i:2d}] '{label}'\")\n",
    "    \n",
    "    # Afficher aussi les PnS labels (descriptions) si disponibles\n",
    "    print(f\"\\n\\nPnS Labels (descriptions):\")\n",
    "    print(\"-\"*80)\n",
    "    for i, label in enumerate(fk_sample.pns_labels, 1):\n",
    "        print(f\"   [{i:2d}] {label}\")\n",
    "    \n",
    "else:\n",
    "    print(\"[!] FlowKit Sample non chargé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les colonnes FSC et SSC pour les visualisations ultérieures\n",
    "fsc_col = next((c for c in var_names if 'FSC-A' in c.upper() or 'FSC' in c.upper()), None)\n",
    "ssc_col = next((c for c in var_names if 'SSC-A' in c.upper() or 'SSC' in c.upper()), None)\n",
    "\n",
    "if fsc_col:\n",
    "    print(f\"[OK] FSC détecté: {fsc_col}\")\n",
    "if ssc_col:\n",
    "    print(f\"[OK] SSC détecté: {ssc_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae982a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme basique FlowKit (échelle linéaire)\n",
    "# source='raw' = données LINÉAIRES (non transformées)\n",
    "# source='xform' = données transformées (Logicle)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    CHANNEL = 'FSC-H'  # Changer ici le channel à afficher\n",
    "    \n",
    "    # Histogramme en échelle LINÉAIRE (source='raw')\n",
    "    p = fk_sample.plot_histogram(CHANNEL, source='raw', bins=256)\n",
    "    \n",
    "    # Forcer l'échelle linéaire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # Désactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Histogramme {CHANNEL} - Échelle LINÉAIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af808182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot 2D interactif (échelle linéaire)\n",
    "# source='raw' = données LINÉAIRES (non transformées)\n",
    "\n",
    "if fk_sample is not None:\n",
    "    x_channel = 'FSC-H'\n",
    "    y_channel = 'SSC-H'\n",
    "    \n",
    "    # Scatter en échelle LINÉAIRE (source='raw')\n",
    "    p = fk_sample.plot_scatter(x_channel, y_channel, source='raw', color_density=True)\n",
    "    \n",
    "    # Forcer l'échelle linéaire sur les axes (pas log)\n",
    "    p.xaxis.formatter.use_scientific = False  # Désactiver notation scientifique\n",
    "    p.yaxis.formatter.use_scientific = False\n",
    "    \n",
    "    show(p)\n",
    "    print(f\" Scatter {x_channel} vs {y_channel} - Échelle LINÉAIRE (source='raw')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme 1D interactif avec Plotly (zoom, pan, hover)\n",
    "# Sélectionner un marqueur à visualiser (modifiable)\n",
    "MARKER_TO_PLOT = 'CD45 KO525-H'  # Changer ici le nom exact du marqueur à visualiser\n",
    "\n",
    "print(f\"Visualisation: {MARKER_TO_PLOT}\")\n",
    "\n",
    "# Extraire les données\n",
    "marker_data = df_raw[MARKER_TO_PLOT].dropna().values\n",
    "\n",
    "# Importer plotly pour l'interactivité\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    \n",
    "    # Configurer le renderer pour Jupyter (évite l'erreur nbformat)\n",
    "    try:\n",
    "        pio.renderers.default = 'notebook'\n",
    "    except:\n",
    "        try:\n",
    "            pio.renderers.default = 'jupyterlab'\n",
    "        except:\n",
    "            pio.renderers.default = 'browser'\n",
    "    \n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"[!] Plotly non installé - pip install plotly\")\n",
    "\n",
    "if PLOTLY_AVAILABLE:\n",
    "    # Créer une figure avec 4 subplots (2x2)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            f'{MARKER_TO_PLOT} - Brut (Linéaire)',\n",
    "            f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)',\n",
    "            f'{MARKER_TO_PLOT} - Logicle',\n",
    "            f'{MARKER_TO_PLOT} - Log10'\n",
    "        ),\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # 1. Données brutes\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_data, nbinsx=200, name='Brut',\n",
    "                     marker_color='#89b4fa', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.1f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Arcsinh cofactor=5\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_arcsinh, nbinsx=200, name='Arcsinh (5)',\n",
    "                     marker_color='#a6e3a1', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Logicle ou Arcsinh cofactor=150\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        transform_name = 'Logicle'\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        transform_name = 'Arcsinh (150)'\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_logicle, nbinsx=200, name=transform_name,\n",
    "                     marker_color='#f9e2af', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Log10\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=marker_log, nbinsx=200, name='Log10',\n",
    "                     marker_color='#cba6f7', opacity=0.7,\n",
    "                     hovertemplate='Intensité: %{x:.2f}<br>Count: %{y}<extra></extra>'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Mise en page\n",
    "    fig.update_xaxes(title_text=\"Intensité brute\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Intensité transformée\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Intensité transformée\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Intensité log10\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Fréquence\", row=2, col=2)\n",
    "    \n",
    "    # Thème sombre et configuration\n",
    "    fig.update_layout(\n",
    "        title_text=f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)',\n",
    "        title_font_size=16,\n",
    "        height=900,\n",
    "        showlegend=False,\n",
    "        template='plotly_dark',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Afficher avec gestion d'erreur\n",
    "    try:\n",
    "        fig.show()\n",
    "        print(f\"\\n[OK] Visualisation interactive générée\")\n",
    "        print(f\"    Utilisez les outils Plotly: Zoom (box select), Pan, Reset, Download\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!] Erreur affichage Plotly: {e}\")\n",
    "        print(\"   → Affichage en HTML dans le notebook...\")\n",
    "        \n",
    "        # Alternative: Afficher le HTML directement dans le notebook\n",
    "        try:\n",
    "            from IPython.display import HTML, display\n",
    "            html_str = fig.to_html(include_plotlyjs='cdn', include_mathjax='cdn')\n",
    "            display(HTML(html_str))\n",
    "            print(f\"   [OK] Graphique affiché en HTML (pleinement interactif)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   [X] Erreur HTML: {e2}\")\n",
    "            # Dernier recours: sauvegarder en fichier\n",
    "            html_file = 'plotly_visualization.html'\n",
    "            fig.write_html(html_file)\n",
    "            print(f\"   → Fichier sauvegardé: {html_file}\")\n",
    "            print(f\"   → Ouvrez ce fichier dans votre navigateur pour l'interactivité complète\")\n",
    "    \n",
    "    print(f\"   Cellules: {len(marker_data):,}\")\n",
    "    print(f\"   Min brut: {marker_data.min():.2f} | Max brut: {marker_data.max():.2f}\")\n",
    "else:\n",
    "    # Fallback matplotlib si Plotly non disponible\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.hist(marker_data, bins=200, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Brut (Linéaire)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité brute')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    marker_arcsinh = DataTransformer.arcsinh_transform(marker_data, cofactor=5)\n",
    "    ax.hist(marker_arcsinh, bins=200, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=5)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité transformée')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    ax = axes[2]\n",
    "    if FLOWKIT_AVAILABLE:\n",
    "        marker_logicle = DataTransformer.logicle_transform(marker_data)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Logicle', fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        marker_logicle = DataTransformer.arcsinh_transform(marker_data, cofactor=150)\n",
    "        ax.hist(marker_logicle, bins=200, color='#f9e2af', alpha=0.7, edgecolor='none')\n",
    "        ax.set_title(f'{MARKER_TO_PLOT} - Arcsinh (cofactor=150)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité transformée')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    ax = axes[3]\n",
    "    marker_log = DataTransformer.log_transform(marker_data, base=10, min_val=1)\n",
    "    ax.hist(marker_log, bins=200, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{MARKER_TO_PLOT} - Log10', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intensité transformée (log10)')\n",
    "    ax.set_ylabel('Fréquence')\n",
    "    \n",
    "    plt.suptitle(f'Comparaison Transformations - {MARKER_TO_PLOT} ({len(marker_data):,} cellules)', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95bf80",
   "metadata": {},
   "source": [
    "## 5. Pre-Gating: Élimination des Débris, Doublets et Sélection des Populations\n",
    "\n",
    "Application du pre-gating séquentiel en 4 étapes:\n",
    "\n",
    "1. **Gate 1 - Débris (SSC-A vs FSC-A)**: Exclusion des débris et événements hors-limites\n",
    "2. **Gate 2 - Doublets (FSC-H vs FSC-A)**: Exclusion des agrégats cellulaires\n",
    "3. **Gate 3 - Leucocytes CD45+ (CD45 vs SSC-A)**: Sélection des leucocytes — **Gate principal**\n",
    "4. **Gate 4 - Blastes CD34+ (optionnel)**: Sous-sélection CD34 bright + SSC low\n",
    "\n",
    "### Choix du mode de gating : `GATING_MODE`\n",
    "\n",
    "| Mode | Méthode | Avantage | Inconvénient |\n",
    "|------|---------|----------|-------------|\n",
    "| `\"manual\"` | Percentiles fixes (PreGating) | Reproductible, rapide | Seuils arbitraires, perte si échantillon propre |\n",
    "| `\"auto\"` | GMM adaptatif (AutoGating) | Trouve le creux réel entre populations, s'adapte | Dépend de la forme des distributions |\n",
    "\n",
    "### Stratégie de gating classique en cytométrie:\n",
    "```\n",
    "Événements totaux\n",
    "    └── Gate Débris (SSC-A vs FSC-A) → Cellules viables\n",
    "            └── Gate Singlets (FSC-H vs FSC-A) → Cellules individuelles\n",
    "                    └── Gate CD45+ (CD45 vs SSC-A) → Leucocytes\n",
    "                            └── [optionnel] Gate CD34+ (CD34 vs SSC-A) → Blastes\n",
    "```\n",
    "\n",
    "### Paramètres:\n",
    "- **`GATING_MODE`**: `\"manual\"` (percentiles) ou `\"auto\"` (GMM adaptatif)\n",
    "- **`FILTER_BLASTS`**: True = sous-filtrage CD34+ | False = tous les CD45+ conservés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ba663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLICATION DU PRE-GATING SÉQUENTIEL (4 ÉTAPES)\n",
    "# =============================================================================\n",
    "# Stratégie de gating hiérarchique:\n",
    "# 1. SSC-A vs FSC-A → Exclure débris\n",
    "# 2. FSC-H vs FSC-A → Exclure doublets (singlets line)\n",
    "# 3. CD45 vs SSC-A  → Sélectionner leucocytes (GATE PRINCIPAL)\n",
    "# 4. CD34 vs SSC-A  → Sélectionner blastes (optionnel, si FILTER_BLASTS=True)\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== OPTIONS DE PRE-GATING =====================\n",
    "APPLY_PREGATING = True  # Activer/désactiver le pre-gating complet\n",
    "\n",
    "# =================================================================\n",
    "# MODE DE GATING: MANUEL (percentiles) ou AUTOMATIQUE (GMM adaptatif)\n",
    "# =================================================================\n",
    "# \"manual\" : Seuils fixes basés sur les percentiles (classe PreGating)\n",
    "#            → Coupe toujours aux mêmes percentiles, peu importe la distribution\n",
    "#            → Rapide et reproductible, mais perd des données si échantillon propre\n",
    "#\n",
    "# \"auto\"   : Gating adaptatif par modèles de mélange gaussien (classe AutoGating)\n",
    "#            → Trouve le \"creux\" réel entre les populations (débris vs cellules)\n",
    "#            → S'adapte automatiquement: 10% de débris → porte à 10%, pas 2%\n",
    "#            → Pour les doublets: modélise la diagonale FSC-A/FSC-H statistiquement\n",
    "#            → Inspiré de CytoPy AutonomousGate (GMM/KDE)\n",
    "# =================================================================\n",
    "GATING_MODE = \"auto\"  # ← CHANGER ICI: \"manual\" ou \"auto\"\n",
    "\n",
    "# =================================================================\n",
    "# MODE SPÉCIAL: BLASTES CD34+ (PATHO) vs MOELLE NORMALE (SAIN)\n",
    "# =================================================================\n",
    "# Si activé:\n",
    "#   - Fichier PATHOLOGIQUE: Gate complet (débris + doublets + CD45+ + éventuellement CD34+)\n",
    "#   - Fichier SAIN: Gate partiel (débris + doublets + CD45+ UNIQUEMENT, pas de CD34+)\n",
    "# Résultat: Population sélectionnée du patient + Leucocytes normaux de la moelle saine\n",
    "# =================================================================\n",
    "MODE_BLASTES_VS_NORMAL = True  # [!] ACTIVER POUR CE MODE SPÉCIAL\n",
    "\n",
    "# Gate 1: Débris (SSC-A vs FSC-A) - True/False\n",
    "GATE_DEBRIS = True\n",
    "DEBRIS_MIN_PERCENTILE = 1.0   # [Manual] Exclure les 1% les plus bas (débris/bruit)\n",
    "DEBRIS_MAX_PERCENTILE = 99.0  # [Manual] Exclure les 1% les plus hauts (saturés)\n",
    "\n",
    "# Gate 2: Doublets (FSC-H vs FSC-A) - True/False\n",
    "GATE_DOUBLETS = True\n",
    "RATIO_MIN = 0.6   # [Manual] Ratio FSC-A/FSC-H minimum (cellules trop petites)\n",
    "RATIO_MAX = 1.4   # [Manual] Ratio FSC-A/FSC-H maximum (doublets/agrégats)\n",
    "\n",
    "# Gate 3: Leucocytes CD45+ (CD45 vs SSC-A) - GATE PRINCIPAL\n",
    "GATE_CD45 = True  # [!] Sélectionner les leucocytes CD45+\n",
    "CD45_THRESHOLD_PERCENTILE = 5  # [Manual] Seuil CD45+ (exclure les 5% les plus bas)\n",
    "\n",
    "# Gate 4: Blastes CD34+ (CD34 vs SSC-A) - OPTIONNEL (sous-population des CD45+)\n",
    "# =================================================================\n",
    "# FILTER_BLASTS: Contrôle le sous-filtrage CD34+ après le gate CD45+\n",
    "#   - True:  Après CD45+, applique un gate CD34+ → Blastes uniquement\n",
    "#   - False: Conserve TOUS les leucocytes CD45+ pour FlowSOM\n",
    "# =================================================================\n",
    "FILTER_BLASTS = False  # [!] Mettre False pour garder tous les leucocytes CD45+\n",
    "\n",
    "# Paramètres CD34 (utilisés uniquement si FILTER_BLASTS=True)\n",
    "CD34_THRESHOLD_PERCENTILE = 85  # [Manual] Seuil CD34+ (top 15% = percentile 85)\n",
    "USE_SSC_FILTER_FOR_BLASTS = True  # Combiner avec SSC low pour blastes purs\n",
    "SSC_MAX_PERCENTILE_BLASTS = 60  # [Manual] SSC maximum pour blastes (faible granularité)\n",
    "\n",
    "# =================================================================\n",
    "# VALIDATION DES PARAMÈTRES\n",
    "# =================================================================\n",
    "assert GATING_MODE in (\"manual\", \"auto\"), f\"GATING_MODE doit être 'manual' ou 'auto', reçu: '{GATING_MODE}'\"\n",
    "\n",
    "if GATING_MODE == \"auto\" and not SKLEARN_AVAILABLE:\n",
    "    print(\"[!] ATTENTION: scikit-learn requis pour GATING_MODE='auto'\")\n",
    "    print(\"    → Fallback automatique vers mode 'manual'\")\n",
    "    GATING_MODE = \"manual\"\n",
    "\n",
    "# Vérification de cohérence pour MODE_BLASTES_VS_NORMAL\n",
    "if MODE_BLASTES_VS_NORMAL and not COMPARE_MODE:\n",
    "    print(\"[!] ATTENTION: MODE_BLASTES_VS_NORMAL nécessite COMPARE_MODE=True\")\n",
    "    print(\"    → Le mode a besoin de fichiers Sain + Patho pour fonctionner\")\n",
    "    print(\"    → Désactivation automatique du mode différentiel\")\n",
    "    MODE_BLASTES_VS_NORMAL = False\n",
    "\n",
    "# Données avant gating\n",
    "X_raw = combined_data.X\n",
    "if hasattr(X_raw, 'toarray'):\n",
    "    X_raw = X_raw.toarray()\n",
    "n_before = X_raw.shape[0]\n",
    "\n",
    "# Récupérer le vecteur de conditions pour le mode différentiel\n",
    "conditions = combined_data.obs['condition'].values\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" PRE-GATING SÉQUENTIEL - STRATÉGIE EN 4 ÉTAPES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n Événements initiaux: {n_before:,}\")\n",
    "\n",
    "# Affichage du mode de gating\n",
    "mode_label = \"AUTOMATIQUE (GMM adaptatif)\" if GATING_MODE == \"auto\" else \"MANUEL (percentiles fixes)\"\n",
    "print(f\"\\n Mode de gating: {mode_label}\")\n",
    "if GATING_MODE == \"auto\":\n",
    "    print(\"    → Les seuils sont calculés automatiquement par modèle de mélange gaussien\")\n",
    "    print(\"    → Les paramètres [Manual] ci-dessus sont IGNORÉS\")\n",
    "else:\n",
    "    print(\"    → Seuils basés sur les percentiles configurés ci-dessus\")\n",
    "\n",
    "# Affichage mode spécial\n",
    "if MODE_BLASTES_VS_NORMAL:\n",
    "    print(\"\\n [!] MODE BLASTES vs MOELLE NORMALE ACTIVÉ (GATING ASYMÉTRIQUE)\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"     - Patho: Gate complet (débris + doublets + CD45+ + CD34+) → Blastes seuls\")\n",
    "    else:\n",
    "        print(\"     - Patho: Gate (débris + doublets + CD45+) → Leucocytes CD45+ stricts\")\n",
    "    print(\"     - Sain:  Gate (débris + doublets UNIQUEMENT) → Toutes les cellules conservées (pas de gate CD45)\")\n",
    "    n_patho = (conditions == \"Pathologique\").sum()\n",
    "    n_sain = (conditions == \"Sain\").sum()\n",
    "    print(f\"     - Cellules Patho: {n_patho:,}\")\n",
    "    print(f\"     - Cellules Sain: {n_sain:,}\")\n",
    "\n",
    "print(f\"\\n Configuration:\")\n",
    "print(f\"   [Gate 1] Débris (SSC-A/FSC-A):     {'[OK] ACTIVÉ' if GATE_DEBRIS else '[X] DÉSACTIVÉ'}\")\n",
    "print(f\"   [Gate 2] Doublets (FSC-H/FSC-A):   {'[OK] ACTIVÉ' if GATE_DOUBLETS else '[X] DÉSACTIVÉ'}\")\n",
    "if MODE_BLASTES_VS_NORMAL and GATE_CD45:\n",
    "    print(f\"   [Gate 3] Leucocytes CD45+:         [OK] PATHO UNIQUEMENT (gating asymétrique — Sain: pas de gate CD45)\")\n",
    "else:\n",
    "    print(f\"   [Gate 3] Leucocytes CD45+:         {'[OK] ACTIVÉ' if GATE_CD45 else '[X] DÉSACTIVÉ'}\")\n",
    "if FILTER_BLASTS:\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        print(f\"   [Gate 4] Blastes CD34+:            [OK] PATHO UNIQUEMENT (mode différentiel)\")\n",
    "    else:\n",
    "        print(f\"   [Gate 4] Blastes CD34+:            [OK] ACTIVÉ (FILTER_BLASTS=True)\")\n",
    "else:\n",
    "    print(f\"   [Gate 4] Blastes CD34+:            [X] DÉSACTIVÉ (FILTER_BLASTS=False → tous les CD45+ conservés)\")\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    # Initialisation des masques\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    \n",
    "    # ========== GATE 1: DÉBRIS (SSC-A vs FSC-A) ==========\n",
    "    if GATE_DEBRIS:\n",
    "        print(f\"\\n GATE 1: Exclusion des débris (SSC-A vs FSC-A) [{GATING_MODE.upper()}]\")\n",
    "        if GATING_MODE == \"auto\":\n",
    "            mask_debris = AutoGating.auto_gate_debris(X_raw, var_names)\n",
    "        else:\n",
    "            mask_debris = PreGating.gate_debris_polygon(\n",
    "                X_raw, var_names,\n",
    "                auto_percentiles=True,\n",
    "                min_pct=DEBRIS_MIN_PERCENTILE,\n",
    "                max_pct=DEBRIS_MAX_PERCENTILE\n",
    "            )\n",
    "        n_after_debris = mask_debris.sum()\n",
    "        n_excluded_debris = n_before - n_after_debris\n",
    "        if GATING_MODE == \"manual\":\n",
    "            print(f\"   Percentiles: [{DEBRIS_MIN_PERCENTILE}%, {DEBRIS_MAX_PERCENTILE}%]\")\n",
    "        print(f\"   → Conservés: {n_after_debris:,} ({n_after_debris/n_before*100:.1f}%)\")\n",
    "        print(f\"   → Exclus (débris): {n_excluded_debris:,} ({n_excluded_debris/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n GATE 1: Débris - SKIP\")\n",
    "    \n",
    "    # ========== GATE 2: DOUBLETS (FSC-H vs FSC-A) ==========\n",
    "    if GATE_DOUBLETS:\n",
    "        print(f\"\\n GATE 2: Exclusion des doublets (FSC-H vs FSC-A) [{GATING_MODE.upper()}]\")\n",
    "        if GATING_MODE == \"auto\":\n",
    "            # Passer l'information des fichiers pour gating adaptatif par fichier\n",
    "            file_origins = combined_data.obs['file_origin'].values\n",
    "            mask_singlets = AutoGating.auto_gate_singlets(\n",
    "                X_raw, var_names, \n",
    "                file_origin=file_origins,\n",
    "                per_file=True  # Activer le gating par fichier\n",
    "            )\n",
    "        else:\n",
    "            mask_singlets = PreGating.gate_singlets(\n",
    "                X_raw, var_names,\n",
    "                ratio_min=RATIO_MIN,\n",
    "                ratio_max=RATIO_MAX\n",
    "            )\n",
    "        # Appliquer sur les cellules déjà filtrées par gate 1\n",
    "        mask_after_g1_g2 = mask_debris & mask_singlets\n",
    "        n_after_singlets = mask_after_g1_g2.sum()\n",
    "        n_doublets = mask_debris.sum() - n_after_singlets\n",
    "        if GATING_MODE == \"manual\":\n",
    "            print(f\"   Ratio FSC-A/FSC-H: [{RATIO_MIN}, {RATIO_MAX}]\")\n",
    "        print(f\"   → Conservés (singlets): {n_after_singlets:,}\")\n",
    "        print(f\"   → Exclus (doublets): {n_doublets:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 2: Doublets - SKIP\")\n",
    "    \n",
    "    # ========== GATE 3: LEUCOCYTES CD45+ (CD45 vs SSC-A) — GATE PRINCIPAL ==========\n",
    "    # LOGIQUE ASYMÉTRIQUE: Pathologique → CD45 strict | Sain → Pas de gate CD45\n",
    "    if GATE_CD45:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n GATE 3: Sélection ASYMÉTRIQUE CD45+ [{GATING_MODE.upper()}]\")\n",
    "            print(\"   → Patho: Gate CD45+ STRICT appliqué (élimination CD45-)\")\n",
    "            print(\"   → Sain:  Gate CD45+ IGNORÉ (toutes cellules conservées — progéniteurs, CD45 low/neg inclus)\")\n",
    "            \n",
    "            # Calculer le masque CD45+ sur TOUTES les données\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd45_full = AutoGating.auto_gate_cd45(X_raw, var_names)\n",
    "            else:\n",
    "                mask_cd45_full = PreGating.gate_cd45_positive(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD45_THRESHOLD_PERCENTILE\n",
    "                )\n",
    "            \n",
    "            # Appliquer le gate CD45 UNIQUEMENT aux cellules pathologiques\n",
    "            mask_patho_cd45 = (conditions == \"Pathologique\")\n",
    "            mask_sain_cd45 = (conditions == \"Sain\")\n",
    "            \n",
    "            # Masque CD45: True pour Sain (on garde tout), mask_cd45_full pour Patho\n",
    "            mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "            mask_cd45[mask_patho_cd45] = mask_cd45_full[mask_patho_cd45]\n",
    "            # Sain: mask_cd45 reste True → aucun filtrage CD45\n",
    "            \n",
    "            # Stats par condition\n",
    "            n_patho_g12 = (mask_patho_cd45 & mask_debris & mask_singlets).sum()\n",
    "            n_patho_cd45_kept = (mask_patho_cd45 & mask_debris & mask_singlets & mask_cd45).sum()\n",
    "            n_patho_cd45_excl = n_patho_g12 - n_patho_cd45_kept\n",
    "            n_sain_g12 = (mask_sain_cd45 & mask_debris & mask_singlets).sum()\n",
    "            \n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD45+: percentile {CD45_THRESHOLD_PERCENTILE} (appliqué PATHO uniquement)\")\n",
    "            print(f\"   → Patho CD45+ conservés: {n_patho_cd45_kept:,} / {n_patho_g12:,} ({n_patho_cd45_kept/max(n_patho_g12,1)*100:.1f}%)\")\n",
    "            print(f\"   → Patho CD45- exclus:    {n_patho_cd45_excl:,}\")\n",
    "            print(f\"   → Sain conservés (100%):  {n_sain_g12:,} / {n_sain_g12:,} (aucun gate CD45)\")\n",
    "            \n",
    "            mask_after_g1_g2_g3 = mask_debris & mask_singlets & mask_cd45\n",
    "            n_after_cd45 = mask_after_g1_g2_g3.sum()\n",
    "            n_cd45_excluded = (mask_debris & mask_singlets).sum() - n_after_cd45\n",
    "            print(f\"   → Total après Gate 3: {n_after_cd45:,} (exclus CD45: {n_cd45_excluded:,} — Patho uniquement)\")\n",
    "        else:\n",
    "            print(f\"\\n GATE 3: Sélection des leucocytes CD45+ (GATE PRINCIPAL) [{GATING_MODE.upper()}]\")\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd45 = AutoGating.auto_gate_cd45(X_raw, var_names)\n",
    "            else:\n",
    "                mask_cd45 = PreGating.gate_cd45_positive(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD45_THRESHOLD_PERCENTILE\n",
    "                )\n",
    "            mask_after_g1_g2_g3 = mask_debris & mask_singlets & mask_cd45\n",
    "            n_after_cd45 = mask_after_g1_g2_g3.sum()\n",
    "            n_cd45_excluded = (mask_debris & mask_singlets).sum() - n_after_cd45\n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD45+: percentile {CD45_THRESHOLD_PERCENTILE} (exclure les {CD45_THRESHOLD_PERCENTILE}% les plus bas)\")\n",
    "            print(f\"   → Leucocytes CD45+ conservés: {n_after_cd45:,}\")\n",
    "            print(f\"   → Exclus (CD45-): {n_cd45_excluded:,}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 3: CD45+ - SKIP\")\n",
    "    \n",
    "    # ========== GATE 4: BLASTES CD34+ (optionnel, conditionné par FILTER_BLASTS) ==========\n",
    "    if FILTER_BLASTS:\n",
    "        # Mode différentiel: appliquer CD34+ gate UNIQUEMENT sur les cellules pathologiques\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n GATE 4: Sélection DIFFÉRENTIELLE des blastes CD34+ [{GATING_MODE.upper()}]\")\n",
    "            print(\"   → Patho: Gate CD34+ appliqué (blastes uniquement)\")\n",
    "            print(\"   → Sain: Gate CD34+ IGNORÉ (tous les leucocytes CD45+ conservés)\")\n",
    "            \n",
    "            # Calculer le masque CD34+ sur TOUTES les données\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd34_full = AutoGating.auto_gate_cd34(\n",
    "                    X_raw, var_names,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS\n",
    "                )\n",
    "            else:\n",
    "                mask_cd34_full = PreGating.gate_cd34_blasts(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "                    ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "                )\n",
    "            \n",
    "            # Appliquer le gate CD34+ UNIQUEMENT aux cellules pathologiques\n",
    "            mask_patho = (conditions == \"Pathologique\")\n",
    "            mask_sain = (conditions == \"Sain\")\n",
    "            \n",
    "            # Masque CD34: True pour sain (on garde tout), mask_cd34_full pour patho\n",
    "            mask_cd34 = np.ones(n_before, dtype=bool)\n",
    "            mask_cd34[mask_patho] = mask_cd34_full[mask_patho]\n",
    "            \n",
    "            # Stats\n",
    "            n_patho_before = mask_patho.sum()\n",
    "            n_patho_cd34 = (mask_patho & mask_cd34_full).sum()\n",
    "            n_sain_kept = mask_sain.sum()\n",
    "            \n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    print(f\"   Filtre SSC low: ≤ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "            print(f\"   → Patho: {n_patho_cd34:,} blastes / {n_patho_before:,} ({n_patho_cd34/n_patho_before*100:.1f}%)\")\n",
    "            print(f\"   → Sain: {n_sain_kept:,} leucocytes conservés (100%)\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n GATE 4: Sélection des blastes CD34+ (toutes conditions) [{GATING_MODE.upper()}]\")\n",
    "            if GATING_MODE == \"auto\":\n",
    "                mask_cd34 = AutoGating.auto_gate_cd34(\n",
    "                    X_raw, var_names,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS\n",
    "                )\n",
    "            else:\n",
    "                mask_cd34 = PreGating.gate_cd34_blasts(\n",
    "                    X_raw, var_names,\n",
    "                    threshold_percentile=CD34_THRESHOLD_PERCENTILE,\n",
    "                    use_ssc_filter=USE_SSC_FILTER_FOR_BLASTS,\n",
    "                    ssc_max_percentile=SSC_MAX_PERCENTILE_BLASTS\n",
    "                )\n",
    "            if GATING_MODE == \"manual\":\n",
    "                print(f\"   Seuil CD34+: top {100-CD34_THRESHOLD_PERCENTILE:.0f}% (percentile {CD34_THRESHOLD_PERCENTILE})\")\n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    print(f\"   Filtre SSC low: ≤ percentile {SSC_MAX_PERCENTILE_BLASTS}\")\n",
    "    else:\n",
    "        print(\"\\n GATE 4: Blastes CD34+ - SKIP (FILTER_BLASTS=False)\")\n",
    "        print(\"   → Tous les leucocytes CD45+ seront conservés pour FlowSOM\")\n",
    "    \n",
    "    # ========== MASQUE FINAL COMBINÉ ==========\n",
    "    mask_final = mask_debris & mask_singlets & mask_cd45 & mask_cd34\n",
    "    n_final = mask_final.sum()\n",
    "    n_excluded = n_before - n_final\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\" RÉSUMÉ DU PRE-GATING [{mode_label}]\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   Événements initiaux:       {n_before:,}\")\n",
    "    print(f\"   Après Gate 1 (débris):     {mask_debris.sum():,}\")\n",
    "    print(f\"   Après Gate 2 (doublets):   {(mask_debris & mask_singlets).sum():,}\")\n",
    "    print(f\"   Après Gate 3 (CD45+):      {(mask_debris & mask_singlets & mask_cd45).sum():,}\")\n",
    "    \n",
    "    # --- Détails par condition si MODE_BLASTES_VS_NORMAL ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        mask_patho = (conditions == \"Pathologique\")\n",
    "        mask_sain = (conditions == \"Sain\")\n",
    "        n_patho_total = mask_patho.sum()\n",
    "        n_sain_total = mask_sain.sum()\n",
    "        n_patho_final = (mask_final & mask_patho).sum()\n",
    "        n_sain_final = (mask_final & mask_sain).sum()\n",
    "        \n",
    "        print(f\"\\n   {'─'*55}\")\n",
    "        print(f\"   DÉTAIL PAR CONDITION (GATING ASYMÉTRIQUE)\")\n",
    "        print(f\"   {'─'*55}\")\n",
    "        print(f\"   PATHOLOGIQUE (CD45 strict):\")\n",
    "        print(f\"     Initial:                 {n_patho_total:,}\")\n",
    "        print(f\"     Après débris+doublets:   {(mask_patho & mask_debris & mask_singlets).sum():,}\")\n",
    "        print(f\"     Après CD45+ (strict):    {(mask_patho & mask_debris & mask_singlets & mask_cd45).sum():,}\")\n",
    "        print(f\"     Final conservé:          {n_patho_final:,} ({n_patho_final/max(n_patho_total,1)*100:.1f}%)\")\n",
    "        print(f\"   SAIN / NBM (pas de gate CD45):\")\n",
    "        print(f\"     Initial:                 {n_sain_total:,}\")\n",
    "        print(f\"     Après débris+doublets:   {(mask_sain & mask_debris & mask_singlets).sum():,}\")\n",
    "        print(f\"     CD45 gate:               NON APPLIQUÉ (toutes cellules conservées)\")\n",
    "        print(f\"     Final conservé:          {n_sain_final:,} ({n_sain_final/max(n_sain_total,1)*100:.1f}%)\")\n",
    "        print(f\"   {'─'*55}\")\n",
    "    \n",
    "    if FILTER_BLASTS:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"   Après Gate 4 (CD34+ patho): {n_final:,}\")\n",
    "            print(f\"\\n   [MODE BLASTES vs MOELLE NORMALE]\")\n",
    "            print(f\"   Blastes CD34+ (patho):     {n_patho_final:,}\")\n",
    "            print(f\"   Cellules normales (sain):  {n_sain_final:,}\")\n",
    "            print(f\"   ─────────────────────────────────────\")\n",
    "            print(f\"   [OK] TOTAL CONSERVÉ:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   → Prêt pour FlowSOM: Blastes purs + Cellules normales (moelle saine complète)\")\n",
    "        else:\n",
    "            print(f\"   Après Gate 4 (CD34+):      {n_final:,}\")\n",
    "            print(f\"\\n   [OK] ÉVÉNEMENTS CONSERVÉS: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] ÉVÉNEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "    else:\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            print(f\"\\n   [MODE ASYMÉTRIQUE — LEUCOCYTES vs MOELLE NORMALE]\")\n",
    "            print(f\"   Patho (CD45+ stricts):     {n_patho_final:,} ({n_patho_final/max(n_patho_total,1)*100:.1f}% du fichier patient)\")\n",
    "            print(f\"   Sain (toutes cellules):    {n_sain_final:,} ({n_sain_final/max(n_sain_total,1)*100:.1f}% du fichier NBM)\")\n",
    "            print(f\"   ─────────────────────────────────────\")\n",
    "            print(f\"   [OK] TOTAL CONSERVÉ:       {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] TOTAL EXCLUS:          {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   → Prêt pour FlowSOM: Leucocytes CD45+ (patho) + Moelle normale complète (sain)\")\n",
    "        else:\n",
    "            population_type = \"Leucocytes CD45+\" if GATE_CD45 else \"Cellules\"\n",
    "            print(f\"\\n   [OK] {population_type} CONSERVÉS: {n_final:,} ({n_final/n_before*100:.1f}%)\")\n",
    "            print(f\"   [X] ÉVÉNEMENTS EXCLUS: {n_excluded:,} ({n_excluded/n_before*100:.1f}%)\")\n",
    "            print(f\"\\n   → Prêt pour FlowSOM: Population CD45+ complète (pas de sous-sélection CD34+)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n PRE-GATING COMPLÈTEMENT DÉSACTIVÉ\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   → Toutes les {n_before:,} cellules seront conservées\")\n",
    "    mask_final = np.ones(n_before, dtype=bool)\n",
    "    n_final = n_before\n",
    "    mask_debris = np.ones(n_before, dtype=bool)\n",
    "    mask_singlets = np.ones(n_before, dtype=bool)\n",
    "    mask_cd45 = np.ones(n_before, dtype=bool)\n",
    "    mask_cd34 = np.ones(n_before, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7672363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION PROFESSIONNELLE DES ÉTAPES DE GATING\n",
    "# =============================================================================\n",
    "# Graphiques SÉPARÉS et BIEN DÉFINIS pour chaque étape\n",
    "# Style professionnel type FlowJo/Kaluza\n",
    "# =============================================================================\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "# =============================================================================\n",
    "# FONCTIONS DE VISUALISATION\n",
    "# =============================================================================\n",
    "\n",
    "def format_axis(value, pos):\n",
    "    \"\"\"Format intelligent des axes (K pour milliers, M pour millions)\"\"\"\n",
    "    if abs(value) >= 1e6:\n",
    "        return f'{value/1e6:.1f}M'\n",
    "    elif abs(value) >= 1e3:\n",
    "        return f'{value/1e3:.0f}K'\n",
    "    return f'{value:.0f}'\n",
    "\n",
    "\n",
    "def plot_density(ax, x, y, title, xlabel, ylabel, n_bins=120):\n",
    "    \"\"\"Scatter plot avec densité 2D (style FlowJo)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[valid], y[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'Données insuffisantes', ha='center', va='center', \n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    \n",
    "    # Colormap densité\n",
    "    cmap = LinearSegmentedColormap.from_list('density', \n",
    "        ['#0d0d0d', '#1a1a2e', '#0077b6', '#00b4d8', '#90e0ef', '#f9e2af', '#ffffff'])\n",
    "    \n",
    "    # Histogramme 2D\n",
    "    h = ax.hist2d(x, y, bins=n_bins, \n",
    "                  range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                  cmap=cmap, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(h[3], ax=ax, shrink=0.85)\n",
    "    cbar.ax.tick_params(colors='white', labelsize=9)\n",
    "    cbar.set_label('Densité', color='white', fontsize=11)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "def plot_gating(ax, x, y, mask, title, xlabel, ylabel, \n",
    "                label_in='Conservés', label_out='Exclus', max_pts=100000):\n",
    "    \"\"\"Scatter plot avec overlay gating (vert=conservés, rouge=exclus)\"\"\"\n",
    "    # Nettoyer\n",
    "    valid = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y, mask = x[valid], y[valid], mask[valid]\n",
    "    \n",
    "    if len(x) < 100:\n",
    "        ax.text(0.5, 0.5, 'Données insuffisantes', ha='center', va='center',\n",
    "                transform=ax.transAxes, fontsize=14, color='white')\n",
    "        ax.set_facecolor('#1e1e2e')\n",
    "        return\n",
    "    \n",
    "    # Sous-échantillonner\n",
    "    if len(x) > max_pts:\n",
    "        idx = np.random.choice(len(x), max_pts, replace=False)\n",
    "        x, y, mask = x[idx], y[idx], mask[idx]\n",
    "    \n",
    "    # Couleurs\n",
    "    c_out = '#f38ba8'  # Rouge pastel\n",
    "    c_in = '#a6e3a1'   # Vert pastel\n",
    "    \n",
    "    # Tracer exclus (fond)\n",
    "    ax.scatter(x[~mask], y[~mask], s=4, c=c_out, alpha=0.3, \n",
    "               label=label_out, edgecolors='none', rasterized=True)\n",
    "    # Tracer conservés (avant-plan)\n",
    "    ax.scatter(x[mask], y[mask], s=5, c=c_in, alpha=0.5, \n",
    "               label=label_in, edgecolors='none', rasterized=True)\n",
    "    \n",
    "    # Stats\n",
    "    n_tot = len(x)\n",
    "    n_in = mask.sum()\n",
    "    pct = n_in / n_tot * 100 if n_tot > 0 else 0\n",
    "    \n",
    "    # Style\n",
    "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold', color='white')\n",
    "    ax.set_title(f'{title}\\n{n_in:,} / {n_tot:,} ({pct:.1f}%)', \n",
    "                fontsize=14, fontweight='bold', color='white', pad=12)\n",
    "    ax.set_facecolor('#1e1e2e')\n",
    "    ax.tick_params(colors='white', labelsize=11)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#45475a')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=10, markerscale=3,\n",
    "              facecolor='#313244', labelcolor='white', edgecolor='#45475a')\n",
    "    \n",
    "    # Limites\n",
    "    x_lo, x_hi = np.percentile(x, [0.5, 99.5])\n",
    "    y_lo, y_hi = np.percentile(y, [0.5, 99.5])\n",
    "    ax.set_xlim(x_lo - (x_hi-x_lo)*0.05, x_hi + (x_hi-x_lo)*0.05)\n",
    "    ax.set_ylim(y_lo - (y_hi-y_lo)*0.05, y_hi + (y_hi-y_lo)*0.05)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GÉNÉRATION DES GRAPHIQUES (UN PAR UN)\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\" VISUALISATION DU PRE-GATING - GRAPHIQUES SÉPARÉS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Indices des canaux\n",
    "    fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    cd45_idx = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "    cd34_idx = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "    \n",
    "    # Sous-échantillonner\n",
    "    n_sample = min(60000, n_before)\n",
    "    np.random.seed(42)\n",
    "    idx_s = np.random.choice(n_before, n_sample, replace=False)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 1 : VUE D'ENSEMBLE (FSC-A vs SSC-A)\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"─\"*50)\n",
    "    print(\" GRAPHIQUE 1 : VUE D'ENSEMBLE\")\n",
    "    print(\"─\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "        \n",
    "        plot_density(ax1, \n",
    "                     X_raw[idx_s, fsc_a_idx], \n",
    "                     X_raw[idx_s, ssc_a_idx],\n",
    "                     f'VUE D\\'ENSEMBLE\\n{n_before:,} événements totaux',\n",
    "                     'FSC-A (Forward Scatter - Taille)',\n",
    "                     'SSC-A (Side Scatter - Granularité)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_01_overview.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] Sauvegardé: gating_01_overview.png\")\n",
    "    else:\n",
    "        print(\"   [!] FSC-A ou SSC-A non trouvé dans les données\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 2 : GATE DÉBRIS (FSC-A vs SSC-A avec overlay)\n",
    "    # =========================================================================\n",
    "    if GATE_DEBRIS:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 2 : GATE DÉBRIS\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "            fig2, ax2 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            plot_gating(ax2,\n",
    "                        X_raw[idx_s, fsc_a_idx],\n",
    "                        X_raw[idx_s, ssc_a_idx],\n",
    "                        mask_debris[idx_s],\n",
    "                        'GATE 1 : Exclusion des Débris',\n",
    "                        'FSC-A (Taille)',\n",
    "                        'SSC-A (Granularité)',\n",
    "                        'Cellules viables', 'Débris/Bruit')\n",
    "            \n",
    "            # Rectangle de gate\n",
    "            fsc_lo = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            fsc_hi = np.nanpercentile(X_raw[:, fsc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            ssc_lo = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MIN_PERCENTILE)\n",
    "            ssc_hi = np.nanpercentile(X_raw[:, ssc_a_idx], DEBRIS_MAX_PERCENTILE)\n",
    "            \n",
    "            rect = Rectangle((fsc_lo, ssc_lo), fsc_hi-fsc_lo, ssc_hi-ssc_lo,\n",
    "                             fill=False, edgecolor='#f9e2af', linewidth=3, linestyle='--')\n",
    "            ax2.add_patch(rect)\n",
    "            ax2.text(fsc_lo + (fsc_hi-fsc_lo)/2, ssc_hi, ' Zone de sélection',\n",
    "                    ha='center', va='bottom', fontsize=11, color='#f9e2af', fontweight='bold')\n",
    "            \n",
    "            # Stats\n",
    "            n_kept = mask_debris.sum()\n",
    "            print(f\"   → Événements conservés: {n_kept:,} ({n_kept/n_before*100:.1f}%)\")\n",
    "            print(f\"   → Débris exclus: {n_before - n_kept:,}\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('gating_02_debris.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(\"   [OK] Sauvegardé: gating_02_debris.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 3 : GATE SINGLETS (FSC-H vs FSC-A)\n",
    "    # =========================================================================\n",
    "    if GATE_DOUBLETS:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 3 : GATE SINGLETS (Doublets)\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if fsc_a_idx is not None and fsc_h_idx is not None:\n",
    "            fig3, ax3 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Après gate 1\n",
    "            m_g1 = mask_debris[idx_s]\n",
    "            x3 = X_raw[idx_s, fsc_a_idx][m_g1]\n",
    "            y3 = X_raw[idx_s, fsc_h_idx][m_g1]\n",
    "            m3 = mask_singlets[idx_s][m_g1]\n",
    "            \n",
    "            if len(x3) > 100:\n",
    "                plot_gating(ax3, x3, y3, m3,\n",
    "                            f'GATE 2 : Exclusion des Doublets - Mode {GATING_MODE.upper()}',\n",
    "                            'FSC-A (Area)',\n",
    "                            'FSC-H (Height)',\n",
    "                            'Singlets', 'Doublets/Agrégats')\n",
    "                \n",
    "                if GATING_MODE == \"auto\":\n",
    "                    # Tracer les droites RANSAC par fichier\n",
    "                    from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "                    \n",
    "                    # Récupérer les fichiers pour les cellules échantillonnées\n",
    "                    file_origins_sample = combined_data.obs['file_origin'].values[idx_s][m_g1]\n",
    "                    unique_files_sample = np.unique(file_origins_sample)\n",
    "                    \n",
    "                    # Palette de couleurs pour les droites\n",
    "                    colors_lines = ['#f9e2af', '#89b4fa', '#cba6f7', '#fab387', '#a6e3a1']\n",
    "                    \n",
    "                    print(f\"   → Visualisation des {len(unique_files_sample)} droites RANSAC\")\n",
    "                    \n",
    "                    for i, file_name in enumerate(unique_files_sample):\n",
    "                        file_mask_sample = (file_origins_sample == file_name)\n",
    "                        if file_mask_sample.sum() < 50:\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            x_file = x3[file_mask_sample].reshape(-1, 1)\n",
    "                            y_file = y3[file_mask_sample].reshape(-1, 1)\n",
    "                            \n",
    "                            ransac = RANSACRegressor(\n",
    "                                estimator=LinearRegression(),\n",
    "                                min_samples=50,\n",
    "                                residual_threshold=None,\n",
    "                                random_state=42,\n",
    "                                max_trials=100\n",
    "                            )\n",
    "                            ransac.fit(y_file, x_file.ravel())\n",
    "                            \n",
    "                            # Tracer la droite\n",
    "                            y_range = np.linspace(y_file.min(), y_file.max(), 100)\n",
    "                            x_pred = ransac.predict(y_range.reshape(-1, 1))\n",
    "                            \n",
    "                            color = colors_lines[i % len(colors_lines)]\n",
    "                            file_short = file_name[:20] + \"...\" if len(file_name) > 20 else file_name\n",
    "                            ax3.plot(x_pred, y_range, '-', color=color, lw=2.5, alpha=0.8,\n",
    "                                    label=f'{file_short}')\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"      [!] Échec visualisation pour {file_name}: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Légende compacte\n",
    "                    if len(unique_files_sample) <= 5:\n",
    "                        ax3.legend(loc='lower right', fontsize=9, markerscale=2,\n",
    "                                  facecolor='#313244', labelcolor='white', edgecolor='#45475a',\n",
    "                                  title='Droites RANSAC par fichier', title_fontsize=10)\n",
    "                    else:\n",
    "                        ax3.text(0.98, 0.02, f'{len(unique_files_sample)} droites calculées',\n",
    "                                transform=ax3.transAxes, ha='right', va='bottom',\n",
    "                                fontsize=10, color='#f9e2af', fontweight='bold',\n",
    "                                bbox=dict(boxstyle='round', facecolor='#313244', alpha=0.8))\n",
    "                    \n",
    "                else:\n",
    "                    # Mode manuel: lignes de ratio fixes\n",
    "                    x_range = np.linspace(np.nanpercentile(x3, 1), np.nanpercentile(x3, 99), 100)\n",
    "                    ax3.plot(x_range, x_range, 'w-', lw=2, alpha=0.7, label='Ratio 1:1')\n",
    "                    ax3.plot(x_range, x_range * RATIO_MIN, '--', color='#f9e2af', lw=2,\n",
    "                            label=f'Ratio min ({RATIO_MIN})')\n",
    "                    ax3.plot(x_range, x_range * RATIO_MAX, '--', color='#fab387', lw=2,\n",
    "                            label=f'Ratio max ({RATIO_MAX})')\n",
    "                    ax3.fill_between(x_range, x_range * RATIO_MIN, x_range * RATIO_MAX,\n",
    "                                    alpha=0.1, color='#f9e2af')\n",
    "                    ax3.legend(loc='lower right', fontsize=10, markerscale=2,\n",
    "                              facecolor='#313244', labelcolor='white', edgecolor='#45475a')\n",
    "                \n",
    "                # Stats\n",
    "                n_after_g2 = (mask_debris & mask_singlets).sum()\n",
    "                n_doublets = mask_debris.sum() - n_after_g2\n",
    "                print(f\"   → Singlets conservés: {n_after_g2:,}\")\n",
    "                print(f\"   → Doublets exclus: {n_doublets:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_03_singlets.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegardé: gating_03_singlets.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 4 : GATE CD45+ (CD45 vs SSC-A) — GATE PRINCIPAL\n",
    "    # =========================================================================\n",
    "    if GATE_CD45:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 4 : GATE CD45+ (Leucocytes) — GATE PRINCIPAL\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if cd45_idx is not None and ssc_a_idx is not None:\n",
    "            fig4, ax4 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Après gates 1+2\n",
    "            m_g12 = (mask_debris & mask_singlets)[idx_s]\n",
    "            x4 = X_raw[idx_s, cd45_idx][m_g12]\n",
    "            y4 = X_raw[idx_s, ssc_a_idx][m_g12]\n",
    "            m4 = mask_cd45[idx_s][m_g12]\n",
    "            \n",
    "            if len(x4) > 100:\n",
    "                plot_gating(ax4, x4, y4, m4,\n",
    "                            'GATE 3 : Sélection des Leucocytes CD45+',\n",
    "                            'CD45 (Intensité)',\n",
    "                            'SSC-A (Granularité)',\n",
    "                            'Leucocytes CD45+', 'Cellules CD45-')\n",
    "                \n",
    "                # Seuil CD45\n",
    "                cd45_th = np.nanpercentile(X_raw[:, cd45_idx], CD45_THRESHOLD_PERCENTILE)\n",
    "                ax4.axvline(x=cd45_th, color='#89b4fa', lw=3, ls='--')\n",
    "                ax4.text(cd45_th, ax4.get_ylim()[1], f' Seuil CD45+\\n (P{CD45_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#89b4fa', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                n_cd45_kept = (mask_debris & mask_singlets & mask_cd45).sum()\n",
    "                print(f\"   → Leucocytes CD45+ conservés: {n_cd45_kept:,}\")\n",
    "                print(f\"   → CD45- exclus: {(mask_debris & mask_singlets).sum() - n_cd45_kept:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_04_cd45.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegardé: gating_04_cd45.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD45 non trouvé - Gate CD45+ ignoré\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 5 : GATE CD34+ (CD34 vs SSC-A) — OPTIONNEL\n",
    "    # =========================================================================\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"\\n\" + \"─\"*50)\n",
    "        print(\" GRAPHIQUE 5 : GATE CD34+ (Blastes) — Sous-population des CD45+\")\n",
    "        print(\"─\"*50)\n",
    "        \n",
    "        if cd34_idx is not None and ssc_a_idx is not None:\n",
    "            fig_cd34, ax_cd34 = plt.subplots(figsize=(10, 8), facecolor='#1e1e2e')\n",
    "            \n",
    "            # Après gates 1+2+3 (CD45+)\n",
    "            m_g123 = (mask_debris & mask_singlets & mask_cd45)[idx_s]\n",
    "            x5 = X_raw[idx_s, cd34_idx][m_g123]\n",
    "            y5 = X_raw[idx_s, ssc_a_idx][m_g123]\n",
    "            m5 = mask_cd34[idx_s][m_g123]\n",
    "            \n",
    "            if len(x5) > 100:\n",
    "                plot_gating(ax_cd34, x5, y5, m5,\n",
    "                            'GATE 4 : Sélection des Blastes CD34+ (parmi CD45+)',\n",
    "                            'CD34 (Intensité)',\n",
    "                            'SSC-A (Granularité)',\n",
    "                            'Blastes CD34+', 'Autres leucocytes')\n",
    "                \n",
    "                # Seuils\n",
    "                cd34_th = np.nanpercentile(X_raw[:, cd34_idx], CD34_THRESHOLD_PERCENTILE)\n",
    "                ax_cd34.axvline(x=cd34_th, color='#f9e2af', lw=3, ls='--')\n",
    "                ax_cd34.text(cd34_th, ax_cd34.get_ylim()[1], f' Seuil CD34\\n (P{CD34_THRESHOLD_PERCENTILE})',\n",
    "                        va='top', ha='left', fontsize=10, color='#f9e2af', fontweight='bold')\n",
    "                \n",
    "                if USE_SSC_FILTER_FOR_BLASTS:\n",
    "                    ssc_th = np.nanpercentile(X_raw[:, ssc_a_idx], SSC_MAX_PERCENTILE_BLASTS)\n",
    "                    ax_cd34.axhline(y=ssc_th, color='#fab387', lw=3, ls='--')\n",
    "                    ax_cd34.text(ax_cd34.get_xlim()[1], ssc_th, f' SSC max (P{SSC_MAX_PERCENTILE_BLASTS}) ',\n",
    "                            va='bottom', ha='right', fontsize=10, color='#fab387', fontweight='bold')\n",
    "                \n",
    "                # Stats\n",
    "                print(f\"   → Blastes CD34+ sélectionnés: {n_final:,}\")\n",
    "                print(f\"   → Autres leucocytes exclus: {(mask_debris & mask_singlets & mask_cd45).sum() - n_final:,}\")\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('gating_05_cd34.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                print(\"   [OK] Sauvegardé: gating_05_cd34.png\")\n",
    "        else:\n",
    "            print(\"   [!] CD34 non trouvé - Gate CD34+ ignoré\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GRAPHIQUE 6 : COMPARAISON AVANT / APRÈS\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"─\"*50)\n",
    "    print(\" GRAPHIQUE 6 : COMPARAISON AVANT / APRÈS\")\n",
    "    print(\"─\"*50)\n",
    "    \n",
    "    if fsc_a_idx is not None and ssc_a_idx is not None:\n",
    "        fig5, (ax5a, ax5b) = plt.subplots(1, 2, figsize=(16, 7), facecolor='#1e1e2e')\n",
    "        \n",
    "        # AVANT\n",
    "        cmap_red = LinearSegmentedColormap.from_list('reds', \n",
    "            ['#1a1a2e', '#7f1d1d', '#dc2626', '#fca5a5', '#ffffff'])\n",
    "        \n",
    "        valid = np.isfinite(X_raw[idx_s, fsc_a_idx]) & np.isfinite(X_raw[idx_s, ssc_a_idx])\n",
    "        x_bef = X_raw[idx_s, fsc_a_idx][valid]\n",
    "        y_bef = X_raw[idx_s, ssc_a_idx][valid]\n",
    "        \n",
    "        x_lo, x_hi = np.percentile(x_bef, [0.5, 99.5])\n",
    "        y_lo, y_hi = np.percentile(y_bef, [0.5, 99.5])\n",
    "        \n",
    "        h1 = ax5a.hist2d(x_bef, y_bef, bins=100, \n",
    "                         range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                         cmap=cmap_red, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        ax5a.set_title(f'AVANT Gating\\n{n_before:,} événements', fontsize=14, fontweight='bold', color='white')\n",
    "        ax5a.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5a.set_facecolor('#1e1e2e')\n",
    "        ax5a.tick_params(colors='white')\n",
    "        ax5a.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5a.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5a.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        # APRÈS\n",
    "        cmap_green = LinearSegmentedColormap.from_list('greens', \n",
    "            ['#1a1a2e', '#14532d', '#22c55e', '#86efac', '#ffffff'])\n",
    "        \n",
    "        m_final = mask_final[idx_s]\n",
    "        x_aft = X_raw[idx_s, fsc_a_idx][m_final]\n",
    "        y_aft = X_raw[idx_s, ssc_a_idx][m_final]\n",
    "        \n",
    "        if len(x_aft) > 100:\n",
    "            h2 = ax5b.hist2d(x_aft, y_aft, bins=100,\n",
    "                             range=[[x_lo, x_hi], [y_lo, y_hi]],\n",
    "                             cmap=cmap_green, norm=plt.matplotlib.colors.LogNorm(vmin=1))\n",
    "        \n",
    "        pct_final = n_final / n_before * 100\n",
    "        population_label = \"Blastes CD34+\" if FILTER_BLASTS else \"Leucocytes CD45+\"\n",
    "        ax5b.set_title(f'APRÈS Gating ({population_label})\\n{n_final:,} événements ({pct_final:.1f}%)', \n",
    "                      fontsize=14, fontweight='bold', color='white')\n",
    "        ax5b.set_xlabel('FSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_ylabel('SSC-A', fontsize=12, fontweight='bold', color='white')\n",
    "        ax5b.set_facecolor('#1e1e2e')\n",
    "        ax5b.tick_params(colors='white')\n",
    "        ax5b.xaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        ax5b.yaxis.set_major_formatter(FuncFormatter(format_axis))\n",
    "        for spine in ax5b.spines.values():\n",
    "            spine.set_color('#45475a')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gating_06_comparison.png', dpi=150, facecolor='#1e1e2e', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"   [OK] Sauvegardé: gating_06_comparison.png\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # RÉSUMÉ FINAL\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" RÉSUMÉ DU PRE-GATING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ret_g1 = mask_debris.sum() / n_before * 100\n",
    "    ret_g2 = (mask_debris & mask_singlets).sum() / n_before * 100\n",
    "    ret_g3 = (mask_debris & mask_singlets & mask_cd45).sum() / n_before * 100\n",
    "    ret_final = n_final / n_before * 100\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    ┌─────────────────────────────────────────────────────────────┐\n",
    "    │                    STATISTIQUES DE RÉTENTION                │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  Étape                        Cellules        Rétention     │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │   Initial                   {n_before:>10,}        100.0%     │\n",
    "    │  - Gate 1 (Débris)           {mask_debris.sum():>10,}        {ret_g1:>5.1f}%     │\n",
    "    │  - Gate 2 (Doublets)         {(mask_debris & mask_singlets).sum():>10,}        {ret_g2:>5.1f}%     │\n",
    "    │  - Gate 3 (CD45+)            {(mask_debris & mask_singlets & mask_cd45).sum():>10,}        {ret_g3:>5.1f}%     │\"\"\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(f\"    │  - Gate 4 (CD34+)            {n_final:>10,}        {ret_final:>5.1f}%     │\")\n",
    "    print(f\"\"\"    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  [OK] CELLULES CONSERVÉES       {n_final:>10,}        {ret_final:>5.1f}%     │\n",
    "    │  [X] CELLULES EXCLUES          {n_before - n_final:>10,}        {100-ret_final:>5.1f}%     │\n",
    "    └─────────────────────────────────────────────────────────────┘\n",
    "    \"\"\")\n",
    "    \n",
    "    # --- Détail par condition si gating asymétrique ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        _mask_patho = (conditions == \"Pathologique\")\n",
    "        _mask_sain = (conditions == \"Sain\")\n",
    "        _n_patho_tot = _mask_patho.sum()\n",
    "        _n_sain_tot = _mask_sain.sum()\n",
    "        _n_patho_fin = (mask_final & _mask_patho).sum()\n",
    "        _n_sain_fin = (mask_final & _mask_sain).sum()\n",
    "        _ret_patho = _n_patho_fin / max(_n_patho_tot, 1) * 100\n",
    "        _ret_sain = _n_sain_fin / max(_n_sain_tot, 1) * 100\n",
    "        print(f\"\"\"\n",
    "    ┌─────────────────────────────────────────────────────────────┐\n",
    "    │          DÉTAIL GATING ASYMÉTRIQUE PAR CONDITION            │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  PATHOLOGIQUE (CD45 strict appliqué):                       │\n",
    "    │    Initial:          {_n_patho_tot:>10,}                              │\n",
    "    │    Conservé:         {_n_patho_fin:>10,}   ({_ret_patho:>5.1f}%)                   │\n",
    "    │    Gates: Débris + Doublets + CD45+ strict                  │\n",
    "    ├─────────────────────────────────────────────────────────────┤\n",
    "    │  SAIN / NBM (PAS de gate CD45):                             │\n",
    "    │    Initial:          {_n_sain_tot:>10,}                              │\n",
    "    │    Conservé:         {_n_sain_fin:>10,}   ({_ret_sain:>5.1f}%)                   │\n",
    "    │    Gates: Débris + Doublets UNIQUEMENT                      │\n",
    "    └─────────────────────────────────────────────────────────────┘\n",
    "        \"\"\")\n",
    "    \n",
    "    population_desc = \"Blastes CD34+ (parmi CD45+)\" if FILTER_BLASTS else (\"Leucocytes CD45+ (patho) + Moelle normale complète (sain)\" if MODE_BLASTES_VS_NORMAL else \"Leucocytes CD45+ (population complète)\")\n",
    "    print(f\" Population finale: {population_desc}\")\n",
    "    \n",
    "    print(\"\\n Fichiers générés:\")\n",
    "    print(\"   - gating_01_overview.png    - Vue d'ensemble\")\n",
    "    print(\"   - gating_02_debris.png      - Gate débris\")\n",
    "    print(\"   - gating_03_singlets.png    - Gate singlets\")\n",
    "    print(\"   - gating_04_cd45.png        - Gate CD45+ (leucocytes)\")\n",
    "    if FILTER_BLASTS:\n",
    "        print(\"   - gating_05_cd34.png        - Gate CD34+ (blastes)\")\n",
    "    print(\"   - gating_06_comparison.png  - Avant/Après\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n Pre-gating désactivé - Aucun graphique généré\")\n",
    "    print(\"   → Activez APPLY_PREGATING = True pour visualiser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f56b5b",
   "metadata": {},
   "source": [
    "## Visualisation Interactive du Pre-Gating — Style CytoPy\n",
    "\n",
    "Dashboard interactif Plotly pour inspecter chaque étape du gating séquentiel :\n",
    "\n",
    "1. **Sankey Diagram** : Flux des événements à travers les 4 gates (rétention vs exclusion)\n",
    "2. **Density Plots Interactifs** : Scatter 2D avec contours de densité pour chaque gate\n",
    "3. **Histogrammes 1D** : Distribution des marqueurs clés avec seuils GMM annotés\n",
    "4. **Comparaison Patho / Sain** (si `MODE_BLASTES_VS_NORMAL`)\n",
    "\n",
    "> *Inspiré de CytoPy AutonomousGate — tous les graphiques sont interactifs (zoom, hover, export)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION INTERACTIVE STYLE CYTOPY — DASHBOARD DE GATING\n",
    "# =============================================================================\n",
    "# Utilise Plotly pour des graphiques interactifs (zoom, hover, export)\n",
    "# Inspiré de CytoPy AutonomousGate et FlowJo hierarchical gating\n",
    "# =============================================================================\n",
    "\n",
    "if APPLY_PREGATING and PLOTLY_AVAILABLE:\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\" CYTOPY-STYLE GATING DASHBOARD — VISUALISATION INTERACTIVE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # =====================================================================\n",
    "    # 0. PRÉPARATION DES DONNÉES\n",
    "    # =====================================================================\n",
    "    _fsc_a_idx = PreGating.find_marker_index(var_names, ['FSC-A'])\n",
    "    _fsc_h_idx = PreGating.find_marker_index(var_names, ['FSC-H'])\n",
    "    _ssc_a_idx = PreGating.find_marker_index(var_names, ['SSC-A', 'SSC-H', 'SSC'])\n",
    "    _cd45_idx  = PreGating.find_marker_index(var_names, ['CD45', 'CD45-PECY5', 'CD45-PC5'])\n",
    "    _cd34_idx  = PreGating.find_marker_index(var_names, ['CD34', 'CD34-PE', 'CD34-APC'])\n",
    "\n",
    "    # Sous-échantillonner pour fluidité Plotly\n",
    "    _n_pts = min(40_000, n_before)\n",
    "    np.random.seed(42)\n",
    "    _idx = np.random.choice(n_before, _n_pts, replace=False)\n",
    "\n",
    "    # Masques cumulatifs appliqués séquentiellement\n",
    "    _m_g1     = mask_debris[_idx]\n",
    "    _m_g12    = (mask_debris & mask_singlets)[_idx]\n",
    "    _m_g123   = (mask_debris & mask_singlets & mask_cd45)[_idx]\n",
    "    _m_final  = mask_final[_idx]\n",
    "\n",
    "    # Vecteur de conditions pour le sous-échantillon\n",
    "    _cond_sub = conditions[_idx]\n",
    "    _is_sain_sub = (_cond_sub == \"Sain\")\n",
    "\n",
    "    # Labels de gate pour chaque événement (gating asymétrique)\n",
    "    # ─── LÉGENDE DÉTAILLÉE : sépare Patho conservés / Sain NBM conservés ───\n",
    "    def _gate_label(i):\n",
    "        if not _m_g1[i]:\n",
    "            return \"Débris (exclu G1)\"\n",
    "        if not _m_g12[i]:\n",
    "            return \"Doublet (exclu G2)\"\n",
    "        if not _m_g123[i]:\n",
    "            # En mode asymétrique, seuls les Patho peuvent être exclus par CD45\n",
    "            return \"CD45- Patho (exclu G3)\"\n",
    "        if FILTER_BLASTS and not _m_final[i]:\n",
    "            return \"Non-blaste (exclu G4)\"\n",
    "        # Cellule conservée → distinguer Patho CD45+ vs Sain NBM\n",
    "        if _cond_sub[i] == \"Pathologique\":\n",
    "            return \"CD45+ Patho conservés ✓\"\n",
    "        elif _cond_sub[i] == \"Sain\":\n",
    "            return \"Conservés sains NBM ✓\"\n",
    "        return \"Conservé ✓\"\n",
    "\n",
    "    _labels = np.array([_gate_label(i) for i in range(_n_pts)])\n",
    "\n",
    "    # Palette CytoPy-style (avec catégories détaillées pour conservés)\n",
    "    _color_map = {\n",
    "        \"Débris (exclu G1)\":        \"#636363\",\n",
    "        \"Doublet (exclu G2)\":       \"#e6550d\",\n",
    "        \"CD45- Patho (exclu G3)\":   \"#fd8d3c\",\n",
    "        \"Non-blaste (exclu G4)\":    \"#fdae6b\",\n",
    "        \"CD45+ Patho conservés ✓\":  \"#d62728\",   # rouge – patho conservés\n",
    "        \"Conservés sains NBM ✓\":    \"#2ca02c\",   # vert  – sains NBM conservés\n",
    "        \"Conservé ✓\":               \"#31a354\",   # fallback\n",
    "    }\n",
    "\n",
    "    # =====================================================================\n",
    "    # 1. SANKEY DIAGRAM — FLUX DES ÉVÉNEMENTS (avec % relatifs)\n",
    "    # =====================================================================\n",
    "    print(\"\\n [1/6] Sankey Diagram — Flux du gating hiérarchique (avec % relatifs)\")\n",
    "\n",
    "    _n_total   = n_before\n",
    "    _n_g1_pass = int(mask_debris.sum())\n",
    "    _n_g1_fail = _n_total - _n_g1_pass\n",
    "    _n_g2_pass = int((mask_debris & mask_singlets).sum())\n",
    "    _n_g2_fail = _n_g1_pass - _n_g2_pass\n",
    "    _n_g3_pass = int((mask_debris & mask_singlets & mask_cd45).sum())\n",
    "    _n_g3_fail = _n_g2_pass - _n_g3_pass\n",
    "    _n_g4_pass = int(n_final)\n",
    "    _n_g4_fail = _n_g3_pass - _n_g4_pass\n",
    "\n",
    "    # Helper: % of previous gate\n",
    "    def _pct_of(value, parent):\n",
    "        return f\"{value/max(parent,1)*100:.1f}%\"\n",
    "\n",
    "    _sankey_labels = [\n",
    "        f\"Événements<br>totaux<br>{_n_total:,}\",                                                    # 0\n",
    "        f\"Gate 1<br>Viables<br>{_n_g1_pass:,}<br>({_pct_of(_n_g1_pass, _n_total)} of total)\",       # 1\n",
    "        f\"Débris<br>exclus<br>{_n_g1_fail:,}<br>({_pct_of(_n_g1_fail, _n_total)})\",                  # 2\n",
    "        f\"Gate 2<br>Singlets<br>{_n_g2_pass:,}<br>({_pct_of(_n_g2_pass, _n_g1_pass)} of G1)\",       # 3\n",
    "        f\"Doublets<br>exclus<br>{_n_g2_fail:,}<br>({_pct_of(_n_g2_fail, _n_g1_pass)})\",              # 4\n",
    "        f\"Gate 3<br>CD45+<br>{_n_g3_pass:,}<br>({_pct_of(_n_g3_pass, _n_g2_pass)} of G2)\",          # 5\n",
    "        f\"CD45-<br>exclus<br>{_n_g3_fail:,}<br>({_pct_of(_n_g3_fail, _n_g2_pass)})\",                 # 6\n",
    "    ]\n",
    "\n",
    "    _src  = [0, 0, 1, 1, 3, 3]\n",
    "    _tgt  = [1, 2, 3, 4, 5, 6]\n",
    "    _vals = [_n_g1_pass, _n_g1_fail, _n_g2_pass, _n_g2_fail, _n_g3_pass, _n_g3_fail]\n",
    "    _link_colors = [\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(99,99,99,0.3)\",      # G1: vert conservé / gris débris\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(230,85,13,0.3)\",      # G2: vert singlets / orange doublets\n",
    "        \"rgba(49,163,84,0.4)\", \"rgba(253,141,60,0.3)\",      # G3: vert CD45+ / orange CD45-\n",
    "    ]\n",
    "\n",
    "    if FILTER_BLASTS:\n",
    "        _sankey_labels.append(f\"Gate 4<br>CD34+<br>{_n_g4_pass:,}<br>({_pct_of(_n_g4_pass, _n_g3_pass)} of G3)\")   # 7\n",
    "        _sankey_labels.append(f\"Non-blastes<br>exclus<br>{_n_g4_fail:,}<br>({_pct_of(_n_g4_fail, _n_g3_pass)})\")    # 8\n",
    "        _src  += [5, 5]\n",
    "        _tgt  += [7, 8]\n",
    "        _vals += [_n_g4_pass, _n_g4_fail]\n",
    "        _link_colors += [\"rgba(49,163,84,0.4)\", \"rgba(253,174,107,0.3)\"]\n",
    "        _final_label = f\"Population<br>finale<br>{_n_g4_pass:,}<br>({_pct_of(_n_g4_pass, _n_total)} of total)\"\n",
    "        _sankey_labels.append(_final_label)  # 9\n",
    "        _src.append(7)\n",
    "        _tgt.append(9)\n",
    "        _vals.append(_n_g4_pass)\n",
    "        _link_colors.append(\"rgba(49,163,84,0.6)\")\n",
    "    else:\n",
    "        _final_label = f\"Population<br>finale<br>{_n_g3_pass:,}<br>({_pct_of(_n_g3_pass, _n_total)} of total)\"\n",
    "        _sankey_labels.append(_final_label)  # 7\n",
    "        _src.append(5)\n",
    "        _tgt.append(7)\n",
    "        _vals.append(_n_g3_pass)\n",
    "        _link_colors.append(\"rgba(49,163,84,0.6)\")\n",
    "\n",
    "    # Couleurs harmonisées: vert = conservé, orange/rouge = exclu\n",
    "    _node_colors = [\"#4a90d9\"] + [\"#31a354\", \"#636363\"] * 1 + \\\n",
    "                   [\"#31a354\", \"#e6550d\", \"#31a354\", \"#fd8d3c\"]\n",
    "    if FILTER_BLASTS:\n",
    "        _node_colors += [\"#31a354\", \"#fdae6b\", \"#2ca02c\"]\n",
    "    else:\n",
    "        _node_colors += [\"#2ca02c\"]\n",
    "\n",
    "    fig_sankey = go.Figure(go.Sankey(\n",
    "        arrangement=\"snap\",\n",
    "        node=dict(\n",
    "            pad=20,\n",
    "            thickness=25,\n",
    "            line=dict(color=\"#333\", width=1),\n",
    "            label=_sankey_labels,\n",
    "            color=_node_colors[:len(_sankey_labels)],\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=_src,\n",
    "            target=_tgt,\n",
    "            value=_vals,\n",
    "            color=_link_colors,\n",
    "        ),\n",
    "    ))\n",
    "    fig_sankey.update_layout(\n",
    "        title=dict(\n",
    "            text=\"<b>Gating Hierarchy — Flux des Événements (global)</b>\",\n",
    "            font=dict(size=18),\n",
    "        ),\n",
    "        font=dict(size=13, color=\"#222\"),\n",
    "        paper_bgcolor=\"#fafafa\",\n",
    "        height=450,\n",
    "        margin=dict(l=20, r=20, t=60, b=20),\n",
    "    )\n",
    "    fig_sankey.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 1b. MINI SANKEY PAR FICHIER (onglet secondaire)\n",
    "    # =====================================================================\n",
    "    if 'file_origins' in dir() and file_origins is not None and len(singlets_summary_per_file) > 0:\n",
    "        print(\" [1b/6] Mini Sankey par fichier (résumé)\")\n",
    "        \n",
    "        _unique_files_sankey = np.unique(file_origins) if hasattr(file_origins, '__len__') else []\n",
    "        \n",
    "        # Limiter à max 6 fichiers mini-Sankey pour ne pas saturer le rapport\n",
    "        _files_to_show = _unique_files_sankey[:6] if len(_unique_files_sankey) > 6 else _unique_files_sankey\n",
    "        \n",
    "        if len(_files_to_show) > 0:\n",
    "            from plotly.subplots import make_subplots\n",
    "            \n",
    "            for _f_name in _files_to_show:\n",
    "                _f_mask = (file_origins == _f_name)\n",
    "                _f_total = int(_f_mask.sum())\n",
    "                if _f_total < 10:\n",
    "                    continue\n",
    "                \n",
    "                _f_g1 = int((mask_debris & _f_mask).sum())\n",
    "                _f_g1_fail = _f_total - _f_g1\n",
    "                _f_g2 = int((mask_debris & mask_singlets & _f_mask).sum())\n",
    "                _f_g2_fail = _f_g1 - _f_g2\n",
    "                _f_g3 = int((mask_debris & mask_singlets & mask_cd45 & _f_mask).sum())\n",
    "                _f_g3_fail = _f_g2 - _f_g3\n",
    "                _f_final = int((mask_final & _f_mask).sum())\n",
    "                _f_g4_fail = _f_g3 - _f_final\n",
    "                \n",
    "                _f_short = str(_f_name) if len(str(_f_name)) <= 30 else str(_f_name)[:27] + \"...\"\n",
    "                \n",
    "                _f_labels = [\n",
    "                    f\"Total<br>{_f_total:,}\",\n",
    "                    f\"G1<br>{_f_g1:,}<br>({_pct_of(_f_g1, _f_total)})\",\n",
    "                    f\"Débris<br>{_f_g1_fail:,}\",\n",
    "                    f\"G2<br>{_f_g2:,}<br>({_pct_of(_f_g2, _f_g1)})\",\n",
    "                    f\"Doubl.<br>{_f_g2_fail:,}\",\n",
    "                    f\"G3<br>{_f_g3:,}<br>({_pct_of(_f_g3, _f_g2)})\",\n",
    "                    f\"CD45-<br>{_f_g3_fail:,}\",\n",
    "                ]\n",
    "                _f_src = [0, 0, 1, 1, 3, 3]\n",
    "                _f_tgt = [1, 2, 3, 4, 5, 6]\n",
    "                _f_vals_sk = [_f_g1, max(_f_g1_fail, 1), _f_g2, max(_f_g2_fail, 1), _f_g3, max(_f_g3_fail, 1)]\n",
    "                _f_link_col = [\n",
    "                    \"rgba(49,163,84,0.4)\", \"rgba(99,99,99,0.3)\",\n",
    "                    \"rgba(49,163,84,0.4)\", \"rgba(230,85,13,0.3)\",\n",
    "                    \"rgba(49,163,84,0.4)\", \"rgba(253,141,60,0.3)\",\n",
    "                ]\n",
    "                \n",
    "                if FILTER_BLASTS:\n",
    "                    _f_labels += [\n",
    "                        f\"G4<br>{_f_final:,}<br>({_pct_of(_f_final, _f_g3)})\",\n",
    "                        f\"Excl.<br>{_f_g4_fail:,}\",\n",
    "                        f\"Final<br>{_f_final:,}\",\n",
    "                    ]\n",
    "                    _f_src += [5, 5, 7]\n",
    "                    _f_tgt += [7, 8, 9]\n",
    "                    _f_vals_sk += [_f_final, max(_f_g4_fail, 1), _f_final]\n",
    "                    _f_link_col += [\"rgba(49,163,84,0.4)\", \"rgba(253,174,107,0.3)\", \"rgba(49,163,84,0.6)\"]\n",
    "                    _f_node_col = [\"#4a90d9\", \"#31a354\", \"#636363\", \"#31a354\", \"#e6550d\",\n",
    "                                   \"#31a354\", \"#fd8d3c\", \"#31a354\", \"#fdae6b\", \"#2ca02c\"]\n",
    "                else:\n",
    "                    _f_labels.append(f\"Final<br>{_f_g3:,}\")\n",
    "                    _f_src.append(5)\n",
    "                    _f_tgt.append(7)\n",
    "                    _f_vals_sk.append(_f_g3)\n",
    "                    _f_link_col.append(\"rgba(49,163,84,0.6)\")\n",
    "                    _f_node_col = [\"#4a90d9\", \"#31a354\", \"#636363\", \"#31a354\", \"#e6550d\",\n",
    "                                   \"#31a354\", \"#fd8d3c\", \"#2ca02c\"]\n",
    "                \n",
    "                _fig_f_sankey = go.Figure(go.Sankey(\n",
    "                    arrangement=\"snap\",\n",
    "                    node=dict(pad=15, thickness=20, line=dict(color=\"#333\", width=0.5),\n",
    "                              label=_f_labels, color=_f_node_col[:len(_f_labels)]),\n",
    "                    link=dict(source=_f_src, target=_f_tgt, value=_f_vals_sk, color=_f_link_col),\n",
    "                ))\n",
    "                _fig_f_sankey.update_layout(\n",
    "                    title=dict(text=f\"<b>Gating — {_f_short}</b>\", font=dict(size=14)),\n",
    "                    font=dict(size=11, color=\"#222\"), paper_bgcolor=\"#fafafa\",\n",
    "                    height=300, margin=dict(l=10, r=10, t=45, b=10),\n",
    "                )\n",
    "                _fig_f_sankey.show()\n",
    "        \n",
    "        # Nettoyer la variable temporaire pour éviter le doublon dans le rapport HTML\n",
    "        try:\n",
    "            del _fig_f_sankey\n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        if len(_unique_files_sankey) > 6:\n",
    "            print(f\"      (Affichage limité à 6/{len(_unique_files_sankey)} fichiers pour lisibilité)\")\n",
    "    \n",
    "    # =====================================================================\n",
    "    # 1c. SCATTER FSC-A vs FSC-H PAR FICHIER (avec droite RANSAC)\n",
    "    # =====================================================================\n",
    "    if ransac_scatter_data:\n",
    "        print(\" [1c/6] Scatter FSC-A vs FSC-H par fichier (droite RANSAC + R²)\")\n",
    "        \n",
    "        _n_scatter_files = len(ransac_scatter_data)\n",
    "        _n_cols_sc = min(3, _n_scatter_files)\n",
    "        _n_rows_sc = int(np.ceil(_n_scatter_files / _n_cols_sc))\n",
    "        \n",
    "        _fig_ransac_scatter = make_subplots(\n",
    "            rows=_n_rows_sc, cols=_n_cols_sc,\n",
    "            subplot_titles=[f[:30] for f in ransac_scatter_data.keys()],\n",
    "            horizontal_spacing=0.06, vertical_spacing=0.10,\n",
    "        )\n",
    "        \n",
    "        for _si, (_sf_name, _sf_data) in enumerate(ransac_scatter_data.items()):\n",
    "            _row = _si // _n_cols_sc + 1\n",
    "            _col = _si % _n_cols_sc + 1\n",
    "            \n",
    "            _r2_disp = f\"R²={_sf_data['r2']:.3f}\" if _sf_data['r2'] is not None else \"R²=N/A\"\n",
    "            _method_disp = \"RATIO\" if _sf_data['method'] == 'ratio_fallback' else \"RANSAC\"\n",
    "            _color_pts = \"#d62728\" if _sf_data['method'] == 'ratio_fallback' else \"#2ca02c\"\n",
    "            \n",
    "            # Points (échantillonnés)\n",
    "            _fig_ransac_scatter.add_trace(go.Scattergl(\n",
    "                x=_sf_data['fsc_h'], y=_sf_data['fsc_a'],\n",
    "                mode='markers', marker=dict(size=2, color=_color_pts, opacity=0.3),\n",
    "                name=f\"{_sf_name[:20]} ({_method_disp})\", showlegend=False,\n",
    "                hovertemplate=f\"FSC-H: %{{x:.0f}}<br>FSC-A: %{{y:.0f}}<br>{_r2_disp}<extra></extra>\",\n",
    "            ), row=_row, col=_col)\n",
    "            \n",
    "            # Droite RANSAC\n",
    "            _x_line = sorted(_sf_data['fsc_h'])\n",
    "            _y_line = [_sf_data['slope'] * x + _sf_data['intercept'] for x in _x_line]\n",
    "            _fig_ransac_scatter.add_trace(go.Scatter(\n",
    "                x=_x_line, y=_y_line,\n",
    "                mode='lines', line=dict(color='#ff7f0e', width=2, dash='dash'),\n",
    "                name=f\"RANSAC {_r2_disp}\", showlegend=False,\n",
    "            ), row=_row, col=_col)\n",
    "            \n",
    "            _fig_ransac_scatter.update_xaxes(title_text=\"FSC-H\", row=_row, col=_col)\n",
    "            _fig_ransac_scatter.update_yaxes(title_text=\"FSC-A\", row=_row, col=_col)\n",
    "        \n",
    "        _fig_ransac_scatter.update_layout(\n",
    "            title=\"<b>QC RANSAC — FSC-A vs FSC-H par fichier (droite + R²)</b>\",\n",
    "            height=350 * _n_rows_sc, width=min(450 * _n_cols_sc, 1400),\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "        )\n",
    "        del _fig_ransac_scatter  # Éviter doublon dans le collecteur de figures\n",
    "    \n",
    "    # =====================================================================\n",
    "    # 1d. TABLEAU % SINGLETS PAR FICHIER\n",
    "    # =====================================================================\n",
    "    if singlets_summary_per_file:\n",
    "        print(\" [1d/6] Tableau % singlets par fichier\")\n",
    "        \n",
    "        _df_singlets = pd.DataFrame(singlets_summary_per_file)\n",
    "        \n",
    "        # Coloriser les R² faibles\n",
    "        _cell_colors = []\n",
    "        for col_name in _df_singlets.columns:\n",
    "            col_colors = []\n",
    "            for _, row in _df_singlets.iterrows():\n",
    "                if col_name == 'r2' and row['r2'] is not None and row['r2'] < 0.85:\n",
    "                    col_colors.append('#ffe0e0')  # Rouge léger\n",
    "                elif col_name == 'method' and row['method'] == 'ratio_fallback':\n",
    "                    col_colors.append('#fff3cd')  # Jaune léger\n",
    "                else:\n",
    "                    col_colors.append('#f9f9f9' if _ % 2 == 0 else '#fff')\n",
    "            _cell_colors.append(col_colors)\n",
    "        \n",
    "        fig_singlets_table = go.Figure(go.Table(\n",
    "            header=dict(\n",
    "                values=[f\"<b>{c.upper()}</b>\" for c in _df_singlets.columns],\n",
    "                fill_color=\"#4a90d9\", font=dict(color=\"white\", size=12),\n",
    "                align=\"center\", height=35,\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[_df_singlets[c] for c in _df_singlets.columns],\n",
    "                fill_color=_cell_colors,\n",
    "                font=dict(size=11), align=\"center\", height=28,\n",
    "            ),\n",
    "        ))\n",
    "        fig_singlets_table.update_layout(\n",
    "            title=\"<b>QC Singlets — % par fichier (R² RANSAC, méthode utilisée)</b>\",\n",
    "            height=50 + 30 * (len(_df_singlets) + 1), width=900,\n",
    "            margin=dict(l=20, r=20, t=50, b=10),\n",
    "        )\n",
    "        fig_singlets_table.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 2. DENSITY SCATTER PLOTS — CHAQUE GATE\n",
    "    # =====================================================================\n",
    "    print(\" [2/5] Density Scatter Plots — Gating séquentiel\")\n",
    "\n",
    "    _gate_plots = []\n",
    "\n",
    "    # --- Gate 1 : FSC-A vs SSC-A (Débris) ---\n",
    "    if GATE_DEBRIS and _fsc_a_idx is not None and _ssc_a_idx is not None:\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 1 — Débris (SSC-A vs FSC-A)\",\n",
    "            \"x\": X_raw[_idx, _fsc_a_idx],\n",
    "            \"y\": X_raw[_idx, _ssc_a_idx],\n",
    "            \"mask\": _m_g1,\n",
    "            \"xlabel\": \"FSC-A (Taille)\",\n",
    "            \"ylabel\": \"SSC-A (Granularité)\",\n",
    "            \"label_in\": \"Cellules viables\",\n",
    "            \"label_out\": \"Débris\",\n",
    "        })\n",
    "\n",
    "    # --- Gate 2 : FSC-H vs FSC-A (Doublets) — sur les survivants de G1 ---\n",
    "    if GATE_DOUBLETS and _fsc_a_idx is not None and _fsc_h_idx is not None:\n",
    "        _g1_ok = _m_g1\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 2 — Doublets (FSC-H vs FSC-A) [après G1]\",\n",
    "            \"x\": X_raw[_idx, _fsc_a_idx][_g1_ok],\n",
    "            \"y\": X_raw[_idx, _fsc_h_idx][_g1_ok],\n",
    "            \"mask\": mask_singlets[_idx][_g1_ok],\n",
    "            \"xlabel\": \"FSC-A (Area)\",\n",
    "            \"ylabel\": \"FSC-H (Height)\",\n",
    "            \"label_in\": \"Singlets\",\n",
    "            \"label_out\": \"Doublets\",\n",
    "        })\n",
    "\n",
    "    # --- Gate 3 : CD45 vs SSC-A (Leucocytes) — sur les survivants de G1+G2 ---\n",
    "    # En mode asymétrique: affiche UNIQUEMENT les cellules Patho (les Sain ne sont pas gatées CD45)\n",
    "    if GATE_CD45 and _cd45_idx is not None and _ssc_a_idx is not None:\n",
    "        _g12_ok = _m_g12\n",
    "        if MODE_BLASTES_VS_NORMAL:\n",
    "            # Filtre: montrer seulement les cellules Patho après G1+G2\n",
    "            _patho_g12 = _g12_ok & (_cond_sub == \"Pathologique\")\n",
    "            _gate_plots.append({\n",
    "                \"title\": \"Gate 3 — CD45+ PATHO seul (Sain: pas de gate CD45)\",\n",
    "                \"x\": X_raw[_idx, _cd45_idx][_patho_g12],\n",
    "                \"y\": X_raw[_idx, _ssc_a_idx][_patho_g12],\n",
    "                \"mask\": mask_cd45[_idx][_patho_g12],\n",
    "                \"xlabel\": \"CD45 (Intensité)\",\n",
    "                \"ylabel\": \"SSC-A (Granularité)\",\n",
    "                \"label_in\": \"CD45+ Patho (conservés)\",\n",
    "                \"label_out\": \"CD45− Patho (exclus)\",\n",
    "            })\n",
    "        else:\n",
    "            _gate_plots.append({\n",
    "                \"title\": \"Gate 3 — CD45+ Leucocytes (CD45 vs SSC-A) [après G1+G2]\",\n",
    "                \"x\": X_raw[_idx, _cd45_idx][_g12_ok],\n",
    "                \"y\": X_raw[_idx, _ssc_a_idx][_g12_ok],\n",
    "                \"mask\": mask_cd45[_idx][_g12_ok],\n",
    "                \"xlabel\": \"CD45 (Intensité)\",\n",
    "                \"ylabel\": \"SSC-A (Granularité)\",\n",
    "                \"label_in\": \"Leucocytes CD45+\",\n",
    "                \"label_out\": \"CD45−\",\n",
    "            })\n",
    "\n",
    "    # --- Gate 4 : CD34 vs SSC-A (Blastes) — si activé ---\n",
    "    if FILTER_BLASTS and _cd34_idx is not None and _ssc_a_idx is not None:\n",
    "        _g123_ok = _m_g123\n",
    "        _gate_plots.append({\n",
    "            \"title\": \"Gate 4 — CD34+ Blastes (CD34 vs SSC-A) [après G1+G2+G3]\",\n",
    "            \"x\": X_raw[_idx, _cd34_idx][_g123_ok],\n",
    "            \"y\": X_raw[_idx, _ssc_a_idx][_g123_ok],\n",
    "            \"mask\": mask_cd34[_idx][_g123_ok],\n",
    "            \"xlabel\": \"CD34 (Intensité)\",\n",
    "            \"ylabel\": \"SSC-A (Granularité)\",\n",
    "            \"label_in\": \"Blastes CD34+\",\n",
    "            \"label_out\": \"Autres leucocytes\",\n",
    "        })\n",
    "\n",
    "    # Générer chaque subplot avec Plotly\n",
    "    n_gates = len(_gate_plots)\n",
    "    if n_gates > 0:\n",
    "        fig_gates = make_subplots(\n",
    "            rows=1, cols=n_gates,\n",
    "            subplot_titles=[g[\"title\"] for g in _gate_plots],\n",
    "            horizontal_spacing=0.06,\n",
    "        )\n",
    "\n",
    "        for col_i, gp in enumerate(_gate_plots, 1):\n",
    "            _x, _y, _mk = gp[\"x\"], gp[\"y\"], gp[\"mask\"]\n",
    "            _valid = np.isfinite(_x) & np.isfinite(_y)\n",
    "            _x, _y, _mk = _x[_valid], _y[_valid], _mk[_valid]\n",
    "\n",
    "            # Exclus (fond, semi-transparent)\n",
    "            fig_gates.add_trace(go.Scattergl(\n",
    "                x=_x[~_mk], y=_y[~_mk],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=\"#d62728\", opacity=0.25),\n",
    "                name=gp[\"label_out\"],\n",
    "                legendgroup=f\"g{col_i}_out\",\n",
    "                showlegend=(col_i == 1),\n",
    "                hovertemplate=f\"{gp['xlabel']}: %{{x:.0f}}<br>{gp['ylabel']}: %{{y:.0f}}<br>{gp['label_out']}<extra></extra>\",\n",
    "            ), row=1, col=col_i)\n",
    "\n",
    "            # Conservés (avant-plan)\n",
    "            fig_gates.add_trace(go.Scattergl(\n",
    "                x=_x[_mk], y=_y[_mk],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=\"#2ca02c\", opacity=0.4),\n",
    "                name=gp[\"label_in\"],\n",
    "                legendgroup=f\"g{col_i}_in\",\n",
    "                showlegend=(col_i == 1),\n",
    "                hovertemplate=f\"{gp['xlabel']}: %{{x:.0f}}<br>{gp['ylabel']}: %{{y:.0f}}<br>{gp['label_in']}<extra></extra>\",\n",
    "            ), row=1, col=col_i)\n",
    "\n",
    "            # Axes labels\n",
    "            fig_gates.update_xaxes(title_text=gp[\"xlabel\"], row=1, col=col_i)\n",
    "            fig_gates.update_yaxes(title_text=gp[\"ylabel\"], row=1, col=col_i)\n",
    "\n",
    "        fig_gates.update_layout(\n",
    "            title=\"<b>Gating Séquentiel — Density Scatter (Plotly interactif)</b>\",\n",
    "            height=500,\n",
    "            width=min(500 * n_gates, 2000),\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(\n",
    "                orientation=\"h\", yanchor=\"bottom\", y=-0.22,\n",
    "                xanchor=\"center\", x=0.5,\n",
    "                font=dict(size=12),\n",
    "            ),\n",
    "            margin=dict(t=80, b=100),\n",
    "        )\n",
    "        fig_gates.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 3. HISTOGRAMMES 1D — DISTRIBUTIONS DES MARQUEURS CLÉS\n",
    "    # =====================================================================\n",
    "    print(\" [3/5] Histogrammes 1D — Distributions avec seuils GMM\")\n",
    "\n",
    "    _hist_data = []\n",
    "    if _fsc_a_idx is not None:\n",
    "        _hist_data.append((\"FSC-A\", X_raw[:, _fsc_a_idx], None))\n",
    "    if _cd45_idx is not None:\n",
    "        _hist_data.append((\"CD45\", X_raw[:, _cd45_idx], \"cd45\"))\n",
    "    if FILTER_BLASTS and _cd34_idx is not None:\n",
    "        _hist_data.append((\"CD34\", X_raw[:, _cd34_idx], \"cd34\"))\n",
    "\n",
    "    if _hist_data:\n",
    "        fig_hist = make_subplots(\n",
    "            rows=1, cols=len(_hist_data),\n",
    "            subplot_titles=[h[0] for h in _hist_data],\n",
    "            horizontal_spacing=0.08,\n",
    "        )\n",
    "\n",
    "        for hi, (name, vals, marker_type) in enumerate(_hist_data, 1):\n",
    "            _v = vals[np.isfinite(vals)]\n",
    "\n",
    "            # Avant gating (toutes cellules)\n",
    "            fig_hist.add_trace(go.Histogram(\n",
    "                x=_v, nbinsx=200, name=f\"{name} (tous)\",\n",
    "                marker_color=\"rgba(100,100,100,0.4)\",\n",
    "                showlegend=(hi == 1),\n",
    "                legendgroup=\"all\",\n",
    "            ), row=1, col=hi)\n",
    "\n",
    "            # Après gating (conservés)\n",
    "            _v_kept = vals[mask_final & np.isfinite(vals)]\n",
    "            fig_hist.add_trace(go.Histogram(\n",
    "                x=_v_kept, nbinsx=200, name=f\"{name} (conservés)\",\n",
    "                marker_color=\"rgba(44,160,44,0.6)\",\n",
    "                showlegend=(hi == 1),\n",
    "                legendgroup=\"kept\",\n",
    "            ), row=1, col=hi)\n",
    "\n",
    "            # Annoter le seuil GMM si pertinent\n",
    "            if marker_type == \"cd45\" and GATE_CD45:\n",
    "                _cd45_vals = X_raw[:, _cd45_idx]\n",
    "                _cd45_clean = _cd45_vals[np.isfinite(_cd45_vals)]\n",
    "                _th = np.percentile(_cd45_clean, CD45_THRESHOLD_PERCENTILE)\n",
    "                fig_hist.add_vline(\n",
    "                    x=_th, line_dash=\"dash\", line_color=\"#d62728\", line_width=2,\n",
    "                    annotation_text=f\"Seuil CD45+\", annotation_position=\"top right\",\n",
    "                    row=1, col=hi,\n",
    "                )\n",
    "            elif marker_type == \"cd34\" and FILTER_BLASTS:\n",
    "                _cd34_vals = X_raw[:, _cd34_idx]\n",
    "                _cd34_clean = _cd34_vals[np.isfinite(_cd34_vals)]\n",
    "                _th34 = np.percentile(_cd34_clean, CD34_THRESHOLD_PERCENTILE)\n",
    "                fig_hist.add_vline(\n",
    "                    x=_th34, line_dash=\"dash\", line_color=\"#ff7f0e\", line_width=2,\n",
    "                    annotation_text=f\"Seuil CD34+\", annotation_position=\"top right\",\n",
    "                    row=1, col=hi,\n",
    "                )\n",
    "\n",
    "            fig_hist.update_xaxes(title_text=name, row=1, col=hi)\n",
    "            fig_hist.update_yaxes(title_text=\"Nombre d'événements\", row=1, col=hi)\n",
    "\n",
    "        fig_hist.update_layout(\n",
    "            title=\"<b>Distributions 1D — Avant / Après Gating (seuils annotés)</b>\",\n",
    "            barmode=\"overlay\",\n",
    "            height=400,\n",
    "            width=min(550 * len(_hist_data), 1800),\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f5f5f5\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.25, xanchor=\"center\", x=0.5),\n",
    "            margin=dict(t=70, b=90),\n",
    "        )\n",
    "        fig_hist.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # 4. COMPARAISON PATHO vs SAIN (si MODE_BLASTES_VS_NORMAL)\n",
    "    # =====================================================================\n",
    "    if MODE_BLASTES_VS_NORMAL and _cd45_idx is not None and _ssc_a_idx is not None:\n",
    "        print(\" [4/5] Comparaison Patho vs Sain — CD45 vs SSC-A (GATING ASYMÉTRIQUE)\")\n",
    "\n",
    "        _cond = conditions[_idx]\n",
    "\n",
    "        fig_comp = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=[\n",
    "                \"Pathologique (CD45 strict appliqué)\",\n",
    "                \"Sain / NBM (PAS de gate CD45)\"\n",
    "            ],\n",
    "            horizontal_spacing=0.08,\n",
    "        )\n",
    "\n",
    "        for ci, (cond_label, color_kept, color_all) in enumerate([\n",
    "            (\"Pathologique\", \"#d62728\", \"#ffcccc\"),\n",
    "            (\"Sain\", \"#2ca02c\", \"#ccffcc\"),\n",
    "        ], 1):\n",
    "            _sel = (_cond == cond_label)\n",
    "            _sel_final = _sel & _m_final\n",
    "\n",
    "            _xc = X_raw[_idx, _cd45_idx]\n",
    "            _yc = X_raw[_idx, _ssc_a_idx]\n",
    "\n",
    "            # Toutes les cellules de cette condition (fond)\n",
    "            fig_comp.add_trace(go.Scattergl(\n",
    "                x=_xc[_sel], y=_yc[_sel],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2, color=color_all, opacity=0.15),\n",
    "                name=f\"{cond_label} (tous)\",\n",
    "                showlegend=True,\n",
    "            ), row=1, col=ci)\n",
    "\n",
    "            # Cellules conservées\n",
    "            fig_comp.add_trace(go.Scattergl(\n",
    "                x=_xc[_sel_final], y=_yc[_sel_final],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=2.5, color=color_kept, opacity=0.5),\n",
    "                name=f\"{cond_label} (conservés)\",\n",
    "                showlegend=True,\n",
    "            ), row=1, col=ci)\n",
    "\n",
    "            _n_all = _sel.sum()\n",
    "            _n_kept = _sel_final.sum()\n",
    "            _gate_info = \"CD45 strict\" if cond_label == \"Pathologique\" else \"Pas de gate CD45\"\n",
    "            fig_comp.update_xaxes(title_text=\"CD45\", row=1, col=ci)\n",
    "            fig_comp.update_yaxes(title_text=\"SSC-A\", row=1, col=ci)\n",
    "\n",
    "            _xax = \"x domain\" if ci == 1 else f\"x{ci} domain\"\n",
    "            _yax = \"y domain\" if ci == 1 else f\"y{ci} domain\"\n",
    "            fig_comp.add_annotation(\n",
    "                text=f\"<b>{_n_kept:,} / {_n_all:,} ({_n_kept/_n_all*100:.1f}%)<br>{_gate_info}</b>\" if _n_all > 0 else \"N/A\",\n",
    "                xref=_xax, yref=_yax,\n",
    "                x=0.5, y=0.02, showarrow=False,\n",
    "                font=dict(size=13, color=color_kept),\n",
    "                bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "                bordercolor=color_kept, borderwidth=1, borderpad=4,\n",
    "            )\n",
    "\n",
    "        fig_comp.update_layout(\n",
    "            title=\"<b>Gating Asymétrique — Patho (CD45 strict) vs Sain (pas de CD45)</b>\",\n",
    "            height=500,\n",
    "            width=1100,\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=11),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.2, xanchor=\"center\", x=0.5),\n",
    "            margin=dict(t=70, b=90),\n",
    "        )\n",
    "        fig_comp.show()\n",
    "    else:\n",
    "        print(\" [4/5] Comparaison Patho vs Sain — SKIP (MODE_BLASTES_VS_NORMAL désactivé)\")\n",
    "\n",
    "    # =====================================================================\n",
    "    # 5. OVERVIEW FINAL — FSC-A vs SSC-A coloré par gate d'exclusion\n",
    "    # =====================================================================\n",
    "    if _fsc_a_idx is not None and _ssc_a_idx is not None:\n",
    "        print(\" [5/5] Overview Final — Coloré par étape d'exclusion\")\n",
    "\n",
    "        _xo = X_raw[_idx, _fsc_a_idx]\n",
    "        _yo = X_raw[_idx, _ssc_a_idx]\n",
    "\n",
    "        fig_overview = go.Figure()\n",
    "\n",
    "        # Tracer chaque catégorie d'exclusion dans l'ordre\n",
    "        # ─── Inclut désormais les conservés Patho et Sain séparément ───\n",
    "        _order = [\n",
    "            \"Débris (exclu G1)\",\n",
    "            \"Doublet (exclu G2)\",\n",
    "            \"CD45- Patho (exclu G3)\",\n",
    "            \"Non-blaste (exclu G4)\",\n",
    "            \"CD45+ Patho conservés ✓\",\n",
    "            \"Conservés sains NBM ✓\",\n",
    "            \"Conservé ✓\",          # fallback si condition inconnue\n",
    "        ]\n",
    "        for cat in _order:\n",
    "            _sel_cat = (_labels == cat)\n",
    "            if _sel_cat.sum() == 0:\n",
    "                continue\n",
    "            _is_kept = cat.endswith(\"✓\")\n",
    "            fig_overview.add_trace(go.Scattergl(\n",
    "                x=_xo[_sel_cat], y=_yo[_sel_cat],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=2.5,\n",
    "                    color=_color_map.get(cat, \"#999\"),\n",
    "                    opacity=0.55 if _is_kept else 0.25,\n",
    "                ),\n",
    "                name=f\"{cat} ({_sel_cat.sum():,})\",\n",
    "                hovertemplate=f\"FSC-A: %{{x:.0f}}<br>SSC-A: %{{y:.0f}}<br>{cat}<extra></extra>\",\n",
    "            ))\n",
    "\n",
    "        fig_overview.update_layout(\n",
    "            title=\"<b>Overview — Événements colorés par étape d'exclusion</b>\",\n",
    "            xaxis_title=\"FSC-A (Taille)\",\n",
    "            yaxis_title=\"SSC-A (Granularité)\",\n",
    "            height=600,\n",
    "            width=900,\n",
    "            paper_bgcolor=\"#fafafa\",\n",
    "            plot_bgcolor=\"#f0f0f0\",\n",
    "            font=dict(size=12),\n",
    "            legend=dict(\n",
    "                title=\"Catégorie\",\n",
    "                font=dict(size=12),\n",
    "                bgcolor=\"rgba(255,255,255,0.9)\",\n",
    "                bordercolor=\"#ccc\", borderwidth=1,\n",
    "            ),\n",
    "            margin=dict(t=70, b=50),\n",
    "        )\n",
    "        fig_overview.show()\n",
    "\n",
    "    # =====================================================================\n",
    "    # RÉSUMÉ TABULAIRE\n",
    "    # =====================================================================\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" RÉSUMÉ GATING — TABLEAU INTERACTIF\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    _summary_df = pd.DataFrame({\n",
    "        \"Étape\": [\"Initial\", \"Gate 1 (Débris)\", \"Gate 2 (Doublets)\",\n",
    "                  \"Gate 3 (CD45+ Patho only)\" if MODE_BLASTES_VS_NORMAL else \"Gate 3 (CD45+)\"] + ([\"Gate 4 (CD34+)\"] if FILTER_BLASTS else []) + [\"Population finale\"],\n",
    "        \"Événements\": [\n",
    "            n_before,\n",
    "            int(mask_debris.sum()),\n",
    "            int((mask_debris & mask_singlets).sum()),\n",
    "            int((mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "        ] + ([int(n_final)] if FILTER_BLASTS else []) + [int(n_final)],\n",
    "        \"Rétention (%)\": [\n",
    "            100.0,\n",
    "            mask_debris.sum() / n_before * 100,\n",
    "            (mask_debris & mask_singlets).sum() / n_before * 100,\n",
    "            (mask_debris & mask_singlets & mask_cd45).sum() / n_before * 100,\n",
    "        ] + ([n_final / n_before * 100] if FILTER_BLASTS else []) + [n_final / n_before * 100],\n",
    "        \"Exclus\": [\n",
    "            0,\n",
    "            n_before - int(mask_debris.sum()),\n",
    "            int(mask_debris.sum()) - int((mask_debris & mask_singlets).sum()),\n",
    "            int((mask_debris & mask_singlets).sum()) - int((mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "        ] + ([int((mask_debris & mask_singlets & mask_cd45).sum()) - int(n_final)] if FILTER_BLASTS else []) + [n_before - int(n_final)],\n",
    "    })\n",
    "    _summary_df[\"Rétention (%)\"] = _summary_df[\"Rétention (%)\"].round(1)\n",
    "\n",
    "    fig_table = go.Figure(go.Table(\n",
    "        header=dict(\n",
    "            values=[f\"<b>{c}</b>\" for c in _summary_df.columns],\n",
    "            fill_color=\"#4a90d9\",\n",
    "            font=dict(color=\"white\", size=13),\n",
    "            align=\"center\", height=35,\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[_summary_df[c] for c in _summary_df.columns],\n",
    "            fill_color=[\n",
    "                [\"#f9f9f9\", \"#fff\", \"#f9f9f9\", \"#fff\"] +\n",
    "                ([\"#f9f9f9\"] if FILTER_BLASTS else []) + [\"#d4edda\"]\n",
    "            ] * 4,\n",
    "            font=dict(size=12),\n",
    "            align=\"center\", height=30,\n",
    "            format=[None, \",\", \".1f\", \",\"],\n",
    "        ),\n",
    "    ))\n",
    "    fig_table.update_layout(\n",
    "        title=\"<b>Résumé du Pre-Gating — Statistiques par étape</b>\",\n",
    "        height=50 + 35 * (len(_summary_df) + 1),\n",
    "        width=800,\n",
    "        margin=dict(l=20, r=20, t=50, b=10),\n",
    "    )\n",
    "    fig_table.show()\n",
    "\n",
    "    # --- Tableau par condition si gating asymétrique ---\n",
    "    if MODE_BLASTES_VS_NORMAL:\n",
    "        _mp = (conditions == \"Pathologique\")\n",
    "        _ms = (conditions == \"Sain\")\n",
    "        _cond_df = pd.DataFrame({\n",
    "            \"Condition\": [\"Pathologique\", \"Sain / NBM\"],\n",
    "            \"Initial\": [int(_mp.sum()), int(_ms.sum())],\n",
    "            \"Après Débris+Doublets\": [\n",
    "                int((_mp & mask_debris & mask_singlets).sum()),\n",
    "                int((_ms & mask_debris & mask_singlets).sum()),\n",
    "            ],\n",
    "            \"Après Gate CD45\": [\n",
    "                int((_mp & mask_debris & mask_singlets & mask_cd45).sum()),\n",
    "                f\"{int((_ms & mask_debris & mask_singlets).sum())} (non appliqué)\",\n",
    "            ],\n",
    "            \"Final\": [int((mask_final & _mp).sum()), int((mask_final & _ms).sum())],\n",
    "            \"Rétention (%)\": [\n",
    "                round((mask_final & _mp).sum() / max(_mp.sum(), 1) * 100, 1),\n",
    "                round((mask_final & _ms).sum() / max(_ms.sum(), 1) * 100, 1),\n",
    "            ],\n",
    "            \"Logique CD45\": [\"CD45 STRICT\", \"AUCUN gate CD45\"],\n",
    "        })\n",
    "\n",
    "        fig_table_cond = go.Figure(go.Table(\n",
    "            header=dict(\n",
    "                values=[f\"<b>{c}</b>\" for c in _cond_df.columns],\n",
    "                fill_color=\"#6a0dad\",\n",
    "                font=dict(color=\"white\", size=13),\n",
    "                align=\"center\", height=35,\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[_cond_df[c] for c in _cond_df.columns],\n",
    "                fill_color=[[\"#ffe6e6\", \"#e6ffe6\"]] * len(_cond_df.columns),\n",
    "                font=dict(size=12),\n",
    "                align=\"center\", height=30,\n",
    "            ),\n",
    "        ))\n",
    "        fig_table_cond.update_layout(\n",
    "            title=\"<b>Gating Asymétrique — Détail par Condition (Patho: CD45 strict / Sain: pas de CD45)</b>\",\n",
    "            height=150,\n",
    "            width=1100,\n",
    "            margin=dict(l=20, r=20, t=50, b=10),\n",
    "        )\n",
    "        fig_table_cond.show()\n",
    "\n",
    "    print(\"\\n [OK] Dashboard CytoPy-style généré avec succès !\")\n",
    "    print(\"     → Utilisez la souris pour zoomer, survoler, et exporter (icône 📷)\")\n",
    "\n",
    "elif not PLOTLY_AVAILABLE:\n",
    "    print(\"[!] Plotly requis pour le dashboard interactif.\")\n",
    "    print(\"    → pip install plotly\")\n",
    "else:\n",
    "\n",
    "    print(\"[!] Pre-gating désactivé — Aucun dashboard généré.\")\n",
    "    print(\"[!] Pre-gating désactivé — Aucun dashboard généré.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CRÉATION DU SECOND ANNDATA (avec ou sans gating)\n",
    "# =============================================================================\n",
    "\n",
    "# Créer l'AnnData filtré (ou copie complète si pas de gating)\n",
    "combined_gated = combined_data[mask_final].copy()\n",
    "\n",
    "if APPLY_PREGATING:\n",
    "    print(f\"[OK] AnnData après gating: {combined_gated.shape}\")\n",
    "    print(f\"   → {combined_gated.shape[0]:,} cellules conservées\")\n",
    "    print(f\"   → {combined_gated.shape[1]} marqueurs\")\n",
    "else:\n",
    "    print(f\"[OK] AnnData créé (sans pre-gating): {combined_gated.shape}\")\n",
    "    print(f\"   → {combined_gated.shape[0]:,} cellules (toutes conservées)\")\n",
    "    print(f\"   → {combined_gated.shape[1]} marqueurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0e40a",
   "metadata": {},
   "source": [
    "## 6. Transformation des Données (Arcsinh / Logicle)\n",
    "\n",
    "Les données brutes de cytométrie nécessitent une transformation pour:\n",
    "- Gérer les valeurs négatives (compensation)\n",
    "- Compresser la plage dynamique\n",
    "- Améliorer la visualisation des populations faiblement exprimées\n",
    "\n",
    "### Transformations disponibles:\n",
    "- **Arcsinh (cofactor=5)**: Recommandé pour flow cytometry\n",
    "- **Logicle**: Transformation biexponentielle (standard ISAC)\n",
    "- **Log10**: Transformation logarithmique simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DE LA TRANSFORMATION\n",
    "\n",
    "# Choix de la transformation\n",
    "TRANSFORM_TYPE = \"logicle\"  # Options: \"arcsinh\", \"logicle\", \"log10\", \"none\"\n",
    "COFACTOR = 5  # Pour arcsinh: 5 (flow)\n",
    "\n",
    "# Appliquer uniquement aux marqueurs de fluorescence (pas FSC/SSC/Time)\n",
    "APPLY_TO_SCATTER = False\n",
    "\n",
    "print(\"TRANSFORMATION DES DONNÉES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Type: {TRANSFORM_TYPE.upper()}\")\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"   Cofacteur: {COFACTOR}\")\n",
    "print(f\"   Appliquer au scatter: {'Oui' if APPLY_TO_SCATTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION DE LA TRANSFORMATION\n",
    "\n",
    "# Extraire les données\n",
    "X_gated = combined_gated.X\n",
    "if hasattr(X_gated, 'toarray'):\n",
    "    X_gated = X_gated.toarray()\n",
    "\n",
    "# Copie pour transformation\n",
    "X_transformed = X_gated.copy()\n",
    "\n",
    "# Déterminer les indices des colonnes à transformer\n",
    "if APPLY_TO_SCATTER:\n",
    "    cols_to_transform = list(range(len(var_names)))\n",
    "else:\n",
    "    # Exclure FSC, SSC, Time\n",
    "    scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "    cols_to_transform = [i for i, name in enumerate(var_names) \n",
    "                         if not any(p in name.upper() for p in scatter_patterns)]\n",
    "\n",
    "print(f\"\\nColonnes à transformer: {len(cols_to_transform)}/{len(var_names)}\")\n",
    "\n",
    "# Appliquer la transformation\n",
    "if TRANSFORM_TYPE == \"arcsinh\":\n",
    "    print(f\"\\n Application Arcsinh (cofactor={COFACTOR})...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.arcsinh_transform(\n",
    "        X_gated[:, cols_to_transform], cofactor=COFACTOR\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"logicle\":\n",
    "    print(\"\\n Application Logicle...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.logicle_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "elif TRANSFORM_TYPE == \"log10\":\n",
    "    print(\"\\n Application Log10...\")\n",
    "    X_transformed[:, cols_to_transform] = DataTransformer.log_transform(\n",
    "        X_gated[:, cols_to_transform]\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"\\n[!] Pas de transformation appliquée\")\n",
    "\n",
    "# Vérifier les résultats\n",
    "print(f\"\\n[OK] Transformation terminée!\")\n",
    "print(f\"   Plage avant: [{X_gated[:, cols_to_transform].min():.2f}, {X_gated[:, cols_to_transform].max():.2f}]\")\n",
    "print(f\"   Plage après: [{X_transformed[:, cols_to_transform].min():.2f}, {X_transformed[:, cols_to_transform].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec484f1",
   "metadata": {},
   "source": [
    "## 7. Comparaison Avant/Après Transformation\n",
    "\n",
    "Visualisation côte à côte des distributions pour valider l'effet de la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAISON DISTRIBUTIONS AVANT/APRÈS\n",
    "\n",
    "# Sélectionner quelques marqueurs représentatifs\n",
    "markers_compare = [var_names[i] for i in cols_to_transform[:6]]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(markers_compare), figsize=(4*len(markers_compare), 8))\n",
    "\n",
    "for i, marker in enumerate(markers_compare):\n",
    "    col_idx = var_names.index(marker)\n",
    "    \n",
    "    # Avant transformation\n",
    "    ax = axes[0, i]\n",
    "    data_before = X_gated[:, col_idx]\n",
    "    ax.hist(data_before, bins=80, color='#f38ba8', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{marker}\\n(Brut)', fontsize=10, fontweight='bold')\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('AVANT\\nCount', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Après transformation\n",
    "    ax = axes[1, i]\n",
    "    data_after = X_transformed[:, col_idx]\n",
    "    ax.hist(data_after, bins=80, color='#a6e3a1', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'{TRANSFORM_TYPE.upper()}', fontsize=10)\n",
    "    ax.axvline(0, color='white', linestyle='--', alpha=0.5)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('APRÈS\\nCount', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Comparaison des Distributions: Brut vs {TRANSFORM_TYPE.upper()} (cofactor={COFACTOR})', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DE DIFFÉRENTS COFACTEURS (pour tuning)\n",
    "\n",
    "print(\"COMPARAISON DES COFACTEURS ARCSINH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sélectionner un marqueur représentatif\n",
    "test_marker = markers_compare[0]\n",
    "test_idx = var_names.index(test_marker)\n",
    "test_data = X_gated[:, test_idx]\n",
    "\n",
    "# Tester différents cofacteurs\n",
    "cofactors = [1, 5, 50, 150, 500]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cofactors)+1, figsize=(4*(len(cofactors)+1), 4))\n",
    "\n",
    "# Données brutes\n",
    "ax = axes[0]\n",
    "ax.hist(test_data, bins=80, color='#89b4fa', alpha=0.7, edgecolor='none')\n",
    "ax.set_title('Brut\\n(pas de transfo)', fontsize=10, fontweight='bold')\n",
    "ax.set_xlabel(test_marker)\n",
    "\n",
    "# Transformations avec différents cofacteurs\n",
    "for i, cof in enumerate(cofactors):\n",
    "    ax = axes[i+1]\n",
    "    transformed = DataTransformer.arcsinh_transform(test_data, cofactor=cof)\n",
    "    ax.hist(transformed, bins=80, color='#cba6f7', alpha=0.7, edgecolor='none')\n",
    "    ax.set_title(f'Arcsinh\\ncofactor={cof}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(test_marker)\n",
    "\n",
    "plt.suptitle(f'Impact du Cofacteur sur la Distribution ({test_marker})', \n",
    "             fontsize=13, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087eb83",
   "metadata": {},
   "source": [
    "## 8. Préparation des Données pour FlowSOM\n",
    "\n",
    "Sélection des colonnes pour le clustering:\n",
    "- Exclusion des paramètres scatter (FSC, SSC) et Time\n",
    "- Conservation uniquement des marqueurs de fluorescence\n",
    "- Nettoyage final (NaN/Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÉLECTION DES COLONNES POUR FLOWSOM\n",
    "\n",
    "# Option: exclure FSC/SSC/Time\n",
    "EXCLUDE_SCATTER = True\n",
    "\n",
    "# Identifier les colonnes à utiliser\n",
    "scatter_patterns = ['FSC', 'SSC', 'TIME', 'EVENT']\n",
    "\n",
    "if EXCLUDE_SCATTER:\n",
    "    cols_to_use = [i for i, name in enumerate(var_names) \n",
    "                   if not any(p in name.upper() for p in scatter_patterns)]\n",
    "else:\n",
    "    cols_to_use = list(range(len(var_names)))\n",
    "\n",
    "used_markers = [var_names[i] for i in cols_to_use]\n",
    "\n",
    "print(\"COLONNES POUR FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Exclure scatter: {'Oui' if EXCLUDE_SCATTER else 'Non'}\")\n",
    "print(f\"   Colonnes sélectionnées: {len(cols_to_use)}/{len(var_names)}\")\n",
    "print(f\"\\nMarqueurs utilisés:\")\n",
    "for i, marker in enumerate(used_markers):\n",
    "    print(f\"   [{i:2d}] {marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTRAGE PAR TYPE DE MARQUEUR (-A vs -H) - OPTIONNEL\n",
    "# =============================================================================\n",
    "# EXPLICATION:\n",
    "# - Les suffixes -A (Area) et -H (Height) dans les noms de marqueurs représentent\n",
    "#   des mesures différentes du MÊME signal:\n",
    "#     • -A (Area) = Aire sous la courbe du pulse → plus stable\n",
    "#     • -H (Height) = Hauteur maximale du pulse → plus sensible\n",
    "#\n",
    "# - En cytométrie, on utilise généralement:\n",
    "#     • FSC-A et SSC-A pour le gating (débris, doublets)\n",
    "#     • Fluorescence -A pour le clustering (plus stable)\n",
    "#\n",
    "# - Ce filtre permet de DÉDUPLIQUER les marqueurs redondants si vous avez\n",
    "#   à la fois -A et -H pour chaque marqueur (ex: CD13 PE-A ET CD13 PE-H)\n",
    "#\n",
    "# [!] ATTENTION: Cette section ne filtre PAS les fichiers, mais les MARQUEURS!\n",
    "# =============================================================================\n",
    "\n",
    "# ===================== ACTIVATION DU FILTRAGE =====================\n",
    "APPLY_MARKER_FILTERING = True  # [!] Mettre True pour dédupliquer (garder uniquement -A ou -H)\n",
    "\n",
    "# OPTIONS DE FILTRAGE (utilisées seulement si APPLY_MARKER_FILTERING = True)\n",
    "KEEP_AREA = True    # True = garder les marqueurs -A (Area) [RECOMMANDÉ]\n",
    "KEEP_HEIGHT = False # True = garder les marqueurs -H (Height)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FILTRAGE PAR TYPE DE MARQUEUR (-A vs -H)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Filtrage activé: {'[OK] OUI' if APPLY_MARKER_FILTERING else '[X] NON (tous les marqueurs conservés)'}\")\n",
    "\n",
    "if APPLY_MARKER_FILTERING:\n",
    "    print(f\"   Garder -A (Area):   {'[OK] Oui' if KEEP_AREA else '[X] Non'}\")\n",
    "    print(f\"   Garder -H (Height): {'[OK] Oui' if KEEP_HEIGHT else '[X] Non'}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES/MARQUEURS AVEC -A ET -H\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ANALYSE DES MARQUEURS PAR TYPE (-A Area vs -H Height)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n[INFO] Les suffixes -A et -H sont dans les NOMS DE MARQUEURS (pas les fichiers)\")\n",
    "print(\"       -A = Area (aire du pulse) | -H = Height (hauteur du pulse)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Récupérer les noms de colonnes\n",
    "all_columns = list(combined_gated.var_names)\n",
    "\n",
    "# Séparer les colonnes avec -A, -H, ou autres\n",
    "# IMPORTANT: Vérifier que -A et -H sont à la FIN du nom (suffixes), pas n'importe où\n",
    "# Exemple: \"CD19 APC-A750-H\" se termine par -H (Height), pas -A même si \"APC-A750\" contient -A\n",
    "cols_with_A = [col for col in all_columns if col.upper().endswith(\"-A\")]\n",
    "cols_with_H = [col for col in all_columns if col.upper().endswith(\"-H\")]\n",
    "cols_other = [col for col in all_columns if not col.upper().endswith(\"-A\") and not col.upper().endswith(\"-H\")]\n",
    "\n",
    "print(f\"\\n🔵 MARQUEURS avec '-A' (Area - aire du pulse) - {len(cols_with_A)} au total:\")\n",
    "for col in cols_with_A:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "print(f\"\\n🟣 MARQUEURS avec '-H' (Height - hauteur du pulse) - {len(cols_with_H)} au total:\")\n",
    "for col in cols_with_H:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "print(f\"\\n⚪ MARQUEURS sans -A/-H - {len(cols_other)} au total:\")\n",
    "for col in cols_other:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTRAGE DES MARQUEURS (si activé)\n",
    "# =============================================================================\n",
    "if APPLY_MARKER_FILTERING:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES MARQUEURS PAR TYPE (-A Area vs -H Height)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Déterminer quels marqueurs garder\n",
    "    markers_to_keep = []\n",
    "    \n",
    "    if KEEP_AREA:\n",
    "        markers_to_keep.extend(cols_with_A)\n",
    "    if KEEP_HEIGHT:\n",
    "        markers_to_keep.extend(cols_with_H)\n",
    "    \n",
    "    # Toujours garder les marqueurs sans -A/-H\n",
    "    markers_to_keep.extend(cols_other)\n",
    "    \n",
    "    # Dédupliquer (au cas où)\n",
    "    markers_to_keep = list(dict.fromkeys(markers_to_keep))\n",
    "    \n",
    "    # Vérification\n",
    "    if len(markers_to_keep) == 0:\n",
    "        print(\"\\n[!] ATTENTION: Aucun marqueur sélectionné!\")\n",
    "        print(\"   → KEEP_AREA et KEEP_HEIGHT sont tous les deux False\")\n",
    "        print(\"   → Désactivation automatique du filtrage\")\n",
    "        APPLY_MARKER_FILTERING = False\n",
    "        markers_to_keep = all_columns\n",
    "    \n",
    "    if APPLY_MARKER_FILTERING:\n",
    "        # Afficher le résumé\n",
    "        n_before_markers = len(all_columns)\n",
    "        n_after_markers = len(markers_to_keep)\n",
    "        n_excluded_markers = n_before_markers - n_after_markers\n",
    "        \n",
    "        print(f\"\\n Marqueurs AVANT filtrage: {n_before_markers}\")\n",
    "        print(f\" Marqueurs APRÈS filtrage: {n_after_markers}\")\n",
    "        print(f\" Marqueurs exclus: {n_excluded_markers}\")\n",
    "        \n",
    "        if n_excluded_markers > 0:\n",
    "            print(f\"\\n Marqueurs CONSERVÉS:\")\n",
    "            for m in markers_to_keep:\n",
    "                print(f\"   [OK] {m}\")\n",
    "            \n",
    "            excluded_markers = [m for m in all_columns if m not in markers_to_keep]\n",
    "            print(f\"\\n Marqueurs EXCLUS:\")\n",
    "            for m in excluded_markers:\n",
    "                print(f\"   [X] {m}\")\n",
    "            \n",
    "            # Appliquer le filtrage en sélectionnant les colonnes\n",
    "            # Créer un masque de colonnes\n",
    "            col_indices = [i for i, col in enumerate(all_columns) if col in markers_to_keep]\n",
    "            \n",
    "            # Filtrer combined_gated (AnnData)\n",
    "            combined_gated = combined_gated[:, markers_to_keep].copy()\n",
    "            \n",
    "            # Filtrer X_transformed\n",
    "            X_transformed = X_transformed[:, col_indices]\n",
    "            \n",
    "            # Mettre à jour var_names\n",
    "            var_names = markers_to_keep\n",
    "            \n",
    "            print(f\"\\n[OK] Filtrage des marqueurs appliqué!\")\n",
    "            print(f\"   Shape combined_gated: {combined_gated.shape}\")\n",
    "            print(f\"   Shape X_transformed: {X_transformed.shape}\")\n",
    "        else:\n",
    "            print(f\"\\n[INFO] Tous les marqueurs sont déjà conservés (rien à filtrer)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FILTRAGE DES MARQUEURS DÉSACTIVÉ\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   → Tous les {len(all_columns)} marqueurs sont conservés\")\n",
    "    \n",
    "    # Afficher quand même les fichiers disponibles\n",
    "    print(f\"\\n Fichiers disponibles dans le dataset:\")\n",
    "    file_counts = combined_gated.obs['file_origin'].value_counts()\n",
    "    for fname, count in file_counts.items():\n",
    "        print(f\"   {fname}: {count:,} cellules\")\n",
    "\n",
    "# =============================================================================\n",
    "# AFFICHAGE DES COLONNES UTILISÉES POUR FLOWSOM\n",
    "# =============================================================================\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\" MARQUEURS DISPONIBLES POUR FLOWSOM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTous les marqueurs actuels ({len(list(combined_gated.var_names))}):\")\n",
    "for i, col in enumerate(combined_gated.var_names):\n",
    "    marker_type = \"\"\n",
    "    if \"-A\" in col.upper():\n",
    "        marker_type = \" [Type -A = Area]\"\n",
    "    elif \"-H\" in col.upper():\n",
    "        marker_type = \" [Type -H = Height]\"\n",
    "    print(f\"   [{i:2d}] {col}{marker_type}\")\n",
    "\n",
    "print(f\"\\n[OK] Données prêtes pour la suite du pipeline\")\n",
    "print(f\"   Shape combined_gated: {combined_gated.shape}\")\n",
    "print(f\"   Shape X_transformed: {X_transformed.shape}\")\n",
    "print(f\"   Nombre de cellules: {combined_gated.shape[0]:,}\")\n",
    "print(f\"   Nombre de marqueurs: {combined_gated.shape[1]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MISE À JOUR DE cols_to_use ET used_markers APRÈS FILTRAGE\n",
    "# =============================================================================\n",
    "# Recalculer cols_to_use après le filtrage car var_names a peut-être été modifié\n",
    "if EXCLUDE_SCATTER:\n",
    "    cols_to_use = [i for i, name in enumerate(var_names) \n",
    "                   if not any(p in name.upper() for p in scatter_patterns)]\n",
    "else:\n",
    "    cols_to_use = list(range(len(var_names)))\n",
    "\n",
    "used_markers = [var_names[i] for i in cols_to_use]\n",
    "\n",
    "print(f\"\\n[OK] Variables 'cols_to_use' et 'used_markers' mises à jour après filtrage\")\n",
    "print(f\"   Marqueurs utilisés pour FlowSOM: {len(used_markers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRÉATION DE L'ANNDATA TRANSFORMÉ ET EXPLORATION POST-ARCSINH\n",
    "\n",
    "# Créer un nouvel AnnData avec les données transformées (X_transformed)\n",
    "import anndata as ad\n",
    "\n",
    "# Créer adata_flowsom - le nouvel AnnData pour FlowSOM avec données transformées\n",
    "adata_flowsom = ad.AnnData(\n",
    "    X=X_transformed,  # Données POST-transformation arcsinh\n",
    "    obs=combined_gated.obs.copy(),  # Copie des métadonnées\n",
    "    var=combined_gated.var.copy() if combined_gated.var is not None else None\n",
    ")\n",
    "\n",
    "# Ajouter les noms de variables\n",
    "adata_flowsom.var_names = var_names\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CRÉATION ANNDATA POUR FLOWSOM (DONNÉES POST-ARCSINH)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n[OK] Nouvel AnnData 'adata_flowsom' créé avec données transformées\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Observations (cellules): {adata_flowsom.n_obs:,}\")\n",
    "print(f\"   Variables (marqueurs): {adata_flowsom.n_vars}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPLORATION DU DATAFRAME POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "\n",
    "# Extraire la matrice transformée depuis le NOUVEL AnnData\n",
    "X_trans = adata_flowsom.X\n",
    "if hasattr(X_trans, 'toarray'):\n",
    "    X_trans = X_trans.toarray()\n",
    "\n",
    "# Créer un DataFrame pour exploration\n",
    "df_transformed = pd.DataFrame(X_trans, columns=var_names)\n",
    "df_transformed['condition'] = adata_flowsom.obs['condition'].values\n",
    "df_transformed['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"APERÇU DES DONNÉES TRANSFORMÉES (premières 10 lignes)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape du DataFrame: {df_transformed.shape}\")\n",
    "display(df_transformed.head(10))\n",
    "\n",
    "# VÉRIFICATION DES NaN ET Inf POST-ARCSINH\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÉRIFICATION DES VALEURS NaN ET Inf POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Colonnes numériques uniquement\n",
    "numeric_cols = df_transformed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Comptage des NaN\n",
    "nan_counts = df_transformed[numeric_cols].isna().sum()\n",
    "total_nan = nan_counts.sum()\n",
    "\n",
    "# Comptage des Inf (positifs et négatifs)\n",
    "inf_pos_counts = (df_transformed[numeric_cols] == np.inf).sum()\n",
    "inf_neg_counts = (df_transformed[numeric_cols] == -np.inf).sum()\n",
    "total_inf_pos = inf_pos_counts.sum()\n",
    "total_inf_neg = inf_neg_counts.sum()\n",
    "total_inf = total_inf_pos + total_inf_neg\n",
    "\n",
    "total_cells = df_transformed.shape[0] * len(numeric_cols)\n",
    "\n",
    "print(f\"\\nRÉSUMÉ GLOBAL:\")\n",
    "print(f\"   Total valeurs analysées: {total_cells:,}\")\n",
    "print(f\"   Total NaN:    {total_nan:,} ({100*total_nan/total_cells:.4f}%)\")\n",
    "print(f\"   Total +Inf:   {total_inf_pos:,} ({100*total_inf_pos/total_cells:.4f}%)\")\n",
    "print(f\"   Total -Inf:   {total_inf_neg:,} ({100*total_inf_neg/total_cells:.4f}%)\")\n",
    "\n",
    "# Détail par colonne si problèmes détectés\n",
    "if total_nan > 0 or total_inf > 0:\n",
    "    print(f\"\\nDÉTAIL PAR COLONNE AVEC PROBLÈMES:\")\n",
    "    print(\"-\"*60)\n",
    "    for col in numeric_cols:\n",
    "        n_nan = df_transformed[col].isna().sum()\n",
    "        n_inf_pos = (df_transformed[col] == np.inf).sum()\n",
    "        n_inf_neg = (df_transformed[col] == -np.inf).sum()\n",
    "        if n_nan > 0 or n_inf_pos > 0 or n_inf_neg > 0:\n",
    "            print(f\"   {col:30s}: NaN={n_nan:,}, +Inf={n_inf_pos:,}, -Inf={n_inf_neg:,}\")\n",
    "else:\n",
    "    print(f\"\\nAucune valeur NaN ou Inf détectée - Données propres!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STATISTIQUES DESCRIPTIVES POST-ARCSINH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTIQUES DESCRIPTIVES POST-ARCSINH\")\n",
    "print(\"=\"*70)\n",
    "display(df_transformed[numeric_cols].describe())\n",
    "\n",
    "# ============================================================================\n",
    "# VÉRIFICATION DES RANGES POST-TRANSFORMATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VÉRIFICATION DES RANGES POST-TRANSFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"(arcsinh avec cofactor=150 donne typiquement des valeurs entre -5 et 10)\\n\")\n",
    "\n",
    "# Utiliser les colonnes numériques réellement présentes dans df_transformed\n",
    "markers_to_check = [col for col in var_names if col in numeric_cols][:10]\n",
    "\n",
    "for col in markers_to_check:  # Premiers 10 marqueurs numériques\n",
    "    col_min = df_transformed[col].min()\n",
    "    col_max = df_transformed[col].max()\n",
    "    col_mean = df_transformed[col].mean()\n",
    "    print(f\"   {col:30s}: min={col_min:8.3f}, max={col_max:8.3f}, mean={col_mean:8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETTOYAGE FINAL ET VALIDATION DE L'ANNDATA POUR FLOWSOM\n",
    "\n",
    "# Nettoyage final: remplacer NaN/Inf par 0 dans adata_flowsom\n",
    "X_final = adata_flowsom.X\n",
    "if hasattr(X_final, 'toarray'):\n",
    "    X_final = X_final.toarray()\n",
    "\n",
    "# Vérifier et nettoyer\n",
    "nan_mask = ~np.isfinite(X_final)\n",
    "n_nan = nan_mask.sum()\n",
    "if n_nan > 0:\n",
    "    print(f\"[!] {n_nan} valeurs NaN/Inf détectées et remplacées par 0\")\n",
    "    X_final = np.nan_to_num(X_final, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    adata_flowsom.X = X_final\n",
    "else:\n",
    "    print(\"[OK] Aucune valeur problématique - pas de nettoyage nécessaire\")\n",
    "\n",
    "print(f\"\\n[OK] AnnData 'adata_flowsom' prêt pour FlowSOM:\")\n",
    "print(f\"   Shape: {adata_flowsom.shape}\")\n",
    "print(f\"   Colonnes pour clustering: {len(cols_to_use)}\")\n",
    "\n",
    "# Résumé par condition\n",
    "print(f\"\\n Distribution par condition:\")\n",
    "for condition in adata_flowsom.obs['condition'].unique():\n",
    "    n = (adata_flowsom.obs['condition'] == condition).sum()\n",
    "    print(f\"   {condition}: {n:,} cellules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08a195",
   "metadata": {},
   "source": [
    "## 9. Exécution du Clustering FlowSOM\n",
    "\n",
    "Configuration et lancement de l'analyse FlowSOM avec:\n",
    "- Grille SOM (xdim × ydim)\n",
    "- Nombre de métaclusters\n",
    "- Seed pour reproductibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMÈTRES FLOWSOM\n",
    "\n",
    "# Dimensions de la grille SOM\n",
    "XDIM = 10\n",
    "YDIM = 10\n",
    "\n",
    "# Nombre de métaclusters\n",
    "N_CLUSTERS = 7\n",
    "\n",
    "# Seed pour reproductibilité\n",
    "SEED = 42\n",
    "\n",
    "# Auto-clustering avec silhouette score?\n",
    "AUTO_CLUSTER = False\n",
    "MAX_CLUSTERS_AUTO = 20\n",
    "\n",
    "print(\"PARAMÈTRES FLOWSOM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Grille SOM: {XDIM} × {YDIM} = {XDIM*YDIM} nodes\")\n",
    "print(f\"   Métaclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "print(f\"   Auto-clustering: {'Oui' if AUTO_CLUSTER else 'Non'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION POUR TROUVER LE NOMBRE OPTIMAL DE CLUSTERS (optionnel)\n",
    "# [!] Le silhouette score nécessite une matrice N×N → impossible avec 1M cellules\n",
    "# Solution: Sous-échantillonner pour l'évaluation silhouette uniquement\n",
    "\n",
    "SAMPLE_SIZE_SILHOUETTE = 10000  # Taille de l'échantillon pour silhouette\n",
    "\n",
    "def find_optimal_clusters(data, cols_to_use, seed, max_clusters=20, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Trouve le nombre optimal de métaclusters via silhouette score.\n",
    "    Utilise un échantillon représentatif pour éviter l'explosion mémoire.\n",
    "    \"\"\"\n",
    "    print(\"Recherche du nombre optimal de clusters...\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = data.X\n",
    "    if hasattr(X, 'toarray'):\n",
    "        X = X.toarray()\n",
    "    \n",
    "    X_full = X[:, cols_to_use]\n",
    "    X_full = np.nan_to_num(X_full, nan=0.0)\n",
    "    \n",
    "    n_total = X_full.shape[0]\n",
    "    \n",
    "    # Sous-échantillonner pour silhouette (sinon O(N²) mémoire)\n",
    "    if n_total > sample_size:\n",
    "        print(f\"   [!] {n_total:,} cellules → échantillon de {sample_size:,} pour silhouette\")\n",
    "        idx = np.random.choice(n_total, sample_size, replace=False)\n",
    "        X_sample = X_full[idx]\n",
    "    else:\n",
    "        print(f\"   Utilisation de {n_total:,} cellules\")\n",
    "        X_sample = X_full\n",
    "    \n",
    "    scores = []\n",
    "    cluster_range = range(2, min(max_clusters + 1, len(X_sample) // 10))\n",
    "    \n",
    "    for k in cluster_range:\n",
    "        try:\n",
    "            clustering = AgglomerativeClustering(n_clusters=k)\n",
    "            labels = clustering.fit_predict(X_sample)\n",
    "            score = silhouette_score(X_sample, labels)\n",
    "            scores.append((k, score))\n",
    "            print(f\"   k={k}: silhouette={score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   k={k}: erreur - {e}\")\n",
    "    \n",
    "    if scores:\n",
    "        best_k, best_score = max(scores, key=lambda x: x[1])\n",
    "        print(f\"\\n[OK] Nombre optimal: {best_k} (silhouette={best_score:.4f})\")\n",
    "        return best_k\n",
    "    \n",
    "    return 10  # Valeur par défaut\n",
    "\n",
    "# Exécuter si AUTO_CLUSTER est activé\n",
    "if AUTO_CLUSTER:\n",
    "    N_CLUSTERS = find_optimal_clusters(\n",
    "        combined_gated, cols_to_use, SEED, \n",
    "        MAX_CLUSTERS_AUTO, SAMPLE_SIZE_SILHOUETTE\n",
    "    )\n",
    "    print(f\"\\n Utilisation de {N_CLUSTERS} métaclusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ffa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXÉCUTION FLOWSOM\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Exécuter FlowSOM avec adata_flowsom (données transformées arcsinh)\n",
    "fsom = fs.FlowSOM(\n",
    "    adata_flowsom,  # ← IMPORTANT: utilise les données POST-transformation\n",
    "    cols_to_use=cols_to_use,\n",
    "    xdim=XDIM,\n",
    "    ydim=YDIM,\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTemps d'exécution: {elapsed:.2f} secondes\")\n",
    "\n",
    "# Récupérer les données de clustering\n",
    "cell_data = fsom.get_cell_data()\n",
    "cluster_data = fsom.get_cluster_data()\n",
    "\n",
    "# Ajouter les métadonnées originales\n",
    "cell_data.obs['condition'] = adata_flowsom.obs['condition'].values\n",
    "cell_data.obs['file_origin'] = adata_flowsom.obs['file_origin'].values\n",
    "\n",
    "print(f\"\\n[OK] FlowSOM terminé!\")\n",
    "print(f\"   Cellules analysées: {cell_data.shape[0]:,}\")\n",
    "print(f\"   Nodes SOM: {cluster_data.shape[0]}\")\n",
    "print(f\"   Métaclusters: {N_CLUSTERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0e07e",
   "metadata": {},
   "source": [
    "## 10. Visualisation des Résultats FlowSOM\n",
    "\n",
    "Génération des visualisations standards:\n",
    "- Heatmap d'expression par métacluster\n",
    "- Arbre MST (Minimum Spanning Tree)\n",
    "- Star Charts\n",
    "- Distribution par condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP D'EXPRESSION PAR MÉTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" Génération de la Heatmap d'expression...\")\n",
    "\n",
    "# Récupérer les données\n",
    "X = cell_data.X\n",
    "if hasattr(X, 'toarray'):\n",
    "    X = X.toarray()\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "\n",
    "# Calculer la MFI (Mean Fluorescence Intensity) par métacluster — VECTORISÉ\n",
    "# Utilise pd.DataFrame.groupby au lieu d'une boucle O(n_cells × n_clusters)\n",
    "X_markers = X[:, cols_to_use]\n",
    "_mc_series = pd.Series(metaclustering, name='mc')\n",
    "mfi_matrix = (\n",
    "    pd.DataFrame(X_markers, columns=range(len(cols_to_use)))\n",
    "    .groupby(_mc_series)\n",
    "    .mean()\n",
    "    .reindex(range(N_CLUSTERS))\n",
    "    .fillna(0)\n",
    "    .values\n",
    ")\n",
    "\n",
    "# Normalisation Z-score pour la heatmap\n",
    "mfi_normalized = (mfi_matrix - np.nanmean(mfi_matrix, axis=0)) / (np.nanstd(mfi_matrix, axis=0) + 1e-10)\n",
    "\n",
    "# Créer la heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "im = ax.imshow(mfi_normalized.T, aspect='auto', cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "\n",
    "# Labels\n",
    "ax.set_yticks(range(len(used_markers)))\n",
    "ax.set_yticklabels(used_markers, fontsize=9)\n",
    "ax.set_xticks(range(N_CLUSTERS))\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "\n",
    "ax.set_title('Heatmap - Expression par Métacluster (Z-score)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('Métacluster', fontsize=12)\n",
    "ax.set_ylabel('Marqueur', fontsize=12)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8, label='Z-score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAR CHART FLOWSOM (MST View)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Génération du Star Chart MST...\")\n",
    "\n",
    "try:\n",
    "    # Utiliser l'API FlowSOM pour le Star Chart\n",
    "    fig_stars = fs.pl.plot_stars(\n",
    "        fsom,\n",
    "        background_values=fsom.get_cluster_data().obs.metaclustering,\n",
    "        view=\"MST\"\n",
    "    )\n",
    "    plt.suptitle('FlowSOM Star Chart (MST View)', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur Star Chart: {e}\")\n",
    "    print(\"   Utilisation de la visualisation alternative...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION GRILLE SOM (xGrid, yGrid) - Style FlowSOM R exact\n",
    "# =============================================================================\n",
    "# PARTIE 1 : MATPLOTLIB (statique, haute résolution pour PDF/export)\n",
    "# =============================================================================\n",
    "\n",
    "print(\" VISUALISATION GRILLE SOM (style FlowSOM R avec cercles)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R)\n",
    "# =====================================================================\n",
    "def circular_jitter_viz(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    Génère un jitter circulaire style FlowSOM R — VECTORISÉ.\n",
    "    Le rayon des cercles dépend du nombre de cellules dans le node.\n",
    "    \"\"\"\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    max_size_val = node_sizes.max()\n",
    "    \n",
    "    # Calcul vectorisé des rayons (pas de boucle Python)\n",
    "    size_ratios = np.sqrt(node_sizes[cluster_ids.astype(int)] / max_size_val)\n",
    "    radii = (min_radius + (max_radius - min_radius) * size_ratios).astype(np.float32)\n",
    "    \n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "try:\n",
    "    # Récupérer les coordonnées de grille\n",
    "    grid_coords = cluster_data.obsm.get('grid', None)\n",
    "    \n",
    "    if grid_coords is not None:\n",
    "        # Récupérer les infos de clustering\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        conditions = cell_data.obs['condition'].values\n",
    "        \n",
    "        # Calculer les coordonnées de grille pour chaque cellule\n",
    "        xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "        yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "        \n",
    "        # Décaler pour commencer à 1\n",
    "        xGrid_shifted = xGrid_base - xGrid_base.min() + 1\n",
    "        yGrid_shifted = yGrid_base - yGrid_base.min() + 1\n",
    "        \n",
    "        # Métacluster pour chaque cellule\n",
    "        metaclustering_cells = np.array([metaclustering_nodes[int(c)] for c in clustering])\n",
    "        \n",
    "        # Calculer la taille de chaque node\n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes, dtype=np.float32)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        # JITTER CIRCULAIRE style FlowSOM R\n",
    "        MAX_NODE_SIZE = 0.45\n",
    "        MIN_NODE_SIZE = 0.1\n",
    "        np.random.seed(SEED)\n",
    "        jitter_x, jitter_y = circular_jitter_viz(len(clustering), clustering, node_sizes, \n",
    "                                                  max_radius=MAX_NODE_SIZE, \n",
    "                                                  min_radius=MIN_NODE_SIZE)\n",
    "        \n",
    "        print(f\" Jitter circulaire appliqué (rayon proportionnel à la taille du node)\")\n",
    "        print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "        \n",
    "        # Créer la figure avec 2 sous-plots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 1: Grille SOM colorée par Métacluster\n",
    "        # =====================================================================\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        \n",
    "        scatter1 = ax1.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=metaclustering_cells,\n",
    "            cmap=cmap,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        # Ajouter les labels des métaclusters au centre de chaque node\n",
    "        for node_id in range(n_nodes):\n",
    "            if node_sizes[node_id] > 0:\n",
    "                x_pos = grid_coords[node_id, 0] - xGrid_base.min() + 1\n",
    "                y_pos = grid_coords[node_id, 1] - yGrid_base.min() + 1\n",
    "                meta_id = metaclustering_nodes[node_id]\n",
    "                ax1.annotate(\n",
    "                    str(int(meta_id + 1)),\n",
    "                    (x_pos, y_pos),\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=8, fontweight='bold',\n",
    "                    color='white',\n",
    "                    bbox=dict(boxstyle='circle,pad=0.2', facecolor=cmap(meta_id / max(n_meta - 1, 1)), edgecolor='white', alpha=0.9)\n",
    "                )\n",
    "        \n",
    "        ax1.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColoré par Métacluster (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax1.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax1.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax1.set_aspect('equal')\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        cbar1 = plt.colorbar(scatter1, ax=ax1, label='Métacluster')\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Plot 2: Grille SOM colorée par Condition\n",
    "        # =====================================================================\n",
    "        ax2 = axes[1]\n",
    "        \n",
    "        condition_num = np.array([0 if c == 'Sain' else 1 for c in conditions])\n",
    "        \n",
    "        from matplotlib.colors import ListedColormap\n",
    "        cmap_cond = ListedColormap(['#a6e3a1', '#f38ba8'])\n",
    "        \n",
    "        scatter2 = ax2.scatter(\n",
    "            xGrid_shifted + jitter_x, \n",
    "            yGrid_shifted + jitter_y,\n",
    "            c=condition_num,\n",
    "            cmap=cmap_cond,\n",
    "            s=5,\n",
    "            alpha=0.5,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "        \n",
    "        ax2.set_xlabel('xGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('yGrid', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title(f'Grille FlowSOM - {XDIM}x{YDIM} nodes\\nColoré par Condition (style FlowSOM R)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlim(0.5, XDIM + 1.5)\n",
    "        ax2.set_ylim(0.5, YDIM + 1.5)\n",
    "        ax2.set_aspect('equal')\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='#a6e3a1', edgecolor='white', label='Sain (NBM)'),\n",
    "            Patch(facecolor='#f38ba8', edgecolor='white', label='Pathologique')\n",
    "        ]\n",
    "        ax2.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Afficher les statistiques\n",
    "        print(f\"\\n STATISTIQUES DE LA GRILLE SOM:\")\n",
    "        print(f\"   Dimensions: {XDIM} x {YDIM} = {XDIM * YDIM} nodes\")\n",
    "        print(f\"   Nodes utilisés: {(node_sizes > 0).sum()} / {n_nodes}\")\n",
    "        print(f\"   xGrid range: [{xGrid_shifted.min():.1f}, {xGrid_shifted.max():.1f}]\")\n",
    "        print(f\"   yGrid range: [{yGrid_shifted.min():.1f}, {yGrid_shifted.max():.1f}]\")\n",
    "        \n",
    "        # Afficher la taille des nodes\n",
    "        print(f\"\\n Distribution des tailles de nodes:\")\n",
    "        print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "        print(f\"   Max: {node_sizes.max():.0f} cellules\")\n",
    "        print(f\"   Moyenne: {node_sizes.mean():.0f} cellules\")\n",
    "        \n",
    "        # =================================================================\n",
    "        # PARTIE 2 : PLOTLY INTERACTIF (zoom, hover, export)\n",
    "        # =================================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" GRILLE SOM — VERSION PLOTLY INTERACTIVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.colors as pc_grid\n",
    "        \n",
    "        _xj = xGrid_shifted + jitter_x\n",
    "        _yj = yGrid_shifted + jitter_y\n",
    "        \n",
    "        # Sous-échantillonner si trop de points pour la fluidité Plotly\n",
    "        _max_pts = 50_000\n",
    "        if len(clustering) > _max_pts:\n",
    "            np.random.seed(SEED)\n",
    "            _sample_idx = np.random.choice(len(clustering), _max_pts, replace=False)\n",
    "        else:\n",
    "            _sample_idx = np.arange(len(clustering))\n",
    "        \n",
    "        if n_meta <= 20:\n",
    "            _mc_palette = pc_grid.qualitative.Alphabet[:n_meta]\n",
    "        else:\n",
    "            _mc_palette = [f\"hsl({int(i*360/n_meta)},70%,55%)\" for i in range(n_meta)]\n",
    "        \n",
    "        # --- Plot 1 Plotly : Métacluster ---\n",
    "        fig_grid_mc = go.Figure()\n",
    "        \n",
    "        for mc_id in range(n_meta):\n",
    "            _mask_mc = metaclustering_cells[_sample_idx] == mc_id\n",
    "            if _mask_mc.sum() == 0:\n",
    "                continue\n",
    "            _si = _sample_idx[_mask_mc]\n",
    "            fig_grid_mc.add_trace(go.Scattergl(\n",
    "                x=_xj[_si], y=_yj[_si],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=_mc_palette[mc_id % len(_mc_palette)], opacity=0.5),\n",
    "                name=f\"MC{mc_id} ({_mask_mc.sum():,})\",\n",
    "                hovertemplate=f\"MC{mc_id}<br>xGrid: %{{x:.2f}}<br>yGrid: %{{y:.2f}}<extra></extra>\",\n",
    "            ))\n",
    "        \n",
    "        _node_x = [grid_coords[i, 0] - xGrid_base.min() + 1 for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_y = [grid_coords[i, 1] - yGrid_base.min() + 1 for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_txt = [str(int(metaclustering_nodes[i]+1)) for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        _node_sz = [node_sizes[i] for i in range(n_nodes) if node_sizes[i] > 0]\n",
    "        \n",
    "        fig_grid_mc.add_trace(go.Scatter(\n",
    "            x=_node_x, y=_node_y,\n",
    "            mode='text',\n",
    "            text=_node_txt,\n",
    "            textfont=dict(size=9, color='black', family='Arial Black'),\n",
    "            hovertemplate=[f\"Node — MC{t}<br>{int(s):,} cellules<extra></extra>\" for t, s in zip(_node_txt, _node_sz)],\n",
    "            showlegend=False,\n",
    "        ))\n",
    "        \n",
    "        fig_grid_mc.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Grille FlowSOM — {XDIM}×{YDIM} nodes — Coloré par Métacluster</b><br>\"\n",
    "                     \"<sup>Style FlowSOM R (jitter circulaire proportionnel) — Interactif</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xGrid\", range=[0.3, XDIM+1.7], scaleanchor=\"y\", scaleratio=1,\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            yaxis=dict(title=\"yGrid\", range=[0.3, YDIM+1.7],\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            height=700, width=800,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(title=\"Métacluster\", font=dict(size=10),\n",
    "                        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                        bordercolor=\"#ccc\", borderwidth=1,\n",
    "                        yanchor=\"top\", y=1, xanchor=\"left\", x=1.02),\n",
    "            margin=dict(t=80, b=50, l=60, r=180),\n",
    "        )\n",
    "        fig_grid_mc.show()\n",
    "        \n",
    "        # --- Plot 2 Plotly : Condition ---\n",
    "        fig_grid_cond = go.Figure()\n",
    "        \n",
    "        _cond_colors = {\"Sain\": \"#2ca02c\", \"Pathologique\": \"#d62728\"}\n",
    "        for cond_label, cond_color in _cond_colors.items():\n",
    "            _mask_c = conditions[_sample_idx] == cond_label\n",
    "            if _mask_c.sum() == 0:\n",
    "                continue\n",
    "            _si = _sample_idx[_mask_c]\n",
    "            fig_grid_cond.add_trace(go.Scattergl(\n",
    "                x=_xj[_si], y=_yj[_si],\n",
    "                mode='markers',\n",
    "                marker=dict(size=3, color=cond_color, opacity=0.45),\n",
    "                name=f\"{cond_label} ({_mask_c.sum():,})\",\n",
    "                hovertemplate=f\"{cond_label}<br>xGrid: %{{x:.2f}}<br>yGrid: %{{y:.2f}}<extra></extra>\",\n",
    "            ))\n",
    "        \n",
    "        fig_grid_cond.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Grille FlowSOM — {XDIM}×{YDIM} nodes — Coloré par Condition</b><br>\"\n",
    "                     \"<sup>Style FlowSOM R (jitter circulaire proportionnel) — Interactif</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xGrid\", range=[0.3, XDIM+1.7], scaleanchor=\"y\", scaleratio=1,\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            yaxis=dict(title=\"yGrid\", range=[0.3, YDIM+1.7],\n",
    "                       gridcolor=\"rgba(0,0,0,0.08)\", gridwidth=1),\n",
    "            height=700, width=800,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(title=\"Condition\", font=dict(size=12),\n",
    "                        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                        bordercolor=\"#ccc\", borderwidth=1),\n",
    "            margin=dict(t=80, b=50, l=60, r=60),\n",
    "        )\n",
    "        fig_grid_cond.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"[!] Coordonnées de grille non disponibles dans cluster_data.obsm['grid']\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur visualisation grille: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714730ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ARBRE MST — MATPLOTLIB (statique) + PLOTLY (interactif)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Génération de l'arbre MST...\")\n",
    "\n",
    "# =====================================================================\n",
    "# PARTIE 1 : MATPLOTLIB (statique, haute résolution pour PDF/export)\n",
    "# =====================================================================\n",
    "try:\n",
    "    layout = cluster_data.obsm.get('layout', None)\n",
    "    \n",
    "    if layout is not None:\n",
    "        clustering = cell_data.obs['clustering'].values\n",
    "        metaclustering_nodes = cluster_data.obs['metaclustering'].values\n",
    "        \n",
    "        n_nodes = len(cluster_data)\n",
    "        node_sizes = np.zeros(n_nodes)\n",
    "        for i in range(n_nodes):\n",
    "            node_sizes[i] = (clustering == i).sum()\n",
    "        \n",
    "        max_size = node_sizes.max() if node_sizes.max() > 0 else 1\n",
    "        sizes = 100 + (node_sizes / max_size) * 800\n",
    "        \n",
    "        n_meta = len(np.unique(metaclustering_nodes))\n",
    "        cmap = plt.cm.tab20 if n_meta <= 20 else plt.cm.turbo\n",
    "        colors = [cmap(int(m) / max(n_meta - 1, 1)) for m in metaclustering_nodes]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        scatter = ax.scatter(layout[:, 0], layout[:, 1], \n",
    "                           s=sizes, c=colors, edgecolors='white', \n",
    "                           linewidths=1.5, alpha=0.9, zorder=2)\n",
    "        \n",
    "        for i in range(n_nodes):\n",
    "            ax.annotate(str(int(metaclustering_nodes[i])), \n",
    "                       (layout[i, 0], layout[i, 1]),\n",
    "                       ha='center', va='center', fontsize=8, \n",
    "                       color='white', fontweight='bold')\n",
    "        \n",
    "        ax.set_xlabel('xNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('yNodes', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Arbre MST - {n_nodes} nodes, {n_meta} métaclusters', \n",
    "                    fontsize=14, fontweight='bold', pad=15)\n",
    "        ax.grid(True, alpha=0.15, linestyle='--')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        if n_meta <= 15:\n",
    "            legend_elements = [Patch(facecolor=cmap(i/max(n_meta-1, 1)), \n",
    "                                    label=f'MC {i}') for i in range(n_meta)]\n",
    "            ax.legend(handles=legend_elements, loc='center left', \n",
    "                     bbox_to_anchor=(1.02, 0.5), fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # =================================================================\n",
    "        # PARTIE 2 : PLOTLY INTERACTIF (zoom, hover, export)\n",
    "        # =================================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" ARBRE MST — VERSION PLOTLY INTERACTIVE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.colors as pc_mst\n",
    "        \n",
    "        _bubble_sizes = 10 + (node_sizes / max_size) * 40\n",
    "        \n",
    "        if n_meta <= 20:\n",
    "            _mc_palette = pc_mst.qualitative.Alphabet[:n_meta]\n",
    "        else:\n",
    "            _mc_palette = [f\"hsl({int(i*360/n_meta)},70%,55%)\" for i in range(n_meta)]\n",
    "        \n",
    "        # Récupérer les arêtes du MST si disponibles\n",
    "        _edge_x, _edge_y = [], []\n",
    "        _mst_graph = None\n",
    "        try:\n",
    "            if hasattr(cluster_data, 'uns') and 'mst' in cluster_data.uns:\n",
    "                _mst_graph = cluster_data.uns['mst']\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        if _mst_graph is not None:\n",
    "            try:\n",
    "                import igraph\n",
    "                if isinstance(_mst_graph, igraph.Graph):\n",
    "                    for edge in _mst_graph.es:\n",
    "                        s, t = edge.source, edge.target\n",
    "                        if s < n_nodes and t < n_nodes:\n",
    "                            _edge_x += [layout[s, 0], layout[t, 0], None]\n",
    "                            _edge_y += [layout[s, 1], layout[t, 1], None]\n",
    "            except ImportError:\n",
    "                pass\n",
    "        \n",
    "        fig_mst = go.Figure()\n",
    "        \n",
    "        if _edge_x:\n",
    "            fig_mst.add_trace(go.Scatter(\n",
    "                x=_edge_x, y=_edge_y,\n",
    "                mode='lines',\n",
    "                line=dict(width=1.5, color='rgba(100,100,100,0.5)'),\n",
    "                hoverinfo='skip',\n",
    "                showlegend=False,\n",
    "            ))\n",
    "        \n",
    "        for mc_id in range(n_meta):\n",
    "            _mask = metaclustering_nodes == mc_id\n",
    "            if _mask.sum() == 0:\n",
    "                continue\n",
    "            _indices = np.where(_mask)[0]\n",
    "            fig_mst.add_trace(go.Scatter(\n",
    "                x=layout[_indices, 0],\n",
    "                y=layout[_indices, 1],\n",
    "                mode='markers+text',\n",
    "                marker=dict(\n",
    "                    size=_bubble_sizes[_indices],\n",
    "                    color=_mc_palette[mc_id % len(_mc_palette)],\n",
    "                    line=dict(width=1.5, color='white'),\n",
    "                    opacity=0.9,\n",
    "                ),\n",
    "                text=[str(int(mc_id)) for _ in _indices],\n",
    "                textfont=dict(size=9, color='white', family='Arial Black'),\n",
    "                textposition='middle center',\n",
    "                name=f\"MC{mc_id} ({int(node_sizes[_indices].sum()):,} cells)\",\n",
    "                hovertemplate=[\n",
    "                    f\"<b>Node {ni}</b><br>\"\n",
    "                    f\"MC {int(metaclustering_nodes[ni])}<br>\"\n",
    "                    f\"Cellules: {int(node_sizes[ni]):,}<br>\"\n",
    "                    f\"x: {layout[ni,0]:.2f}, y: {layout[ni,1]:.2f}<extra></extra>\"\n",
    "                    for ni in _indices\n",
    "                ],\n",
    "            ))\n",
    "        \n",
    "        fig_mst.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>Arbre MST — {n_nodes} nodes, {n_meta} métaclusters</b><br>\"\n",
    "                     \"<sup>Taille des bulles ∝ nombre de cellules · Cliquez la légende pour filtrer</sup>\",\n",
    "                font=dict(size=14),\n",
    "            ),\n",
    "            xaxis=dict(title=\"xNodes\", showgrid=True, gridcolor=\"rgba(0,0,0,0.06)\",\n",
    "                       zeroline=False),\n",
    "            yaxis=dict(title=\"yNodes\", showgrid=True, gridcolor=\"rgba(0,0,0,0.06)\",\n",
    "                       zeroline=False, scaleanchor=\"x\", scaleratio=1),\n",
    "            height=750, width=900,\n",
    "            paper_bgcolor=\"#fafafa\", plot_bgcolor=\"#f5f5f5\",\n",
    "            legend=dict(\n",
    "                title=\"Métacluster\",\n",
    "                font=dict(size=10),\n",
    "                bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "                bordercolor=\"#ccc\", borderwidth=1,\n",
    "                yanchor=\"top\", y=1, xanchor=\"left\", x=1.02,\n",
    "            ),\n",
    "            margin=dict(t=80, b=50, l=60, r=200),\n",
    "        )\n",
    "        fig_mst.show()\n",
    "        \n",
    "        print(f\"[OK] Arbre MST — Matplotlib + Plotly interactif ({n_nodes} nodes, {n_meta} MC)\")\n",
    "    else:\n",
    "        print(\"[!] Layout MST non disponible\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[!] Erreur MST: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION PAR CONDITION (Sain vs Pathologique)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Distribution des métaclusters par condition...\")\n",
    "\n",
    "metaclustering = cell_data.obs['metaclustering'].values\n",
    "conditions = cell_data.obs['condition'].values\n",
    "\n",
    "healthy_pcts = []\n",
    "patho_pcts = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask_cluster = metaclustering == i\n",
    "    \n",
    "    # Pourcentage dans Sain\n",
    "    mask_healthy = (conditions == 'Sain') & mask_cluster\n",
    "    total_healthy = (conditions == 'Sain').sum()\n",
    "    healthy_pcts.append((mask_healthy.sum() / total_healthy * 100) if total_healthy > 0 else 0)\n",
    "    \n",
    "    # Pourcentage dans Pathologique\n",
    "    mask_patho = (conditions == 'Pathologique') & mask_cluster\n",
    "    total_patho = (conditions == 'Pathologique').sum()\n",
    "    patho_pcts.append((mask_patho.sum() / total_patho * 100) if total_patho > 0 else 0)\n",
    "\n",
    "# Créer le graphique\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x = np.arange(N_CLUSTERS)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, healthy_pcts, width, label='Sain (NBM)', \n",
    "               color='#a6e3a1', edgecolor='white', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, patho_pcts, width, label='Pathologique', \n",
    "               color='#f38ba8', edgecolor='white', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Métacluster', fontsize=12)\n",
    "ax.set_ylabel('Pourcentage (%)', fontsize=12)\n",
    "ax.set_title('Distribution des Métaclusters par Condition', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'MC{i}' for i in range(N_CLUSTERS)], fontsize=10)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    if height > 1:  # N'afficher que si > 1%\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3), textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tableau récapitulatif\n",
    "print(\"\\nTableau récapitulatif:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'MC':>4} | {'Sain (%)':>10} | {'Patho (%)':>10} | {'Diff':>8}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(N_CLUSTERS):\n",
    "    diff = patho_pcts[i] - healthy_pcts[i]\n",
    "    print(f\"{i:>4} | {healthy_pcts[i]:>10.2f} | {patho_pcts[i]:>10.2f} | {diff:>+8.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acff00",
   "metadata": {},
   "source": [
    "## 11. Analyse Détaillée des Métaclusters\n",
    "\n",
    "Statistiques approfondies par métacluster:\n",
    "- Nombre de cellules\n",
    "- MFI par marqueur\n",
    "- Phénotype caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATISTIQUES PAR MÉTACLUSTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\" STATISTIQUES PAR MÉTACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer un DataFrame de statistiques\n",
    "stats_data = []\n",
    "\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask = metaclustering == i\n",
    "    n_cells = mask.sum()\n",
    "    pct_total = n_cells / len(metaclustering) * 100\n",
    "    \n",
    "    # Calculer MFI pour chaque marqueur\n",
    "    mfi = np.nanmean(X[mask][:, cols_to_use], axis=0) if n_cells > 0 else np.zeros(len(cols_to_use))\n",
    "    \n",
    "    # Top 3 marqueurs les plus exprimés\n",
    "    top_indices = np.argsort(mfi)[::-1][:3]\n",
    "    top_markers = [used_markers[idx] for idx in top_indices]\n",
    "    \n",
    "    stats_data.append({\n",
    "        'Metacluster': i,\n",
    "        'N_Cells': n_cells,\n",
    "        'Pct_Total': pct_total,\n",
    "        'Top_Markers': ', '.join(top_markers)\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats_data)\n",
    "print(df_stats.to_string(index=False))\n",
    "\n",
    "# Graphique camembert\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Pie chart des tailles\n",
    "ax = axes[0]\n",
    "sizes = [s['N_Cells'] for s in stats_data]\n",
    "labels = [f\"MC{s['Metacluster']}\" for s in stats_data]\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, N_CLUSTERS))\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, \n",
    "                                   autopct='%1.1f%%', pctdistance=0.8)\n",
    "ax.set_title('Distribution des Cellules par Métacluster', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Bar chart des tailles\n",
    "ax = axes[1]\n",
    "ax.barh(range(N_CLUSTERS), sizes, color=colors, edgecolor='white')\n",
    "ax.set_yticks(range(N_CLUSTERS))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Nombre de cellules')\n",
    "ax.set_title('Taille des Métaclusters', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c773749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROFIL D'EXPRESSION DÉTAILLÉ PAR MÉTACLUSTER — SPIDER PLOT INTERACTIF\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n PROFIL D'EXPRESSION MOYEN PAR MÉTACLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer un DataFrame avec MFI par marqueur et métacluster — VECTORISÉ\n",
    "X_markers_mfi = X[:, cols_to_use]\n",
    "_mc_mfi = pd.Series(metaclustering, name='mc')\n",
    "mfi_matrix = (\n",
    "    pd.DataFrame(X_markers_mfi, columns=range(len(used_markers)))\n",
    "    .groupby(_mc_mfi)\n",
    "    .mean()\n",
    "    .reindex(range(N_CLUSTERS))\n",
    "    .fillna(0)\n",
    "    .values\n",
    ")\n",
    "\n",
    "df_mfi = pd.DataFrame(mfi_matrix, \n",
    "                       columns=used_markers,\n",
    "                       index=[f'MC{i}' for i in range(N_CLUSTERS)])\n",
    "\n",
    "# Afficher le tableau formaté\n",
    "print(df_mfi.round(2).to_string())\n",
    "\n",
    "# =============================================================================\n",
    "# SPIDER / RADAR PLOT INTERACTIF — TOUS LES CLUSTERS (Plotly)\n",
    "# =============================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "\n",
    "# Palette de couleurs suffisante pour tous les clusters\n",
    "if N_CLUSTERS <= 10:\n",
    "    _radar_palette = pc.qualitative.Set3\n",
    "elif N_CLUSTERS <= 20:\n",
    "    _radar_palette = pc.qualitative.Alphabet\n",
    "else:\n",
    "    _radar_palette = [f\"hsl({int(i*360/N_CLUSTERS)},70%,55%)\" for i in range(N_CLUSTERS)]\n",
    "\n",
    "fig_radar = go.Figure()\n",
    "\n",
    "for cluster_id in range(N_CLUSTERS):\n",
    "    values = mfi_matrix[cluster_id].copy()\n",
    "    # Normaliser entre 0 et 1 pour la visualisation\n",
    "    v_min, v_max = np.min(values), np.max(values)\n",
    "    values_norm = (values - v_min) / (v_max - v_min + 1e-10)\n",
    "\n",
    "    _c = _radar_palette[cluster_id % len(_radar_palette)]\n",
    "    _n_cells = int((metaclustering == cluster_id).sum())\n",
    "\n",
    "    # Construire une couleur de remplissage semi-transparente\n",
    "    if 'rgb' in str(_c):\n",
    "        _fill = _c.replace(')', ',0.08)').replace('rgb', 'rgba')\n",
    "    else:\n",
    "        _fill = f\"rgba(128,128,128,0.05)\"\n",
    "\n",
    "    fig_radar.add_trace(go.Scatterpolar(\n",
    "        r=np.append(values_norm, values_norm[0]),\n",
    "        theta=used_markers + [used_markers[0]],\n",
    "        fill='toself',\n",
    "        fillcolor=_fill,\n",
    "        opacity=0.85,\n",
    "        name=f\"MC{cluster_id}  ({_n_cells:,} cells)\",\n",
    "        line=dict(color=_c, width=2),\n",
    "        marker=dict(size=5),\n",
    "        customdata=np.stack([\n",
    "            np.append(mfi_matrix[cluster_id], mfi_matrix[cluster_id][0]),\n",
    "            np.append(values_norm, values_norm[0]),\n",
    "        ], axis=-1),\n",
    "        hovertemplate=(\n",
    "            f\"<b>MC{cluster_id}</b><br>\"\n",
    "            \"Marqueur: %{theta}<br>\"\n",
    "            \"MFI brute: %{customdata[0]:.2f}<br>\"\n",
    "            \"Normalisé: %{customdata[1]:.3f}<extra></extra>\"\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "fig_radar.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1.05],\n",
    "            tickfont=dict(size=9),\n",
    "            gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            tickfont=dict(size=11),\n",
    "            gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "            rotation=90,\n",
    "            direction=\"clockwise\",\n",
    "        ),\n",
    "        bgcolor=\"rgba(250,250,250,0.5)\",\n",
    "    ),\n",
    "    title=dict(\n",
    "        text=f\"<b>Profil d'Expression Normalisé — {N_CLUSTERS} Métaclusters</b><br>\"\n",
    "             \"<sup>Cliquez sur la légende pour masquer/afficher un cluster</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=\"Métacluster\",\n",
    "        font=dict(size=11),\n",
    "        bgcolor=\"rgba(255,255,255,0.85)\",\n",
    "        bordercolor=\"#ccc\", borderwidth=1,\n",
    "        yanchor=\"top\", y=1.0,\n",
    "        xanchor=\"left\", x=1.05,\n",
    "    ),\n",
    "    height=750,\n",
    "    width=950,\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=90, b=40, l=80, r=200),\n",
    ")\n",
    "\n",
    "fig_radar.show()\n",
    "print(f\"\\n[OK] Spider plot interactif — {N_CLUSTERS} métaclusters affichés\")\n",
    "print(\"     → Cliquez sur la légende pour isoler un métacluster\")\n",
    "print(\"     → Survolez les points pour voir les MFI brutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f58bc",
   "metadata": {},
   "source": [
    "## Visualisations Plus Lisibles pour Cliniciens\n",
    "\n",
    "**Alternatives au Spider Plot** pour faciliter l'interprétation clinique :\n",
    "\n",
    "1. **Heatmap cluster × marqueur** (MFI) avec clustering hiérarchique des lignes\n",
    "2. **Barplots** par cluster montrant les marqueurs clés côte à côte NBM vs Patho\n",
    "3. **Tableau \"signature phénotypique\"** par métacluster (CD34+/−, CD117+/−, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAP CLUSTER × MARQUEUR + BARPLOTS NBM vs PATHO + SIGNATURE PHÉNOTYPIQUE\n",
    "# =============================================================================\n",
    "# Visualisations alternatives plus lisibles pour les cliniciens\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" VISUALISATIONS CLINIQUES — HEATMAP, BARPLOTS, SIGNATURE PHÉNOTYPIQUE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. HEATMAP CLUSTER × MARQUEUR (MFI normalisé) avec clustering hiérarchique\n",
    "# =====================================================================\n",
    "print(\"\\n [1/3] Heatmap Cluster × Marqueur (MFI, clustering hiérarchique)\")\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Utiliser la matrice MFI déjà calculée (mfi_matrix: N_CLUSTERS × n_markers)\n",
    "# Normaliser par marqueur (Z-score par colonne) pour mieux comparer\n",
    "mfi_zscore = (mfi_matrix - mfi_matrix.mean(axis=0)) / (mfi_matrix.std(axis=0) + 1e-10)\n",
    "\n",
    "# Clustering hiérarchique des lignes (métaclusters)\n",
    "if N_CLUSTERS > 2:\n",
    "    row_linkage = linkage(pdist(mfi_zscore, metric='euclidean'), method='ward')\n",
    "    row_order = leaves_list(row_linkage)\n",
    "else:\n",
    "    row_order = np.arange(N_CLUSTERS)\n",
    "\n",
    "# Clustering hiérarchique des colonnes (marqueurs) \n",
    "if len(used_markers) > 2:\n",
    "    col_linkage = linkage(pdist(mfi_zscore.T, metric='euclidean'), method='ward')\n",
    "    col_order = leaves_list(col_linkage)\n",
    "else:\n",
    "    col_order = np.arange(len(used_markers))\n",
    "\n",
    "# Réordonner\n",
    "mfi_ordered = mfi_zscore[row_order][:, col_order]\n",
    "markers_ordered = [used_markers[i] for i in col_order]\n",
    "mc_labels_ordered = [f\"MC{i}\" for i in row_order]\n",
    "\n",
    "# Taille des métaclusters pour annotation\n",
    "mc_sizes = [(metaclustering == i).sum() for i in range(N_CLUSTERS)]\n",
    "mc_pcts_ordered = [mc_sizes[i] / sum(mc_sizes) * 100 for i in row_order]\n",
    "\n",
    "# Heatmap Plotly avec annotation\n",
    "fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "    z=mfi_ordered,\n",
    "    x=markers_ordered,\n",
    "    y=[f\"{mc_labels_ordered[i]} ({mc_pcts_ordered[i]:.1f}%)\" for i in range(len(mc_labels_ordered))],\n",
    "    colorscale='RdBu_r',\n",
    "    zmid=0,\n",
    "    colorbar=dict(title=\"Z-score MFI\", thickness=15, len=0.8),\n",
    "    text=np.round(mfi_ordered, 2),\n",
    "    texttemplate=\"%{text:.1f}\",\n",
    "    textfont=dict(size=9),\n",
    "    hovertemplate=\"Métacluster: %{y}<br>Marqueur: %{x}<br>Z-score: %{z:.2f}<extra></extra>\",\n",
    "))\n",
    "\n",
    "fig_heatmap.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Heatmap MFI — Métaclusters × Marqueurs</b><br>\"\n",
    "             \"<sup>Z-score normalisé par marqueur · Clustering hiérarchique (Ward)</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=11)),\n",
    "    yaxis=dict(title=\"Métaclusters\", tickfont=dict(size=11), autorange=\"reversed\"),\n",
    "    height=max(400, 40 * N_CLUSTERS + 150),\n",
    "    width=max(700, 50 * len(used_markers) + 200),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=100, b=120, l=150, r=50),\n",
    ")\n",
    "fig_heatmap.show()\n",
    "print(f\"   [OK] Heatmap {N_CLUSTERS} métaclusters × {len(used_markers)} marqueurs\")\n",
    "\n",
    "# =====================================================================\n",
    "# 2. HEATMAP EXPRESSION INTENSITY (+ / ++ / +++) pour cliniciens\n",
    "# =====================================================================\n",
    "print(\"\\n [1b/3] Heatmap expression qualitative (+/++/+++ légende clinique)\")\n",
    "\n",
    "# Classifier l'expression en catégories cliniques\n",
    "def classify_expression(zscore):\n",
    "    \"\"\"Convertir Z-score en catégorie clinique.\"\"\"\n",
    "    if zscore <= -1.0:\n",
    "        return \"−\"\n",
    "    elif zscore <= -0.3:\n",
    "        return \"low\"\n",
    "    elif zscore <= 0.3:\n",
    "        return \"+\"\n",
    "    elif zscore <= 1.0:\n",
    "        return \"++\"\n",
    "    else:\n",
    "        return \"+++\"\n",
    "\n",
    "# Créer matrice de texte clinique\n",
    "clinical_text = np.vectorize(classify_expression)(mfi_ordered)\n",
    "\n",
    "# Créer aussi une heatmap numérique discrétisée\n",
    "clinical_numeric = np.zeros_like(mfi_ordered)\n",
    "for i in range(mfi_ordered.shape[0]):\n",
    "    for j in range(mfi_ordered.shape[1]):\n",
    "        val = mfi_ordered[i, j]\n",
    "        if val <= -1.0:\n",
    "            clinical_numeric[i, j] = -2\n",
    "        elif val <= -0.3:\n",
    "            clinical_numeric[i, j] = -1\n",
    "        elif val <= 0.3:\n",
    "            clinical_numeric[i, j] = 0\n",
    "        elif val <= 1.0:\n",
    "            clinical_numeric[i, j] = 1\n",
    "        else:\n",
    "            clinical_numeric[i, j] = 2\n",
    "\n",
    "fig_heatmap_clinical = go.Figure(data=go.Heatmap(\n",
    "    z=clinical_numeric,\n",
    "    x=markers_ordered,\n",
    "    y=[f\"{mc_labels_ordered[i]} ({mc_pcts_ordered[i]:.1f}%)\" for i in range(len(mc_labels_ordered))],\n",
    "    colorscale=[\n",
    "        [0.0, '#3182bd'],    # − (négatif fort)\n",
    "        [0.25, '#9ecae1'],   # low\n",
    "        [0.5, '#f0f0f0'],    # +\n",
    "        [0.75, '#fdae6b'],   # ++\n",
    "        [1.0, '#d62728'],    # +++\n",
    "    ],\n",
    "    text=clinical_text,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=11, color=\"black\"),\n",
    "    hovertemplate=\"Métacluster: %{y}<br>Marqueur: %{x}<br>Expression: %{text}<extra></extra>\",\n",
    "    showscale=True,\n",
    "    colorbar=dict(\n",
    "        title=\"Expression\",\n",
    "        tickvals=[-2, -1, 0, 1, 2],\n",
    "        ticktext=[\"−\", \"low\", \"+\", \"++\", \"+++\"],\n",
    "        thickness=15, len=0.8,\n",
    "    ),\n",
    "))\n",
    "\n",
    "fig_heatmap_clinical.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Expression Phénotypique — Métaclusters × Marqueurs</b><br>\"\n",
    "             \"<sup>Légende clinique: − / low / + / ++ / +++ (basé sur Z-score MFI)</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    xaxis=dict(title=\"Marqueurs\", tickangle=-45, tickfont=dict(size=11)),\n",
    "    yaxis=dict(title=\"Métaclusters\", tickfont=dict(size=11), autorange=\"reversed\"),\n",
    "    height=max(400, 40 * N_CLUSTERS + 150),\n",
    "    width=max(700, 50 * len(used_markers) + 200),\n",
    "    paper_bgcolor=\"#fafafa\",\n",
    "    margin=dict(t=100, b=120, l=150, r=50),\n",
    ")\n",
    "fig_heatmap_clinical.show()\n",
    "\n",
    "# =====================================================================\n",
    "# 3. BARPLOTS MARQUEURS CLÉS — NBM vs PATHO (si COMPARE_MODE)\n",
    "# =====================================================================\n",
    "if COMPARE_MODE or MODE_BLASTES_VS_NORMAL:\n",
    "    print(\"\\n [2/3] Barplots marqueurs clés — NBM vs Patho par métacluster\")\n",
    "    \n",
    "    # Marqueurs clés pour la cytométrie de flux hémato\n",
    "    _key_markers_patterns = ['CD34', 'CD117', 'CD13', 'CD33', 'HLA-DR', 'CD45', 'CD15', 'CD16', \n",
    "                              'CD38', 'CD123', 'CD7', 'CD56', 'CD19', 'CD64']\n",
    "    _key_markers_idx = []\n",
    "    _key_markers_names = []\n",
    "    for pattern in _key_markers_patterns:\n",
    "        idx = PreGating.find_marker_index(used_markers, [pattern])\n",
    "        if idx is not None:\n",
    "            _key_markers_idx.append(idx)\n",
    "            _key_markers_names.append(used_markers[idx])\n",
    "    \n",
    "    if len(_key_markers_idx) >= 2:\n",
    "        # MFI par condition et métacluster\n",
    "        conditions_arr = adata_flowsom.obs['condition'].values if 'condition' in adata_flowsom.obs.columns else None\n",
    "        \n",
    "        if conditions_arr is not None:\n",
    "            _n_key = len(_key_markers_idx)\n",
    "            _n_mc_show = min(N_CLUSTERS, 8)  # Limiter à 8 pour lisibilité\n",
    "            \n",
    "            # Top métaclusters par taille\n",
    "            _mc_sizes_arr = np.array(mc_sizes)\n",
    "            _top_mc = np.argsort(_mc_sizes_arr)[::-1][:_n_mc_show]\n",
    "            \n",
    "            _n_cols_bp = min(4, _n_mc_show)\n",
    "            _n_rows_bp = int(np.ceil(_n_mc_show / _n_cols_bp))\n",
    "            \n",
    "            fig_barplots = make_subplots(\n",
    "                rows=_n_rows_bp, cols=_n_cols_bp,\n",
    "                subplot_titles=[f\"MC{mc} ({mc_sizes[mc]:,} cells)\" for mc in _top_mc],\n",
    "                horizontal_spacing=0.08, vertical_spacing=0.12,\n",
    "            )\n",
    "            \n",
    "            for bi, mc_id in enumerate(_top_mc):\n",
    "                _row_bp = bi // _n_cols_bp + 1\n",
    "                _col_bp = bi % _n_cols_bp + 1\n",
    "                \n",
    "                _mc_mask = (metaclustering == mc_id)\n",
    "                \n",
    "                for cond_label, cond_color in [(\"Sain\", \"#2ca02c\"), (\"Pathologique\", \"#d62728\")]:\n",
    "                    _cond_mask = (conditions_arr == cond_label) & _mc_mask\n",
    "                    if _cond_mask.sum() < 5:\n",
    "                        continue\n",
    "                    \n",
    "                    _mfi_cond = np.nanmean(X[_cond_mask][:, [cols_to_use[i] for i in _key_markers_idx]], axis=0)\n",
    "                    \n",
    "                    fig_barplots.add_trace(go.Bar(\n",
    "                        x=_key_markers_names,\n",
    "                        y=_mfi_cond,\n",
    "                        name=cond_label,\n",
    "                        marker_color=cond_color,\n",
    "                        opacity=0.8,\n",
    "                        showlegend=(bi == 0),\n",
    "                        legendgroup=cond_label,\n",
    "                    ), row=_row_bp, col=_col_bp)\n",
    "            \n",
    "            fig_barplots.update_layout(\n",
    "                title=dict(\n",
    "                    text=\"<b>Marqueurs Clés par Métacluster — NBM vs Pathologique</b>\",\n",
    "                    font=dict(size=16),\n",
    "                ),\n",
    "                barmode='group',\n",
    "                height=350 * _n_rows_bp + 100,\n",
    "                width=min(350 * _n_cols_bp, 1400),\n",
    "                paper_bgcolor=\"#fafafa\",\n",
    "                font=dict(size=10),\n",
    "                legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.15, xanchor=\"center\", x=0.5),\n",
    "                margin=dict(t=80, b=80),\n",
    "            )\n",
    "            fig_barplots.show()\n",
    "            print(f\"   [OK] Barplots {_n_mc_show} métaclusters × {_n_key} marqueurs clés\")\n",
    "        else:\n",
    "            print(\"   [!] Pas de colonne 'condition' — barplots ignorés\")\n",
    "    else:\n",
    "        print(f\"   [!] Seulement {len(_key_markers_idx)} marqueurs clés trouvés — barplots ignorés\")\n",
    "else:\n",
    "    print(\"\\n [2/3] Barplots NBM vs Patho — Mode comparaison non activé (skipped)\")\n",
    "\n",
    "# =====================================================================\n",
    "# 4. TABLEAU SIGNATURE PHÉNOTYPIQUE PAR MÉTACLUSTER\n",
    "# =====================================================================\n",
    "print(\"\\n [3/3] Tableau signature phénotypique par métacluster\")\n",
    "\n",
    "def generate_phenotype_summary(mfi_row, marker_names, zscore_row):\n",
    "    \"\"\"Génère un résumé phénotypique lisible à partir des MFI Z-scores.\"\"\"\n",
    "    phenotype_parts = []\n",
    "    # Trier par Z-score décroissant (marqueurs les plus exprimés en premier)\n",
    "    sorted_idx = np.argsort(zscore_row)[::-1]\n",
    "    \n",
    "    for idx in sorted_idx:\n",
    "        z = zscore_row[idx]\n",
    "        name = marker_names[idx]\n",
    "        if z > 1.0:\n",
    "            phenotype_parts.append(f\"{name}+++\")\n",
    "        elif z > 0.3:\n",
    "            phenotype_parts.append(f\"{name}++\")\n",
    "        elif z > -0.3:\n",
    "            phenotype_parts.append(f\"{name}+\")\n",
    "        elif z > -1.0:\n",
    "            phenotype_parts.append(f\"{name}<sup>low</sup>\")\n",
    "        else:\n",
    "            phenotype_parts.append(f\"{name}−\")\n",
    "    \n",
    "    # Garder les 6 marqueurs les plus informatifs (top 3 + bottom 3)\n",
    "    top = phenotype_parts[:3]\n",
    "    bottom = phenotype_parts[-3:] if len(phenotype_parts) > 6 else []\n",
    "    \n",
    "    result = \" \".join(top)\n",
    "    if bottom:\n",
    "        result += \" \" + \" \".join(bottom)\n",
    "    return result\n",
    "\n",
    "# Construire le tableau\n",
    "phenotype_rows = []\n",
    "for i in range(N_CLUSTERS):\n",
    "    mc_idx = row_order[i] if i < len(row_order) else i\n",
    "    size = mc_sizes[mc_idx]\n",
    "    pct = size / sum(mc_sizes) * 100\n",
    "    \n",
    "    # Signature phénotypique\n",
    "    zscore_row = mfi_zscore[mc_idx]\n",
    "    phenotype = generate_phenotype_summary(mfi_matrix[mc_idx], used_markers, zscore_row)\n",
    "    \n",
    "    phenotype_rows.append({\n",
    "        \"Métacluster\": f\"MC{mc_idx:02d}\",\n",
    "        \"Taille (%)\": f\"{pct:.1f}\",\n",
    "        \"Phénotype résumé\": phenotype,\n",
    "    })\n",
    "\n",
    "# Trier par taille décroissante\n",
    "phenotype_rows.sort(key=lambda x: float(x[\"Taille (%)\"]), reverse=True)\n",
    "\n",
    "_df_phenotype = pd.DataFrame(phenotype_rows)\n",
    "\n",
    "# Afficher en tant que tableau Plotly\n",
    "fig_phenotype = go.Figure(go.Table(\n",
    "    header=dict(\n",
    "        values=[f\"<b>{c}</b>\" for c in _df_phenotype.columns],\n",
    "        fill_color=\"#4a90d9\",\n",
    "        font=dict(color=\"white\", size=13),\n",
    "        align=[\"center\", \"center\", \"left\"],\n",
    "        height=35,\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[_df_phenotype[c] for c in _df_phenotype.columns],\n",
    "        fill_color=[\n",
    "            [\"#f9f9f9\" if i % 2 == 0 else \"#fff\" for i in range(len(_df_phenotype))]\n",
    "        ] * 3,\n",
    "        font=dict(size=12),\n",
    "        align=[\"center\", \"center\", \"left\"],\n",
    "        height=30,\n",
    "    ),\n",
    "))\n",
    "fig_phenotype.update_layout(\n",
    "    title=dict(\n",
    "        text=\"<b>Signature Phénotypique par Métacluster</b><br>\"\n",
    "             \"<sup>Basé sur l'expression MFI normalisée (+++ / ++ / + / low / −)</sup>\",\n",
    "        font=dict(size=15),\n",
    "    ),\n",
    "    height=50 + 35 * (len(_df_phenotype) + 1),\n",
    "    width=1100,\n",
    "    margin=dict(l=20, r=20, t=70, b=10),\n",
    ")\n",
    "fig_phenotype.show()\n",
    "\n",
    "# Afficher aussi en texte pour copier-coller\n",
    "print(f\"\\n   {'Métacluster':<14} {'Taille (%)':>10}   Phénotype résumé\")\n",
    "print(f\"   {'─'*14} {'─'*10}   {'─'*50}\")\n",
    "for row in phenotype_rows:\n",
    "    # Nettoyer les tags HTML pour l'affichage console\n",
    "    pheno_clean = row['Phénotype résumé'].replace('<sup>', '').replace('</sup>', '')\n",
    "    print(f\"   {row['Métacluster']:<14} {row['Taille (%)']:>10}%  {pheno_clean}\")\n",
    "\n",
    "# =====================================================================\n",
    "# STOCKER GATING REPORTS DANS combined_data.uns (si disponible)\n",
    "# =====================================================================\n",
    "try:\n",
    "    if 'combined_data' in dir() and hasattr(combined_data, 'uns'):\n",
    "        combined_data.uns[\"gating_reports\"] = [gr.to_dict() for gr in gating_reports]\n",
    "        print(f\"\\n[OK] {len(gating_reports)} gating reports stockés dans combined_data.uns['gating_reports']\")\n",
    "except Exception as e:\n",
    "    print(f\"[!] Impossible de stocker gating_reports dans combined_data.uns: {e}\")\n",
    "\n",
    "# Export du gating log JSON\n",
    "try:\n",
    "    if gating_log_entries:\n",
    "        import json\n",
    "        _output_dir = globals().get('OUTPUT_OTHER', '.')\n",
    "        _log_path = os.path.join(_output_dir, \n",
    "                                  f\"gating_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "        with open(_log_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(gating_log_entries, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"[OK] Gating log JSON exporté: {_log_path} ({len(gating_log_entries)} entrées)\")\n",
    "except Exception as e:\n",
    "    print(f\"[!] Erreur export gating log: {e}\")\n",
    "\n",
    "print(\"\\n[OK] Visualisations cliniques complètes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc989dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANALYSE DES CLUSTERS EXCLUSIFS (mono-condition)\n",
    "# =============================================================================\n",
    "# Identification des clusters contenant UNIQUEMENT des cellules d'une condition\n",
    "# Utile pour détecter les populations pathologiques spécifiques\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" ANALYSE DES CLUSTERS EXCLUSIFS PAR CONDITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Récupérer les conditions des cellules\n",
    "cell_conditions = adata_flowsom.obs['condition'].values\n",
    "unique_conditions = np.unique(cell_conditions)\n",
    "\n",
    "print(f\"\\nConditions présentes: {list(unique_conditions)}\")\n",
    "print(f\"Nombre de metaclusters: {n_meta}\")\n",
    "\n",
    "# Analyse par metacluster\n",
    "clusters_patho_only = []\n",
    "clusters_sain_only = []\n",
    "clusters_mixed = []\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\" METACLUSTERS EXCLUSIFS (100% d'une seule condition)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cluster_id in range(1, n_meta + 1):\n",
    "    mask_cluster = (metaclustering_cells == cluster_id)\n",
    "    n_cluster = mask_cluster.sum()\n",
    "    \n",
    "    if n_cluster == 0:\n",
    "        continue\n",
    "    \n",
    "    # Compter les cellules par condition dans ce cluster\n",
    "    conditions_in_cluster = cell_conditions[mask_cluster]\n",
    "    \n",
    "    # Calculer les proportions\n",
    "    condition_counts = {}\n",
    "    for cond in unique_conditions:\n",
    "        count = (conditions_in_cluster == cond).sum()\n",
    "        condition_counts[cond] = count\n",
    "    \n",
    "    # Vérifier si le cluster est exclusif à une condition\n",
    "    total = sum(condition_counts.values())\n",
    "    \n",
    "    # Cluster 100% pathologique\n",
    "    if \"Pathologique\" in condition_counts and condition_counts.get(\"Pathologique\", 0) == total:\n",
    "        clusters_patho_only.append((cluster_id, total))\n",
    "        print(f\"   [PATHO] Metacluster {cluster_id:2d}: {total:6,} cellules (100% Pathologique)\")\n",
    "    \n",
    "    # Cluster 100% sain\n",
    "    elif \"Sain\" in condition_counts and condition_counts.get(\"Sain\", 0) == total:\n",
    "        clusters_sain_only.append((cluster_id, total))\n",
    "        print(f\"   [SAIN]  Metacluster {cluster_id:2d}: {total:6,} cellules (100% Sain)\")\n",
    "    \n",
    "    else:\n",
    "        clusters_mixed.append(cluster_id)\n",
    "\n",
    "# Résumé\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" RÉSUMÉ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if clusters_patho_only:\n",
    "    total_patho_exclusive = sum([c[1] for c in clusters_patho_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% PATHOLOGIQUES: {len(clusters_patho_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_patho_only]}\")\n",
    "    print(f\"    Total cellules: {total_patho_exclusive:,}\")\n",
    "    print(f\"    → Ces clusters représentent des populations UNIQUEMENT présentes chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement pathologique détecté\")\n",
    "\n",
    "if clusters_sain_only:\n",
    "    total_sain_exclusive = sum([c[1] for c in clusters_sain_only])\n",
    "    print(f\"\\n[!] CLUSTERS 100% SAINS: {len(clusters_sain_only)}\")\n",
    "    print(f\"    Metaclusters: {[c[0] for c in clusters_sain_only]}\")\n",
    "    print(f\"    Total cellules: {total_sain_exclusive:,}\")\n",
    "    print(f\"    → Ces clusters représentent des populations ABSENTES chez le patient\")\n",
    "else:\n",
    "    print(f\"\\n    Aucun cluster exclusivement sain détecté\")\n",
    "\n",
    "print(f\"\\n    Clusters mixtes (partagés): {len(clusters_mixed)}\")\n",
    "\n",
    "# Visualisation si clusters exclusifs pathologiques\n",
    "if clusters_patho_only and len(clusters_patho_only) > 0:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\" DÉTAIL DES CLUSTERS PATHOLOGIQUES EXCLUSIFS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Calculer le MFI des marqueurs pour ces clusters\n",
    "    for cluster_id, n_cells in clusters_patho_only:\n",
    "        mask_c = (metaclustering_cells == cluster_id)\n",
    "        print(f\"\\n   Metacluster {cluster_id} ({n_cells:,} cellules):\")\n",
    "        \n",
    "        # Top 3 marqueurs les plus exprimés\n",
    "        mfi_cluster = adata_flowsom.X[mask_c].mean(axis=0)\n",
    "        top_3_idx = np.argsort(mfi_cluster)[-3:][::-1]\n",
    "        print(f\"      Top marqueurs: \", end=\"\")\n",
    "        for idx in top_3_idx:\n",
    "            marker_name = adata_flowsom.var_names[idx]\n",
    "            print(f\"{marker_name}({mfi_cluster[idx]:.2f}) \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0c0fd",
   "metadata": {},
   "source": [
    "## 12. Export des Résultats\n",
    "\n",
    "Sauvegarde des résultats d'analyse:\n",
    "- **CSV**: Tableau avec métaclusters assignés à chaque cellule\n",
    "- **FCS**: Fichier FCS avec colonne métacluster ajoutée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT CSV/FCS AVEC COORDONNÉES SOM (style FlowSOM R EXACT)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Créer le dossier de sortie et ses sous-dossiers\n",
    "OUTPUT_DIR = \"./output\"\n",
    "OUTPUT_FCS = os.path.join(OUTPUT_DIR, \"fcs\")\n",
    "OUTPUT_CSV = os.path.join(OUTPUT_DIR, \"csv\")\n",
    "OUTPUT_OTHER = os.path.join(OUTPUT_DIR, \"other\")\n",
    "os.makedirs(OUTPUT_FCS, exist_ok=True)\n",
    "os.makedirs(OUTPUT_CSV, exist_ok=True)\n",
    "os.makedirs(OUTPUT_OTHER, exist_ok=True)\n",
    "\n",
    "print(\" PRÉPARATION DES DONNÉES POUR EXPORT (style FlowSOM R EXACT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# PARAMÈTRES DE JITTER - STYLE FLOWSOM R EXACT\n",
    "# Dans FlowSOM R, le jitter est CIRCULAIRE (pas carré!)\n",
    "# La taille du cercle dépend du nombre de cellules dans le cluster\n",
    "# Formule R: rnorm() * scale_factor * sqrt(node_size/max_size)\n",
    "# =====================================================================\n",
    "np.random.seed(SEED)  # Pour reproductibilité\n",
    "\n",
    "# Paramètres FlowSOM R\n",
    "MAX_NODE_SIZE = 0.45  # Rayon maximum du cercle (quand le node est le plus grand)\n",
    "MIN_NODE_SIZE = 0.1   # Rayon minimum du cercle (pour éviter que les petits nodes disparaissent)\n",
    "\n",
    "# Récupérer les coordonnées de grille et MST depuis cluster_data\n",
    "grid_coords = cluster_data.obsm.get('grid', None)\n",
    "layout_coords = cluster_data.obsm.get('layout', None)\n",
    "\n",
    "# Récupérer le clustering pour mapper les coordonnées sur chaque cellule\n",
    "clustering = cell_data.obs['clustering'].values\n",
    "n_cells = len(clustering)\n",
    "n_nodes = len(cluster_data)\n",
    "\n",
    "# Calculer la taille de chaque node (nombre de cellules) — VECTORISÉ\n",
    "node_sizes = np.bincount(clustering.astype(int), minlength=n_nodes).astype(np.float32)\n",
    "\n",
    "max_size = node_sizes.max()\n",
    "print(f\"\\n Taille des nodes:\")\n",
    "print(f\"   Min: {node_sizes.min():.0f} cellules\")\n",
    "print(f\"   Max: {max_size:.0f} cellules\")\n",
    "print(f\"   Total: {n_cells} cellules\")\n",
    "\n",
    "# Créer un DataFrame avec toutes les données\n",
    "df_export = pd.DataFrame(X, columns=var_names)\n",
    "\n",
    "# MetaCluster avec +1 pour Kaluza (éviter le 0, commencer à 1)\n",
    "df_export['FlowSOM_metacluster'] = metaclustering + 1\n",
    "\n",
    "# FlowSOM cluster (nodes) avec +1\n",
    "df_export['FlowSOM_cluster'] = clustering + 1\n",
    "\n",
    "# Ajouter les métadonnées si disponibles\n",
    "if 'condition' in cell_data.obs.columns:\n",
    "    df_export['Condition'] = cell_data.obs['condition'].values\n",
    "    df_export['Condition_Num'] = np.where(df_export['Condition'] == 'Sain', 1, 2)\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    df_export['File_Origin'] = cell_data.obs['file_origin'].values\n",
    "\n",
    "# =====================================================================\n",
    "# FONCTION JITTER CIRCULAIRE (style FlowSOM R exact)\n",
    "# Génère des points distribués uniformément dans un disque\n",
    "# Le rayon dépend de la taille du cluster\n",
    "# =====================================================================\n",
    "def circular_jitter(n_points, cluster_ids, node_sizes, max_radius=0.45, min_radius=0.1):\n",
    "    \"\"\"\n",
    "    Génère un jitter circulaire style FlowSOM R.\n",
    "    \n",
    "    Génère un jitter circulaire style FlowSOM R — ENTIÈREMENT VECTORISÉ.\n",
    "    dont le rayon dépend du nombre de cellules dans le node.\n",
    "    Plus un node a de cellules, plus le cercle est grand.\n",
    "    \n",
    "    Méthode: \n",
    "    - Angle theta uniforme [0, 2*pi]\n",
    "    - Rayon r = sqrt(u) * max_r (pour distribution uniforme dans le disque)\n",
    "    - Le max_r dépend de la taille du node\n",
    "    \"\"\"\n",
    "    # Angle uniforme autour du cercle\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n_points)\n",
    "    \n",
    "    # Rayon - distribution uniforme dans le disque (sqrt pour uniformité)\n",
    "    u = np.random.uniform(0, 1, n_points)\n",
    "    \n",
    "    # Calculer le rayon pour chaque cellule selon la taille de son cluster\n",
    "    # Dans FlowSOM R, le rayon est proportionnel à sqrt(node_size/max_size)\n",
    "    # Calculer le rayon pour chaque cellule — VECTORISÉ (pas de boucle)\n",
    "    max_size_val = node_sizes.max()\n",
    "    radii = min_radius + (max_radius - min_radius) * np.sqrt(\n",
    "        node_sizes[cluster_ids.astype(int)] / max_size_val\n",
    "    )\n",
    "    \n",
    "    # Rayon final pour distribution uniforme dans le disque\n",
    "    r = np.sqrt(u) * radii\n",
    "    \n",
    "    # Convertir en coordonnées cartésiennes\n",
    "    jitter_x = r * np.cos(theta)\n",
    "    jitter_y = r * np.sin(theta)\n",
    "    \n",
    "    return jitter_x.astype(np.float32), jitter_y.astype(np.float32)\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONNÉES GRILLE SOM (xGrid, yGrid) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "print(f\"\\n Application du jitter CIRCULAIRE style FlowSOM R\")\n",
    "print(f\"   Rayon min: {MIN_NODE_SIZE}, Rayon max: {MAX_NODE_SIZE}\")\n",
    "\n",
    "if grid_coords is not None:\n",
    "    # Générer jitter CIRCULAIRE dépendant de la taille du node\n",
    "    jitter_x, jitter_y = circular_jitter(n_cells, clustering, node_sizes, \n",
    "                                          max_radius=MAX_NODE_SIZE, \n",
    "                                          min_radius=MIN_NODE_SIZE)\n",
    "    \n",
    "    # Mapper les coordonnées de grille sur chaque cellule\n",
    "    xGrid_base = np.array([grid_coords[int(c), 0] for c in clustering], dtype=np.float32)\n",
    "    yGrid_base = np.array([grid_coords[int(c), 1] for c in clustering], dtype=np.float32)\n",
    "    \n",
    "    # Appliquer le jitter circulaire\n",
    "    xGrid_jittered = xGrid_base + jitter_x\n",
    "    yGrid_jittered = yGrid_base + jitter_y\n",
    "    \n",
    "    # Décaler pour que les axes commencent à 1 (X ET Y)\n",
    "    # Mapper les coordonnées de grille sur chaque cellule — VECTORISÉ\n",
    "    cl_int = clustering.astype(int)\n",
    "    xGrid_base = grid_coords[cl_int, 0].astype(np.float32)\n",
    "    yGrid_base = grid_coords[cl_int, 1].astype(np.float32)\n",
    "    \n",
    "    # Appliquer le jitter circulaire\n",
    "    xGrid_jittered = xGrid_base + jitter_x\n",
    "    yGrid_jittered = yGrid_base + jitter_y\n",
    "    \n",
    "    # Décaler pour que les axes commencent à 1 (X ET Y)\n",
    "    xGrid = xGrid_jittered - xGrid_jittered.min() + 1.0\n",
    "    yGrid = yGrid_jittered - yGrid_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xGrid'] = xGrid.astype(np.float32)\n",
    "    df_export['yGrid'] = yGrid.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xGrid: [{xGrid.min():.3f} - {xGrid.max():.3f}]\")\n",
    "    print(f\"[OK] yGrid: [{yGrid.min():.3f} - {yGrid.max():.3f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# COORDONNÉES MST (xNodes, yNodes) - Style FlowSOM R\n",
    "# =====================================================================\n",
    "    # Mapper les coordonnées MST sur chaque cellule — VECTORISÉ\n",
    "    cl_int = clustering.astype(int)\n",
    "    xNodes_base = layout_coords[cl_int, 0].astype(np.float32)\n",
    "    yNodes_base = layout_coords[cl_int, 1].astype(np.float32)\n",
    "    \n",
    "    # Calculer l'échelle pour le jitter MST (proportionnel à l'espacement moyen)\n",
    "    x_range = xNodes_base.max() - xNodes_base.min()\n",
    "    y_range = yNodes_base.max() - yNodes_base.min()\n",
    "    mst_scale = min(x_range, y_range) / (XDIM * 2)  # Proportionnel à la grille\n",
    "    \n",
    "    # Jitter circulaire pour MST aussi\n",
    "    mst_jitter_x, mst_jitter_y = circular_jitter(\n",
    "        n_cells, clustering, node_sizes,\n",
    "        max_radius=mst_scale * 0.8,  # Un peu moins que Grid car MST est plus espacé\n",
    "        min_radius=mst_scale * 0.2\n",
    "    )\n",
    "    \n",
    "    # Appliquer le jitter\n",
    "    xNodes_jittered = xNodes_base + mst_jitter_x\n",
    "    yNodes_jittered = yNodes_base + mst_jitter_y\n",
    "    \n",
    "    # Décaler pour que les axes commencent à 1 (X ET Y)\n",
    "    xNodes = xNodes_jittered - xNodes_jittered.min() + 1.0\n",
    "    yNodes = yNodes_jittered - yNodes_jittered.min() + 1.0\n",
    "    \n",
    "    df_export['xNodes'] = xNodes.astype(np.float32)\n",
    "    df_export['yNodes'] = yNodes.astype(np.float32)\n",
    "    \n",
    "    print(f\"[OK] xNodes: [{xNodes.min():.3f} - {xNodes.max():.3f}]\")\n",
    "    print(f\"[OK] yNodes: [{yNodes.min():.3f} - {yNodes.max():.3f}]\")\n",
    "\n",
    "# TAILLE DES NODES (pour chaque cellule) — VECTORISÉ\n",
    "# TAILLE DES NODES (pour chaque cellule)\n",
    "size_col = node_sizes[clustering.astype(int)]\n",
    "size_col = np.array([node_sizes[int(c)] for c in clustering], dtype=np.float32)\n",
    "df_export['size'] = size_col\n",
    "print(f\"[OK] size: [{size_col.min():.0f} - {size_col.max():.0f}]\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT CSV\n",
    "# =====================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_path = os.path.join(OUTPUT_DIR, f\"flowsom_results_{timestamp}.csv\")\n",
    "df_export.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n[OK] CSV exporté: {csv_path}\")\n",
    "print(f\"   Shape: {df_export.shape}\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT FCS COMPATIBLE KALUZA\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📄 EXPORT FCS COMPATIBLE KALUZA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def export_to_fcs_kaluza(df, output_path):\n",
    "    \"\"\"Export FCS compatible Kaluza avec toutes les coordonnées positives.\"\"\"\n",
    "    try:\n",
    "        import fcswrite\n",
    "        \n",
    "        numeric_df = df.select_dtypes(include=[np.number])\n",
    "        data = numeric_df.values.astype(np.float32)\n",
    "        channels = list(numeric_df.columns)\n",
    "        \n",
    "        # Nettoyer NaN/Inf\n",
    "        data = np.nan_to_num(data, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "        \n",
    "        print(f\"   {data.shape[0]:,} events, {data.shape[1]} canaux\")\n",
    "        \n",
    "        fcswrite.write_fcs(output_path, channels, data, compat_chn_names=True)\n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"   [!] fcswrite non disponible (pip install fcswrite)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "# Préparer le DataFrame FCS\n",
    "df_fcs = df_export.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Vérifier les ranges\n",
    "print(f\"\\n Colonnes exportées vers FCS:\")\n",
    "for col in ['FlowSOM_metacluster', 'FlowSOM_cluster', 'xGrid', 'yGrid', 'xNodes', 'yNodes', 'size', 'Condition_Num']:\n",
    "    if col in df_fcs.columns:\n",
    "        print(f\"   [OK] {col:25s}: [{df_fcs[col].min():10.2f}, {df_fcs[col].max():10.2f}]\")\n",
    "\n",
    "# Export FCS complet → dossier fcs/\n",
    "fcs_path = os.path.join(OUTPUT_FCS, f\"flowsom_results_{timestamp}.fcs\")\n",
    "if export_to_fcs_kaluza(df_fcs, fcs_path):\n",
    "    print(f\"\\n[OK] FCS exporté: {fcs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT DU RAPPORT DE STATISTIQUES\n",
    "# =============================================================================\n",
    "\n",
    "# Sauvegarder le rapport de statistiques → dossier csv/\n",
    "stats_path = os.path.join(OUTPUT_CSV, f\"flowsom_statistics_{timestamp}.csv\")\n",
    "df_stats.to_csv(stats_path, index=False)\n",
    "print(f\"[OK] Statistiques exportées: {stats_path}\")\n",
    "\n",
    "# Sauvegarder la matrice MFI → dossier csv/\n",
    "mfi_path = os.path.join(OUTPUT_CSV, f\"flowsom_mfi_matrix_{timestamp}.csv\")\n",
    "df_mfi.to_csv(mfi_path)\n",
    "print(f\"[OK] Matrice MFI exportée: {mfi_path}\")\n",
    "\n",
    "# Résumé final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RÉSUMÉ DE L'ANALYSE FLOWSOM\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   Fichiers analysés: {len(all_adatas)}\")\n",
    "print(f\"   Cellules totales: {len(cell_data)}\")\n",
    "print(f\"   Marqueurs utilisés: {len(used_markers)}\")\n",
    "print(f\"   Nombre de métaclusters: {N_CLUSTERS}\")\n",
    "print(f\"   Transformation: {TRANSFORM_TYPE}\")\n",
    "print(f\"   Cofacteur: {COFACTOR}\")\n",
    "if TRANSFORM_TYPE != \"none\":\n",
    "    print(f\"   ⚠️  Export FCS: données BRUTES (transformation inversée pour Kaluza)\")\n",
    "print(\"=\"*80)\n",
    "print(\"[OK] Analyse FlowSOM terminée avec succès!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17109a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT JSON MÉTADONNÉES - TRAÇABILITÉ COMPLÈTE DE L'ANALYSE\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" EXPORT DES MÉTADONNÉES (JSON) → dossier other/\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Collecter toutes les métadonnées de l'analyse\n",
    "metadata = {\n",
    "    \"analysis_info\": {\n",
    "        \"date\": datetime.now().isoformat(),\n",
    "        \"timestamp\": timestamp,\n",
    "        \"pipeline_version\": \"FlowSOM_Analysis_Pipeline v2.0\",\n",
    "    },\n",
    "    \"input_files\": {\n",
    "        \"total_files\": len(all_fcs_files) if 'all_fcs_files' in dir() else len(all_adatas),\n",
    "        \"healthy_files\": [str(f) for f in healthy_files] if 'healthy_files' in dir() else [],\n",
    "        \"pathological_files\": [str(f) for f in patho_files] if 'patho_files' in dir() else [],\n",
    "        \"healthy_folder\": str(HEALTHY_FOLDER) if 'HEALTHY_FOLDER' in dir() else \"N/A\",\n",
    "        \"pathological_folder\": str(PATHOLOGICAL_FOLDER) if 'PATHOLOGICAL_FOLDER' in dir() else \"N/A\",\n",
    "    },\n",
    "    \"preprocessing\": {\n",
    "        \"gating_mode\": GATING_MODE if 'GATING_MODE' in dir() else \"N/A\",\n",
    "        \"gate_doublets\": GATE_DOUBLETS if 'GATE_DOUBLETS' in dir() else \"N/A\",\n",
    "        \"gate_debris\": GATE_DEBRIS if 'GATE_DEBRIS' in dir() else \"N/A\",\n",
    "        \"gate_cd45\": GATE_CD45 if 'GATE_CD45' in dir() else \"N/A\",\n",
    "        \"filter_blasts\": FILTER_BLASTS if 'FILTER_BLASTS' in dir() else \"N/A\",\n",
    "        \"marker_filtering\": {\n",
    "            \"enabled\": APPLY_MARKER_FILTERING,\n",
    "            \"keep_area\": KEEP_AREA,\n",
    "            \"keep_height\": KEEP_HEIGHT,\n",
    "        },\n",
    "    },\n",
    "    \"transformation\": {\n",
    "        \"type\": TRANSFORM_TYPE,\n",
    "        \"cofactor\": COFACTOR,\n",
    "        \"apply_to_scatter\": APPLY_TO_SCATTER,\n",
    "        \"export_data\": \"raw (inverse transform applied)\" if TRANSFORM_TYPE != \"none\" else \"raw (no transform)\",\n",
    "    },\n",
    "    \"flowsom_parameters\": {\n",
    "        \"seed\": SEED,\n",
    "        \"xdim\": XDIM,\n",
    "        \"ydim\": YDIM,\n",
    "        \"n_clusters\": N_CLUSTERS,\n",
    "        \"total_nodes\": XDIM * YDIM,\n",
    "        \"exclude_scatter\": EXCLUDE_SCATTER,\n",
    "    },\n",
    "    \"data_summary\": {\n",
    "        \"total_cells\": int(n_cells),\n",
    "        \"total_markers\": len(var_names),\n",
    "        \"markers_used_for_clustering\": used_markers,\n",
    "        \"all_markers\": var_names,\n",
    "        \"cells_per_condition\": {\n",
    "            cond: int((cell_data.obs['condition'] == cond).sum())\n",
    "            for cond in cell_data.obs['condition'].unique()\n",
    "        } if 'condition' in cell_data.obs.columns else {},\n",
    "        \"cells_per_file\": {\n",
    "            fname: int((cell_data.obs['file_origin'] == fname).sum())\n",
    "            for fname in cell_data.obs['file_origin'].unique()\n",
    "        } if 'file_origin' in cell_data.obs.columns else {},\n",
    "    },\n",
    "    \"metacluster_summary\": {\n",
    "        f\"MC{i}\": {\n",
    "            \"n_cells\": int((metaclustering == i).sum()),\n",
    "            \"pct_total\": round(float((metaclustering == i).sum() / len(metaclustering) * 100), 2),\n",
    "        }\n",
    "        for i in range(N_CLUSTERS)\n",
    "    },\n",
    "    \"export_files\": {\n",
    "        \"fcs_complete\": fcs_path,\n",
    "        \"csv_complete\": csv_path,\n",
    "        \"statistics\": stats_path if 'stats_path' in dir() else \"N/A\",\n",
    "        \"mfi_matrix\": mfi_path if 'mfi_path' in dir() else \"N/A\",\n",
    "    },\n",
    "    \"export_folders\": {\n",
    "        \"fcs\": OUTPUT_FCS,\n",
    "        \"csv\": OUTPUT_CSV,\n",
    "        \"other\": OUTPUT_OTHER,\n",
    "    },\n",
    "    \"jitter_parameters\": {\n",
    "        \"max_node_size\": MAX_NODE_SIZE,\n",
    "        \"min_node_size\": MIN_NODE_SIZE,\n",
    "        \"method\": \"circular_jitter (style FlowSOM R)\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Sauvegarder le JSON → dossier other/\n",
    "metadata_path = os.path.join(OUTPUT_OTHER, f\"flowsom_metadata_{timestamp}.json\")\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"\\n[OK] Métadonnées exportées: {metadata_path}\")\n",
    "print(f\"\\nContenu du fichier:\")\n",
    "print(f\"   - Informations d'analyse (date, version)\")\n",
    "print(f\"   - Fichiers source ({metadata['input_files']['total_files']} fichiers)\")\n",
    "print(f\"   - Paramètres de preprocessing (gating, filtrage)\")\n",
    "print(f\"   - Paramètres de transformation ({TRANSFORM_TYPE}, cofactor={COFACTOR})\")\n",
    "print(f\"   - Paramètres FlowSOM (grille {XDIM}x{YDIM}, {N_CLUSTERS} métaclusters)\")\n",
    "print(f\"   - Résumé des données ({n_cells:,} cellules, {len(used_markers)} marqueurs)\")\n",
    "print(f\"   - Résumé par métacluster\")\n",
    "print(f\"   - Chemins des fichiers exportés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT PAR CONDITION (Sain vs Pathologique) + COLONNE TIMEPOINT\n",
    "# =============================================================================\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" EXPORT PAR CONDITION + TIMEPOINT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# AJOUT DE LA COLONNE TIMEPOINT (extraction depuis le nom de fichier)\n",
    "# =====================================================================\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"Extrait une date depuis un nom de fichier FCS.\"\"\"\n",
    "    patterns = [\n",
    "        r'(\\d{2}[-/]\\d{2}[-/]\\d{4})',  # DD-MM-YYYY ou DD/MM/YYYY\n",
    "        r'(\\d{4}[-/]\\d{2}[-/]\\d{2})',  # YYYY-MM-DD ou YYYY/MM/DD\n",
    "        r'(\\d{2}[-/]\\d{2}[-/]\\d{2})',  # DD-MM-YY\n",
    "        r'(\\d{8})',                      # YYYYMMDD\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, str(filename))\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return \"unknown\"\n",
    "\n",
    "# Créer la colonne timepoint\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    file_origins_arr = cell_data.obs['file_origin'].values\n",
    "    \n",
    "    unique_files = list(set(file_origins_arr))\n",
    "    file_to_date = {f: extract_date_from_filename(f) for f in unique_files}\n",
    "    \n",
    "    timepoints = np.array([file_to_date[str(f)] for f in file_origins_arr])\n",
    "    df_export['Timepoint'] = timepoints\n",
    "    \n",
    "    unique_dates = sorted(set(timepoints))\n",
    "    date_to_idx = {d: i+1 for i, d in enumerate(unique_dates)}\n",
    "    df_export['Timepoint_Num'] = np.array([date_to_idx[t] for t in timepoints])\n",
    "    \n",
    "    print(f\"\\n[OK] Colonne 'Timepoint' ajoutée\")\n",
    "    print(f\"   Dates détectées: {len(unique_dates)}\")\n",
    "    for dt in unique_dates:\n",
    "        n_dt = (timepoints == dt).sum()\n",
    "        print(f\"   [{date_to_idx[dt]}] {dt}: {n_dt:,} cellules\")\n",
    "else:\n",
    "    print(\"[INFO] Pas de colonne 'file_origin' — Timepoint non créé\")\n",
    "\n",
    "# =====================================================================\n",
    "# EXPORT SÉPARÉ PAR CONDITION → dossiers fcs/ et csv/\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" EXPORT SÉPARÉ PAR CONDITION → fcs/ et csv/\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'Condition' in df_export.columns:\n",
    "    conditions_list = df_export['Condition'].unique()\n",
    "    \n",
    "    for cond in conditions_list:\n",
    "        mask_cond = df_export['Condition'] == cond\n",
    "        df_cond = df_export[mask_cond].copy()\n",
    "        \n",
    "        # Export CSV par condition → dossier csv/\n",
    "        cond_safe = str(cond).replace(' ', '_').replace('/', '-')\n",
    "        csv_cond_path = os.path.join(OUTPUT_CSV, f\"flowsom_{cond_safe}_{timestamp}.csv\")\n",
    "        df_cond.to_csv(csv_cond_path, index=False)\n",
    "        \n",
    "        # Export FCS par condition → dossier fcs/\n",
    "        fcs_cond_path = os.path.join(OUTPUT_FCS, f\"flowsom_{cond_safe}_{timestamp}.fcs\")\n",
    "        df_cond_numeric = df_cond.select_dtypes(include=[np.number]).copy()\n",
    "        export_to_fcs_kaluza(df_cond_numeric, fcs_cond_path)\n",
    "        \n",
    "        print(f\"\\n[OK] Condition '{cond}':\")\n",
    "        print(f\"   Cellules: {len(df_cond):,}\")\n",
    "        print(f\"   CSV: {csv_cond_path}\")\n",
    "        print(f\"   FCS: {fcs_cond_path}\")\n",
    "        \n",
    "        # Résumé des métaclusters par condition\n",
    "        mc_counts = df_cond['FlowSOM_metacluster'].value_counts().sort_index()\n",
    "        mc_pcts = (mc_counts / len(df_cond) * 100).round(1)\n",
    "        print(f\"   Métaclusters:\")\n",
    "        for mc, (cnt, pct) in enumerate(zip(mc_counts.values, mc_pcts.values)):\n",
    "            print(f\"      MC{mc+1}: {cnt:>7,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Export aussi par fichier si plusieurs fichiers\n",
    "    if 'File_Origin' in df_export.columns:\n",
    "        unique_files_export = df_export['File_Origin'].unique()\n",
    "        if len(unique_files_export) > 1:\n",
    "            print(f\"\\n\" + \"-\"*70)\n",
    "            print(f\" EXPORT PAR FICHIER ({len(unique_files_export)} fichiers) → csv/\")\n",
    "            print(f\"-\"*70)\n",
    "            \n",
    "            for fname in unique_files_export:\n",
    "                mask_file = df_export['File_Origin'] == fname\n",
    "                df_file = df_export[mask_file].copy()\n",
    "                \n",
    "                fname_safe = str(fname).replace(' ', '_').replace('/', '-').replace('.fcs', '')\n",
    "                csv_file_path = os.path.join(OUTPUT_CSV, f\"flowsom_{fname_safe}_{timestamp}.csv\")\n",
    "                df_file.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                print(f\"   [OK] {fname}: {len(df_file):,} cellules → {csv_file_path}\")\n",
    "else:\n",
    "    print(\"[INFO] Pas de colonne 'Condition' — Export par condition non disponible\")\n",
    "\n",
    "print(f\"\\n[OK] Tous les exports par condition/fichier terminés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT RAPPORT HTML COMPLET — VISUALISATIONS INTERACTIVES PLOTLY + IMAGES\n",
    "# =============================================================================\n",
    "# Ce rapport HTML est autonome (self-contained): il inclut toutes les\n",
    "# visualisations Plotly interactives en temps réel + les figures matplotlib\n",
    "# converties en images base64 inline. Pas de dépendance externe.\n",
    "# =============================================================================\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import plotly.io as pio\n",
    "import plotly.offline\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" GÉNÉRATION DU RAPPORT HTML COMPLET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# RÉCUPÉRATION DU BUNDLE PLOTLY.JS POUR HTML SELF-CONTAINED\n",
    "# =====================================================================\n",
    "# On embarque plotly.js directement dans le HTML pour que le rapport\n",
    "# fonctionne hors-ligne, sans dépendance CDN.\n",
    "plotly_js_bundle = plotly.offline.get_plotlyjs()\n",
    "print(f\"   [OK] Plotly.js embarqué ({len(plotly_js_bundle)//1024} KB)\")\n",
    "\n",
    "# =====================================================================\n",
    "# COLLECTE DE TOUTES LES FIGURES\n",
    "# =====================================================================\n",
    "\n",
    "# --- Convertir les figures Matplotlib en base64 PNG ---\n",
    "def fig_to_base64(fig_mpl):\n",
    "    \"\"\"Convertit une figure matplotlib en string base64 PNG.\"\"\"\n",
    "    buf = BytesIO()\n",
    "    fig_mpl.savefig(buf, format='png', dpi=150, bbox_inches='tight',\n",
    "                    facecolor='white', edgecolor='none')\n",
    "    buf.seek(0)\n",
    "    return base64.b64encode(buf.read()).decode('utf-8')\n",
    "\n",
    "# --- Convertir les figures Plotly en HTML div ---\n",
    "def plotly_to_html_div(fig_plotly, fig_id=\"\"):\n",
    "    \"\"\"Convertit une figure Plotly en div HTML avec interactivité.\n",
    "    Utilise la hauteur définie dans le layout de la figure pour préserver\n",
    "    les dimensions originales (ex: spider plot 750px).\n",
    "    include_plotlyjs=False car plotly.js est embarqué dans le <head>.\n",
    "    \"\"\"\n",
    "    fig_height = fig_plotly.layout.height or 500\n",
    "    fig_width_val = fig_plotly.layout.width\n",
    "    default_w = f'{fig_width_val}px' if fig_width_val else '100%'\n",
    "    return pio.to_html(\n",
    "        fig_plotly,\n",
    "        full_html=False,\n",
    "        include_plotlyjs=False,\n",
    "        div_id=fig_id if fig_id else None,\n",
    "        default_height=f'{fig_height}px',\n",
    "        default_width=default_w,\n",
    "        config={'responsive': True}\n",
    "    )\n",
    "\n",
    "# Collecter les figures matplotlib existantes\n",
    "mpl_figures = {}\n",
    "plotly_figures = {}\n",
    "\n",
    "# Chercher toutes les variables de type Figure dans le namespace\n",
    "import matplotlib.figure\n",
    "\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, matplotlib.figure.Figure):\n",
    "        try:\n",
    "            mpl_figures[name] = fig_to_base64(obj)\n",
    "            print(f\"   [OK] Figure matplotlib: {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   [!] Erreur {name}: {e}\")\n",
    "\n",
    "# Chercher toutes les figures Plotly — on stocke les OBJETS Figure\n",
    "# pour les convertir en HTML avec les bonnes dimensions\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly_figure_objects = {}\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, go.Figure):\n",
    "        try:\n",
    "            # Vérifier que la figure contient des données\n",
    "            n_traces = len(obj.data)\n",
    "            plotly_figure_objects[name] = obj\n",
    "            print(f\"   [OK] Figure Plotly: {name} ({n_traces} traces, h={obj.layout.height or 'auto'})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   [!] Erreur {name}: {e}\")\n",
    "\n",
    "print(f\"\\n   Total: {len(mpl_figures)} figures matplotlib, {len(plotly_figure_objects)} figures Plotly\")\n",
    "\n",
    "# =====================================================================\n",
    "# CONSTRUCTION DU HTML\n",
    "# =====================================================================\n",
    "\n",
    "# Noms lisibles pour les figures\n",
    "figure_labels = {\n",
    "    'fig': 'Aperçu général',\n",
    "    'fig1': 'Visualisation 1',\n",
    "    'fig2': 'Visualisation 2',\n",
    "    'fig3': 'Visualisation 3',\n",
    "    'fig4': 'Visualisation 4',\n",
    "    'fig5': 'Visualisation 5',\n",
    "    'fig_stars': 'Star Chart FlowSOM',\n",
    "    'fig_comp': 'Comparaison Conditions',\n",
    "    'fig_gates': 'Gates de pré-traitement',\n",
    "    'fig_grid_mc': 'Grille SOM — Métaclusters',\n",
    "    'fig_grid_cond': 'Grille SOM — Conditions',\n",
    "    'fig_hist': 'Histogrammes des marqueurs',\n",
    "    'fig_mst': 'Arbre MST',\n",
    "    'fig_overview': 'Vue d\\'ensemble',\n",
    "    'fig_radar': 'Spider Plot — Profils MFI',\n",
    "    'fig_sankey': 'Diagramme Sankey',\n",
    "    'fig_table': 'Tableau résumé',\n",
    "    'fig_table_cond': 'Tableau par condition',\n",
    "    'fig_ransac_qc': 'QC RANSAC — Scatter FSC-A vs FSC-H',\n",
    "    'fig_singlets_table': 'QC Singlets — Tableau par fichier',\n",
    "    'fig_heatmap': 'Heatmap MFI — Métaclusters × Marqueurs (Z-score)',\n",
    "    'fig_heatmap_clinical': 'Expression Phénotypique — Métaclusters × Marqueurs',\n",
    "    'fig_barplots': 'Marqueurs Clés — NBM vs Pathologique',\n",
    "    'fig_phenotype': 'Signature Phénotypique par Métacluster',\n",
    "}\n",
    "\n",
    "# --- Statistiques par métacluster pour le tableau HTML ---\n",
    "mc_rows_html = \"\"\n",
    "for i in range(N_CLUSTERS):\n",
    "    mask_mc = metaclustering == i\n",
    "    n_mc = int(mask_mc.sum())\n",
    "    pct_mc = n_mc / len(metaclustering) * 100\n",
    "    \n",
    "    # MFI top 3\n",
    "    if n_mc > 0:\n",
    "        mfi_mc = np.nanmean(X[mask_mc][:, cols_to_use], axis=0)\n",
    "        top3_idx = np.argsort(mfi_mc)[::-1][:3]\n",
    "        top3 = ', '.join([used_markers[j] for j in top3_idx])\n",
    "    else:\n",
    "        top3 = \"N/A\"\n",
    "    \n",
    "    mc_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "        <td style=\"font-weight:bold; text-align:center;\">MC{i+1}</td>\n",
    "        <td style=\"text-align:right;\">{n_mc:,}</td>\n",
    "        <td style=\"text-align:right;\">{pct_mc:.1f}%</td>\n",
    "        <td>{top3}</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# --- Cellules par condition ---\n",
    "cond_rows_html = \"\"\n",
    "if 'condition' in cell_data.obs.columns:\n",
    "    for cond in cell_data.obs['condition'].unique():\n",
    "        n_cond = int((cell_data.obs['condition'] == cond).sum())\n",
    "        pct_cond = n_cond / len(cell_data) * 100\n",
    "        cond_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "        <td style=\"font-weight:bold;\">{cond}</td>\n",
    "        <td style=\"text-align:right;\">{n_cond:,}</td>\n",
    "        <td style=\"text-align:right;\">{pct_cond:.1f}%</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# --- Fichiers source ---\n",
    "files_rows_html = \"\"\n",
    "if 'file_origin' in cell_data.obs.columns:\n",
    "    for fname in cell_data.obs['file_origin'].unique():\n",
    "        n_f = int((cell_data.obs['file_origin'] == fname).sum())\n",
    "        files_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "        <td>{fname}</td>\n",
    "        <td style=\"text-align:right;\">{n_f:,}</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# --- Sections Plotly (conversion des objets Figure → HTML divs) ---\n",
    "plotly_sections = \"\"\n",
    "for _fig_name, _fig_iter in plotly_figure_objects.items():\n",
    "    label = figure_labels.get(_fig_name, _fig_name)\n",
    "    try:\n",
    "        div_html = plotly_to_html_div(_fig_iter, fig_id=_fig_name)\n",
    "        plotly_sections += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h2>{label}</h2>\n",
    "        <div class=\"plotly-container\">\n",
    "            {div_html}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    except Exception as e:\n",
    "        print(f\"   [!] Erreur conversion HTML pour {_fig_name}: {e}\")\n",
    "del _fig_name, _fig_iter  # Éviter que la variable de boucle se retrouve comme figure\n",
    "\n",
    "# --- Sections Matplotlib ---\n",
    "mpl_sections = \"\"\n",
    "for name, b64 in mpl_figures.items():\n",
    "    label = figure_labels.get(name, name)\n",
    "    mpl_sections += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h2>{label}</h2>\n",
    "        <div style=\"text-align:center;\">\n",
    "            <img src=\"data:image/png;base64,{b64}\" style=\"max-width:100%; border-radius:8px; box-shadow:0 2px 8px rgba(0,0,0,0.1);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "# --- Marqueurs utilisés ---\n",
    "markers_html = \"\"\n",
    "for i, m in enumerate(used_markers):\n",
    "    markers_html += f'<span class=\"marker-badge\">{m}</span>\\n'\n",
    "\n",
    "# =====================================================================\n",
    "# TEMPLATE HTML COMPLET\n",
    "# =====================================================================\n",
    "# Note: On utilise un placeholder __PLOTLY_JS_BUNDLE__ pour le script\n",
    "# plotly.js car le bundle fait ~3.5 MB et ne doit pas être dans le f-string.\n",
    "# Il sera remplacé après la construction du template.\n",
    "\n",
    "html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>FlowSOM Analysis Report — {timestamp}</title>\n",
    "    <script type=\"text/javascript\">__PLOTLY_JS_BUNDLE__</script>\n",
    "    <style>\n",
    "        :root {{\n",
    "            --primary: #667eea;\n",
    "            --primary-dark: #764ba2;\n",
    "            --bg: #f8f9fa;\n",
    "            --card-bg: #ffffff;\n",
    "            --text: #2d3748;\n",
    "            --text-light: #718096;\n",
    "            --border: #e2e8f0;\n",
    "            --success: #48bb78;\n",
    "            --warning: #ed8936;\n",
    "        }}\n",
    "        \n",
    "        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n",
    "        \n",
    "        body {{\n",
    "            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;\n",
    "            background: var(--bg);\n",
    "            color: var(--text);\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "        \n",
    "        .header {{\n",
    "            background: linear-gradient(135deg, var(--primary), var(--primary-dark));\n",
    "            color: white;\n",
    "            padding: 40px 0;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "        }}\n",
    "        \n",
    "        .header h1 {{\n",
    "            font-size: 2.2em;\n",
    "            margin-bottom: 8px;\n",
    "            font-weight: 700;\n",
    "        }}\n",
    "        \n",
    "        .header .subtitle {{\n",
    "            font-size: 1.1em;\n",
    "            opacity: 0.9;\n",
    "        }}\n",
    "        \n",
    "        .container {{\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            padding: 0 20px;\n",
    "        }}\n",
    "        \n",
    "        .section {{\n",
    "            background: var(--card-bg);\n",
    "            border-radius: 12px;\n",
    "            padding: 30px;\n",
    "            margin-bottom: 24px;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.08);\n",
    "            border: 1px solid var(--border);\n",
    "        }}\n",
    "        \n",
    "        .section h2 {{\n",
    "            font-size: 1.4em;\n",
    "            color: var(--primary);\n",
    "            margin-bottom: 20px;\n",
    "            padding-bottom: 10px;\n",
    "            border-bottom: 2px solid var(--border);\n",
    "        }}\n",
    "        \n",
    "        .grid-2 {{\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr 1fr;\n",
    "            gap: 20px;\n",
    "        }}\n",
    "        \n",
    "        .grid-3 {{\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr 1fr 1fr;\n",
    "            gap: 20px;\n",
    "        }}\n",
    "        \n",
    "        .stat-card {{\n",
    "            background: linear-gradient(135deg, #f6f8ff, #f0f4ff);\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "            border: 1px solid #dde4f0;\n",
    "        }}\n",
    "        \n",
    "        .stat-card .value {{\n",
    "            font-size: 2em;\n",
    "            font-weight: 700;\n",
    "            color: var(--primary);\n",
    "        }}\n",
    "        \n",
    "        .stat-card .label {{\n",
    "            font-size: 0.9em;\n",
    "            color: var(--text-light);\n",
    "            margin-top: 4px;\n",
    "        }}\n",
    "        \n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        \n",
    "        th {{\n",
    "            background: linear-gradient(135deg, var(--primary), var(--primary-dark));\n",
    "            color: white;\n",
    "            padding: 12px 16px;\n",
    "            text-align: left;\n",
    "            font-weight: 600;\n",
    "        }}\n",
    "        \n",
    "        td {{\n",
    "            padding: 10px 16px;\n",
    "            border-bottom: 1px solid var(--border);\n",
    "        }}\n",
    "        \n",
    "        tr:nth-child(even) {{\n",
    "            background: #f7fafc;\n",
    "        }}\n",
    "        \n",
    "        tr:hover {{\n",
    "            background: #edf2f7;\n",
    "        }}\n",
    "        \n",
    "        .marker-badge {{\n",
    "            display: inline-block;\n",
    "            background: linear-gradient(135deg, #667eea22, #764ba222);\n",
    "            color: var(--primary-dark);\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 0.85em;\n",
    "            margin: 3px;\n",
    "            border: 1px solid #667eea44;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "        \n",
    "        .plotly-container {{\n",
    "            width: 100%;\n",
    "            overflow-x: auto;\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "        }}\n",
    "        \n",
    "        .plotly-container > div {{\n",
    "            min-width: 0;\n",
    "        }}\n",
    "        \n",
    "        .param-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));\n",
    "            gap: 12px;\n",
    "        }}\n",
    "        \n",
    "        .param-item {{\n",
    "            background: #f7fafc;\n",
    "            padding: 10px 15px;\n",
    "            border-radius: 8px;\n",
    "            border-left: 3px solid var(--primary);\n",
    "        }}\n",
    "        \n",
    "        .param-item .param-label {{\n",
    "            font-size: 0.8em;\n",
    "            color: var(--text-light);\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 0.5px;\n",
    "        }}\n",
    "        \n",
    "        .param-item .param-value {{\n",
    "            font-size: 1.1em;\n",
    "            font-weight: 600;\n",
    "            color: var(--text);\n",
    "        }}\n",
    "        \n",
    "        .toc {{\n",
    "            background: #f0f4ff;\n",
    "            border-radius: 10px;\n",
    "            padding: 20px 30px;\n",
    "            margin-bottom: 24px;\n",
    "        }}\n",
    "        \n",
    "        .toc h3 {{\n",
    "            margin-bottom: 10px;\n",
    "            color: var(--primary-dark);\n",
    "        }}\n",
    "        \n",
    "        .toc ul {{\n",
    "            list-style: none;\n",
    "            columns: 2;\n",
    "        }}\n",
    "        \n",
    "        .toc li {{\n",
    "            padding: 4px 0;\n",
    "        }}\n",
    "        \n",
    "        .toc a {{\n",
    "            color: var(--primary);\n",
    "            text-decoration: none;\n",
    "        }}\n",
    "        \n",
    "        .toc a:hover {{\n",
    "            text-decoration: underline;\n",
    "        }}\n",
    "        \n",
    "        .footer {{\n",
    "            text-align: center;\n",
    "            padding: 30px;\n",
    "            color: var(--text-light);\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        \n",
    "        @media (max-width: 768px) {{\n",
    "            .grid-2, .grid-3 {{ grid-template-columns: 1fr; }}\n",
    "            .toc ul {{ columns: 1; }}\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<!-- HEADER -->\n",
    "<div class=\"header\">\n",
    "    <div class=\"container\">\n",
    "        <h1>FlowSOM Analysis Report</h1>\n",
    "        <div class=\"subtitle\">\n",
    "            Analyse générée le {datetime.now().strftime('%d/%m/%Y à %H:%M')} — \n",
    "            {n_cells:,} cellules · {len(used_markers)} marqueurs · {N_CLUSTERS} métaclusters\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"container\">\n",
    "\n",
    "<!-- TABLE DES MATIÈRES -->\n",
    "<div class=\"toc\">\n",
    "    <h3>Table des matières</h3>\n",
    "    <ul>\n",
    "        <li><a href=\"#params\">1. Paramètres de l'analyse</a></li>\n",
    "        <li><a href=\"#data\">2. Résumé des données</a></li>\n",
    "        <li><a href=\"#markers\">3. Marqueurs utilisés</a></li>\n",
    "        <li><a href=\"#metaclusters\">4. Métaclusters</a></li>\n",
    "        <li><a href=\"#plotly-viz\">5. Visualisations interactives</a></li>\n",
    "        <li><a href=\"#static-viz\">6. Visualisations statiques</a></li>\n",
    "        <li><a href=\"#exports\">7. Fichiers exportés</a></li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<!-- 1. PARAMÈTRES -->\n",
    "<div class=\"section\" id=\"params\">\n",
    "    <h2>1. Paramètres de l'Analyse</h2>\n",
    "    <div class=\"param-grid\">\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Transformation</div>\n",
    "            <div class=\"param-value\">{TRANSFORM_TYPE.upper()}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Cofacteur</div>\n",
    "            <div class=\"param-value\">{COFACTOR}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Grille SOM</div>\n",
    "            <div class=\"param-value\">{XDIM} × {YDIM} ({XDIM*YDIM} nodes)</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Métaclusters</div>\n",
    "            <div class=\"param-value\">{N_CLUSTERS}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Seed</div>\n",
    "            <div class=\"param-value\">{SEED}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Filtrage marqueurs</div>\n",
    "            <div class=\"param-value\">{'Area (-A)' if KEEP_AREA else ''} {'Height (-H)' if KEEP_HEIGHT else ''}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Gating mode</div>\n",
    "            <div class=\"param-value\">{GATING_MODE if 'GATING_MODE' in dir() else 'N/A'}</div>\n",
    "        </div>\n",
    "        <div class=\"param-item\">\n",
    "            <div class=\"param-label\">Exclure Scatter</div>\n",
    "            <div class=\"param-value\">{'Oui' if EXCLUDE_SCATTER else 'Non'}</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- 2. RÉSUMÉ DES DONNÉES -->\n",
    "<div class=\"section\" id=\"data\">\n",
    "    <h2>2. Résumé des Données</h2>\n",
    "    <div class=\"grid-3\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"value\">{n_cells:,}</div>\n",
    "            <div class=\"label\">Cellules totales</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"value\">{len(used_markers)}</div>\n",
    "            <div class=\"label\">Marqueurs (clustering)</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"value\">{len(all_adatas) if 'all_adatas' in dir() else 'N/A'}</div>\n",
    "            <div class=\"label\">Fichiers analysés</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <h3 style=\"margin-top:25px; margin-bottom:10px;\">Par condition</h3>\n",
    "    <table>\n",
    "        <tr><th>Condition</th><th>Cellules</th><th>Pourcentage</th></tr>\n",
    "        {cond_rows_html}\n",
    "    </table>\n",
    "    \n",
    "    <h3 style=\"margin-top:25px; margin-bottom:10px;\">Par fichier source</h3>\n",
    "    <table>\n",
    "        <tr><th>Fichier</th><th>Cellules</th></tr>\n",
    "        {files_rows_html}\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<!-- 3. MARQUEURS -->\n",
    "<div class=\"section\" id=\"markers\">\n",
    "    <h2>3. Marqueurs Utilisés pour le Clustering</h2>\n",
    "    <p style=\"margin-bottom:15px; color:var(--text-light);\">\n",
    "        {len(used_markers)} marqueurs sélectionnés (scatter et Time exclus)\n",
    "    </p>\n",
    "    {markers_html}\n",
    "</div>\n",
    "\n",
    "<!-- 4. MÉTACLUSTERS -->\n",
    "<div class=\"section\" id=\"metaclusters\">\n",
    "    <h2>4. Résumé des Métaclusters</h2>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>Métacluster</th>\n",
    "            <th>Cellules</th>\n",
    "            <th>% Total</th>\n",
    "            <th>Top 3 Marqueurs</th>\n",
    "        </tr>\n",
    "        {mc_rows_html}\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<!-- 5. VISUALISATIONS PLOTLY (INTERACTIVES) -->\n",
    "<div id=\"plotly-viz\">\n",
    "    <div class=\"section\">\n",
    "        <h2>5. Visualisations Interactives (Plotly)</h2>\n",
    "        <p style=\"color:var(--text-light); margin-bottom:10px;\">\n",
    "            {len(plotly_figure_objects)} figures interactives — zoom, pan, hover pour explorer les données\n",
    "        </p>\n",
    "    </div>\n",
    "    {plotly_sections}\n",
    "</div>\n",
    "\n",
    "<!-- 6. VISUALISATIONS MATPLOTLIB (STATIQUES) -->\n",
    "<div id=\"static-viz\">\n",
    "    <div class=\"section\">\n",
    "        <h2>6. Visualisations Statiques (Matplotlib)</h2>\n",
    "        <p style=\"color:var(--text-light); margin-bottom:10px;\">\n",
    "            {len(mpl_figures)} figures haute résolution\n",
    "        </p>\n",
    "    </div>\n",
    "    {mpl_sections}\n",
    "</div>\n",
    "\n",
    "<!-- 7. FICHIERS EXPORTÉS -->\n",
    "<div class=\"section\" id=\"exports\">\n",
    "    <h2>7. Fichiers Exportés</h2>\n",
    "    <table>\n",
    "        <tr><th>Type</th><th>Fichier</th></tr>\n",
    "        <tr><td>CSV complet</td><td>{csv_path}</td></tr>\n",
    "        <tr><td>FCS (Kaluza compatible)</td><td>{fcs_path}</td></tr>\n",
    "        <tr><td>Statistiques</td><td>{stats_path if 'stats_path' in dir() else 'N/A'}</td></tr>\n",
    "        <tr><td>Matrice MFI</td><td>{mfi_path if 'mfi_path' in dir() else 'N/A'}</td></tr>\n",
    "        <tr><td>Métadonnées JSON</td><td>{metadata_path}</td></tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "<!-- FOOTER -->\n",
    "<div class=\"footer\">\n",
    "    <p>FlowSOM Analysis Pipeline v2.0 — Rapport généré automatiquement le {datetime.now().strftime('%d/%m/%Y à %H:%M:%S')}</p>\n",
    "    <p>Transformation: {TRANSFORM_TYPE.upper()} (cofactor={COFACTOR}) · Grille: {XDIM}×{YDIM} · {N_CLUSTERS} métaclusters · Seed: {SEED}</p>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# =====================================================================\n",
    "# INJECTION DU BUNDLE PLOTLY.JS (self-contained, pas de CDN)\n",
    "# =====================================================================\n",
    "# On remplace le placeholder par le vrai code plotly.js.\n",
    "# Cela rend le HTML autonome (~3-4 MB de JS embarqué).\n",
    "html_content = html_content.replace('__PLOTLY_JS_BUNDLE__', plotly_js_bundle)\n",
    "\n",
    "# =====================================================================\n",
    "# SAUVEGARDE DU RAPPORT HTML → dossier other/\n",
    "# =====================================================================\n",
    "html_path = os.path.join(OUTPUT_OTHER, f\"flowsom_report_{timestamp}.html\")\n",
    "with open(html_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "# Taille du fichier\n",
    "html_size_mb = os.path.getsize(html_path) / (1024 * 1024)\n",
    "\n",
    "print(f\"\\n[OK] Rapport HTML exporté: {html_path}\")\n",
    "print(f\"   Taille: {html_size_mb:.1f} MB (plotly.js embarqué = self-contained)\")\n",
    "print(f\"   Figures Plotly interactives: {len(plotly_figure_objects)}\")\n",
    "print(f\"   Figures Matplotlib (images): {len(mpl_figures)}\")\n",
    "print(f\"\\n   Ouvrez le fichier dans un navigateur pour explorer les données\")\n",
    "print(f\"   Les figures Plotly sont entièrement interactives (zoom, hover, etc.)\")\n",
    "print(f\"   Le rapport fonctionne HORS-LIGNE (pas de dépendance CDN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc03dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECTION DES VARIABLES DU NOTEBOOK\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" LISTE DES OBJETS AnnData\")\n",
    "print(\"=\"*70)\n",
    "%who AnnData\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" LISTE DES DataFrames\")\n",
    "print(\"=\"*70)\n",
    "%who DataFrame\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" DÉTAILS DE adata_flowsom\")\n",
    "print(\"=\"*70)\n",
    "print(adata_flowsom)\n",
    "\n",
    "print(\"\\n- Shape:\", adata_flowsom.shape)\n",
    "print(\"- Variables (colonnes):\", list(adata_flowsom.var_names))\n",
    "print(\"- Observations (fichiers):\", adata_flowsom.obs.columns.tolist() if len(adata_flowsom.obs.columns) > 0 else \"Aucune annotation\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Statistiques de la matrice X:\")\n",
    "print(\"-\"*70)\n",
    "import pandas as pd\n",
    "stats = pd.DataFrame({\n",
    "    'Colonne': adata_flowsom.var_names,\n",
    "    'Min': adata_flowsom.X.min(axis=0),\n",
    "    'Max': adata_flowsom.X.max(axis=0),\n",
    "    'Moyenne': adata_flowsom.X.mean(axis=0),\n",
    "    'Std': adata_flowsom.X.std(axis=0)\n",
    "})\n",
    "display(stats)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Aperçu des observations (.obs):\")\n",
    "print(\"-\"*70)\n",
    "if adata_flowsom.obs.shape[1] > 0:\n",
    "    display(adata_flowsom.obs.head(10))\n",
    "else:\n",
    "    print(\"Aucune annotation dans .obs\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"- Toutes les variables disponibles:\")\n",
    "print(\"-\"*70)\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e481f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FLOWSOM SUMMARY - RAPPORT PDF COMPLET\n",
    "# =============================================================================\n",
    "# Génération automatique d'un PDF récapitulatif avec toutes les visualisations\n",
    "# Documentation: https://flowsom.readthedocs.io/en/stable/generated/flowsom.pl.FlowSOMmary.html\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Chemin du fichier PDF de sortie → dossier other/\n",
    "summary_pdf_path = os.path.join(OUTPUT_OTHER, f\"FlowSOMmary_{timestamp}.pdf\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" GÉNÉRATION DU RAPPORT FlowSOMmary (PDF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Génération du rapport FlowSOMmary\n",
    "    # Inclut: marker_diff, cluster_profiles, grid, mst\n",
    "    # Exclut: UMAP (non demandé)\n",
    "    fs.pl.FlowSOMmary(\n",
    "        fsom,\n",
    "        plot_file=summary_pdf_path\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[OK] Rapport PDF généré avec succès!\")\n",
    "    print(f\"    Fichier: {summary_pdf_path}\")\n",
    "    print(f\"\\n    Contenu du rapport:\")\n",
    "    print(f\"    - Star plots (profils MFI par cluster)\")\n",
    "    print(f\"    - Grid SOM avec metaclusters\")\n",
    "    print(f\"    - Arbre MST avec metaclusters\")\n",
    "    print(f\"    - Heatmap des marqueurs par cluster\")\n",
    "    print(f\"    - Distribution des tailles de clusters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n[!] Erreur lors de la génération du FlowSOMmary:\")\n",
    "    print(f\"    {str(e)}\")\n",
    "    print(f\"\\n    Tentative de génération manuelle des graphiques...\")\n",
    "    \n",
    "    # Alternative: générer les graphiques individuellement\n",
    "    try:\n",
    "        from matplotlib.backends.backend_pdf import PdfPages\n",
    "        \n",
    "        with PdfPages(summary_pdf_path) as pdf:\n",
    "            # 1. Star plots par metacluster\n",
    "            print(\"    - Génération des star plots...\")\n",
    "            fig_stars = fs.pl.plot_stars(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_stars, bbox_inches='tight')\n",
    "            plt.close(fig_stars)\n",
    "            \n",
    "            # 2. Grid SOM\n",
    "            print(\"    - Génération de la grille SOM...\")\n",
    "            fig_grid = fs.pl.plot_grid(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_grid, bbox_inches='tight')\n",
    "            plt.close(fig_grid)\n",
    "            \n",
    "            # 3. Arbre MST\n",
    "            print(\"    - Génération de l'arbre MST...\")\n",
    "            fig_mst = fs.pl.plot_mst(fsom, background_values=fsom.get_cluster_data().obs[\"metaclustering\"])\n",
    "            pdf.savefig(fig_mst, bbox_inches='tight')\n",
    "            plt.close(fig_mst)\n",
    "            \n",
    "            # 4. Marker heatmap\n",
    "            print(\"    - Génération de la heatmap des marqueurs...\")\n",
    "            fig_heatmap = fs.pl.plot_marker_heatmap(fsom)\n",
    "            pdf.savefig(fig_heatmap, bbox_inches='tight')\n",
    "            plt.close(fig_heatmap)\n",
    "            \n",
    "        print(f\"\\n[OK] Rapport PDF alternatif généré!\")\n",
    "        print(f\"    Fichier: {summary_pdf_path}\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"\\n[X] Impossible de générer le rapport: {str(e2)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FIN DE L'ANALYSE FlowSOM\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
